{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d1146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e7e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma MLP simples com 1 camada oculta e tendo como função de ativação a ReLU\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fa = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fa(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cac6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "class Multiclass(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.act = nn.Sigmoid()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0291fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código do Zscore que fiz na lista 02, vou utilizar ele para normalizar os dados\n",
    "class Zscore():\n",
    "    def __init__(self, columnNumber = 2):\n",
    "        self.__means = np.empty(columnNumber)\n",
    "        self.__stds = np.empty(columnNumber)\n",
    "        self.__quantity = 0\n",
    "        \n",
    "    def __setMeans(self, newMeans):\n",
    "        self.__means = newMeans\n",
    "    \n",
    "    def getMeans(self):\n",
    "        return self.__means\n",
    "    \n",
    "    def __setStds(self, newStds):\n",
    "        self.__stds = newStds\n",
    "    \n",
    "    def getStds(self):\n",
    "        return self.__stds\n",
    "    \n",
    "    def __setQuantity(self, newQ):\n",
    "        self.__quantity = newQ\n",
    "    \n",
    "    def getQuantity(self):\n",
    "        return self.__quantity\n",
    "    \n",
    "    def __addValues(self, mu, sigma):\n",
    "        means = self.getMeans()\n",
    "        stds = self.getStds()\n",
    "        quantity = self.getQuantity()\n",
    "        \n",
    "        means[quantity] = mu\n",
    "        stds[quantity] = sigma\n",
    "        \n",
    "        self.__setMeans(means)\n",
    "        self.__setStds(stds)\n",
    "        \n",
    "        self.__setQuantity(quantity + 1)\n",
    "    \n",
    "    def scale(self, data):\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "        #Utiliza a Normalização Z-score, seria o equivalente ao Standard Scaler\n",
    "        #Recebe um conjunto de dados e Retorna o mesmo conjunto de dados normalizado com média 0 e dp 1\n",
    "        dataScaled = np.empty([rows, 0])\n",
    "        for i in range(columns):\n",
    "            #Esse método faz a normalização coluna por coluna, onde i é o número da coluna\n",
    "            dataColumn = data[:, [i]]\n",
    "\n",
    "            #Cálculo da média e desvio-padrão da coluna que vai ser normalizada\n",
    "            mu = np.mean(dataColumn)\n",
    "            sigma = np.std(dataColumn)\n",
    "\n",
    "            columnScaled = (dataColumn - mu)/sigma\n",
    "            #columnScaled = (xi - mu)/sigma\n",
    "            #operação broadcasting para toda a coluna\n",
    "            dataScaled = np.c_[dataScaled, columnScaled]\n",
    "            \n",
    "            self.__addValues(mu, sigma)\n",
    "            #adiciona a coluna no dataset normalizado\n",
    "        #print(dataScaled)\n",
    "        return dataScaled\n",
    "    \n",
    "    def unscale(self, data, column = -1):\n",
    "        # pensando em implementar um atributo dataset original\n",
    "        # mas esse método tem como função principal fazer o \"unscale\" de novos atributos de um dado escalado\n",
    "        # anteriormente, como por exemplo ŷ que é escalado na normal com base nos dados de y\n",
    "        if column == -1:\n",
    "            mu = self.getMeans()\n",
    "            sigma = self.getStds()\n",
    "            \n",
    "        elif column >= self.getQuantity():\n",
    "            print(\"ERRO: Número de Coluna \", column ,\" Inválida.\")\n",
    "            return\n",
    "            \n",
    "        else:\n",
    "            mu = self.getMeans()[column]\n",
    "            sigma = self.getStds()[column]\n",
    "            \n",
    "        return sigma * data + mu\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92afabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_valid(dataset, train_size = 0.6, test_size = 0.2, valid_size = 0.2):\n",
    "    assert train_size + test_size + valid_size == 1.0, \"As proporções de divisão devem somar 1.0\"\n",
    "    total_size = len(dataset)\n",
    "\n",
    "    # Calcular o tamanho de cada conjunto\n",
    "    train_size = int(train_size * total_size)\n",
    "    test_size = int(test_size * total_size)\n",
    "    valid_size = int(valid_size * total_size)\n",
    "\n",
    "    # Embaralhar o dataset\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # Dividir o dataset em train, test e valid usando fatiamento\n",
    "    train = torch.from_numpy(dataset[:train_size]).float()\n",
    "    test = torch.from_numpy(dataset[train_size:train_size + test_size]).float()\n",
    "    valid = torch.from_numpy(dataset[train_size + test_size:train_size + test_size + valid_size]).float()\n",
    "\n",
    "    return train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c56a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.47791487 -0.85688789 -0.84714393 ... -1.21767004 -0.27973311\n",
      "   2.64540763]\n",
      " [ 2.47791487 -0.85688789 -0.84714393 ... -1.21767004 -0.27973311\n",
      "   1.56142148]\n",
      " [ 0.49142531  0.79552649 -0.84714393 ... -2.24091709  3.55306569\n",
      "   0.26662698]\n",
      " ...\n",
      " [-1.27008832  0.75957923  0.85063487 ...  0.0801067  -0.27973311\n",
      "  -0.72572939]\n",
      " [-1.16860982  1.30806485 -0.84714393 ...  0.19116644 -0.27973311\n",
      "  -0.18253855]\n",
      " [-0.19403325  0.30849909  0.3769452  ... -0.15074782 -0.27973311\n",
      "  -0.20469738]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt(\"ama_lista_04/concrete.csv\", delimiter = \",\")\n",
    "\n",
    "dataset = dataset\n",
    "normalizer = Zscore(dataset.shape[1])\n",
    "dataset = normalizer.scale(dataset)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc306fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 8)\n",
      "(990, 1)\n"
     ]
    }
   ],
   "source": [
    "# Definir os hiperparâmetros\n",
    "input_size = 8  # Tamanho da camada de entrada (9 colunas de entrada - 1 coluna de saída)\n",
    "output_size = 1  # Tamanho da camada de saída (regressão)\n",
    "\n",
    "data_train, data_test, data_valid = split_train_test_valid(dataset)\n",
    "\n",
    "x_train = data_train[:, :8]\n",
    "x_test = data_test[:, :8]\n",
    "x_valid = data_valid[:, :8]\n",
    "\n",
    "y_train = data_train[:, 8]\n",
    "y_test = data_test[:, 8]\n",
    "y_valid = data_valid[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2d3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros\n",
    "hidden_sizes = [32, 64, 128]\n",
    "learning_rates = [0.001,0.01] \n",
    "momentum_values = [0.5, 0.7, 0.9]\n",
    "weight_decays = [0.005, 0]\n",
    "#\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b9c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss=1.110596, Validation Loss=0.901508\n",
      "Epoch 1 Training Loss=1.093800, Validation Loss=0.899197\n",
      "Epoch 2 Training Loss=1.080588, Validation Loss=0.898269\n",
      "Epoch 3 Training Loss=1.070168, Validation Loss=0.898290\n",
      "Epoch 4 Training Loss=1.061891, Validation Loss=0.898950\n",
      "Epoch 5 Training Loss=1.055270, Validation Loss=0.900027\n",
      "Epoch 6 Training Loss=1.049938, Validation Loss=0.901363\n",
      "Epoch 7 Training Loss=1.045613, Validation Loss=0.902846\n",
      "Epoch 8 Training Loss=1.042081, Validation Loss=0.904395\n",
      "Epoch 9 Training Loss=1.039176, Validation Loss=0.905957\n",
      "Epoch 10 Training Loss=1.036769, Validation Loss=0.907494\n",
      "Epoch 11 Training Loss=1.034759, Validation Loss=0.908981\n",
      "Epoch 12 Training Loss=1.033068, Validation Loss=0.910403\n",
      "Epoch 13 Training Loss=1.031634, Validation Loss=0.911751\n",
      "Epoch 14 Training Loss=1.030408, Validation Loss=0.913022\n",
      "Epoch 15 Training Loss=1.029351, Validation Loss=0.914214\n",
      "Epoch 16 Training Loss=1.028433, Validation Loss=0.915330\n",
      "Epoch 17 Training Loss=1.027630, Validation Loss=0.916371\n",
      "Epoch 18 Training Loss=1.026921, Validation Loss=0.917343\n",
      "Epoch 19 Training Loss=1.026292, Validation Loss=0.918250\n",
      "Epoch 20 Training Loss=1.025728, Validation Loss=0.919097\n",
      "Epoch 21 Training Loss=1.025221, Validation Loss=0.919888\n",
      "Epoch 22 Training Loss=1.024761, Validation Loss=0.920628\n",
      "Epoch 23 Training Loss=1.024342, Validation Loss=0.921323\n",
      "Epoch 24 Training Loss=1.023958, Validation Loss=0.921974\n",
      "Epoch 25 Training Loss=1.023604, Validation Loss=0.922588\n",
      "Epoch 26 Training Loss=1.023277, Validation Loss=0.923168\n",
      "Epoch 27 Training Loss=1.022974, Validation Loss=0.923716\n",
      "Epoch 28 Training Loss=1.022691, Validation Loss=0.924237\n",
      "Epoch 29 Training Loss=1.022426, Validation Loss=0.924732\n",
      "Epoch 30 Training Loss=1.022178, Validation Loss=0.925204\n",
      "Epoch 31 Training Loss=1.021944, Validation Loss=0.925656\n",
      "Epoch 32 Training Loss=1.021724, Validation Loss=0.926090\n",
      "Epoch 33 Training Loss=1.021516, Validation Loss=0.926507\n",
      "Epoch 34 Training Loss=1.021319, Validation Loss=0.926909\n",
      "Epoch 35 Training Loss=1.021132, Validation Loss=0.927298\n",
      "Epoch 36 Training Loss=1.020954, Validation Loss=0.927674\n",
      "Epoch 37 Training Loss=1.020785, Validation Loss=0.928040\n",
      "Epoch 38 Training Loss=1.020623, Validation Loss=0.928395\n",
      "Epoch 39 Training Loss=1.020469, Validation Loss=0.928741\n",
      "Epoch 40 Training Loss=1.020321, Validation Loss=0.929078\n",
      "Epoch 41 Training Loss=1.020180, Validation Loss=0.929408\n",
      "Epoch 42 Training Loss=1.020045, Validation Loss=0.929731\n",
      "Epoch 43 Training Loss=1.019915, Validation Loss=0.930048\n",
      "Epoch 44 Training Loss=1.019790, Validation Loss=0.930358\n",
      "Epoch 45 Training Loss=1.019670, Validation Loss=0.930663\n",
      "Epoch 46 Training Loss=1.019554, Validation Loss=0.930963\n",
      "Epoch 47 Training Loss=1.019442, Validation Loss=0.931257\n",
      "Epoch 48 Training Loss=1.019335, Validation Loss=0.931548\n",
      "Epoch 49 Training Loss=1.019231, Validation Loss=0.931834\n",
      "Epoch 50 Training Loss=1.019131, Validation Loss=0.932115\n",
      "Epoch 51 Training Loss=1.019033, Validation Loss=0.932394\n",
      "Epoch 52 Training Loss=1.018939, Validation Loss=0.932668\n",
      "Epoch 53 Training Loss=1.018848, Validation Loss=0.932939\n",
      "Epoch 54 Training Loss=1.018760, Validation Loss=0.933206\n",
      "Epoch 55 Training Loss=1.018674, Validation Loss=0.933471\n",
      "Epoch 56 Training Loss=1.018591, Validation Loss=0.933732\n",
      "Epoch 57 Training Loss=1.018510, Validation Loss=0.933991\n",
      "Epoch 58 Training Loss=1.018431, Validation Loss=0.934246\n",
      "Epoch 59 Training Loss=1.018354, Validation Loss=0.934499\n",
      "Epoch 60 Training Loss=1.018280, Validation Loss=0.934749\n",
      "Epoch 61 Training Loss=1.018207, Validation Loss=0.934996\n",
      "Epoch 62 Training Loss=1.018136, Validation Loss=0.935241\n",
      "Epoch 63 Training Loss=1.018066, Validation Loss=0.935483\n",
      "Epoch 64 Training Loss=1.017999, Validation Loss=0.935722\n",
      "Epoch 65 Training Loss=1.017933, Validation Loss=0.935959\n",
      "Epoch 66 Training Loss=1.017868, Validation Loss=0.936194\n",
      "Epoch 67 Training Loss=1.017805, Validation Loss=0.936427\n",
      "Epoch 68 Training Loss=1.017743, Validation Loss=0.936657\n",
      "Epoch 69 Training Loss=1.017682, Validation Loss=0.936885\n",
      "Epoch 70 Training Loss=1.017622, Validation Loss=0.937111\n",
      "Epoch 71 Training Loss=1.017564, Validation Loss=0.937334\n",
      "Epoch 72 Training Loss=1.017507, Validation Loss=0.937556\n",
      "Epoch 73 Training Loss=1.017451, Validation Loss=0.937775\n",
      "Epoch 74 Training Loss=1.017396, Validation Loss=0.937992\n",
      "Epoch 75 Training Loss=1.017341, Validation Loss=0.938207\n",
      "Epoch 76 Training Loss=1.017288, Validation Loss=0.938420\n",
      "Epoch 77 Training Loss=1.017236, Validation Loss=0.938631\n",
      "Epoch 78 Training Loss=1.017184, Validation Loss=0.938840\n",
      "Epoch 79 Training Loss=1.017134, Validation Loss=0.939047\n",
      "Epoch 80 Training Loss=1.017084, Validation Loss=0.939253\n",
      "Epoch 81 Training Loss=1.017035, Validation Loss=0.939456\n",
      "Epoch 82 Training Loss=1.016986, Validation Loss=0.939657\n",
      "Epoch 83 Training Loss=1.016938, Validation Loss=0.939857\n",
      "Epoch 84 Training Loss=1.016891, Validation Loss=0.940055\n",
      "Epoch 85 Training Loss=1.016845, Validation Loss=0.940251\n",
      "Epoch 86 Training Loss=1.016799, Validation Loss=0.940445\n",
      "Epoch 87 Training Loss=1.016754, Validation Loss=0.940637\n",
      "Epoch 88 Training Loss=1.016710, Validation Loss=0.940828\n",
      "Epoch 89 Training Loss=1.016666, Validation Loss=0.941017\n",
      "Epoch 90 Training Loss=1.016622, Validation Loss=0.941205\n",
      "Epoch 91 Training Loss=1.016579, Validation Loss=0.941390\n",
      "Epoch 92 Training Loss=1.016537, Validation Loss=0.941574\n",
      "Epoch 93 Training Loss=1.016495, Validation Loss=0.941757\n",
      "Epoch 94 Training Loss=1.016453, Validation Loss=0.941937\n",
      "Epoch 95 Training Loss=1.016412, Validation Loss=0.942116\n",
      "Epoch 96 Training Loss=1.016372, Validation Loss=0.942294\n",
      "Epoch 97 Training Loss=1.016332, Validation Loss=0.942470\n",
      "Epoch 98 Training Loss=1.016292, Validation Loss=0.942645\n",
      "Epoch 99 Training Loss=1.016253, Validation Loss=0.942818\n",
      "Epoch 100 Training Loss=1.016214, Validation Loss=0.942990\n",
      "Epoch 101 Training Loss=1.016175, Validation Loss=0.943160\n",
      "Epoch 102 Training Loss=1.016137, Validation Loss=0.943329\n",
      "Epoch 103 Training Loss=1.016099, Validation Loss=0.943496\n",
      "Epoch 104 Training Loss=1.016062, Validation Loss=0.943662\n",
      "Epoch 105 Training Loss=1.016025, Validation Loss=0.943826\n",
      "Epoch 106 Training Loss=1.015988, Validation Loss=0.943990\n",
      "Epoch 107 Training Loss=1.015951, Validation Loss=0.944151\n",
      "Epoch 108 Training Loss=1.015915, Validation Loss=0.944312\n",
      "Epoch 109 Training Loss=1.015879, Validation Loss=0.944471\n",
      "Epoch 110 Training Loss=1.015844, Validation Loss=0.944629\n",
      "Epoch 111 Training Loss=1.015808, Validation Loss=0.944786\n",
      "Epoch 112 Training Loss=1.015773, Validation Loss=0.944941\n",
      "Epoch 113 Training Loss=1.015739, Validation Loss=0.945095\n",
      "Epoch 114 Training Loss=1.015704, Validation Loss=0.945248\n",
      "Epoch 115 Training Loss=1.015670, Validation Loss=0.945400\n",
      "Epoch 116 Training Loss=1.015636, Validation Loss=0.945550\n",
      "Epoch 117 Training Loss=1.015602, Validation Loss=0.945700\n",
      "Epoch 118 Training Loss=1.015569, Validation Loss=0.945848\n",
      "Epoch 119 Training Loss=1.015535, Validation Loss=0.945995\n",
      "Epoch 120 Training Loss=1.015502, Validation Loss=0.946141\n",
      "Epoch 121 Training Loss=1.015470, Validation Loss=0.946285\n",
      "Epoch 122 Training Loss=1.015437, Validation Loss=0.946429\n",
      "Epoch 123 Training Loss=1.015405, Validation Loss=0.946572\n",
      "Epoch 124 Training Loss=1.015372, Validation Loss=0.946713\n",
      "Epoch 125 Training Loss=1.015340, Validation Loss=0.946854\n",
      "Epoch 126 Training Loss=1.015309, Validation Loss=0.946993\n",
      "Epoch 127 Training Loss=1.015277, Validation Loss=0.947132\n",
      "Epoch 128 Training Loss=1.015246, Validation Loss=0.947269\n",
      "Epoch 129 Training Loss=1.015215, Validation Loss=0.947405\n",
      "Epoch 130 Training Loss=1.015184, Validation Loss=0.947541\n",
      "Epoch 131 Training Loss=1.015153, Validation Loss=0.947675\n",
      "Epoch 132 Training Loss=1.015122, Validation Loss=0.947808\n",
      "Epoch 133 Training Loss=1.015092, Validation Loss=0.947941\n",
      "Epoch 134 Training Loss=1.015061, Validation Loss=0.948072\n",
      "Epoch 135 Training Loss=1.015031, Validation Loss=0.948203\n",
      "Epoch 136 Training Loss=1.015001, Validation Loss=0.948333\n",
      "Epoch 137 Training Loss=1.014971, Validation Loss=0.948462\n",
      "Epoch 138 Training Loss=1.014942, Validation Loss=0.948589\n",
      "Epoch 139 Training Loss=1.014912, Validation Loss=0.948716\n",
      "Epoch 140 Training Loss=1.014883, Validation Loss=0.948843\n",
      "Epoch 141 Training Loss=1.014853, Validation Loss=0.948968\n",
      "Epoch 142 Training Loss=1.014824, Validation Loss=0.949092\n",
      "Epoch 143 Training Loss=1.014795, Validation Loss=0.949216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Training Loss=1.014766, Validation Loss=0.949339\n",
      "Epoch 145 Training Loss=1.014738, Validation Loss=0.949461\n",
      "Epoch 146 Training Loss=1.014709, Validation Loss=0.949582\n",
      "Epoch 147 Training Loss=1.014681, Validation Loss=0.949702\n",
      "Epoch 148 Training Loss=1.014652, Validation Loss=0.949822\n",
      "Epoch 149 Training Loss=1.014624, Validation Loss=0.949941\n",
      "Epoch 150 Training Loss=1.014596, Validation Loss=0.950059\n",
      "Epoch 151 Training Loss=1.014568, Validation Loss=0.950176\n",
      "Epoch 152 Training Loss=1.014540, Validation Loss=0.950292\n",
      "Epoch 153 Training Loss=1.014513, Validation Loss=0.950408\n",
      "Epoch 154 Training Loss=1.014485, Validation Loss=0.950523\n",
      "Epoch 155 Training Loss=1.014458, Validation Loss=0.950638\n",
      "Epoch 156 Training Loss=1.014430, Validation Loss=0.950751\n",
      "Epoch 157 Training Loss=1.014403, Validation Loss=0.950864\n",
      "Epoch 158 Training Loss=1.014376, Validation Loss=0.950976\n",
      "Epoch 159 Training Loss=1.014349, Validation Loss=0.951088\n",
      "Epoch 160 Training Loss=1.014322, Validation Loss=0.951199\n",
      "Epoch 161 Training Loss=1.014295, Validation Loss=0.951309\n",
      "Epoch 162 Training Loss=1.014268, Validation Loss=0.951419\n",
      "Epoch 163 Training Loss=1.014241, Validation Loss=0.951527\n",
      "Epoch 164 Training Loss=1.014215, Validation Loss=0.951636\n",
      "Epoch 165 Training Loss=1.014188, Validation Loss=0.951743\n",
      "Epoch 166 Training Loss=1.014162, Validation Loss=0.951850\n",
      "Epoch 167 Training Loss=1.014136, Validation Loss=0.951957\n",
      "Epoch 168 Training Loss=1.014109, Validation Loss=0.952062\n",
      "Epoch 169 Training Loss=1.014083, Validation Loss=0.952168\n",
      "Epoch 170 Training Loss=1.014057, Validation Loss=0.952272\n",
      "Epoch 171 Training Loss=1.014031, Validation Loss=0.952376\n",
      "Epoch 172 Training Loss=1.014005, Validation Loss=0.952480\n",
      "Epoch 173 Training Loss=1.013979, Validation Loss=0.952582\n",
      "Epoch 174 Training Loss=1.013954, Validation Loss=0.952685\n",
      "Epoch 175 Training Loss=1.013928, Validation Loss=0.952786\n",
      "Epoch 176 Training Loss=1.013903, Validation Loss=0.952887\n",
      "Epoch 177 Training Loss=1.013877, Validation Loss=0.952988\n",
      "Epoch 178 Training Loss=1.013852, Validation Loss=0.953088\n",
      "Epoch 179 Training Loss=1.013826, Validation Loss=0.953188\n",
      "Epoch 180 Training Loss=1.013801, Validation Loss=0.953287\n",
      "Epoch 181 Training Loss=1.013776, Validation Loss=0.953385\n",
      "Epoch 182 Training Loss=1.013751, Validation Loss=0.953483\n",
      "Epoch 183 Training Loss=1.013726, Validation Loss=0.953580\n",
      "Epoch 184 Training Loss=1.013701, Validation Loss=0.953677\n",
      "Epoch 185 Training Loss=1.013676, Validation Loss=0.953774\n",
      "Epoch 186 Training Loss=1.013651, Validation Loss=0.953870\n",
      "Epoch 187 Training Loss=1.013626, Validation Loss=0.953965\n",
      "Epoch 188 Training Loss=1.013601, Validation Loss=0.954060\n",
      "Epoch 189 Training Loss=1.013577, Validation Loss=0.954155\n",
      "Epoch 190 Training Loss=1.013552, Validation Loss=0.954249\n",
      "Epoch 191 Training Loss=1.013528, Validation Loss=0.954342\n",
      "Epoch 192 Training Loss=1.013503, Validation Loss=0.954435\n",
      "Epoch 193 Training Loss=1.013479, Validation Loss=0.954528\n",
      "Epoch 194 Training Loss=1.013454, Validation Loss=0.954620\n",
      "Epoch 195 Training Loss=1.013430, Validation Loss=0.954712\n",
      "Epoch 196 Training Loss=1.013406, Validation Loss=0.954803\n",
      "Epoch 197 Training Loss=1.013382, Validation Loss=0.954894\n",
      "Epoch 198 Training Loss=1.013357, Validation Loss=0.954984\n",
      "Epoch 199 Training Loss=1.013333, Validation Loss=0.955074\n",
      "Epoch 0 Training Loss=1.033348, Validation Loss=0.950641\n",
      "Epoch 1 Training Loss=1.030801, Validation Loss=0.950089\n",
      "Epoch 2 Training Loss=1.028668, Validation Loss=0.949622\n",
      "Epoch 3 Training Loss=1.026900, Validation Loss=0.949219\n",
      "Epoch 4 Training Loss=1.025427, Validation Loss=0.948863\n",
      "Epoch 5 Training Loss=1.024192, Validation Loss=0.948547\n",
      "Epoch 6 Training Loss=1.023154, Validation Loss=0.948263\n",
      "Epoch 7 Training Loss=1.022276, Validation Loss=0.948006\n",
      "Epoch 8 Training Loss=1.021532, Validation Loss=0.947775\n",
      "Epoch 9 Training Loss=1.020898, Validation Loss=0.947566\n",
      "Epoch 10 Training Loss=1.020356, Validation Loss=0.947377\n",
      "Epoch 11 Training Loss=1.019891, Validation Loss=0.947208\n",
      "Epoch 12 Training Loss=1.019491, Validation Loss=0.947057\n",
      "Epoch 13 Training Loss=1.019145, Validation Loss=0.946923\n",
      "Epoch 14 Training Loss=1.018845, Validation Loss=0.946805\n",
      "Epoch 15 Training Loss=1.018584, Validation Loss=0.946703\n",
      "Epoch 16 Training Loss=1.018356, Validation Loss=0.946615\n",
      "Epoch 17 Training Loss=1.018156, Validation Loss=0.946541\n",
      "Epoch 18 Training Loss=1.017980, Validation Loss=0.946479\n",
      "Epoch 19 Training Loss=1.017824, Validation Loss=0.946430\n",
      "Epoch 20 Training Loss=1.017685, Validation Loss=0.946393\n",
      "Epoch 21 Training Loss=1.017561, Validation Loss=0.946366\n",
      "Epoch 22 Training Loss=1.017449, Validation Loss=0.946349\n",
      "Epoch 23 Training Loss=1.017348, Validation Loss=0.946341\n",
      "Epoch 24 Training Loss=1.017257, Validation Loss=0.946342\n",
      "Epoch 25 Training Loss=1.017172, Validation Loss=0.946352\n",
      "Epoch 26 Training Loss=1.017095, Validation Loss=0.946368\n",
      "Epoch 27 Training Loss=1.017023, Validation Loss=0.946393\n",
      "Epoch 28 Training Loss=1.016957, Validation Loss=0.946423\n",
      "Epoch 29 Training Loss=1.016894, Validation Loss=0.946460\n",
      "Epoch 30 Training Loss=1.016835, Validation Loss=0.946502\n",
      "Epoch 31 Training Loss=1.016779, Validation Loss=0.946549\n",
      "Epoch 32 Training Loss=1.016725, Validation Loss=0.946602\n",
      "Epoch 33 Training Loss=1.016674, Validation Loss=0.946659\n",
      "Epoch 34 Training Loss=1.016625, Validation Loss=0.946720\n",
      "Epoch 35 Training Loss=1.016577, Validation Loss=0.946785\n",
      "Epoch 36 Training Loss=1.016531, Validation Loss=0.946853\n",
      "Epoch 37 Training Loss=1.016486, Validation Loss=0.946925\n",
      "Epoch 38 Training Loss=1.016442, Validation Loss=0.946999\n",
      "Epoch 39 Training Loss=1.016399, Validation Loss=0.947076\n",
      "Epoch 40 Training Loss=1.016357, Validation Loss=0.947156\n",
      "Epoch 41 Training Loss=1.016315, Validation Loss=0.947238\n",
      "Epoch 42 Training Loss=1.016274, Validation Loss=0.947323\n",
      "Epoch 43 Training Loss=1.016233, Validation Loss=0.947409\n",
      "Epoch 44 Training Loss=1.016193, Validation Loss=0.947497\n",
      "Epoch 45 Training Loss=1.016153, Validation Loss=0.947586\n",
      "Epoch 46 Training Loss=1.016114, Validation Loss=0.947677\n",
      "Epoch 47 Training Loss=1.016074, Validation Loss=0.947770\n",
      "Epoch 48 Training Loss=1.016035, Validation Loss=0.947863\n",
      "Epoch 49 Training Loss=1.015997, Validation Loss=0.947958\n",
      "Epoch 50 Training Loss=1.015958, Validation Loss=0.948053\n",
      "Epoch 51 Training Loss=1.015919, Validation Loss=0.948150\n",
      "Epoch 52 Training Loss=1.015881, Validation Loss=0.948247\n",
      "Epoch 53 Training Loss=1.015843, Validation Loss=0.948345\n",
      "Epoch 54 Training Loss=1.015805, Validation Loss=0.948443\n",
      "Epoch 55 Training Loss=1.015767, Validation Loss=0.948542\n",
      "Epoch 56 Training Loss=1.015729, Validation Loss=0.948641\n",
      "Epoch 57 Training Loss=1.015691, Validation Loss=0.948741\n",
      "Epoch 58 Training Loss=1.015653, Validation Loss=0.948841\n",
      "Epoch 59 Training Loss=1.015615, Validation Loss=0.948942\n",
      "Epoch 60 Training Loss=1.015578, Validation Loss=0.949042\n",
      "Epoch 61 Training Loss=1.015540, Validation Loss=0.949143\n",
      "Epoch 62 Training Loss=1.015503, Validation Loss=0.949244\n",
      "Epoch 63 Training Loss=1.015465, Validation Loss=0.949345\n",
      "Epoch 64 Training Loss=1.015428, Validation Loss=0.949446\n",
      "Epoch 65 Training Loss=1.015390, Validation Loss=0.949547\n",
      "Epoch 66 Training Loss=1.015353, Validation Loss=0.949648\n",
      "Epoch 67 Training Loss=1.015316, Validation Loss=0.949749\n",
      "Epoch 68 Training Loss=1.015279, Validation Loss=0.949850\n",
      "Epoch 69 Training Loss=1.015242, Validation Loss=0.949951\n",
      "Epoch 70 Training Loss=1.015204, Validation Loss=0.950052\n",
      "Epoch 71 Training Loss=1.015167, Validation Loss=0.950153\n",
      "Epoch 72 Training Loss=1.015130, Validation Loss=0.950253\n",
      "Epoch 73 Training Loss=1.015094, Validation Loss=0.950353\n",
      "Epoch 74 Training Loss=1.015057, Validation Loss=0.950453\n",
      "Epoch 75 Training Loss=1.015020, Validation Loss=0.950553\n",
      "Epoch 76 Training Loss=1.014983, Validation Loss=0.950653\n",
      "Epoch 77 Training Loss=1.014946, Validation Loss=0.950752\n",
      "Epoch 78 Training Loss=1.014910, Validation Loss=0.950851\n",
      "Epoch 79 Training Loss=1.014873, Validation Loss=0.950950\n",
      "Epoch 80 Training Loss=1.014837, Validation Loss=0.951049\n",
      "Epoch 81 Training Loss=1.014800, Validation Loss=0.951147\n",
      "Epoch 82 Training Loss=1.014764, Validation Loss=0.951245\n",
      "Epoch 83 Training Loss=1.014727, Validation Loss=0.951343\n",
      "Epoch 84 Training Loss=1.014691, Validation Loss=0.951440\n",
      "Epoch 85 Training Loss=1.014655, Validation Loss=0.951537\n",
      "Epoch 86 Training Loss=1.014619, Validation Loss=0.951634\n",
      "Epoch 87 Training Loss=1.014583, Validation Loss=0.951730\n",
      "Epoch 88 Training Loss=1.014547, Validation Loss=0.951827\n",
      "Epoch 89 Training Loss=1.014510, Validation Loss=0.951922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Training Loss=1.014475, Validation Loss=0.952018\n",
      "Epoch 91 Training Loss=1.014439, Validation Loss=0.952113\n",
      "Epoch 92 Training Loss=1.014403, Validation Loss=0.952208\n",
      "Epoch 93 Training Loss=1.014367, Validation Loss=0.952302\n",
      "Epoch 94 Training Loss=1.014331, Validation Loss=0.952396\n",
      "Epoch 95 Training Loss=1.014296, Validation Loss=0.952490\n",
      "Epoch 96 Training Loss=1.014260, Validation Loss=0.952584\n",
      "Epoch 97 Training Loss=1.014224, Validation Loss=0.952677\n",
      "Epoch 98 Training Loss=1.014189, Validation Loss=0.952770\n",
      "Epoch 99 Training Loss=1.014153, Validation Loss=0.952862\n",
      "Epoch 100 Training Loss=1.014118, Validation Loss=0.952954\n",
      "Epoch 101 Training Loss=1.014083, Validation Loss=0.953046\n",
      "Epoch 102 Training Loss=1.014047, Validation Loss=0.953138\n",
      "Epoch 103 Training Loss=1.014012, Validation Loss=0.953229\n",
      "Epoch 104 Training Loss=1.013977, Validation Loss=0.953319\n",
      "Epoch 105 Training Loss=1.013942, Validation Loss=0.953410\n",
      "Epoch 106 Training Loss=1.013907, Validation Loss=0.953500\n",
      "Epoch 107 Training Loss=1.013872, Validation Loss=0.953590\n",
      "Epoch 108 Training Loss=1.013837, Validation Loss=0.953679\n",
      "Epoch 109 Training Loss=1.013802, Validation Loss=0.953768\n",
      "Epoch 110 Training Loss=1.013767, Validation Loss=0.953857\n",
      "Epoch 111 Training Loss=1.013732, Validation Loss=0.953946\n",
      "Epoch 112 Training Loss=1.013697, Validation Loss=0.954034\n",
      "Epoch 113 Training Loss=1.013662, Validation Loss=0.954122\n",
      "Epoch 114 Training Loss=1.013628, Validation Loss=0.954209\n",
      "Epoch 115 Training Loss=1.013593, Validation Loss=0.954296\n",
      "Epoch 116 Training Loss=1.013558, Validation Loss=0.954383\n",
      "Epoch 117 Training Loss=1.013524, Validation Loss=0.954470\n",
      "Epoch 118 Training Loss=1.013489, Validation Loss=0.954556\n",
      "Epoch 119 Training Loss=1.013455, Validation Loss=0.954642\n",
      "Epoch 120 Training Loss=1.013421, Validation Loss=0.954727\n",
      "Epoch 121 Training Loss=1.013386, Validation Loss=0.954813\n",
      "Epoch 122 Training Loss=1.013352, Validation Loss=0.954898\n",
      "Epoch 123 Training Loss=1.013318, Validation Loss=0.954983\n",
      "Epoch 124 Training Loss=1.013283, Validation Loss=0.955067\n",
      "Epoch 125 Training Loss=1.013249, Validation Loss=0.955151\n",
      "Epoch 126 Training Loss=1.013215, Validation Loss=0.955235\n",
      "Epoch 127 Training Loss=1.013181, Validation Loss=0.955319\n",
      "Epoch 128 Training Loss=1.013147, Validation Loss=0.955402\n",
      "Epoch 129 Training Loss=1.013113, Validation Loss=0.955485\n",
      "Epoch 130 Training Loss=1.013079, Validation Loss=0.955568\n",
      "Epoch 131 Training Loss=1.013045, Validation Loss=0.955650\n",
      "Epoch 132 Training Loss=1.013011, Validation Loss=0.955732\n",
      "Epoch 133 Training Loss=1.012977, Validation Loss=0.955814\n",
      "Epoch 134 Training Loss=1.012943, Validation Loss=0.955896\n",
      "Epoch 135 Training Loss=1.012910, Validation Loss=0.955977\n",
      "Epoch 136 Training Loss=1.012876, Validation Loss=0.956058\n",
      "Epoch 137 Training Loss=1.012842, Validation Loss=0.956139\n",
      "Epoch 138 Training Loss=1.012808, Validation Loss=0.956220\n",
      "Epoch 139 Training Loss=1.012775, Validation Loss=0.956300\n",
      "Epoch 140 Training Loss=1.012741, Validation Loss=0.956380\n",
      "Epoch 141 Training Loss=1.012708, Validation Loss=0.956460\n",
      "Epoch 142 Training Loss=1.012674, Validation Loss=0.956539\n",
      "Epoch 143 Training Loss=1.012641, Validation Loss=0.956619\n",
      "Epoch 144 Training Loss=1.012607, Validation Loss=0.956698\n",
      "Epoch 145 Training Loss=1.012574, Validation Loss=0.956776\n",
      "Epoch 146 Training Loss=1.012540, Validation Loss=0.956855\n",
      "Epoch 147 Training Loss=1.012507, Validation Loss=0.956933\n",
      "Epoch 148 Training Loss=1.012474, Validation Loss=0.957011\n",
      "Epoch 149 Training Loss=1.012440, Validation Loss=0.957089\n",
      "Epoch 150 Training Loss=1.012407, Validation Loss=0.957167\n",
      "Epoch 151 Training Loss=1.012374, Validation Loss=0.957244\n",
      "Epoch 152 Training Loss=1.012340, Validation Loss=0.957322\n",
      "Epoch 153 Training Loss=1.012307, Validation Loss=0.957398\n",
      "Epoch 154 Training Loss=1.012274, Validation Loss=0.957475\n",
      "Epoch 155 Training Loss=1.012241, Validation Loss=0.957552\n",
      "Epoch 156 Training Loss=1.012208, Validation Loss=0.957628\n",
      "Epoch 157 Training Loss=1.012175, Validation Loss=0.957704\n",
      "Epoch 158 Training Loss=1.012142, Validation Loss=0.957780\n",
      "Epoch 159 Training Loss=1.012109, Validation Loss=0.957856\n",
      "Epoch 160 Training Loss=1.012076, Validation Loss=0.957931\n",
      "Epoch 161 Training Loss=1.012043, Validation Loss=0.958007\n",
      "Epoch 162 Training Loss=1.012010, Validation Loss=0.958082\n",
      "Epoch 163 Training Loss=1.011977, Validation Loss=0.958156\n",
      "Epoch 164 Training Loss=1.011944, Validation Loss=0.958231\n",
      "Epoch 165 Training Loss=1.011911, Validation Loss=0.958305\n",
      "Epoch 166 Training Loss=1.011878, Validation Loss=0.958380\n",
      "Epoch 167 Training Loss=1.011845, Validation Loss=0.958454\n",
      "Epoch 168 Training Loss=1.011813, Validation Loss=0.958528\n",
      "Epoch 169 Training Loss=1.011780, Validation Loss=0.958601\n",
      "Epoch 170 Training Loss=1.011747, Validation Loss=0.958675\n",
      "Epoch 171 Training Loss=1.011714, Validation Loss=0.958748\n",
      "Epoch 172 Training Loss=1.011682, Validation Loss=0.958821\n",
      "Epoch 173 Training Loss=1.011649, Validation Loss=0.958894\n",
      "Epoch 174 Training Loss=1.011616, Validation Loss=0.958967\n",
      "Epoch 175 Training Loss=1.011584, Validation Loss=0.959040\n",
      "Epoch 176 Training Loss=1.011551, Validation Loss=0.959112\n",
      "Epoch 177 Training Loss=1.011518, Validation Loss=0.959185\n",
      "Epoch 178 Training Loss=1.011486, Validation Loss=0.959257\n",
      "Epoch 179 Training Loss=1.011453, Validation Loss=0.959329\n",
      "Epoch 180 Training Loss=1.011421, Validation Loss=0.959400\n",
      "Epoch 181 Training Loss=1.011388, Validation Loss=0.959472\n",
      "Epoch 182 Training Loss=1.011355, Validation Loss=0.959543\n",
      "Epoch 183 Training Loss=1.011323, Validation Loss=0.959615\n",
      "Epoch 184 Training Loss=1.011290, Validation Loss=0.959686\n",
      "Epoch 185 Training Loss=1.011258, Validation Loss=0.959757\n",
      "Epoch 186 Training Loss=1.011225, Validation Loss=0.959828\n",
      "Epoch 187 Training Loss=1.011193, Validation Loss=0.959898\n",
      "Epoch 188 Training Loss=1.011160, Validation Loss=0.959969\n",
      "Epoch 189 Training Loss=1.011128, Validation Loss=0.960039\n",
      "Epoch 190 Training Loss=1.011096, Validation Loss=0.960109\n",
      "Epoch 191 Training Loss=1.011063, Validation Loss=0.960179\n",
      "Epoch 192 Training Loss=1.011031, Validation Loss=0.960249\n",
      "Epoch 193 Training Loss=1.010998, Validation Loss=0.960319\n",
      "Epoch 194 Training Loss=1.010966, Validation Loss=0.960389\n",
      "Epoch 195 Training Loss=1.010934, Validation Loss=0.960458\n",
      "Epoch 196 Training Loss=1.010901, Validation Loss=0.960528\n",
      "Epoch 197 Training Loss=1.010869, Validation Loss=0.960597\n",
      "Epoch 198 Training Loss=1.010837, Validation Loss=0.960666\n",
      "Epoch 199 Training Loss=1.010804, Validation Loss=0.960735\n",
      "Epoch 0 Training Loss=1.066488, Validation Loss=0.979688\n",
      "Epoch 1 Training Loss=1.053014, Validation Loss=0.972850\n",
      "Epoch 2 Training Loss=1.043916, Validation Loss=0.968388\n",
      "Epoch 3 Training Loss=1.037663, Validation Loss=0.965327\n",
      "Epoch 4 Training Loss=1.033248, Validation Loss=0.963102\n",
      "Epoch 5 Training Loss=1.030046, Validation Loss=0.961389\n",
      "Epoch 6 Training Loss=1.027662, Validation Loss=0.959999\n",
      "Epoch 7 Training Loss=1.025842, Validation Loss=0.958826\n",
      "Epoch 8 Training Loss=1.024420, Validation Loss=0.957807\n",
      "Epoch 9 Training Loss=1.023288, Validation Loss=0.956908\n",
      "Epoch 10 Training Loss=1.022369, Validation Loss=0.956108\n",
      "Epoch 11 Training Loss=1.021614, Validation Loss=0.955395\n",
      "Epoch 12 Training Loss=1.020985, Validation Loss=0.954761\n",
      "Epoch 13 Training Loss=1.020455, Validation Loss=0.954198\n",
      "Epoch 14 Training Loss=1.020005, Validation Loss=0.953702\n",
      "Epoch 15 Training Loss=1.019619, Validation Loss=0.953269\n",
      "Epoch 16 Training Loss=1.019287, Validation Loss=0.952893\n",
      "Epoch 17 Training Loss=1.018998, Validation Loss=0.952571\n",
      "Epoch 18 Training Loss=1.018747, Validation Loss=0.952297\n",
      "Epoch 19 Training Loss=1.018525, Validation Loss=0.952068\n",
      "Epoch 20 Training Loss=1.018330, Validation Loss=0.951880\n",
      "Epoch 21 Training Loss=1.018156, Validation Loss=0.951729\n",
      "Epoch 22 Training Loss=1.018001, Validation Loss=0.951612\n",
      "Epoch 23 Training Loss=1.017861, Validation Loss=0.951524\n",
      "Epoch 24 Training Loss=1.017734, Validation Loss=0.951464\n",
      "Epoch 25 Training Loss=1.017618, Validation Loss=0.951427\n",
      "Epoch 26 Training Loss=1.017512, Validation Loss=0.951412\n",
      "Epoch 27 Training Loss=1.017414, Validation Loss=0.951417\n",
      "Epoch 28 Training Loss=1.017323, Validation Loss=0.951439\n",
      "Epoch 29 Training Loss=1.017238, Validation Loss=0.951475\n",
      "Epoch 30 Training Loss=1.017158, Validation Loss=0.951525\n",
      "Epoch 31 Training Loss=1.017083, Validation Loss=0.951587\n",
      "Epoch 32 Training Loss=1.017011, Validation Loss=0.951659\n",
      "Epoch 33 Training Loss=1.016942, Validation Loss=0.951740\n",
      "Epoch 34 Training Loss=1.016876, Validation Loss=0.951829\n",
      "Epoch 35 Training Loss=1.016813, Validation Loss=0.951925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training Loss=1.016752, Validation Loss=0.952027\n",
      "Epoch 37 Training Loss=1.016692, Validation Loss=0.952134\n",
      "Epoch 38 Training Loss=1.016634, Validation Loss=0.952246\n",
      "Epoch 39 Training Loss=1.016577, Validation Loss=0.952361\n",
      "Epoch 40 Training Loss=1.016522, Validation Loss=0.952479\n",
      "Epoch 41 Training Loss=1.016467, Validation Loss=0.952600\n",
      "Epoch 42 Training Loss=1.016414, Validation Loss=0.952723\n",
      "Epoch 43 Training Loss=1.016361, Validation Loss=0.952848\n",
      "Epoch 44 Training Loss=1.016310, Validation Loss=0.952974\n",
      "Epoch 45 Training Loss=1.016258, Validation Loss=0.953101\n",
      "Epoch 46 Training Loss=1.016208, Validation Loss=0.953229\n",
      "Epoch 47 Training Loss=1.016158, Validation Loss=0.953357\n",
      "Epoch 48 Training Loss=1.016108, Validation Loss=0.953486\n",
      "Epoch 49 Training Loss=1.016059, Validation Loss=0.953615\n",
      "Epoch 50 Training Loss=1.016011, Validation Loss=0.953743\n",
      "Epoch 51 Training Loss=1.015963, Validation Loss=0.953872\n",
      "Epoch 52 Training Loss=1.015915, Validation Loss=0.954000\n",
      "Epoch 53 Training Loss=1.015868, Validation Loss=0.954127\n",
      "Epoch 54 Training Loss=1.015821, Validation Loss=0.954254\n",
      "Epoch 55 Training Loss=1.015774, Validation Loss=0.954379\n",
      "Epoch 56 Training Loss=1.015727, Validation Loss=0.954504\n",
      "Epoch 57 Training Loss=1.015681, Validation Loss=0.954629\n",
      "Epoch 58 Training Loss=1.015635, Validation Loss=0.954752\n",
      "Epoch 59 Training Loss=1.015590, Validation Loss=0.954874\n",
      "Epoch 60 Training Loss=1.015545, Validation Loss=0.954995\n",
      "Epoch 61 Training Loss=1.015500, Validation Loss=0.955115\n",
      "Epoch 62 Training Loss=1.015455, Validation Loss=0.955234\n",
      "Epoch 63 Training Loss=1.015410, Validation Loss=0.955351\n",
      "Epoch 64 Training Loss=1.015366, Validation Loss=0.955468\n",
      "Epoch 65 Training Loss=1.015322, Validation Loss=0.955583\n",
      "Epoch 66 Training Loss=1.015278, Validation Loss=0.955697\n",
      "Epoch 67 Training Loss=1.015234, Validation Loss=0.955810\n",
      "Epoch 68 Training Loss=1.015191, Validation Loss=0.955922\n",
      "Epoch 69 Training Loss=1.015148, Validation Loss=0.956032\n",
      "Epoch 70 Training Loss=1.015105, Validation Loss=0.956141\n",
      "Epoch 71 Training Loss=1.015062, Validation Loss=0.956249\n",
      "Epoch 72 Training Loss=1.015019, Validation Loss=0.956356\n",
      "Epoch 73 Training Loss=1.014977, Validation Loss=0.956462\n",
      "Epoch 74 Training Loss=1.014935, Validation Loss=0.956566\n",
      "Epoch 75 Training Loss=1.014893, Validation Loss=0.956670\n",
      "Epoch 76 Training Loss=1.014851, Validation Loss=0.956772\n",
      "Epoch 77 Training Loss=1.014810, Validation Loss=0.956873\n",
      "Epoch 78 Training Loss=1.014768, Validation Loss=0.956973\n",
      "Epoch 79 Training Loss=1.014727, Validation Loss=0.957071\n",
      "Epoch 80 Training Loss=1.014686, Validation Loss=0.957169\n",
      "Epoch 81 Training Loss=1.014645, Validation Loss=0.957265\n",
      "Epoch 82 Training Loss=1.014604, Validation Loss=0.957361\n",
      "Epoch 83 Training Loss=1.014564, Validation Loss=0.957455\n",
      "Epoch 84 Training Loss=1.014523, Validation Loss=0.957549\n",
      "Epoch 85 Training Loss=1.014483, Validation Loss=0.957641\n",
      "Epoch 86 Training Loss=1.014443, Validation Loss=0.957733\n",
      "Epoch 87 Training Loss=1.014403, Validation Loss=0.957823\n",
      "Epoch 88 Training Loss=1.014364, Validation Loss=0.957913\n",
      "Epoch 89 Training Loss=1.014324, Validation Loss=0.958001\n",
      "Epoch 90 Training Loss=1.014285, Validation Loss=0.958089\n",
      "Epoch 91 Training Loss=1.014246, Validation Loss=0.958176\n",
      "Epoch 92 Training Loss=1.014207, Validation Loss=0.958261\n",
      "Epoch 93 Training Loss=1.014168, Validation Loss=0.958346\n",
      "Epoch 94 Training Loss=1.014129, Validation Loss=0.958431\n",
      "Epoch 95 Training Loss=1.014090, Validation Loss=0.958514\n",
      "Epoch 96 Training Loss=1.014052, Validation Loss=0.958596\n",
      "Epoch 97 Training Loss=1.014014, Validation Loss=0.958678\n",
      "Epoch 98 Training Loss=1.013976, Validation Loss=0.958759\n",
      "Epoch 99 Training Loss=1.013938, Validation Loss=0.958839\n",
      "Epoch 100 Training Loss=1.013900, Validation Loss=0.958918\n",
      "Epoch 101 Training Loss=1.013862, Validation Loss=0.958997\n",
      "Epoch 102 Training Loss=1.013825, Validation Loss=0.959075\n",
      "Epoch 103 Training Loss=1.013787, Validation Loss=0.959152\n",
      "Epoch 104 Training Loss=1.013750, Validation Loss=0.959229\n",
      "Epoch 105 Training Loss=1.013713, Validation Loss=0.959305\n",
      "Epoch 106 Training Loss=1.013676, Validation Loss=0.959380\n",
      "Epoch 107 Training Loss=1.013639, Validation Loss=0.959455\n",
      "Epoch 108 Training Loss=1.013602, Validation Loss=0.959529\n",
      "Epoch 109 Training Loss=1.013566, Validation Loss=0.959602\n",
      "Epoch 110 Training Loss=1.013529, Validation Loss=0.959675\n",
      "Epoch 111 Training Loss=1.013493, Validation Loss=0.959747\n",
      "Epoch 112 Training Loss=1.013456, Validation Loss=0.959819\n",
      "Epoch 113 Training Loss=1.013420, Validation Loss=0.959890\n",
      "Epoch 114 Training Loss=1.013384, Validation Loss=0.959960\n",
      "Epoch 115 Training Loss=1.013349, Validation Loss=0.960030\n",
      "Epoch 116 Training Loss=1.013313, Validation Loss=0.960099\n",
      "Epoch 117 Training Loss=1.013277, Validation Loss=0.960168\n",
      "Epoch 118 Training Loss=1.013242, Validation Loss=0.960236\n",
      "Epoch 119 Training Loss=1.013206, Validation Loss=0.960304\n",
      "Epoch 120 Training Loss=1.013171, Validation Loss=0.960372\n",
      "Epoch 121 Training Loss=1.013136, Validation Loss=0.960439\n",
      "Epoch 122 Training Loss=1.013101, Validation Loss=0.960505\n",
      "Epoch 123 Training Loss=1.013066, Validation Loss=0.960571\n",
      "Epoch 124 Training Loss=1.013031, Validation Loss=0.960637\n",
      "Epoch 125 Training Loss=1.012997, Validation Loss=0.960702\n",
      "Epoch 126 Training Loss=1.012962, Validation Loss=0.960767\n",
      "Epoch 127 Training Loss=1.012928, Validation Loss=0.960831\n",
      "Epoch 128 Training Loss=1.012893, Validation Loss=0.960895\n",
      "Epoch 129 Training Loss=1.012859, Validation Loss=0.960958\n",
      "Epoch 130 Training Loss=1.012825, Validation Loss=0.961021\n",
      "Epoch 131 Training Loss=1.012791, Validation Loss=0.961084\n",
      "Epoch 132 Training Loss=1.012757, Validation Loss=0.961146\n",
      "Epoch 133 Training Loss=1.012723, Validation Loss=0.961208\n",
      "Epoch 134 Training Loss=1.012689, Validation Loss=0.961269\n",
      "Epoch 135 Training Loss=1.012656, Validation Loss=0.961331\n",
      "Epoch 136 Training Loss=1.012622, Validation Loss=0.961391\n",
      "Epoch 137 Training Loss=1.012589, Validation Loss=0.961452\n",
      "Epoch 138 Training Loss=1.012556, Validation Loss=0.961512\n",
      "Epoch 139 Training Loss=1.012522, Validation Loss=0.961572\n",
      "Epoch 140 Training Loss=1.012489, Validation Loss=0.961631\n",
      "Epoch 141 Training Loss=1.012456, Validation Loss=0.961690\n",
      "Epoch 142 Training Loss=1.012423, Validation Loss=0.961749\n",
      "Epoch 143 Training Loss=1.012391, Validation Loss=0.961808\n",
      "Epoch 144 Training Loss=1.012358, Validation Loss=0.961866\n",
      "Epoch 145 Training Loss=1.012325, Validation Loss=0.961924\n",
      "Epoch 146 Training Loss=1.012293, Validation Loss=0.961981\n",
      "Epoch 147 Training Loss=1.012260, Validation Loss=0.962039\n",
      "Epoch 148 Training Loss=1.012228, Validation Loss=0.962096\n",
      "Epoch 149 Training Loss=1.012196, Validation Loss=0.962152\n",
      "Epoch 150 Training Loss=1.012164, Validation Loss=0.962209\n",
      "Epoch 151 Training Loss=1.012131, Validation Loss=0.962265\n",
      "Epoch 152 Training Loss=1.012100, Validation Loss=0.962321\n",
      "Epoch 153 Training Loss=1.012068, Validation Loss=0.962377\n",
      "Epoch 154 Training Loss=1.012036, Validation Loss=0.962432\n",
      "Epoch 155 Training Loss=1.012004, Validation Loss=0.962487\n",
      "Epoch 156 Training Loss=1.011972, Validation Loss=0.962542\n",
      "Epoch 157 Training Loss=1.011941, Validation Loss=0.962597\n",
      "Epoch 158 Training Loss=1.011909, Validation Loss=0.962651\n",
      "Epoch 159 Training Loss=1.011878, Validation Loss=0.962706\n",
      "Epoch 160 Training Loss=1.011847, Validation Loss=0.962759\n",
      "Epoch 161 Training Loss=1.011816, Validation Loss=0.962813\n",
      "Epoch 162 Training Loss=1.011784, Validation Loss=0.962867\n",
      "Epoch 163 Training Loss=1.011753, Validation Loss=0.962920\n",
      "Epoch 164 Training Loss=1.011722, Validation Loss=0.962973\n",
      "Epoch 165 Training Loss=1.011691, Validation Loss=0.963026\n",
      "Epoch 166 Training Loss=1.011661, Validation Loss=0.963079\n",
      "Epoch 167 Training Loss=1.011630, Validation Loss=0.963131\n",
      "Epoch 168 Training Loss=1.011599, Validation Loss=0.963183\n",
      "Epoch 169 Training Loss=1.011569, Validation Loss=0.963235\n",
      "Epoch 170 Training Loss=1.011538, Validation Loss=0.963287\n",
      "Epoch 171 Training Loss=1.011508, Validation Loss=0.963339\n",
      "Epoch 172 Training Loss=1.011477, Validation Loss=0.963390\n",
      "Epoch 173 Training Loss=1.011447, Validation Loss=0.963441\n",
      "Epoch 174 Training Loss=1.011417, Validation Loss=0.963492\n",
      "Epoch 175 Training Loss=1.011387, Validation Loss=0.963543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 Training Loss=1.011357, Validation Loss=0.963593\n",
      "Epoch 177 Training Loss=1.011327, Validation Loss=0.963644\n",
      "Epoch 178 Training Loss=1.011297, Validation Loss=0.963694\n",
      "Epoch 179 Training Loss=1.011267, Validation Loss=0.963744\n",
      "Epoch 180 Training Loss=1.011237, Validation Loss=0.963794\n",
      "Epoch 181 Training Loss=1.011207, Validation Loss=0.963844\n",
      "Epoch 182 Training Loss=1.011178, Validation Loss=0.963893\n",
      "Epoch 183 Training Loss=1.011148, Validation Loss=0.963943\n",
      "Epoch 184 Training Loss=1.011119, Validation Loss=0.963992\n",
      "Epoch 185 Training Loss=1.011089, Validation Loss=0.964041\n",
      "Epoch 186 Training Loss=1.011060, Validation Loss=0.964090\n",
      "Epoch 187 Training Loss=1.011031, Validation Loss=0.964139\n",
      "Epoch 188 Training Loss=1.011001, Validation Loss=0.964187\n",
      "Epoch 189 Training Loss=1.010972, Validation Loss=0.964235\n",
      "Epoch 190 Training Loss=1.010943, Validation Loss=0.964283\n",
      "Epoch 191 Training Loss=1.010914, Validation Loss=0.964332\n",
      "Epoch 192 Training Loss=1.010885, Validation Loss=0.964379\n",
      "Epoch 193 Training Loss=1.010856, Validation Loss=0.964427\n",
      "Epoch 194 Training Loss=1.010827, Validation Loss=0.964475\n",
      "Epoch 195 Training Loss=1.010799, Validation Loss=0.964522\n",
      "Epoch 196 Training Loss=1.010770, Validation Loss=0.964570\n",
      "Epoch 197 Training Loss=1.010741, Validation Loss=0.964617\n",
      "Epoch 198 Training Loss=1.010713, Validation Loss=0.964664\n",
      "Epoch 199 Training Loss=1.010684, Validation Loss=0.964710\n",
      "Epoch 0 Training Loss=1.106470, Validation Loss=0.971932\n",
      "Epoch 1 Training Loss=1.066678, Validation Loss=0.942176\n",
      "Epoch 2 Training Loss=1.046254, Validation Loss=0.926248\n",
      "Epoch 3 Training Loss=1.035735, Validation Loss=0.917799\n",
      "Epoch 4 Training Loss=1.030180, Validation Loss=0.913489\n",
      "Epoch 5 Training Loss=1.027139, Validation Loss=0.911512\n",
      "Epoch 6 Training Loss=1.025387, Validation Loss=0.910873\n",
      "Epoch 7 Training Loss=1.024305, Validation Loss=0.911006\n",
      "Epoch 8 Training Loss=1.023577, Validation Loss=0.911581\n",
      "Epoch 9 Training Loss=1.023041, Validation Loss=0.912407\n",
      "Epoch 10 Training Loss=1.022614, Validation Loss=0.913366\n",
      "Epoch 11 Training Loss=1.022250, Validation Loss=0.914388\n",
      "Epoch 12 Training Loss=1.021926, Validation Loss=0.915431\n",
      "Epoch 13 Training Loss=1.021628, Validation Loss=0.916470\n",
      "Epoch 14 Training Loss=1.021350, Validation Loss=0.917490\n",
      "Epoch 15 Training Loss=1.021087, Validation Loss=0.918482\n",
      "Epoch 16 Training Loss=1.020837, Validation Loss=0.919443\n",
      "Epoch 17 Training Loss=1.020597, Validation Loss=0.920371\n",
      "Epoch 18 Training Loss=1.020367, Validation Loss=0.921268\n",
      "Epoch 19 Training Loss=1.020146, Validation Loss=0.922132\n",
      "Epoch 20 Training Loss=1.019933, Validation Loss=0.922967\n",
      "Epoch 21 Training Loss=1.019727, Validation Loss=0.923773\n",
      "Epoch 22 Training Loss=1.019529, Validation Loss=0.924553\n",
      "Epoch 23 Training Loss=1.019338, Validation Loss=0.925309\n",
      "Epoch 24 Training Loss=1.019153, Validation Loss=0.926041\n",
      "Epoch 25 Training Loss=1.018974, Validation Loss=0.926752\n",
      "Epoch 26 Training Loss=1.018800, Validation Loss=0.927442\n",
      "Epoch 27 Training Loss=1.018632, Validation Loss=0.928115\n",
      "Epoch 28 Training Loss=1.018469, Validation Loss=0.928769\n",
      "Epoch 29 Training Loss=1.018311, Validation Loss=0.929407\n",
      "Epoch 30 Training Loss=1.018158, Validation Loss=0.930029\n",
      "Epoch 31 Training Loss=1.018009, Validation Loss=0.930636\n",
      "Epoch 32 Training Loss=1.017864, Validation Loss=0.931230\n",
      "Epoch 33 Training Loss=1.017723, Validation Loss=0.931810\n",
      "Epoch 34 Training Loss=1.017586, Validation Loss=0.932377\n",
      "Epoch 35 Training Loss=1.017453, Validation Loss=0.932932\n",
      "Epoch 36 Training Loss=1.017323, Validation Loss=0.933475\n",
      "Epoch 37 Training Loss=1.017196, Validation Loss=0.934007\n",
      "Epoch 38 Training Loss=1.017073, Validation Loss=0.934528\n",
      "Epoch 39 Training Loss=1.016952, Validation Loss=0.935038\n",
      "Epoch 40 Training Loss=1.016835, Validation Loss=0.935539\n",
      "Epoch 41 Training Loss=1.016720, Validation Loss=0.936029\n",
      "Epoch 42 Training Loss=1.016607, Validation Loss=0.936510\n",
      "Epoch 43 Training Loss=1.016497, Validation Loss=0.936982\n",
      "Epoch 44 Training Loss=1.016390, Validation Loss=0.937444\n",
      "Epoch 45 Training Loss=1.016284, Validation Loss=0.937898\n",
      "Epoch 46 Training Loss=1.016181, Validation Loss=0.938344\n",
      "Epoch 47 Training Loss=1.016080, Validation Loss=0.938780\n",
      "Epoch 48 Training Loss=1.015981, Validation Loss=0.939209\n",
      "Epoch 49 Training Loss=1.015884, Validation Loss=0.939630\n",
      "Epoch 50 Training Loss=1.015789, Validation Loss=0.940043\n",
      "Epoch 51 Training Loss=1.015695, Validation Loss=0.940449\n",
      "Epoch 52 Training Loss=1.015603, Validation Loss=0.940847\n",
      "Epoch 53 Training Loss=1.015513, Validation Loss=0.941238\n",
      "Epoch 54 Training Loss=1.015424, Validation Loss=0.941622\n",
      "Epoch 55 Training Loss=1.015337, Validation Loss=0.941999\n",
      "Epoch 56 Training Loss=1.015251, Validation Loss=0.942370\n",
      "Epoch 57 Training Loss=1.015166, Validation Loss=0.942733\n",
      "Epoch 58 Training Loss=1.015083, Validation Loss=0.943091\n",
      "Epoch 59 Training Loss=1.015001, Validation Loss=0.943442\n",
      "Epoch 60 Training Loss=1.014920, Validation Loss=0.943786\n",
      "Epoch 61 Training Loss=1.014840, Validation Loss=0.944125\n",
      "Epoch 62 Training Loss=1.014762, Validation Loss=0.944458\n",
      "Epoch 63 Training Loss=1.014684, Validation Loss=0.944784\n",
      "Epoch 64 Training Loss=1.014608, Validation Loss=0.945106\n",
      "Epoch 65 Training Loss=1.014532, Validation Loss=0.945421\n",
      "Epoch 66 Training Loss=1.014457, Validation Loss=0.945731\n",
      "Epoch 67 Training Loss=1.014384, Validation Loss=0.946036\n",
      "Epoch 68 Training Loss=1.014311, Validation Loss=0.946336\n",
      "Epoch 69 Training Loss=1.014239, Validation Loss=0.946630\n",
      "Epoch 70 Training Loss=1.014167, Validation Loss=0.946920\n",
      "Epoch 71 Training Loss=1.014097, Validation Loss=0.947204\n",
      "Epoch 72 Training Loss=1.014027, Validation Loss=0.947484\n",
      "Epoch 73 Training Loss=1.013958, Validation Loss=0.947759\n",
      "Epoch 74 Training Loss=1.013890, Validation Loss=0.948029\n",
      "Epoch 75 Training Loss=1.013822, Validation Loss=0.948295\n",
      "Epoch 76 Training Loss=1.013755, Validation Loss=0.948556\n",
      "Epoch 77 Training Loss=1.013688, Validation Loss=0.948813\n",
      "Epoch 78 Training Loss=1.013623, Validation Loss=0.949066\n",
      "Epoch 79 Training Loss=1.013557, Validation Loss=0.949315\n",
      "Epoch 80 Training Loss=1.013493, Validation Loss=0.949560\n",
      "Epoch 81 Training Loss=1.013428, Validation Loss=0.949800\n",
      "Epoch 82 Training Loss=1.013365, Validation Loss=0.950037\n",
      "Epoch 83 Training Loss=1.013301, Validation Loss=0.950270\n",
      "Epoch 84 Training Loss=1.013239, Validation Loss=0.950499\n",
      "Epoch 85 Training Loss=1.013176, Validation Loss=0.950725\n",
      "Epoch 86 Training Loss=1.013115, Validation Loss=0.950947\n",
      "Epoch 87 Training Loss=1.013053, Validation Loss=0.951165\n",
      "Epoch 88 Training Loss=1.012992, Validation Loss=0.951380\n",
      "Epoch 89 Training Loss=1.012931, Validation Loss=0.951592\n",
      "Epoch 90 Training Loss=1.012871, Validation Loss=0.951800\n",
      "Epoch 91 Training Loss=1.012811, Validation Loss=0.952005\n",
      "Epoch 92 Training Loss=1.012752, Validation Loss=0.952207\n",
      "Epoch 93 Training Loss=1.012693, Validation Loss=0.952406\n",
      "Epoch 94 Training Loss=1.012634, Validation Loss=0.952602\n",
      "Epoch 95 Training Loss=1.012576, Validation Loss=0.952795\n",
      "Epoch 96 Training Loss=1.012517, Validation Loss=0.952985\n",
      "Epoch 97 Training Loss=1.012460, Validation Loss=0.953172\n",
      "Epoch 98 Training Loss=1.012402, Validation Loss=0.953357\n",
      "Epoch 99 Training Loss=1.012345, Validation Loss=0.953539\n",
      "Epoch 100 Training Loss=1.012288, Validation Loss=0.953718\n",
      "Epoch 101 Training Loss=1.012231, Validation Loss=0.953894\n",
      "Epoch 102 Training Loss=1.012175, Validation Loss=0.954068\n",
      "Epoch 103 Training Loss=1.012119, Validation Loss=0.954240\n",
      "Epoch 104 Training Loss=1.012063, Validation Loss=0.954409\n",
      "Epoch 105 Training Loss=1.012007, Validation Loss=0.954575\n",
      "Epoch 106 Training Loss=1.011952, Validation Loss=0.954740\n",
      "Epoch 107 Training Loss=1.011896, Validation Loss=0.954902\n",
      "Epoch 108 Training Loss=1.011841, Validation Loss=0.955062\n",
      "Epoch 109 Training Loss=1.011787, Validation Loss=0.955219\n",
      "Epoch 110 Training Loss=1.011732, Validation Loss=0.955375\n",
      "Epoch 111 Training Loss=1.011678, Validation Loss=0.955528\n",
      "Epoch 112 Training Loss=1.011623, Validation Loss=0.955680\n",
      "Epoch 113 Training Loss=1.011570, Validation Loss=0.955829\n",
      "Epoch 114 Training Loss=1.011516, Validation Loss=0.955976\n",
      "Epoch 115 Training Loss=1.011462, Validation Loss=0.956122\n",
      "Epoch 116 Training Loss=1.011409, Validation Loss=0.956266\n",
      "Epoch 117 Training Loss=1.011356, Validation Loss=0.956407\n",
      "Epoch 118 Training Loss=1.011303, Validation Loss=0.956547\n",
      "Epoch 119 Training Loss=1.011250, Validation Loss=0.956686\n",
      "Epoch 120 Training Loss=1.011197, Validation Loss=0.956822\n",
      "Epoch 121 Training Loss=1.011144, Validation Loss=0.956957\n",
      "Epoch 122 Training Loss=1.011092, Validation Loss=0.957090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 Training Loss=1.011040, Validation Loss=0.957222\n",
      "Epoch 124 Training Loss=1.010988, Validation Loss=0.957352\n",
      "Epoch 125 Training Loss=1.010936, Validation Loss=0.957480\n",
      "Epoch 126 Training Loss=1.010884, Validation Loss=0.957607\n",
      "Epoch 127 Training Loss=1.010832, Validation Loss=0.957732\n",
      "Epoch 128 Training Loss=1.010781, Validation Loss=0.957857\n",
      "Epoch 129 Training Loss=1.010729, Validation Loss=0.957979\n",
      "Epoch 130 Training Loss=1.010678, Validation Loss=0.958100\n",
      "Epoch 131 Training Loss=1.010627, Validation Loss=0.958220\n",
      "Epoch 132 Training Loss=1.010576, Validation Loss=0.958339\n",
      "Epoch 133 Training Loss=1.010525, Validation Loss=0.958456\n",
      "Epoch 134 Training Loss=1.010474, Validation Loss=0.958572\n",
      "Epoch 135 Training Loss=1.010423, Validation Loss=0.958687\n",
      "Epoch 136 Training Loss=1.010373, Validation Loss=0.958800\n",
      "Epoch 137 Training Loss=1.010323, Validation Loss=0.958912\n",
      "Epoch 138 Training Loss=1.010272, Validation Loss=0.959024\n",
      "Epoch 139 Training Loss=1.010222, Validation Loss=0.959134\n",
      "Epoch 140 Training Loss=1.010172, Validation Loss=0.959242\n",
      "Epoch 141 Training Loss=1.010122, Validation Loss=0.959350\n",
      "Epoch 142 Training Loss=1.010072, Validation Loss=0.959457\n",
      "Epoch 143 Training Loss=1.010022, Validation Loss=0.959562\n",
      "Epoch 144 Training Loss=1.009972, Validation Loss=0.959667\n",
      "Epoch 145 Training Loss=1.009923, Validation Loss=0.959771\n",
      "Epoch 146 Training Loss=1.009873, Validation Loss=0.959873\n",
      "Epoch 147 Training Loss=1.009824, Validation Loss=0.959975\n",
      "Epoch 148 Training Loss=1.009775, Validation Loss=0.960076\n",
      "Epoch 149 Training Loss=1.009725, Validation Loss=0.960176\n",
      "Epoch 150 Training Loss=1.009676, Validation Loss=0.960274\n",
      "Epoch 151 Training Loss=1.009627, Validation Loss=0.960372\n",
      "Epoch 152 Training Loss=1.009578, Validation Loss=0.960470\n",
      "Epoch 153 Training Loss=1.009529, Validation Loss=0.960566\n",
      "Epoch 154 Training Loss=1.009481, Validation Loss=0.960661\n",
      "Epoch 155 Training Loss=1.009432, Validation Loss=0.960756\n",
      "Epoch 156 Training Loss=1.009383, Validation Loss=0.960850\n",
      "Epoch 157 Training Loss=1.009335, Validation Loss=0.960943\n",
      "Epoch 158 Training Loss=1.009286, Validation Loss=0.961035\n",
      "Epoch 159 Training Loss=1.009238, Validation Loss=0.961127\n",
      "Epoch 160 Training Loss=1.009189, Validation Loss=0.961218\n",
      "Epoch 161 Training Loss=1.009141, Validation Loss=0.961308\n",
      "Epoch 162 Training Loss=1.009093, Validation Loss=0.961397\n",
      "Epoch 163 Training Loss=1.009045, Validation Loss=0.961486\n",
      "Epoch 164 Training Loss=1.008997, Validation Loss=0.961574\n",
      "Epoch 165 Training Loss=1.008949, Validation Loss=0.961662\n",
      "Epoch 166 Training Loss=1.008901, Validation Loss=0.961748\n",
      "Epoch 167 Training Loss=1.008853, Validation Loss=0.961835\n",
      "Epoch 168 Training Loss=1.008805, Validation Loss=0.961920\n",
      "Epoch 169 Training Loss=1.008757, Validation Loss=0.962005\n",
      "Epoch 170 Training Loss=1.008710, Validation Loss=0.962089\n",
      "Epoch 171 Training Loss=1.008662, Validation Loss=0.962173\n",
      "Epoch 172 Training Loss=1.008615, Validation Loss=0.962256\n",
      "Epoch 173 Training Loss=1.008567, Validation Loss=0.962339\n",
      "Epoch 174 Training Loss=1.008520, Validation Loss=0.962421\n",
      "Epoch 175 Training Loss=1.008472, Validation Loss=0.962502\n",
      "Epoch 176 Training Loss=1.008425, Validation Loss=0.962583\n",
      "Epoch 177 Training Loss=1.008378, Validation Loss=0.962664\n",
      "Epoch 178 Training Loss=1.008331, Validation Loss=0.962744\n",
      "Epoch 179 Training Loss=1.008283, Validation Loss=0.962823\n",
      "Epoch 180 Training Loss=1.008236, Validation Loss=0.962902\n",
      "Epoch 181 Training Loss=1.008189, Validation Loss=0.962981\n",
      "Epoch 182 Training Loss=1.008142, Validation Loss=0.963059\n",
      "Epoch 183 Training Loss=1.008095, Validation Loss=0.963137\n",
      "Epoch 184 Training Loss=1.008049, Validation Loss=0.963214\n",
      "Epoch 185 Training Loss=1.008002, Validation Loss=0.963291\n",
      "Epoch 186 Training Loss=1.007955, Validation Loss=0.963367\n",
      "Epoch 187 Training Loss=1.007908, Validation Loss=0.963443\n",
      "Epoch 188 Training Loss=1.007862, Validation Loss=0.963518\n",
      "Epoch 189 Training Loss=1.007815, Validation Loss=0.963593\n",
      "Epoch 190 Training Loss=1.007768, Validation Loss=0.963668\n",
      "Epoch 191 Training Loss=1.007722, Validation Loss=0.963742\n",
      "Epoch 192 Training Loss=1.007675, Validation Loss=0.963816\n",
      "Epoch 193 Training Loss=1.007629, Validation Loss=0.963890\n",
      "Epoch 194 Training Loss=1.007582, Validation Loss=0.963963\n",
      "Epoch 195 Training Loss=1.007536, Validation Loss=0.964036\n",
      "Epoch 196 Training Loss=1.007490, Validation Loss=0.964108\n",
      "Epoch 197 Training Loss=1.007443, Validation Loss=0.964180\n",
      "Epoch 198 Training Loss=1.007397, Validation Loss=0.964252\n",
      "Epoch 199 Training Loss=1.007351, Validation Loss=0.964323\n",
      "Epoch 0 Training Loss=1.109536, Validation Loss=0.908980\n",
      "Epoch 1 Training Loss=1.068754, Validation Loss=0.902790\n",
      "Epoch 2 Training Loss=1.048363, Validation Loss=0.904432\n",
      "Epoch 3 Training Loss=1.037518, Validation Loss=0.908650\n",
      "Epoch 4 Training Loss=1.031372, Validation Loss=0.913376\n",
      "Epoch 5 Training Loss=1.027675, Validation Loss=0.917843\n",
      "Epoch 6 Training Loss=1.025329, Validation Loss=0.921811\n",
      "Epoch 7 Training Loss=1.023769, Validation Loss=0.925248\n",
      "Epoch 8 Training Loss=1.022688, Validation Loss=0.928201\n",
      "Epoch 9 Training Loss=1.021911, Validation Loss=0.930734\n",
      "Epoch 10 Training Loss=1.021331, Validation Loss=0.932917\n",
      "Epoch 11 Training Loss=1.020884, Validation Loss=0.934807\n",
      "Epoch 12 Training Loss=1.020528, Validation Loss=0.936457\n",
      "Epoch 13 Training Loss=1.020233, Validation Loss=0.937910\n",
      "Epoch 14 Training Loss=1.019984, Validation Loss=0.939199\n",
      "Epoch 15 Training Loss=1.019766, Validation Loss=0.940352\n",
      "Epoch 16 Training Loss=1.019572, Validation Loss=0.941394\n",
      "Epoch 17 Training Loss=1.019396, Validation Loss=0.942342\n",
      "Epoch 18 Training Loss=1.019233, Validation Loss=0.943210\n",
      "Epoch 19 Training Loss=1.019081, Validation Loss=0.944012\n",
      "Epoch 20 Training Loss=1.018937, Validation Loss=0.944756\n",
      "Epoch 21 Training Loss=1.018799, Validation Loss=0.945452\n",
      "Epoch 22 Training Loss=1.018668, Validation Loss=0.946105\n",
      "Epoch 23 Training Loss=1.018541, Validation Loss=0.946720\n",
      "Epoch 24 Training Loss=1.018418, Validation Loss=0.947303\n",
      "Epoch 25 Training Loss=1.018299, Validation Loss=0.947857\n",
      "Epoch 26 Training Loss=1.018183, Validation Loss=0.948385\n",
      "Epoch 27 Training Loss=1.018070, Validation Loss=0.948890\n",
      "Epoch 28 Training Loss=1.017959, Validation Loss=0.949373\n",
      "Epoch 29 Training Loss=1.017851, Validation Loss=0.949838\n",
      "Epoch 30 Training Loss=1.017744, Validation Loss=0.950284\n",
      "Epoch 31 Training Loss=1.017639, Validation Loss=0.950714\n",
      "Epoch 32 Training Loss=1.017536, Validation Loss=0.951129\n",
      "Epoch 33 Training Loss=1.017435, Validation Loss=0.951529\n",
      "Epoch 34 Training Loss=1.017335, Validation Loss=0.951917\n",
      "Epoch 35 Training Loss=1.017236, Validation Loss=0.952292\n",
      "Epoch 36 Training Loss=1.017139, Validation Loss=0.952655\n",
      "Epoch 37 Training Loss=1.017043, Validation Loss=0.953008\n",
      "Epoch 38 Training Loss=1.016948, Validation Loss=0.953350\n",
      "Epoch 39 Training Loss=1.016853, Validation Loss=0.953682\n",
      "Epoch 40 Training Loss=1.016760, Validation Loss=0.954005\n",
      "Epoch 41 Training Loss=1.016668, Validation Loss=0.954319\n",
      "Epoch 42 Training Loss=1.016576, Validation Loss=0.954624\n",
      "Epoch 43 Training Loss=1.016486, Validation Loss=0.954922\n",
      "Epoch 44 Training Loss=1.016396, Validation Loss=0.955212\n",
      "Epoch 45 Training Loss=1.016307, Validation Loss=0.955495\n",
      "Epoch 46 Training Loss=1.016218, Validation Loss=0.955770\n",
      "Epoch 47 Training Loss=1.016130, Validation Loss=0.956039\n",
      "Epoch 48 Training Loss=1.016043, Validation Loss=0.956302\n",
      "Epoch 49 Training Loss=1.015956, Validation Loss=0.956558\n",
      "Epoch 50 Training Loss=1.015870, Validation Loss=0.956809\n",
      "Epoch 51 Training Loss=1.015785, Validation Loss=0.957054\n",
      "Epoch 52 Training Loss=1.015700, Validation Loss=0.957293\n",
      "Epoch 53 Training Loss=1.015615, Validation Loss=0.957528\n",
      "Epoch 54 Training Loss=1.015532, Validation Loss=0.957757\n",
      "Epoch 55 Training Loss=1.015448, Validation Loss=0.957982\n",
      "Epoch 56 Training Loss=1.015365, Validation Loss=0.958202\n",
      "Epoch 57 Training Loss=1.015282, Validation Loss=0.958419\n",
      "Epoch 58 Training Loss=1.015200, Validation Loss=0.958630\n",
      "Epoch 59 Training Loss=1.015118, Validation Loss=0.958838\n",
      "Epoch 60 Training Loss=1.015037, Validation Loss=0.959042\n",
      "Epoch 61 Training Loss=1.014956, Validation Loss=0.959242\n",
      "Epoch 62 Training Loss=1.014876, Validation Loss=0.959439\n",
      "Epoch 63 Training Loss=1.014795, Validation Loss=0.959632\n",
      "Epoch 64 Training Loss=1.014715, Validation Loss=0.959823\n",
      "Epoch 65 Training Loss=1.014636, Validation Loss=0.960009\n",
      "Epoch 66 Training Loss=1.014557, Validation Loss=0.960193\n",
      "Epoch 67 Training Loss=1.014478, Validation Loss=0.960374\n",
      "Epoch 68 Training Loss=1.014400, Validation Loss=0.960553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Training Loss=1.014321, Validation Loss=0.960728\n",
      "Epoch 70 Training Loss=1.014244, Validation Loss=0.960901\n",
      "Epoch 71 Training Loss=1.014166, Validation Loss=0.961071\n",
      "Epoch 72 Training Loss=1.014089, Validation Loss=0.961239\n",
      "Epoch 73 Training Loss=1.014012, Validation Loss=0.961405\n",
      "Epoch 74 Training Loss=1.013935, Validation Loss=0.961568\n",
      "Epoch 75 Training Loss=1.013859, Validation Loss=0.961730\n",
      "Epoch 76 Training Loss=1.013783, Validation Loss=0.961889\n",
      "Epoch 77 Training Loss=1.013707, Validation Loss=0.962046\n",
      "Epoch 78 Training Loss=1.013632, Validation Loss=0.962202\n",
      "Epoch 79 Training Loss=1.013557, Validation Loss=0.962355\n",
      "Epoch 80 Training Loss=1.013482, Validation Loss=0.962507\n",
      "Epoch 81 Training Loss=1.013407, Validation Loss=0.962657\n",
      "Epoch 82 Training Loss=1.013333, Validation Loss=0.962805\n",
      "Epoch 83 Training Loss=1.013259, Validation Loss=0.962952\n",
      "Epoch 84 Training Loss=1.013185, Validation Loss=0.963098\n",
      "Epoch 85 Training Loss=1.013111, Validation Loss=0.963241\n",
      "Epoch 86 Training Loss=1.013038, Validation Loss=0.963383\n",
      "Epoch 87 Training Loss=1.012965, Validation Loss=0.963524\n",
      "Epoch 88 Training Loss=1.012892, Validation Loss=0.963664\n",
      "Epoch 89 Training Loss=1.012819, Validation Loss=0.963802\n",
      "Epoch 90 Training Loss=1.012747, Validation Loss=0.963939\n",
      "Epoch 91 Training Loss=1.012674, Validation Loss=0.964075\n",
      "Epoch 92 Training Loss=1.012603, Validation Loss=0.964209\n",
      "Epoch 93 Training Loss=1.012531, Validation Loss=0.964343\n",
      "Epoch 94 Training Loss=1.012459, Validation Loss=0.964475\n",
      "Epoch 95 Training Loss=1.012388, Validation Loss=0.964606\n",
      "Epoch 96 Training Loss=1.012317, Validation Loss=0.964736\n",
      "Epoch 97 Training Loss=1.012246, Validation Loss=0.964866\n",
      "Epoch 98 Training Loss=1.012176, Validation Loss=0.964994\n",
      "Epoch 99 Training Loss=1.012105, Validation Loss=0.965121\n",
      "Epoch 100 Training Loss=1.012035, Validation Loss=0.965247\n",
      "Epoch 101 Training Loss=1.011965, Validation Loss=0.965373\n",
      "Epoch 102 Training Loss=1.011895, Validation Loss=0.965497\n",
      "Epoch 103 Training Loss=1.011826, Validation Loss=0.965621\n",
      "Epoch 104 Training Loss=1.011756, Validation Loss=0.965743\n",
      "Epoch 105 Training Loss=1.011687, Validation Loss=0.965866\n",
      "Epoch 106 Training Loss=1.011618, Validation Loss=0.965987\n",
      "Epoch 107 Training Loss=1.011549, Validation Loss=0.966107\n",
      "Epoch 108 Training Loss=1.011481, Validation Loss=0.966227\n",
      "Epoch 109 Training Loss=1.011412, Validation Loss=0.966346\n",
      "Epoch 110 Training Loss=1.011344, Validation Loss=0.966464\n",
      "Epoch 111 Training Loss=1.011276, Validation Loss=0.966582\n",
      "Epoch 112 Training Loss=1.011208, Validation Loss=0.966699\n",
      "Epoch 113 Training Loss=1.011141, Validation Loss=0.966815\n",
      "Epoch 114 Training Loss=1.011073, Validation Loss=0.966931\n",
      "Epoch 115 Training Loss=1.011006, Validation Loss=0.967046\n",
      "Epoch 116 Training Loss=1.010939, Validation Loss=0.967160\n",
      "Epoch 117 Training Loss=1.010872, Validation Loss=0.967274\n",
      "Epoch 118 Training Loss=1.010805, Validation Loss=0.967387\n",
      "Epoch 119 Training Loss=1.010739, Validation Loss=0.967500\n",
      "Epoch 120 Training Loss=1.010672, Validation Loss=0.967612\n",
      "Epoch 121 Training Loss=1.010606, Validation Loss=0.967724\n",
      "Epoch 122 Training Loss=1.010540, Validation Loss=0.967835\n",
      "Epoch 123 Training Loss=1.010474, Validation Loss=0.967945\n",
      "Epoch 124 Training Loss=1.010408, Validation Loss=0.968055\n",
      "Epoch 125 Training Loss=1.010343, Validation Loss=0.968165\n",
      "Epoch 126 Training Loss=1.010278, Validation Loss=0.968274\n",
      "Epoch 127 Training Loss=1.010212, Validation Loss=0.968382\n",
      "Epoch 128 Training Loss=1.010147, Validation Loss=0.968490\n",
      "Epoch 129 Training Loss=1.010082, Validation Loss=0.968598\n",
      "Epoch 130 Training Loss=1.010018, Validation Loss=0.968705\n",
      "Epoch 131 Training Loss=1.009953, Validation Loss=0.968812\n",
      "Epoch 132 Training Loss=1.009889, Validation Loss=0.968918\n",
      "Epoch 133 Training Loss=1.009824, Validation Loss=0.969024\n",
      "Epoch 134 Training Loss=1.009760, Validation Loss=0.969129\n",
      "Epoch 135 Training Loss=1.009696, Validation Loss=0.969234\n",
      "Epoch 136 Training Loss=1.009633, Validation Loss=0.969339\n",
      "Epoch 137 Training Loss=1.009569, Validation Loss=0.969443\n",
      "Epoch 138 Training Loss=1.009506, Validation Loss=0.969546\n",
      "Epoch 139 Training Loss=1.009442, Validation Loss=0.969650\n",
      "Epoch 140 Training Loss=1.009379, Validation Loss=0.969753\n",
      "Epoch 141 Training Loss=1.009316, Validation Loss=0.969855\n",
      "Epoch 142 Training Loss=1.009253, Validation Loss=0.969958\n",
      "Epoch 143 Training Loss=1.009190, Validation Loss=0.970060\n",
      "Epoch 144 Training Loss=1.009128, Validation Loss=0.970161\n",
      "Epoch 145 Training Loss=1.009065, Validation Loss=0.970262\n",
      "Epoch 146 Training Loss=1.009003, Validation Loss=0.970363\n",
      "Epoch 147 Training Loss=1.008941, Validation Loss=0.970463\n",
      "Epoch 148 Training Loss=1.008879, Validation Loss=0.970564\n",
      "Epoch 149 Training Loss=1.008817, Validation Loss=0.970663\n",
      "Epoch 150 Training Loss=1.008755, Validation Loss=0.970763\n",
      "Epoch 151 Training Loss=1.008693, Validation Loss=0.970862\n",
      "Epoch 152 Training Loss=1.008632, Validation Loss=0.970960\n",
      "Epoch 153 Training Loss=1.008570, Validation Loss=0.971059\n",
      "Epoch 154 Training Loss=1.008509, Validation Loss=0.971157\n",
      "Epoch 155 Training Loss=1.008448, Validation Loss=0.971255\n",
      "Epoch 156 Training Loss=1.008387, Validation Loss=0.971352\n",
      "Epoch 157 Training Loss=1.008326, Validation Loss=0.971450\n",
      "Epoch 158 Training Loss=1.008265, Validation Loss=0.971547\n",
      "Epoch 159 Training Loss=1.008205, Validation Loss=0.971643\n",
      "Epoch 160 Training Loss=1.008144, Validation Loss=0.971739\n",
      "Epoch 161 Training Loss=1.008084, Validation Loss=0.971835\n",
      "Epoch 162 Training Loss=1.008024, Validation Loss=0.971931\n",
      "Epoch 163 Training Loss=1.007964, Validation Loss=0.972027\n",
      "Epoch 164 Training Loss=1.007904, Validation Loss=0.972122\n",
      "Epoch 165 Training Loss=1.007844, Validation Loss=0.972217\n",
      "Epoch 166 Training Loss=1.007784, Validation Loss=0.972311\n",
      "Epoch 167 Training Loss=1.007724, Validation Loss=0.972406\n",
      "Epoch 168 Training Loss=1.007665, Validation Loss=0.972500\n",
      "Epoch 169 Training Loss=1.007605, Validation Loss=0.972593\n",
      "Epoch 170 Training Loss=1.007546, Validation Loss=0.972687\n",
      "Epoch 171 Training Loss=1.007487, Validation Loss=0.972780\n",
      "Epoch 172 Training Loss=1.007428, Validation Loss=0.972873\n",
      "Epoch 173 Training Loss=1.007369, Validation Loss=0.972966\n",
      "Epoch 174 Training Loss=1.007310, Validation Loss=0.973058\n",
      "Epoch 175 Training Loss=1.007252, Validation Loss=0.973151\n",
      "Epoch 176 Training Loss=1.007193, Validation Loss=0.973243\n",
      "Epoch 177 Training Loss=1.007134, Validation Loss=0.973335\n",
      "Epoch 178 Training Loss=1.007076, Validation Loss=0.973426\n",
      "Epoch 179 Training Loss=1.007018, Validation Loss=0.973517\n",
      "Epoch 180 Training Loss=1.006960, Validation Loss=0.973608\n",
      "Epoch 181 Training Loss=1.006902, Validation Loss=0.973699\n",
      "Epoch 182 Training Loss=1.006844, Validation Loss=0.973790\n",
      "Epoch 183 Training Loss=1.006786, Validation Loss=0.973880\n",
      "Epoch 184 Training Loss=1.006728, Validation Loss=0.973970\n",
      "Epoch 185 Training Loss=1.006671, Validation Loss=0.974060\n",
      "Epoch 186 Training Loss=1.006613, Validation Loss=0.974149\n",
      "Epoch 187 Training Loss=1.006556, Validation Loss=0.974239\n",
      "Epoch 188 Training Loss=1.006498, Validation Loss=0.974328\n",
      "Epoch 189 Training Loss=1.006441, Validation Loss=0.974417\n",
      "Epoch 190 Training Loss=1.006384, Validation Loss=0.974506\n",
      "Epoch 191 Training Loss=1.006327, Validation Loss=0.974594\n",
      "Epoch 192 Training Loss=1.006270, Validation Loss=0.974683\n",
      "Epoch 193 Training Loss=1.006213, Validation Loss=0.974771\n",
      "Epoch 194 Training Loss=1.006157, Validation Loss=0.974859\n",
      "Epoch 195 Training Loss=1.006100, Validation Loss=0.974946\n",
      "Epoch 196 Training Loss=1.006044, Validation Loss=0.975033\n",
      "Epoch 197 Training Loss=1.005987, Validation Loss=0.975121\n",
      "Epoch 198 Training Loss=1.005931, Validation Loss=0.975208\n",
      "Epoch 199 Training Loss=1.005875, Validation Loss=0.975295\n",
      "Epoch 0 Training Loss=1.057726, Validation Loss=0.957276\n",
      "Epoch 1 Training Loss=1.041457, Validation Loss=0.936599\n",
      "Epoch 2 Training Loss=1.034232, Validation Loss=0.925805\n",
      "Epoch 3 Training Loss=1.030557, Validation Loss=0.920191\n",
      "Epoch 4 Training Loss=1.028350, Validation Loss=0.917470\n",
      "Epoch 5 Training Loss=1.026825, Validation Loss=0.916430\n",
      "Epoch 6 Training Loss=1.025662, Validation Loss=0.916391\n",
      "Epoch 7 Training Loss=1.024718, Validation Loss=0.916952\n",
      "Epoch 8 Training Loss=1.023920, Validation Loss=0.917871\n",
      "Epoch 9 Training Loss=1.023228, Validation Loss=0.918997\n",
      "Epoch 10 Training Loss=1.022617, Validation Loss=0.920237\n",
      "Epoch 11 Training Loss=1.022069, Validation Loss=0.921533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Loss=1.021574, Validation Loss=0.922846\n",
      "Epoch 13 Training Loss=1.021121, Validation Loss=0.924155\n",
      "Epoch 14 Training Loss=1.020705, Validation Loss=0.925444\n",
      "Epoch 15 Training Loss=1.020319, Validation Loss=0.926705\n",
      "Epoch 16 Training Loss=1.019961, Validation Loss=0.927933\n",
      "Epoch 17 Training Loss=1.019626, Validation Loss=0.929125\n",
      "Epoch 18 Training Loss=1.019312, Validation Loss=0.930279\n",
      "Epoch 19 Training Loss=1.019016, Validation Loss=0.931396\n",
      "Epoch 20 Training Loss=1.018737, Validation Loss=0.932475\n",
      "Epoch 21 Training Loss=1.018473, Validation Loss=0.933517\n",
      "Epoch 22 Training Loss=1.018222, Validation Loss=0.934524\n",
      "Epoch 23 Training Loss=1.017983, Validation Loss=0.935496\n",
      "Epoch 24 Training Loss=1.017755, Validation Loss=0.936434\n",
      "Epoch 25 Training Loss=1.017537, Validation Loss=0.937340\n",
      "Epoch 26 Training Loss=1.017328, Validation Loss=0.938214\n",
      "Epoch 27 Training Loss=1.017127, Validation Loss=0.939058\n",
      "Epoch 28 Training Loss=1.016933, Validation Loss=0.939874\n",
      "Epoch 29 Training Loss=1.016747, Validation Loss=0.940661\n",
      "Epoch 30 Training Loss=1.016567, Validation Loss=0.941421\n",
      "Epoch 31 Training Loss=1.016393, Validation Loss=0.942156\n",
      "Epoch 32 Training Loss=1.016224, Validation Loss=0.942866\n",
      "Epoch 33 Training Loss=1.016060, Validation Loss=0.943552\n",
      "Epoch 34 Training Loss=1.015900, Validation Loss=0.944215\n",
      "Epoch 35 Training Loss=1.015745, Validation Loss=0.944857\n",
      "Epoch 36 Training Loss=1.015593, Validation Loss=0.945477\n",
      "Epoch 37 Training Loss=1.015446, Validation Loss=0.946078\n",
      "Epoch 38 Training Loss=1.015301, Validation Loss=0.946659\n",
      "Epoch 39 Training Loss=1.015160, Validation Loss=0.947221\n",
      "Epoch 40 Training Loss=1.015021, Validation Loss=0.947766\n",
      "Epoch 41 Training Loss=1.014885, Validation Loss=0.948294\n",
      "Epoch 42 Training Loss=1.014752, Validation Loss=0.948806\n",
      "Epoch 43 Training Loss=1.014621, Validation Loss=0.949302\n",
      "Epoch 44 Training Loss=1.014492, Validation Loss=0.949783\n",
      "Epoch 45 Training Loss=1.014365, Validation Loss=0.950250\n",
      "Epoch 46 Training Loss=1.014240, Validation Loss=0.950703\n",
      "Epoch 47 Training Loss=1.014117, Validation Loss=0.951144\n",
      "Epoch 48 Training Loss=1.013996, Validation Loss=0.951571\n",
      "Epoch 49 Training Loss=1.013876, Validation Loss=0.951987\n",
      "Epoch 50 Training Loss=1.013757, Validation Loss=0.952391\n",
      "Epoch 51 Training Loss=1.013641, Validation Loss=0.952784\n",
      "Epoch 52 Training Loss=1.013525, Validation Loss=0.953167\n",
      "Epoch 53 Training Loss=1.013411, Validation Loss=0.953539\n",
      "Epoch 54 Training Loss=1.013298, Validation Loss=0.953903\n",
      "Epoch 55 Training Loss=1.013186, Validation Loss=0.954256\n",
      "Epoch 56 Training Loss=1.013075, Validation Loss=0.954601\n",
      "Epoch 57 Training Loss=1.012965, Validation Loss=0.954938\n",
      "Epoch 58 Training Loss=1.012856, Validation Loss=0.955266\n",
      "Epoch 59 Training Loss=1.012749, Validation Loss=0.955587\n",
      "Epoch 60 Training Loss=1.012642, Validation Loss=0.955900\n",
      "Epoch 61 Training Loss=1.012536, Validation Loss=0.956207\n",
      "Epoch 62 Training Loss=1.012431, Validation Loss=0.956506\n",
      "Epoch 63 Training Loss=1.012326, Validation Loss=0.956799\n",
      "Epoch 64 Training Loss=1.012223, Validation Loss=0.957085\n",
      "Epoch 65 Training Loss=1.012120, Validation Loss=0.957366\n",
      "Epoch 66 Training Loss=1.012018, Validation Loss=0.957641\n",
      "Epoch 67 Training Loss=1.011917, Validation Loss=0.957911\n",
      "Epoch 68 Training Loss=1.011816, Validation Loss=0.958175\n",
      "Epoch 69 Training Loss=1.011716, Validation Loss=0.958434\n",
      "Epoch 70 Training Loss=1.011617, Validation Loss=0.958688\n",
      "Epoch 71 Training Loss=1.011518, Validation Loss=0.958938\n",
      "Epoch 72 Training Loss=1.011420, Validation Loss=0.959184\n",
      "Epoch 73 Training Loss=1.011323, Validation Loss=0.959424\n",
      "Epoch 74 Training Loss=1.011226, Validation Loss=0.959662\n",
      "Epoch 75 Training Loss=1.011129, Validation Loss=0.959894\n",
      "Epoch 76 Training Loss=1.011034, Validation Loss=0.960124\n",
      "Epoch 77 Training Loss=1.010938, Validation Loss=0.960349\n",
      "Epoch 78 Training Loss=1.010843, Validation Loss=0.960571\n",
      "Epoch 79 Training Loss=1.010749, Validation Loss=0.960790\n",
      "Epoch 80 Training Loss=1.010655, Validation Loss=0.961006\n",
      "Epoch 81 Training Loss=1.010562, Validation Loss=0.961218\n",
      "Epoch 82 Training Loss=1.010469, Validation Loss=0.961428\n",
      "Epoch 83 Training Loss=1.010377, Validation Loss=0.961634\n",
      "Epoch 84 Training Loss=1.010285, Validation Loss=0.961838\n",
      "Epoch 85 Training Loss=1.010194, Validation Loss=0.962039\n",
      "Epoch 86 Training Loss=1.010103, Validation Loss=0.962238\n",
      "Epoch 87 Training Loss=1.010012, Validation Loss=0.962434\n",
      "Epoch 88 Training Loss=1.009922, Validation Loss=0.962628\n",
      "Epoch 89 Training Loss=1.009832, Validation Loss=0.962820\n",
      "Epoch 90 Training Loss=1.009742, Validation Loss=0.963009\n",
      "Epoch 91 Training Loss=1.009653, Validation Loss=0.963196\n",
      "Epoch 92 Training Loss=1.009565, Validation Loss=0.963381\n",
      "Epoch 93 Training Loss=1.009476, Validation Loss=0.963564\n",
      "Epoch 94 Training Loss=1.009388, Validation Loss=0.963745\n",
      "Epoch 95 Training Loss=1.009301, Validation Loss=0.963925\n",
      "Epoch 96 Training Loss=1.009214, Validation Loss=0.964102\n",
      "Epoch 97 Training Loss=1.009127, Validation Loss=0.964278\n",
      "Epoch 98 Training Loss=1.009040, Validation Loss=0.964452\n",
      "Epoch 99 Training Loss=1.008954, Validation Loss=0.964624\n",
      "Epoch 100 Training Loss=1.008868, Validation Loss=0.964795\n",
      "Epoch 101 Training Loss=1.008783, Validation Loss=0.964965\n",
      "Epoch 102 Training Loss=1.008697, Validation Loss=0.965132\n",
      "Epoch 103 Training Loss=1.008612, Validation Loss=0.965299\n",
      "Epoch 104 Training Loss=1.008528, Validation Loss=0.965464\n",
      "Epoch 105 Training Loss=1.008443, Validation Loss=0.965627\n",
      "Epoch 106 Training Loss=1.008359, Validation Loss=0.965790\n",
      "Epoch 107 Training Loss=1.008275, Validation Loss=0.965951\n",
      "Epoch 108 Training Loss=1.008192, Validation Loss=0.966111\n",
      "Epoch 109 Training Loss=1.008108, Validation Loss=0.966269\n",
      "Epoch 110 Training Loss=1.008025, Validation Loss=0.966426\n",
      "Epoch 111 Training Loss=1.007943, Validation Loss=0.966583\n",
      "Epoch 112 Training Loss=1.007860, Validation Loss=0.966738\n",
      "Epoch 113 Training Loss=1.007778, Validation Loss=0.966892\n",
      "Epoch 114 Training Loss=1.007696, Validation Loss=0.967045\n",
      "Epoch 115 Training Loss=1.007614, Validation Loss=0.967196\n",
      "Epoch 116 Training Loss=1.007533, Validation Loss=0.967347\n",
      "Epoch 117 Training Loss=1.007452, Validation Loss=0.967497\n",
      "Epoch 118 Training Loss=1.007371, Validation Loss=0.967646\n",
      "Epoch 119 Training Loss=1.007290, Validation Loss=0.967794\n",
      "Epoch 120 Training Loss=1.007209, Validation Loss=0.967941\n",
      "Epoch 121 Training Loss=1.007129, Validation Loss=0.968087\n",
      "Epoch 122 Training Loss=1.007049, Validation Loss=0.968232\n",
      "Epoch 123 Training Loss=1.006969, Validation Loss=0.968377\n",
      "Epoch 124 Training Loss=1.006889, Validation Loss=0.968520\n",
      "Epoch 125 Training Loss=1.006810, Validation Loss=0.968663\n",
      "Epoch 126 Training Loss=1.006730, Validation Loss=0.968805\n",
      "Epoch 127 Training Loss=1.006651, Validation Loss=0.968946\n",
      "Epoch 128 Training Loss=1.006572, Validation Loss=0.969087\n",
      "Epoch 129 Training Loss=1.006494, Validation Loss=0.969226\n",
      "Epoch 130 Training Loss=1.006415, Validation Loss=0.969365\n",
      "Epoch 131 Training Loss=1.006337, Validation Loss=0.969503\n",
      "Epoch 132 Training Loss=1.006259, Validation Loss=0.969640\n",
      "Epoch 133 Training Loss=1.006181, Validation Loss=0.969777\n",
      "Epoch 134 Training Loss=1.006103, Validation Loss=0.969913\n",
      "Epoch 135 Training Loss=1.006025, Validation Loss=0.970048\n",
      "Epoch 136 Training Loss=1.005948, Validation Loss=0.970183\n",
      "Epoch 137 Training Loss=1.005870, Validation Loss=0.970317\n",
      "Epoch 138 Training Loss=1.005793, Validation Loss=0.970450\n",
      "Epoch 139 Training Loss=1.005716, Validation Loss=0.970583\n",
      "Epoch 140 Training Loss=1.005639, Validation Loss=0.970715\n",
      "Epoch 141 Training Loss=1.005563, Validation Loss=0.970846\n",
      "Epoch 142 Training Loss=1.005486, Validation Loss=0.970977\n",
      "Epoch 143 Training Loss=1.005410, Validation Loss=0.971107\n",
      "Epoch 144 Training Loss=1.005334, Validation Loss=0.971237\n",
      "Epoch 145 Training Loss=1.005258, Validation Loss=0.971366\n",
      "Epoch 146 Training Loss=1.005182, Validation Loss=0.971494\n",
      "Epoch 147 Training Loss=1.005106, Validation Loss=0.971622\n",
      "Epoch 148 Training Loss=1.005030, Validation Loss=0.971749\n",
      "Epoch 149 Training Loss=1.004955, Validation Loss=0.971876\n",
      "Epoch 150 Training Loss=1.004879, Validation Loss=0.972002\n",
      "Epoch 151 Training Loss=1.004804, Validation Loss=0.972128\n",
      "Epoch 152 Training Loss=1.004729, Validation Loss=0.972253\n",
      "Epoch 153 Training Loss=1.004654, Validation Loss=0.972378\n",
      "Epoch 154 Training Loss=1.004579, Validation Loss=0.972502\n",
      "Epoch 155 Training Loss=1.004504, Validation Loss=0.972626\n",
      "Epoch 156 Training Loss=1.004430, Validation Loss=0.972749\n",
      "Epoch 157 Training Loss=1.004355, Validation Loss=0.972871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 Training Loss=1.004281, Validation Loss=0.972994\n",
      "Epoch 159 Training Loss=1.004207, Validation Loss=0.973115\n",
      "Epoch 160 Training Loss=1.004133, Validation Loss=0.973236\n",
      "Epoch 161 Training Loss=1.004058, Validation Loss=0.973357\n",
      "Epoch 162 Training Loss=1.003985, Validation Loss=0.973478\n",
      "Epoch 163 Training Loss=1.003911, Validation Loss=0.973597\n",
      "Epoch 164 Training Loss=1.003837, Validation Loss=0.973717\n",
      "Epoch 165 Training Loss=1.003763, Validation Loss=0.973836\n",
      "Epoch 166 Training Loss=1.003690, Validation Loss=0.973954\n",
      "Epoch 167 Training Loss=1.003616, Validation Loss=0.974072\n",
      "Epoch 168 Training Loss=1.003543, Validation Loss=0.974190\n",
      "Epoch 169 Training Loss=1.003470, Validation Loss=0.974307\n",
      "Epoch 170 Training Loss=1.003397, Validation Loss=0.974424\n",
      "Epoch 171 Training Loss=1.003324, Validation Loss=0.974540\n",
      "Epoch 172 Training Loss=1.003251, Validation Loss=0.974656\n",
      "Epoch 173 Training Loss=1.003178, Validation Loss=0.974772\n",
      "Epoch 174 Training Loss=1.003105, Validation Loss=0.974887\n",
      "Epoch 175 Training Loss=1.003032, Validation Loss=0.975002\n",
      "Epoch 176 Training Loss=1.002960, Validation Loss=0.975117\n",
      "Epoch 177 Training Loss=1.002887, Validation Loss=0.975231\n",
      "Epoch 178 Training Loss=1.002815, Validation Loss=0.975344\n",
      "Epoch 179 Training Loss=1.002743, Validation Loss=0.975457\n",
      "Epoch 180 Training Loss=1.002670, Validation Loss=0.975570\n",
      "Epoch 181 Training Loss=1.002598, Validation Loss=0.975683\n",
      "Epoch 182 Training Loss=1.002526, Validation Loss=0.975795\n",
      "Epoch 183 Training Loss=1.002454, Validation Loss=0.975907\n",
      "Epoch 184 Training Loss=1.002382, Validation Loss=0.976018\n",
      "Epoch 185 Training Loss=1.002310, Validation Loss=0.976130\n",
      "Epoch 186 Training Loss=1.002238, Validation Loss=0.976240\n",
      "Epoch 187 Training Loss=1.002167, Validation Loss=0.976351\n",
      "Epoch 188 Training Loss=1.002095, Validation Loss=0.976461\n",
      "Epoch 189 Training Loss=1.002023, Validation Loss=0.976571\n",
      "Epoch 190 Training Loss=1.001952, Validation Loss=0.976680\n",
      "Epoch 191 Training Loss=1.001880, Validation Loss=0.976789\n",
      "Epoch 192 Training Loss=1.001809, Validation Loss=0.976898\n",
      "Epoch 193 Training Loss=1.001738, Validation Loss=0.977007\n",
      "Epoch 194 Training Loss=1.001666, Validation Loss=0.977115\n",
      "Epoch 195 Training Loss=1.001595, Validation Loss=0.977222\n",
      "Epoch 196 Training Loss=1.001524, Validation Loss=0.977330\n",
      "Epoch 197 Training Loss=1.001453, Validation Loss=0.977437\n",
      "Epoch 198 Training Loss=1.001382, Validation Loss=0.977544\n",
      "Epoch 199 Training Loss=1.001311, Validation Loss=0.977651\n",
      "Epoch 0 Training Loss=1.105929, Validation Loss=0.923180\n",
      "Epoch 1 Training Loss=1.088539, Validation Loss=0.921542\n",
      "Epoch 2 Training Loss=1.076027, Validation Loss=0.921064\n",
      "Epoch 3 Training Loss=1.066868, Validation Loss=0.921033\n",
      "Epoch 4 Training Loss=1.059842, Validation Loss=0.921160\n",
      "Epoch 5 Training Loss=1.054260, Validation Loss=0.921341\n",
      "Epoch 6 Training Loss=1.049713, Validation Loss=0.921545\n",
      "Epoch 7 Training Loss=1.045942, Validation Loss=0.921770\n",
      "Epoch 8 Training Loss=1.042776, Validation Loss=0.922022\n",
      "Epoch 9 Training Loss=1.040093, Validation Loss=0.922307\n",
      "Epoch 10 Training Loss=1.037803, Validation Loss=0.922627\n",
      "Epoch 11 Training Loss=1.035837, Validation Loss=0.922984\n",
      "Epoch 12 Training Loss=1.034140, Validation Loss=0.923375\n",
      "Epoch 13 Training Loss=1.032669, Validation Loss=0.923798\n",
      "Epoch 14 Training Loss=1.031388, Validation Loss=0.924250\n",
      "Epoch 15 Training Loss=1.030269, Validation Loss=0.924726\n",
      "Epoch 16 Training Loss=1.029287, Validation Loss=0.925224\n",
      "Epoch 17 Training Loss=1.028422, Validation Loss=0.925738\n",
      "Epoch 18 Training Loss=1.027657, Validation Loss=0.926266\n",
      "Epoch 19 Training Loss=1.026977, Validation Loss=0.926804\n",
      "Epoch 20 Training Loss=1.026371, Validation Loss=0.927351\n",
      "Epoch 21 Training Loss=1.025828, Validation Loss=0.927902\n",
      "Epoch 22 Training Loss=1.025339, Validation Loss=0.928457\n",
      "Epoch 23 Training Loss=1.024898, Validation Loss=0.929013\n",
      "Epoch 24 Training Loss=1.024497, Validation Loss=0.929568\n",
      "Epoch 25 Training Loss=1.024132, Validation Loss=0.930122\n",
      "Epoch 26 Training Loss=1.023797, Validation Loss=0.930673\n",
      "Epoch 27 Training Loss=1.023490, Validation Loss=0.931220\n",
      "Epoch 28 Training Loss=1.023205, Validation Loss=0.931763\n",
      "Epoch 29 Training Loss=1.022941, Validation Loss=0.932301\n",
      "Epoch 30 Training Loss=1.022695, Validation Loss=0.932833\n",
      "Epoch 31 Training Loss=1.022465, Validation Loss=0.933358\n",
      "Epoch 32 Training Loss=1.022249, Validation Loss=0.933878\n",
      "Epoch 33 Training Loss=1.022045, Validation Loss=0.934390\n",
      "Epoch 34 Training Loss=1.021852, Validation Loss=0.934896\n",
      "Epoch 35 Training Loss=1.021668, Validation Loss=0.935394\n",
      "Epoch 36 Training Loss=1.021493, Validation Loss=0.935886\n",
      "Epoch 37 Training Loss=1.021326, Validation Loss=0.936370\n",
      "Epoch 38 Training Loss=1.021165, Validation Loss=0.936846\n",
      "Epoch 39 Training Loss=1.021011, Validation Loss=0.937316\n",
      "Epoch 40 Training Loss=1.020862, Validation Loss=0.937778\n",
      "Epoch 41 Training Loss=1.020718, Validation Loss=0.938233\n",
      "Epoch 42 Training Loss=1.020579, Validation Loss=0.938680\n",
      "Epoch 43 Training Loss=1.020444, Validation Loss=0.939120\n",
      "Epoch 44 Training Loss=1.020312, Validation Loss=0.939553\n",
      "Epoch 45 Training Loss=1.020184, Validation Loss=0.939980\n",
      "Epoch 46 Training Loss=1.020059, Validation Loss=0.940399\n",
      "Epoch 47 Training Loss=1.019938, Validation Loss=0.940811\n",
      "Epoch 48 Training Loss=1.019818, Validation Loss=0.941217\n",
      "Epoch 49 Training Loss=1.019702, Validation Loss=0.941616\n",
      "Epoch 50 Training Loss=1.019588, Validation Loss=0.942008\n",
      "Epoch 51 Training Loss=1.019475, Validation Loss=0.942394\n",
      "Epoch 52 Training Loss=1.019365, Validation Loss=0.942774\n",
      "Epoch 53 Training Loss=1.019257, Validation Loss=0.943148\n",
      "Epoch 54 Training Loss=1.019151, Validation Loss=0.943515\n",
      "Epoch 55 Training Loss=1.019047, Validation Loss=0.943876\n",
      "Epoch 56 Training Loss=1.018944, Validation Loss=0.944232\n",
      "Epoch 57 Training Loss=1.018842, Validation Loss=0.944582\n",
      "Epoch 58 Training Loss=1.018742, Validation Loss=0.944926\n",
      "Epoch 59 Training Loss=1.018644, Validation Loss=0.945265\n",
      "Epoch 60 Training Loss=1.018547, Validation Loss=0.945598\n",
      "Epoch 61 Training Loss=1.018451, Validation Loss=0.945927\n",
      "Epoch 62 Training Loss=1.018356, Validation Loss=0.946249\n",
      "Epoch 63 Training Loss=1.018263, Validation Loss=0.946567\n",
      "Epoch 64 Training Loss=1.018170, Validation Loss=0.946880\n",
      "Epoch 65 Training Loss=1.018079, Validation Loss=0.947188\n",
      "Epoch 66 Training Loss=1.017989, Validation Loss=0.947492\n",
      "Epoch 67 Training Loss=1.017900, Validation Loss=0.947790\n",
      "Epoch 68 Training Loss=1.017811, Validation Loss=0.948084\n",
      "Epoch 69 Training Loss=1.017724, Validation Loss=0.948374\n",
      "Epoch 70 Training Loss=1.017638, Validation Loss=0.948659\n",
      "Epoch 71 Training Loss=1.017552, Validation Loss=0.948940\n",
      "Epoch 72 Training Loss=1.017468, Validation Loss=0.949217\n",
      "Epoch 73 Training Loss=1.017384, Validation Loss=0.949490\n",
      "Epoch 74 Training Loss=1.017301, Validation Loss=0.949759\n",
      "Epoch 75 Training Loss=1.017219, Validation Loss=0.950024\n",
      "Epoch 76 Training Loss=1.017138, Validation Loss=0.950285\n",
      "Epoch 77 Training Loss=1.017057, Validation Loss=0.950542\n",
      "Epoch 78 Training Loss=1.016977, Validation Loss=0.950796\n",
      "Epoch 79 Training Loss=1.016898, Validation Loss=0.951046\n",
      "Epoch 80 Training Loss=1.016820, Validation Loss=0.951293\n",
      "Epoch 81 Training Loss=1.016742, Validation Loss=0.951536\n",
      "Epoch 82 Training Loss=1.016665, Validation Loss=0.951776\n",
      "Epoch 83 Training Loss=1.016589, Validation Loss=0.952012\n",
      "Epoch 84 Training Loss=1.016513, Validation Loss=0.952246\n",
      "Epoch 85 Training Loss=1.016438, Validation Loss=0.952476\n",
      "Epoch 86 Training Loss=1.016363, Validation Loss=0.952703\n",
      "Epoch 87 Training Loss=1.016289, Validation Loss=0.952928\n",
      "Epoch 88 Training Loss=1.016216, Validation Loss=0.953149\n",
      "Epoch 89 Training Loss=1.016143, Validation Loss=0.953367\n",
      "Epoch 90 Training Loss=1.016071, Validation Loss=0.953583\n",
      "Epoch 91 Training Loss=1.015999, Validation Loss=0.953796\n",
      "Epoch 92 Training Loss=1.015928, Validation Loss=0.954006\n",
      "Epoch 93 Training Loss=1.015858, Validation Loss=0.954214\n",
      "Epoch 94 Training Loss=1.015788, Validation Loss=0.954419\n",
      "Epoch 95 Training Loss=1.015718, Validation Loss=0.954622\n",
      "Epoch 96 Training Loss=1.015649, Validation Loss=0.954822\n",
      "Epoch 97 Training Loss=1.015580, Validation Loss=0.955020\n",
      "Epoch 98 Training Loss=1.015512, Validation Loss=0.955215\n",
      "Epoch 99 Training Loss=1.015444, Validation Loss=0.955409\n",
      "Epoch 100 Training Loss=1.015377, Validation Loss=0.955599\n",
      "Epoch 101 Training Loss=1.015311, Validation Loss=0.955788\n",
      "Epoch 102 Training Loss=1.015244, Validation Loss=0.955975\n",
      "Epoch 103 Training Loss=1.015178, Validation Loss=0.956159\n",
      "Epoch 104 Training Loss=1.015113, Validation Loss=0.956342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Training Loss=1.015048, Validation Loss=0.956522\n",
      "Epoch 106 Training Loss=1.014984, Validation Loss=0.956701\n",
      "Epoch 107 Training Loss=1.014919, Validation Loss=0.956877\n",
      "Epoch 108 Training Loss=1.014856, Validation Loss=0.957052\n",
      "Epoch 109 Training Loss=1.014792, Validation Loss=0.957225\n",
      "Epoch 110 Training Loss=1.014729, Validation Loss=0.957396\n",
      "Epoch 111 Training Loss=1.014667, Validation Loss=0.957565\n",
      "Epoch 112 Training Loss=1.014604, Validation Loss=0.957733\n",
      "Epoch 113 Training Loss=1.014543, Validation Loss=0.957899\n",
      "Epoch 114 Training Loss=1.014481, Validation Loss=0.958063\n",
      "Epoch 115 Training Loss=1.014420, Validation Loss=0.958226\n",
      "Epoch 116 Training Loss=1.014359, Validation Loss=0.958387\n",
      "Epoch 117 Training Loss=1.014299, Validation Loss=0.958546\n",
      "Epoch 118 Training Loss=1.014239, Validation Loss=0.958705\n",
      "Epoch 119 Training Loss=1.014179, Validation Loss=0.958861\n",
      "Epoch 120 Training Loss=1.014120, Validation Loss=0.959016\n",
      "Epoch 121 Training Loss=1.014061, Validation Loss=0.959170\n",
      "Epoch 122 Training Loss=1.014002, Validation Loss=0.959322\n",
      "Epoch 123 Training Loss=1.013943, Validation Loss=0.959473\n",
      "Epoch 124 Training Loss=1.013885, Validation Loss=0.959622\n",
      "Epoch 125 Training Loss=1.013827, Validation Loss=0.959771\n",
      "Epoch 126 Training Loss=1.013770, Validation Loss=0.959918\n",
      "Epoch 127 Training Loss=1.013713, Validation Loss=0.960063\n",
      "Epoch 128 Training Loss=1.013656, Validation Loss=0.960208\n",
      "Epoch 129 Training Loss=1.013599, Validation Loss=0.960351\n",
      "Epoch 130 Training Loss=1.013543, Validation Loss=0.960493\n",
      "Epoch 131 Training Loss=1.013487, Validation Loss=0.960634\n",
      "Epoch 132 Training Loss=1.013431, Validation Loss=0.960774\n",
      "Epoch 133 Training Loss=1.013376, Validation Loss=0.960912\n",
      "Epoch 134 Training Loss=1.013320, Validation Loss=0.961050\n",
      "Epoch 135 Training Loss=1.013265, Validation Loss=0.961186\n",
      "Epoch 136 Training Loss=1.013211, Validation Loss=0.961322\n",
      "Epoch 137 Training Loss=1.013156, Validation Loss=0.961456\n",
      "Epoch 138 Training Loss=1.013102, Validation Loss=0.961590\n",
      "Epoch 139 Training Loss=1.013048, Validation Loss=0.961722\n",
      "Epoch 140 Training Loss=1.012995, Validation Loss=0.961854\n",
      "Epoch 141 Training Loss=1.012941, Validation Loss=0.961984\n",
      "Epoch 142 Training Loss=1.012888, Validation Loss=0.962114\n",
      "Epoch 143 Training Loss=1.012835, Validation Loss=0.962242\n",
      "Epoch 144 Training Loss=1.012783, Validation Loss=0.962370\n",
      "Epoch 145 Training Loss=1.012730, Validation Loss=0.962497\n",
      "Epoch 146 Training Loss=1.012678, Validation Loss=0.962623\n",
      "Epoch 147 Training Loss=1.012626, Validation Loss=0.962748\n",
      "Epoch 148 Training Loss=1.012574, Validation Loss=0.962872\n",
      "Epoch 149 Training Loss=1.012523, Validation Loss=0.962996\n",
      "Epoch 150 Training Loss=1.012471, Validation Loss=0.963119\n",
      "Epoch 151 Training Loss=1.012420, Validation Loss=0.963240\n",
      "Epoch 152 Training Loss=1.012369, Validation Loss=0.963362\n",
      "Epoch 153 Training Loss=1.012319, Validation Loss=0.963482\n",
      "Epoch 154 Training Loss=1.012268, Validation Loss=0.963602\n",
      "Epoch 155 Training Loss=1.012218, Validation Loss=0.963720\n",
      "Epoch 156 Training Loss=1.012168, Validation Loss=0.963839\n",
      "Epoch 157 Training Loss=1.012118, Validation Loss=0.963956\n",
      "Epoch 158 Training Loss=1.012068, Validation Loss=0.964073\n",
      "Epoch 159 Training Loss=1.012019, Validation Loss=0.964189\n",
      "Epoch 160 Training Loss=1.011970, Validation Loss=0.964304\n",
      "Epoch 161 Training Loss=1.011921, Validation Loss=0.964419\n",
      "Epoch 162 Training Loss=1.011872, Validation Loss=0.964533\n",
      "Epoch 163 Training Loss=1.011823, Validation Loss=0.964646\n",
      "Epoch 164 Training Loss=1.011775, Validation Loss=0.964759\n",
      "Epoch 165 Training Loss=1.011726, Validation Loss=0.964871\n",
      "Epoch 166 Training Loss=1.011678, Validation Loss=0.964983\n",
      "Epoch 167 Training Loss=1.011630, Validation Loss=0.965094\n",
      "Epoch 168 Training Loss=1.011582, Validation Loss=0.965205\n",
      "Epoch 169 Training Loss=1.011535, Validation Loss=0.965314\n",
      "Epoch 170 Training Loss=1.011487, Validation Loss=0.965424\n",
      "Epoch 171 Training Loss=1.011440, Validation Loss=0.965532\n",
      "Epoch 172 Training Loss=1.011393, Validation Loss=0.965640\n",
      "Epoch 173 Training Loss=1.011346, Validation Loss=0.965748\n",
      "Epoch 174 Training Loss=1.011299, Validation Loss=0.965855\n",
      "Epoch 175 Training Loss=1.011253, Validation Loss=0.965962\n",
      "Epoch 176 Training Loss=1.011206, Validation Loss=0.966068\n",
      "Epoch 177 Training Loss=1.011160, Validation Loss=0.966173\n",
      "Epoch 178 Training Loss=1.011114, Validation Loss=0.966278\n",
      "Epoch 179 Training Loss=1.011068, Validation Loss=0.966383\n",
      "Epoch 180 Training Loss=1.011022, Validation Loss=0.966487\n",
      "Epoch 181 Training Loss=1.010976, Validation Loss=0.966590\n",
      "Epoch 182 Training Loss=1.010931, Validation Loss=0.966694\n",
      "Epoch 183 Training Loss=1.010885, Validation Loss=0.966796\n",
      "Epoch 184 Training Loss=1.010840, Validation Loss=0.966898\n",
      "Epoch 185 Training Loss=1.010795, Validation Loss=0.967000\n",
      "Epoch 186 Training Loss=1.010750, Validation Loss=0.967101\n",
      "Epoch 187 Training Loss=1.010705, Validation Loss=0.967202\n",
      "Epoch 188 Training Loss=1.010660, Validation Loss=0.967303\n",
      "Epoch 189 Training Loss=1.010616, Validation Loss=0.967403\n",
      "Epoch 190 Training Loss=1.010571, Validation Loss=0.967502\n",
      "Epoch 191 Training Loss=1.010527, Validation Loss=0.967601\n",
      "Epoch 192 Training Loss=1.010483, Validation Loss=0.967700\n",
      "Epoch 193 Training Loss=1.010439, Validation Loss=0.967798\n",
      "Epoch 194 Training Loss=1.010395, Validation Loss=0.967896\n",
      "Epoch 195 Training Loss=1.010351, Validation Loss=0.967994\n",
      "Epoch 196 Training Loss=1.010307, Validation Loss=0.968091\n",
      "Epoch 197 Training Loss=1.010264, Validation Loss=0.968188\n",
      "Epoch 198 Training Loss=1.010221, Validation Loss=0.968284\n",
      "Epoch 199 Training Loss=1.010177, Validation Loss=0.968380\n",
      "Epoch 0 Training Loss=1.083268, Validation Loss=0.968291\n",
      "Epoch 1 Training Loss=1.067177, Validation Loss=0.953451\n",
      "Epoch 2 Training Loss=1.056163, Validation Loss=0.942715\n",
      "Epoch 3 Training Loss=1.048700, Validation Loss=0.934707\n",
      "Epoch 4 Training Loss=1.043462, Validation Loss=0.928606\n",
      "Epoch 5 Training Loss=1.039664, Validation Loss=0.923890\n",
      "Epoch 6 Training Loss=1.036826, Validation Loss=0.920214\n",
      "Epoch 7 Training Loss=1.034646, Validation Loss=0.917340\n",
      "Epoch 8 Training Loss=1.032928, Validation Loss=0.915095\n",
      "Epoch 9 Training Loss=1.031542, Validation Loss=0.913352\n",
      "Epoch 10 Training Loss=1.030401, Validation Loss=0.912011\n",
      "Epoch 11 Training Loss=1.029443, Validation Loss=0.910999\n",
      "Epoch 12 Training Loss=1.028625, Validation Loss=0.910255\n",
      "Epoch 13 Training Loss=1.027916, Validation Loss=0.909731\n",
      "Epoch 14 Training Loss=1.027292, Validation Loss=0.909390\n",
      "Epoch 15 Training Loss=1.026737, Validation Loss=0.909199\n",
      "Epoch 16 Training Loss=1.026238, Validation Loss=0.909133\n",
      "Epoch 17 Training Loss=1.025783, Validation Loss=0.909171\n",
      "Epoch 18 Training Loss=1.025366, Validation Loss=0.909296\n",
      "Epoch 19 Training Loss=1.024981, Validation Loss=0.909493\n",
      "Epoch 20 Training Loss=1.024622, Validation Loss=0.909750\n",
      "Epoch 21 Training Loss=1.024285, Validation Loss=0.910057\n",
      "Epoch 22 Training Loss=1.023968, Validation Loss=0.910406\n",
      "Epoch 23 Training Loss=1.023667, Validation Loss=0.910789\n",
      "Epoch 24 Training Loss=1.023380, Validation Loss=0.911200\n",
      "Epoch 25 Training Loss=1.023107, Validation Loss=0.911635\n",
      "Epoch 26 Training Loss=1.022844, Validation Loss=0.912090\n",
      "Epoch 27 Training Loss=1.022592, Validation Loss=0.912560\n",
      "Epoch 28 Training Loss=1.022348, Validation Loss=0.913042\n",
      "Epoch 29 Training Loss=1.022113, Validation Loss=0.913535\n",
      "Epoch 30 Training Loss=1.021885, Validation Loss=0.914036\n",
      "Epoch 31 Training Loss=1.021663, Validation Loss=0.914543\n",
      "Epoch 32 Training Loss=1.021448, Validation Loss=0.915054\n",
      "Epoch 33 Training Loss=1.021239, Validation Loss=0.915568\n",
      "Epoch 34 Training Loss=1.021034, Validation Loss=0.916085\n",
      "Epoch 35 Training Loss=1.020835, Validation Loss=0.916602\n",
      "Epoch 36 Training Loss=1.020641, Validation Loss=0.917120\n",
      "Epoch 37 Training Loss=1.020451, Validation Loss=0.917638\n",
      "Epoch 38 Training Loss=1.020265, Validation Loss=0.918154\n",
      "Epoch 39 Training Loss=1.020084, Validation Loss=0.918669\n",
      "Epoch 40 Training Loss=1.019906, Validation Loss=0.919182\n",
      "Epoch 41 Training Loss=1.019731, Validation Loss=0.919692\n",
      "Epoch 42 Training Loss=1.019560, Validation Loss=0.920200\n",
      "Epoch 43 Training Loss=1.019393, Validation Loss=0.920705\n",
      "Epoch 44 Training Loss=1.019229, Validation Loss=0.921206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training Loss=1.019067, Validation Loss=0.921705\n",
      "Epoch 46 Training Loss=1.018909, Validation Loss=0.922200\n",
      "Epoch 47 Training Loss=1.018754, Validation Loss=0.922691\n",
      "Epoch 48 Training Loss=1.018601, Validation Loss=0.923178\n",
      "Epoch 49 Training Loss=1.018452, Validation Loss=0.923662\n",
      "Epoch 50 Training Loss=1.018304, Validation Loss=0.924142\n",
      "Epoch 51 Training Loss=1.018160, Validation Loss=0.924618\n",
      "Epoch 52 Training Loss=1.018018, Validation Loss=0.925091\n",
      "Epoch 53 Training Loss=1.017878, Validation Loss=0.925559\n",
      "Epoch 54 Training Loss=1.017740, Validation Loss=0.926023\n",
      "Epoch 55 Training Loss=1.017605, Validation Loss=0.926483\n",
      "Epoch 56 Training Loss=1.017472, Validation Loss=0.926939\n",
      "Epoch 57 Training Loss=1.017341, Validation Loss=0.927391\n",
      "Epoch 58 Training Loss=1.017212, Validation Loss=0.927839\n",
      "Epoch 59 Training Loss=1.017086, Validation Loss=0.928283\n",
      "Epoch 60 Training Loss=1.016961, Validation Loss=0.928723\n",
      "Epoch 61 Training Loss=1.016838, Validation Loss=0.929159\n",
      "Epoch 62 Training Loss=1.016717, Validation Loss=0.929591\n",
      "Epoch 63 Training Loss=1.016597, Validation Loss=0.930019\n",
      "Epoch 64 Training Loss=1.016480, Validation Loss=0.930444\n",
      "Epoch 65 Training Loss=1.016364, Validation Loss=0.930864\n",
      "Epoch 66 Training Loss=1.016250, Validation Loss=0.931280\n",
      "Epoch 67 Training Loss=1.016137, Validation Loss=0.931693\n",
      "Epoch 68 Training Loss=1.016026, Validation Loss=0.932101\n",
      "Epoch 69 Training Loss=1.015916, Validation Loss=0.932506\n",
      "Epoch 70 Training Loss=1.015808, Validation Loss=0.932907\n",
      "Epoch 71 Training Loss=1.015702, Validation Loss=0.933305\n",
      "Epoch 72 Training Loss=1.015597, Validation Loss=0.933699\n",
      "Epoch 73 Training Loss=1.015493, Validation Loss=0.934089\n",
      "Epoch 74 Training Loss=1.015390, Validation Loss=0.934475\n",
      "Epoch 75 Training Loss=1.015289, Validation Loss=0.934858\n",
      "Epoch 76 Training Loss=1.015189, Validation Loss=0.935237\n",
      "Epoch 77 Training Loss=1.015090, Validation Loss=0.935613\n",
      "Epoch 78 Training Loss=1.014993, Validation Loss=0.935985\n",
      "Epoch 79 Training Loss=1.014896, Validation Loss=0.936354\n",
      "Epoch 80 Training Loss=1.014801, Validation Loss=0.936720\n",
      "Epoch 81 Training Loss=1.014707, Validation Loss=0.937082\n",
      "Epoch 82 Training Loss=1.014614, Validation Loss=0.937440\n",
      "Epoch 83 Training Loss=1.014521, Validation Loss=0.937795\n",
      "Epoch 84 Training Loss=1.014430, Validation Loss=0.938148\n",
      "Epoch 85 Training Loss=1.014340, Validation Loss=0.938496\n",
      "Epoch 86 Training Loss=1.014251, Validation Loss=0.938842\n",
      "Epoch 87 Training Loss=1.014163, Validation Loss=0.939184\n",
      "Epoch 88 Training Loss=1.014075, Validation Loss=0.939524\n",
      "Epoch 89 Training Loss=1.013989, Validation Loss=0.939860\n",
      "Epoch 90 Training Loss=1.013903, Validation Loss=0.940193\n",
      "Epoch 91 Training Loss=1.013818, Validation Loss=0.940523\n",
      "Epoch 92 Training Loss=1.013734, Validation Loss=0.940850\n",
      "Epoch 93 Training Loss=1.013651, Validation Loss=0.941174\n",
      "Epoch 94 Training Loss=1.013569, Validation Loss=0.941495\n",
      "Epoch 95 Training Loss=1.013487, Validation Loss=0.941813\n",
      "Epoch 96 Training Loss=1.013406, Validation Loss=0.942129\n",
      "Epoch 97 Training Loss=1.013325, Validation Loss=0.942441\n",
      "Epoch 98 Training Loss=1.013246, Validation Loss=0.942751\n",
      "Epoch 99 Training Loss=1.013167, Validation Loss=0.943058\n",
      "Epoch 100 Training Loss=1.013088, Validation Loss=0.943362\n",
      "Epoch 101 Training Loss=1.013011, Validation Loss=0.943663\n",
      "Epoch 102 Training Loss=1.012933, Validation Loss=0.943962\n",
      "Epoch 103 Training Loss=1.012857, Validation Loss=0.944258\n",
      "Epoch 104 Training Loss=1.012781, Validation Loss=0.944552\n",
      "Epoch 105 Training Loss=1.012705, Validation Loss=0.944843\n",
      "Epoch 106 Training Loss=1.012630, Validation Loss=0.945131\n",
      "Epoch 107 Training Loss=1.012556, Validation Loss=0.945417\n",
      "Epoch 108 Training Loss=1.012482, Validation Loss=0.945700\n",
      "Epoch 109 Training Loss=1.012408, Validation Loss=0.945981\n",
      "Epoch 110 Training Loss=1.012336, Validation Loss=0.946260\n",
      "Epoch 111 Training Loss=1.012263, Validation Loss=0.946536\n",
      "Epoch 112 Training Loss=1.012191, Validation Loss=0.946810\n",
      "Epoch 113 Training Loss=1.012119, Validation Loss=0.947081\n",
      "Epoch 114 Training Loss=1.012048, Validation Loss=0.947350\n",
      "Epoch 115 Training Loss=1.011977, Validation Loss=0.947617\n",
      "Epoch 116 Training Loss=1.011907, Validation Loss=0.947882\n",
      "Epoch 117 Training Loss=1.011837, Validation Loss=0.948144\n",
      "Epoch 118 Training Loss=1.011767, Validation Loss=0.948404\n",
      "Epoch 119 Training Loss=1.011698, Validation Loss=0.948662\n",
      "Epoch 120 Training Loss=1.011629, Validation Loss=0.948918\n",
      "Epoch 121 Training Loss=1.011561, Validation Loss=0.949172\n",
      "Epoch 122 Training Loss=1.011493, Validation Loss=0.949423\n",
      "Epoch 123 Training Loss=1.011425, Validation Loss=0.949673\n",
      "Epoch 124 Training Loss=1.011357, Validation Loss=0.949921\n",
      "Epoch 125 Training Loss=1.011290, Validation Loss=0.950166\n",
      "Epoch 126 Training Loss=1.011223, Validation Loss=0.950410\n",
      "Epoch 127 Training Loss=1.011156, Validation Loss=0.950652\n",
      "Epoch 128 Training Loss=1.011090, Validation Loss=0.950891\n",
      "Epoch 129 Training Loss=1.011024, Validation Loss=0.951129\n",
      "Epoch 130 Training Loss=1.010958, Validation Loss=0.951365\n",
      "Epoch 131 Training Loss=1.010892, Validation Loss=0.951599\n",
      "Epoch 132 Training Loss=1.010827, Validation Loss=0.951832\n",
      "Epoch 133 Training Loss=1.010761, Validation Loss=0.952062\n",
      "Epoch 134 Training Loss=1.010696, Validation Loss=0.952291\n",
      "Epoch 135 Training Loss=1.010632, Validation Loss=0.952518\n",
      "Epoch 136 Training Loss=1.010567, Validation Loss=0.952743\n",
      "Epoch 137 Training Loss=1.010503, Validation Loss=0.952967\n",
      "Epoch 138 Training Loss=1.010439, Validation Loss=0.953189\n",
      "Epoch 139 Training Loss=1.010375, Validation Loss=0.953409\n",
      "Epoch 140 Training Loss=1.010311, Validation Loss=0.953628\n",
      "Epoch 141 Training Loss=1.010248, Validation Loss=0.953845\n",
      "Epoch 142 Training Loss=1.010184, Validation Loss=0.954060\n",
      "Epoch 143 Training Loss=1.010121, Validation Loss=0.954274\n",
      "Epoch 144 Training Loss=1.010058, Validation Loss=0.954487\n",
      "Epoch 145 Training Loss=1.009995, Validation Loss=0.954698\n",
      "Epoch 146 Training Loss=1.009933, Validation Loss=0.954907\n",
      "Epoch 147 Training Loss=1.009870, Validation Loss=0.955115\n",
      "Epoch 148 Training Loss=1.009808, Validation Loss=0.955321\n",
      "Epoch 149 Training Loss=1.009745, Validation Loss=0.955526\n",
      "Epoch 150 Training Loss=1.009683, Validation Loss=0.955730\n",
      "Epoch 151 Training Loss=1.009621, Validation Loss=0.955932\n",
      "Epoch 152 Training Loss=1.009559, Validation Loss=0.956133\n",
      "Epoch 153 Training Loss=1.009497, Validation Loss=0.956332\n",
      "Epoch 154 Training Loss=1.009436, Validation Loss=0.956531\n",
      "Epoch 155 Training Loss=1.009374, Validation Loss=0.956727\n",
      "Epoch 156 Training Loss=1.009313, Validation Loss=0.956923\n",
      "Epoch 157 Training Loss=1.009251, Validation Loss=0.957117\n",
      "Epoch 158 Training Loss=1.009190, Validation Loss=0.957310\n",
      "Epoch 159 Training Loss=1.009129, Validation Loss=0.957502\n",
      "Epoch 160 Training Loss=1.009068, Validation Loss=0.957693\n",
      "Epoch 161 Training Loss=1.009007, Validation Loss=0.957882\n",
      "Epoch 162 Training Loss=1.008946, Validation Loss=0.958070\n",
      "Epoch 163 Training Loss=1.008885, Validation Loss=0.958257\n",
      "Epoch 164 Training Loss=1.008824, Validation Loss=0.958443\n",
      "Epoch 165 Training Loss=1.008763, Validation Loss=0.958628\n",
      "Epoch 166 Training Loss=1.008703, Validation Loss=0.958812\n",
      "Epoch 167 Training Loss=1.008642, Validation Loss=0.958994\n",
      "Epoch 168 Training Loss=1.008581, Validation Loss=0.959175\n",
      "Epoch 169 Training Loss=1.008521, Validation Loss=0.959356\n",
      "Epoch 170 Training Loss=1.008460, Validation Loss=0.959535\n",
      "Epoch 171 Training Loss=1.008400, Validation Loss=0.959714\n",
      "Epoch 172 Training Loss=1.008340, Validation Loss=0.959891\n",
      "Epoch 173 Training Loss=1.008279, Validation Loss=0.960067\n",
      "Epoch 174 Training Loss=1.008219, Validation Loss=0.960243\n",
      "Epoch 175 Training Loss=1.008159, Validation Loss=0.960417\n",
      "Epoch 176 Training Loss=1.008099, Validation Loss=0.960590\n",
      "Epoch 177 Training Loss=1.008039, Validation Loss=0.960763\n",
      "Epoch 178 Training Loss=1.007979, Validation Loss=0.960934\n",
      "Epoch 179 Training Loss=1.007918, Validation Loss=0.961105\n",
      "Epoch 180 Training Loss=1.007858, Validation Loss=0.961275\n",
      "Epoch 181 Training Loss=1.007798, Validation Loss=0.961444\n",
      "Epoch 182 Training Loss=1.007738, Validation Loss=0.961612\n",
      "Epoch 183 Training Loss=1.007678, Validation Loss=0.961779\n",
      "Epoch 184 Training Loss=1.007618, Validation Loss=0.961945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 Training Loss=1.007558, Validation Loss=0.962111\n",
      "Epoch 186 Training Loss=1.007498, Validation Loss=0.962275\n",
      "Epoch 187 Training Loss=1.007438, Validation Loss=0.962439\n",
      "Epoch 188 Training Loss=1.007378, Validation Loss=0.962602\n",
      "Epoch 189 Training Loss=1.007318, Validation Loss=0.962765\n",
      "Epoch 190 Training Loss=1.007258, Validation Loss=0.962926\n",
      "Epoch 191 Training Loss=1.007198, Validation Loss=0.963087\n",
      "Epoch 192 Training Loss=1.007138, Validation Loss=0.963247\n",
      "Epoch 193 Training Loss=1.007078, Validation Loss=0.963407\n",
      "Epoch 194 Training Loss=1.007019, Validation Loss=0.963565\n",
      "Epoch 195 Training Loss=1.006959, Validation Loss=0.963723\n",
      "Epoch 196 Training Loss=1.006899, Validation Loss=0.963881\n",
      "Epoch 197 Training Loss=1.006839, Validation Loss=0.964037\n",
      "Epoch 198 Training Loss=1.006778, Validation Loss=0.964193\n",
      "Epoch 199 Training Loss=1.006718, Validation Loss=0.964348\n",
      "Epoch 0 Training Loss=1.060081, Validation Loss=0.929262\n",
      "Epoch 1 Training Loss=1.048880, Validation Loss=0.922457\n",
      "Epoch 2 Training Loss=1.041913, Validation Loss=0.919130\n",
      "Epoch 3 Training Loss=1.037452, Validation Loss=0.917607\n",
      "Epoch 4 Training Loss=1.034405, Validation Loss=0.917058\n",
      "Epoch 5 Training Loss=1.032206, Validation Loss=0.917061\n",
      "Epoch 6 Training Loss=1.030542, Validation Loss=0.917389\n",
      "Epoch 7 Training Loss=1.029235, Validation Loss=0.917915\n",
      "Epoch 8 Training Loss=1.028174, Validation Loss=0.918565\n",
      "Epoch 9 Training Loss=1.027290, Validation Loss=0.919294\n",
      "Epoch 10 Training Loss=1.026538, Validation Loss=0.920073\n",
      "Epoch 11 Training Loss=1.025885, Validation Loss=0.920882\n",
      "Epoch 12 Training Loss=1.025310, Validation Loss=0.921708\n",
      "Epoch 13 Training Loss=1.024796, Validation Loss=0.922543\n",
      "Epoch 14 Training Loss=1.024332, Validation Loss=0.923380\n",
      "Epoch 15 Training Loss=1.023908, Validation Loss=0.924214\n",
      "Epoch 16 Training Loss=1.023518, Validation Loss=0.925042\n",
      "Epoch 17 Training Loss=1.023156, Validation Loss=0.925862\n",
      "Epoch 18 Training Loss=1.022818, Validation Loss=0.926671\n",
      "Epoch 19 Training Loss=1.022500, Validation Loss=0.927469\n",
      "Epoch 20 Training Loss=1.022201, Validation Loss=0.928254\n",
      "Epoch 21 Training Loss=1.021918, Validation Loss=0.929027\n",
      "Epoch 22 Training Loss=1.021649, Validation Loss=0.929786\n",
      "Epoch 23 Training Loss=1.021393, Validation Loss=0.930532\n",
      "Epoch 24 Training Loss=1.021148, Validation Loss=0.931263\n",
      "Epoch 25 Training Loss=1.020913, Validation Loss=0.931981\n",
      "Epoch 26 Training Loss=1.020688, Validation Loss=0.932685\n",
      "Epoch 27 Training Loss=1.020472, Validation Loss=0.933375\n",
      "Epoch 28 Training Loss=1.020264, Validation Loss=0.934051\n",
      "Epoch 29 Training Loss=1.020063, Validation Loss=0.934714\n",
      "Epoch 30 Training Loss=1.019869, Validation Loss=0.935363\n",
      "Epoch 31 Training Loss=1.019681, Validation Loss=0.935999\n",
      "Epoch 32 Training Loss=1.019499, Validation Loss=0.936622\n",
      "Epoch 33 Training Loss=1.019323, Validation Loss=0.937232\n",
      "Epoch 34 Training Loss=1.019153, Validation Loss=0.937829\n",
      "Epoch 35 Training Loss=1.018987, Validation Loss=0.938414\n",
      "Epoch 36 Training Loss=1.018826, Validation Loss=0.938987\n",
      "Epoch 37 Training Loss=1.018669, Validation Loss=0.939547\n",
      "Epoch 38 Training Loss=1.018517, Validation Loss=0.940096\n",
      "Epoch 39 Training Loss=1.018368, Validation Loss=0.940633\n",
      "Epoch 40 Training Loss=1.018223, Validation Loss=0.941160\n",
      "Epoch 41 Training Loss=1.018082, Validation Loss=0.941674\n",
      "Epoch 42 Training Loss=1.017943, Validation Loss=0.942179\n",
      "Epoch 43 Training Loss=1.017808, Validation Loss=0.942672\n",
      "Epoch 44 Training Loss=1.017676, Validation Loss=0.943155\n",
      "Epoch 45 Training Loss=1.017547, Validation Loss=0.943628\n",
      "Epoch 46 Training Loss=1.017420, Validation Loss=0.944091\n",
      "Epoch 47 Training Loss=1.017296, Validation Loss=0.944545\n",
      "Epoch 48 Training Loss=1.017174, Validation Loss=0.944989\n",
      "Epoch 49 Training Loss=1.017055, Validation Loss=0.945424\n",
      "Epoch 50 Training Loss=1.016938, Validation Loss=0.945849\n",
      "Epoch 51 Training Loss=1.016822, Validation Loss=0.946266\n",
      "Epoch 52 Training Loss=1.016709, Validation Loss=0.946675\n",
      "Epoch 53 Training Loss=1.016598, Validation Loss=0.947075\n",
      "Epoch 54 Training Loss=1.016488, Validation Loss=0.947467\n",
      "Epoch 55 Training Loss=1.016380, Validation Loss=0.947851\n",
      "Epoch 56 Training Loss=1.016274, Validation Loss=0.948227\n",
      "Epoch 57 Training Loss=1.016169, Validation Loss=0.948595\n",
      "Epoch 58 Training Loss=1.016066, Validation Loss=0.948956\n",
      "Epoch 59 Training Loss=1.015964, Validation Loss=0.949310\n",
      "Epoch 60 Training Loss=1.015864, Validation Loss=0.949657\n",
      "Epoch 61 Training Loss=1.015764, Validation Loss=0.949997\n",
      "Epoch 62 Training Loss=1.015666, Validation Loss=0.950331\n",
      "Epoch 63 Training Loss=1.015570, Validation Loss=0.950658\n",
      "Epoch 64 Training Loss=1.015474, Validation Loss=0.950978\n",
      "Epoch 65 Training Loss=1.015379, Validation Loss=0.951293\n",
      "Epoch 66 Training Loss=1.015286, Validation Loss=0.951601\n",
      "Epoch 67 Training Loss=1.015193, Validation Loss=0.951904\n",
      "Epoch 68 Training Loss=1.015102, Validation Loss=0.952201\n",
      "Epoch 69 Training Loss=1.015011, Validation Loss=0.952493\n",
      "Epoch 70 Training Loss=1.014921, Validation Loss=0.952779\n",
      "Epoch 71 Training Loss=1.014832, Validation Loss=0.953060\n",
      "Epoch 72 Training Loss=1.014744, Validation Loss=0.953336\n",
      "Epoch 73 Training Loss=1.014657, Validation Loss=0.953606\n",
      "Epoch 74 Training Loss=1.014570, Validation Loss=0.953872\n",
      "Epoch 75 Training Loss=1.014484, Validation Loss=0.954134\n",
      "Epoch 76 Training Loss=1.014399, Validation Loss=0.954390\n",
      "Epoch 77 Training Loss=1.014314, Validation Loss=0.954643\n",
      "Epoch 78 Training Loss=1.014230, Validation Loss=0.954890\n",
      "Epoch 79 Training Loss=1.014147, Validation Loss=0.955134\n",
      "Epoch 80 Training Loss=1.014065, Validation Loss=0.955374\n",
      "Epoch 81 Training Loss=1.013983, Validation Loss=0.955609\n",
      "Epoch 82 Training Loss=1.013901, Validation Loss=0.955841\n",
      "Epoch 83 Training Loss=1.013820, Validation Loss=0.956069\n",
      "Epoch 84 Training Loss=1.013740, Validation Loss=0.956293\n",
      "Epoch 85 Training Loss=1.013660, Validation Loss=0.956514\n",
      "Epoch 86 Training Loss=1.013580, Validation Loss=0.956731\n",
      "Epoch 87 Training Loss=1.013501, Validation Loss=0.956945\n",
      "Epoch 88 Training Loss=1.013423, Validation Loss=0.957155\n",
      "Epoch 89 Training Loss=1.013345, Validation Loss=0.957363\n",
      "Epoch 90 Training Loss=1.013267, Validation Loss=0.957567\n",
      "Epoch 91 Training Loss=1.013190, Validation Loss=0.957768\n",
      "Epoch 92 Training Loss=1.013114, Validation Loss=0.957966\n",
      "Epoch 93 Training Loss=1.013037, Validation Loss=0.958161\n",
      "Epoch 94 Training Loss=1.012961, Validation Loss=0.958354\n",
      "Epoch 95 Training Loss=1.012886, Validation Loss=0.958544\n",
      "Epoch 96 Training Loss=1.012811, Validation Loss=0.958731\n",
      "Epoch 97 Training Loss=1.012736, Validation Loss=0.958915\n",
      "Epoch 98 Training Loss=1.012661, Validation Loss=0.959097\n",
      "Epoch 99 Training Loss=1.012587, Validation Loss=0.959277\n",
      "Epoch 100 Training Loss=1.012513, Validation Loss=0.959454\n",
      "Epoch 101 Training Loss=1.012440, Validation Loss=0.959629\n",
      "Epoch 102 Training Loss=1.012367, Validation Loss=0.959801\n",
      "Epoch 103 Training Loss=1.012294, Validation Loss=0.959972\n",
      "Epoch 104 Training Loss=1.012221, Validation Loss=0.960140\n",
      "Epoch 105 Training Loss=1.012149, Validation Loss=0.960306\n",
      "Epoch 106 Training Loss=1.012077, Validation Loss=0.960471\n",
      "Epoch 107 Training Loss=1.012005, Validation Loss=0.960633\n",
      "Epoch 108 Training Loss=1.011934, Validation Loss=0.960793\n",
      "Epoch 109 Training Loss=1.011862, Validation Loss=0.960952\n",
      "Epoch 110 Training Loss=1.011792, Validation Loss=0.961108\n",
      "Epoch 111 Training Loss=1.011721, Validation Loss=0.961263\n",
      "Epoch 112 Training Loss=1.011650, Validation Loss=0.961416\n",
      "Epoch 113 Training Loss=1.011580, Validation Loss=0.961568\n",
      "Epoch 114 Training Loss=1.011510, Validation Loss=0.961718\n",
      "Epoch 115 Training Loss=1.011441, Validation Loss=0.961866\n",
      "Epoch 116 Training Loss=1.011371, Validation Loss=0.962013\n",
      "Epoch 117 Training Loss=1.011302, Validation Loss=0.962158\n",
      "Epoch 118 Training Loss=1.011233, Validation Loss=0.962302\n",
      "Epoch 119 Training Loss=1.011164, Validation Loss=0.962444\n",
      "Epoch 120 Training Loss=1.011095, Validation Loss=0.962585\n",
      "Epoch 121 Training Loss=1.011027, Validation Loss=0.962724\n",
      "Epoch 122 Training Loss=1.010959, Validation Loss=0.962863\n",
      "Epoch 123 Training Loss=1.010890, Validation Loss=0.963000\n",
      "Epoch 124 Training Loss=1.010823, Validation Loss=0.963135\n",
      "Epoch 125 Training Loss=1.010755, Validation Loss=0.963270\n",
      "Epoch 126 Training Loss=1.010687, Validation Loss=0.963403\n",
      "Epoch 127 Training Loss=1.010620, Validation Loss=0.963535\n",
      "Epoch 128 Training Loss=1.010553, Validation Loss=0.963666\n",
      "Epoch 129 Training Loss=1.010486, Validation Loss=0.963796\n",
      "Epoch 130 Training Loss=1.010419, Validation Loss=0.963925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 Training Loss=1.010353, Validation Loss=0.964053\n",
      "Epoch 132 Training Loss=1.010286, Validation Loss=0.964180\n",
      "Epoch 133 Training Loss=1.010220, Validation Loss=0.964306\n",
      "Epoch 134 Training Loss=1.010154, Validation Loss=0.964431\n",
      "Epoch 135 Training Loss=1.010088, Validation Loss=0.964555\n",
      "Epoch 136 Training Loss=1.010022, Validation Loss=0.964678\n",
      "Epoch 137 Training Loss=1.009956, Validation Loss=0.964800\n",
      "Epoch 138 Training Loss=1.009891, Validation Loss=0.964921\n",
      "Epoch 139 Training Loss=1.009825, Validation Loss=0.965042\n",
      "Epoch 140 Training Loss=1.009760, Validation Loss=0.965161\n",
      "Epoch 141 Training Loss=1.009695, Validation Loss=0.965280\n",
      "Epoch 142 Training Loss=1.009630, Validation Loss=0.965398\n",
      "Epoch 143 Training Loss=1.009565, Validation Loss=0.965515\n",
      "Epoch 144 Training Loss=1.009500, Validation Loss=0.965632\n",
      "Epoch 145 Training Loss=1.009436, Validation Loss=0.965748\n",
      "Epoch 146 Training Loss=1.009371, Validation Loss=0.965863\n",
      "Epoch 147 Training Loss=1.009307, Validation Loss=0.965977\n",
      "Epoch 148 Training Loss=1.009242, Validation Loss=0.966091\n",
      "Epoch 149 Training Loss=1.009178, Validation Loss=0.966204\n",
      "Epoch 150 Training Loss=1.009114, Validation Loss=0.966317\n",
      "Epoch 151 Training Loss=1.009050, Validation Loss=0.966428\n",
      "Epoch 152 Training Loss=1.008987, Validation Loss=0.966539\n",
      "Epoch 153 Training Loss=1.008923, Validation Loss=0.966650\n",
      "Epoch 154 Training Loss=1.008859, Validation Loss=0.966760\n",
      "Epoch 155 Training Loss=1.008796, Validation Loss=0.966869\n",
      "Epoch 156 Training Loss=1.008733, Validation Loss=0.966978\n",
      "Epoch 157 Training Loss=1.008669, Validation Loss=0.967087\n",
      "Epoch 158 Training Loss=1.008606, Validation Loss=0.967195\n",
      "Epoch 159 Training Loss=1.008543, Validation Loss=0.967302\n",
      "Epoch 160 Training Loss=1.008480, Validation Loss=0.967409\n",
      "Epoch 161 Training Loss=1.008417, Validation Loss=0.967515\n",
      "Epoch 162 Training Loss=1.008355, Validation Loss=0.967621\n",
      "Epoch 163 Training Loss=1.008292, Validation Loss=0.967726\n",
      "Epoch 164 Training Loss=1.008229, Validation Loss=0.967831\n",
      "Epoch 165 Training Loss=1.008167, Validation Loss=0.967936\n",
      "Epoch 166 Training Loss=1.008104, Validation Loss=0.968040\n",
      "Epoch 167 Training Loss=1.008042, Validation Loss=0.968143\n",
      "Epoch 168 Training Loss=1.007980, Validation Loss=0.968246\n",
      "Epoch 169 Training Loss=1.007918, Validation Loss=0.968349\n",
      "Epoch 170 Training Loss=1.007856, Validation Loss=0.968452\n",
      "Epoch 171 Training Loss=1.007794, Validation Loss=0.968554\n",
      "Epoch 172 Training Loss=1.007732, Validation Loss=0.968655\n",
      "Epoch 173 Training Loss=1.007670, Validation Loss=0.968757\n",
      "Epoch 174 Training Loss=1.007608, Validation Loss=0.968857\n",
      "Epoch 175 Training Loss=1.007546, Validation Loss=0.968958\n",
      "Epoch 176 Training Loss=1.007485, Validation Loss=0.969058\n",
      "Epoch 177 Training Loss=1.007423, Validation Loss=0.969158\n",
      "Epoch 178 Training Loss=1.007362, Validation Loss=0.969258\n",
      "Epoch 179 Training Loss=1.007300, Validation Loss=0.969357\n",
      "Epoch 180 Training Loss=1.007239, Validation Loss=0.969456\n",
      "Epoch 181 Training Loss=1.007178, Validation Loss=0.969554\n",
      "Epoch 182 Training Loss=1.007117, Validation Loss=0.969653\n",
      "Epoch 183 Training Loss=1.007055, Validation Loss=0.969751\n",
      "Epoch 184 Training Loss=1.006994, Validation Loss=0.969849\n",
      "Epoch 185 Training Loss=1.006933, Validation Loss=0.969946\n",
      "Epoch 186 Training Loss=1.006872, Validation Loss=0.970043\n",
      "Epoch 187 Training Loss=1.006812, Validation Loss=0.970140\n",
      "Epoch 188 Training Loss=1.006751, Validation Loss=0.970237\n",
      "Epoch 189 Training Loss=1.006690, Validation Loss=0.970333\n",
      "Epoch 190 Training Loss=1.006629, Validation Loss=0.970429\n",
      "Epoch 191 Training Loss=1.006569, Validation Loss=0.970525\n",
      "Epoch 192 Training Loss=1.006508, Validation Loss=0.970621\n",
      "Epoch 193 Training Loss=1.006447, Validation Loss=0.970716\n",
      "Epoch 194 Training Loss=1.006387, Validation Loss=0.970811\n",
      "Epoch 195 Training Loss=1.006326, Validation Loss=0.970906\n",
      "Epoch 196 Training Loss=1.006266, Validation Loss=0.971001\n",
      "Epoch 197 Training Loss=1.006206, Validation Loss=0.971096\n",
      "Epoch 198 Training Loss=1.006145, Validation Loss=0.971190\n",
      "Epoch 199 Training Loss=1.006085, Validation Loss=0.971284\n",
      "Epoch 0 Training Loss=1.097266, Validation Loss=0.954593\n",
      "Epoch 1 Training Loss=1.059169, Validation Loss=0.939897\n",
      "Epoch 2 Training Loss=1.042450, Validation Loss=0.935311\n",
      "Epoch 3 Training Loss=1.034425, Validation Loss=0.934419\n",
      "Epoch 4 Training Loss=1.030034, Validation Loss=0.934906\n",
      "Epoch 5 Training Loss=1.027349, Validation Loss=0.935896\n",
      "Epoch 6 Training Loss=1.025558, Validation Loss=0.937042\n",
      "Epoch 7 Training Loss=1.024281, Validation Loss=0.938204\n",
      "Epoch 8 Training Loss=1.023320, Validation Loss=0.939329\n",
      "Epoch 9 Training Loss=1.022565, Validation Loss=0.940400\n",
      "Epoch 10 Training Loss=1.021949, Validation Loss=0.941415\n",
      "Epoch 11 Training Loss=1.021431, Validation Loss=0.942377\n",
      "Epoch 12 Training Loss=1.020984, Validation Loss=0.943293\n",
      "Epoch 13 Training Loss=1.020590, Validation Loss=0.944166\n",
      "Epoch 14 Training Loss=1.020237, Validation Loss=0.945003\n",
      "Epoch 15 Training Loss=1.019917, Validation Loss=0.945807\n",
      "Epoch 16 Training Loss=1.019622, Validation Loss=0.946583\n",
      "Epoch 17 Training Loss=1.019349, Validation Loss=0.947332\n",
      "Epoch 18 Training Loss=1.019093, Validation Loss=0.948057\n",
      "Epoch 19 Training Loss=1.018852, Validation Loss=0.948759\n",
      "Epoch 20 Training Loss=1.018624, Validation Loss=0.949442\n",
      "Epoch 21 Training Loss=1.018408, Validation Loss=0.950105\n",
      "Epoch 22 Training Loss=1.018201, Validation Loss=0.950750\n",
      "Epoch 23 Training Loss=1.018003, Validation Loss=0.951378\n",
      "Epoch 24 Training Loss=1.017813, Validation Loss=0.951989\n",
      "Epoch 25 Training Loss=1.017630, Validation Loss=0.952585\n",
      "Epoch 26 Training Loss=1.017454, Validation Loss=0.953166\n",
      "Epoch 27 Training Loss=1.017283, Validation Loss=0.953732\n",
      "Epoch 28 Training Loss=1.017117, Validation Loss=0.954284\n",
      "Epoch 29 Training Loss=1.016956, Validation Loss=0.954823\n",
      "Epoch 30 Training Loss=1.016800, Validation Loss=0.955348\n",
      "Epoch 31 Training Loss=1.016648, Validation Loss=0.955861\n",
      "Epoch 32 Training Loss=1.016500, Validation Loss=0.956361\n",
      "Epoch 33 Training Loss=1.016355, Validation Loss=0.956849\n",
      "Epoch 34 Training Loss=1.016214, Validation Loss=0.957326\n",
      "Epoch 35 Training Loss=1.016076, Validation Loss=0.957791\n",
      "Epoch 36 Training Loss=1.015940, Validation Loss=0.958245\n",
      "Epoch 37 Training Loss=1.015808, Validation Loss=0.958688\n",
      "Epoch 38 Training Loss=1.015678, Validation Loss=0.959121\n",
      "Epoch 39 Training Loss=1.015550, Validation Loss=0.959543\n",
      "Epoch 40 Training Loss=1.015425, Validation Loss=0.959955\n",
      "Epoch 41 Training Loss=1.015302, Validation Loss=0.960358\n",
      "Epoch 42 Training Loss=1.015181, Validation Loss=0.960751\n",
      "Epoch 43 Training Loss=1.015061, Validation Loss=0.961134\n",
      "Epoch 44 Training Loss=1.014944, Validation Loss=0.961509\n",
      "Epoch 45 Training Loss=1.014828, Validation Loss=0.961874\n",
      "Epoch 46 Training Loss=1.014714, Validation Loss=0.962232\n",
      "Epoch 47 Training Loss=1.014601, Validation Loss=0.962580\n",
      "Epoch 48 Training Loss=1.014490, Validation Loss=0.962921\n",
      "Epoch 49 Training Loss=1.014380, Validation Loss=0.963254\n",
      "Epoch 50 Training Loss=1.014272, Validation Loss=0.963579\n",
      "Epoch 51 Training Loss=1.014164, Validation Loss=0.963896\n",
      "Epoch 52 Training Loss=1.014058, Validation Loss=0.964206\n",
      "Epoch 53 Training Loss=1.013953, Validation Loss=0.964509\n",
      "Epoch 54 Training Loss=1.013849, Validation Loss=0.964805\n",
      "Epoch 55 Training Loss=1.013746, Validation Loss=0.965094\n",
      "Epoch 56 Training Loss=1.013644, Validation Loss=0.965377\n",
      "Epoch 57 Training Loss=1.013543, Validation Loss=0.965653\n",
      "Epoch 58 Training Loss=1.013443, Validation Loss=0.965923\n",
      "Epoch 59 Training Loss=1.013344, Validation Loss=0.966187\n",
      "Epoch 60 Training Loss=1.013245, Validation Loss=0.966445\n",
      "Epoch 61 Training Loss=1.013147, Validation Loss=0.966697\n",
      "Epoch 62 Training Loss=1.013050, Validation Loss=0.966944\n",
      "Epoch 63 Training Loss=1.012954, Validation Loss=0.967185\n",
      "Epoch 64 Training Loss=1.012858, Validation Loss=0.967422\n",
      "Epoch 65 Training Loss=1.012763, Validation Loss=0.967653\n",
      "Epoch 66 Training Loss=1.012668, Validation Loss=0.967879\n",
      "Epoch 67 Training Loss=1.012574, Validation Loss=0.968100\n",
      "Epoch 68 Training Loss=1.012481, Validation Loss=0.968316\n",
      "Epoch 69 Training Loss=1.012388, Validation Loss=0.968528\n",
      "Epoch 70 Training Loss=1.012296, Validation Loss=0.968736\n",
      "Epoch 71 Training Loss=1.012204, Validation Loss=0.968939\n",
      "Epoch 72 Training Loss=1.012112, Validation Loss=0.969139\n",
      "Epoch 73 Training Loss=1.012021, Validation Loss=0.969334\n",
      "Epoch 74 Training Loss=1.011931, Validation Loss=0.969525\n",
      "Epoch 75 Training Loss=1.011840, Validation Loss=0.969712\n",
      "Epoch 76 Training Loss=1.011751, Validation Loss=0.969896\n",
      "Epoch 77 Training Loss=1.011661, Validation Loss=0.970076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Training Loss=1.011572, Validation Loss=0.970253\n",
      "Epoch 79 Training Loss=1.011484, Validation Loss=0.970426\n",
      "Epoch 80 Training Loss=1.011395, Validation Loss=0.970596\n",
      "Epoch 81 Training Loss=1.011307, Validation Loss=0.970763\n",
      "Epoch 82 Training Loss=1.011220, Validation Loss=0.970927\n",
      "Epoch 83 Training Loss=1.011132, Validation Loss=0.971087\n",
      "Epoch 84 Training Loss=1.011045, Validation Loss=0.971245\n",
      "Epoch 85 Training Loss=1.010958, Validation Loss=0.971400\n",
      "Epoch 86 Training Loss=1.010872, Validation Loss=0.971553\n",
      "Epoch 87 Training Loss=1.010786, Validation Loss=0.971703\n",
      "Epoch 88 Training Loss=1.010700, Validation Loss=0.971850\n",
      "Epoch 89 Training Loss=1.010614, Validation Loss=0.971994\n",
      "Epoch 90 Training Loss=1.010528, Validation Loss=0.972137\n",
      "Epoch 91 Training Loss=1.010443, Validation Loss=0.972277\n",
      "Epoch 92 Training Loss=1.010358, Validation Loss=0.972414\n",
      "Epoch 93 Training Loss=1.010273, Validation Loss=0.972550\n",
      "Epoch 94 Training Loss=1.010188, Validation Loss=0.972683\n",
      "Epoch 95 Training Loss=1.010104, Validation Loss=0.972814\n",
      "Epoch 96 Training Loss=1.010020, Validation Loss=0.972944\n",
      "Epoch 97 Training Loss=1.009936, Validation Loss=0.973071\n",
      "Epoch 98 Training Loss=1.009852, Validation Loss=0.973197\n",
      "Epoch 99 Training Loss=1.009768, Validation Loss=0.973321\n",
      "Epoch 100 Training Loss=1.009685, Validation Loss=0.973442\n",
      "Epoch 101 Training Loss=1.009601, Validation Loss=0.973563\n",
      "Epoch 102 Training Loss=1.009518, Validation Loss=0.973682\n",
      "Epoch 103 Training Loss=1.009435, Validation Loss=0.973799\n",
      "Epoch 104 Training Loss=1.009352, Validation Loss=0.973914\n",
      "Epoch 105 Training Loss=1.009270, Validation Loss=0.974028\n",
      "Epoch 106 Training Loss=1.009187, Validation Loss=0.974141\n",
      "Epoch 107 Training Loss=1.009105, Validation Loss=0.974252\n",
      "Epoch 108 Training Loss=1.009022, Validation Loss=0.974362\n",
      "Epoch 109 Training Loss=1.008940, Validation Loss=0.974471\n",
      "Epoch 110 Training Loss=1.008858, Validation Loss=0.974578\n",
      "Epoch 111 Training Loss=1.008776, Validation Loss=0.974684\n",
      "Epoch 112 Training Loss=1.008695, Validation Loss=0.974789\n",
      "Epoch 113 Training Loss=1.008613, Validation Loss=0.974893\n",
      "Epoch 114 Training Loss=1.008531, Validation Loss=0.974995\n",
      "Epoch 115 Training Loss=1.008450, Validation Loss=0.975097\n",
      "Epoch 116 Training Loss=1.008369, Validation Loss=0.975198\n",
      "Epoch 117 Training Loss=1.008288, Validation Loss=0.975297\n",
      "Epoch 118 Training Loss=1.008207, Validation Loss=0.975396\n",
      "Epoch 119 Training Loss=1.008126, Validation Loss=0.975494\n",
      "Epoch 120 Training Loss=1.008045, Validation Loss=0.975590\n",
      "Epoch 121 Training Loss=1.007964, Validation Loss=0.975686\n",
      "Epoch 122 Training Loss=1.007883, Validation Loss=0.975782\n",
      "Epoch 123 Training Loss=1.007803, Validation Loss=0.975876\n",
      "Epoch 124 Training Loss=1.007722, Validation Loss=0.975969\n",
      "Epoch 125 Training Loss=1.007642, Validation Loss=0.976062\n",
      "Epoch 126 Training Loss=1.007561, Validation Loss=0.976154\n",
      "Epoch 127 Training Loss=1.007481, Validation Loss=0.976246\n",
      "Epoch 128 Training Loss=1.007401, Validation Loss=0.976336\n",
      "Epoch 129 Training Loss=1.007321, Validation Loss=0.976426\n",
      "Epoch 130 Training Loss=1.007241, Validation Loss=0.976516\n",
      "Epoch 131 Training Loss=1.007161, Validation Loss=0.976605\n",
      "Epoch 132 Training Loss=1.007081, Validation Loss=0.976693\n",
      "Epoch 133 Training Loss=1.007002, Validation Loss=0.976781\n",
      "Epoch 134 Training Loss=1.006922, Validation Loss=0.976868\n",
      "Epoch 135 Training Loss=1.006842, Validation Loss=0.976955\n",
      "Epoch 136 Training Loss=1.006763, Validation Loss=0.977041\n",
      "Epoch 137 Training Loss=1.006683, Validation Loss=0.977126\n",
      "Epoch 138 Training Loss=1.006604, Validation Loss=0.977212\n",
      "Epoch 139 Training Loss=1.006524, Validation Loss=0.977297\n",
      "Epoch 140 Training Loss=1.006445, Validation Loss=0.977381\n",
      "Epoch 141 Training Loss=1.006366, Validation Loss=0.977465\n",
      "Epoch 142 Training Loss=1.006287, Validation Loss=0.977548\n",
      "Epoch 143 Training Loss=1.006207, Validation Loss=0.977632\n",
      "Epoch 144 Training Loss=1.006128, Validation Loss=0.977715\n",
      "Epoch 145 Training Loss=1.006049, Validation Loss=0.977797\n",
      "Epoch 146 Training Loss=1.005970, Validation Loss=0.977879\n",
      "Epoch 147 Training Loss=1.005891, Validation Loss=0.977961\n",
      "Epoch 148 Training Loss=1.005812, Validation Loss=0.978043\n",
      "Epoch 149 Training Loss=1.005734, Validation Loss=0.978124\n",
      "Epoch 150 Training Loss=1.005655, Validation Loss=0.978205\n",
      "Epoch 151 Training Loss=1.005576, Validation Loss=0.978286\n",
      "Epoch 152 Training Loss=1.005497, Validation Loss=0.978367\n",
      "Epoch 153 Training Loss=1.005419, Validation Loss=0.978447\n",
      "Epoch 154 Training Loss=1.005340, Validation Loss=0.978527\n",
      "Epoch 155 Training Loss=1.005262, Validation Loss=0.978607\n",
      "Epoch 156 Training Loss=1.005183, Validation Loss=0.978687\n",
      "Epoch 157 Training Loss=1.005105, Validation Loss=0.978766\n",
      "Epoch 158 Training Loss=1.005026, Validation Loss=0.978845\n",
      "Epoch 159 Training Loss=1.004948, Validation Loss=0.978925\n",
      "Epoch 160 Training Loss=1.004869, Validation Loss=0.979004\n",
      "Epoch 161 Training Loss=1.004791, Validation Loss=0.979083\n",
      "Epoch 162 Training Loss=1.004713, Validation Loss=0.979161\n",
      "Epoch 163 Training Loss=1.004634, Validation Loss=0.979240\n",
      "Epoch 164 Training Loss=1.004556, Validation Loss=0.979318\n",
      "Epoch 165 Training Loss=1.004478, Validation Loss=0.979397\n",
      "Epoch 166 Training Loss=1.004400, Validation Loss=0.979475\n",
      "Epoch 167 Training Loss=1.004322, Validation Loss=0.979553\n",
      "Epoch 168 Training Loss=1.004243, Validation Loss=0.979631\n",
      "Epoch 169 Training Loss=1.004165, Validation Loss=0.979709\n",
      "Epoch 170 Training Loss=1.004087, Validation Loss=0.979787\n",
      "Epoch 171 Training Loss=1.004009, Validation Loss=0.979865\n",
      "Epoch 172 Training Loss=1.003931, Validation Loss=0.979943\n",
      "Epoch 173 Training Loss=1.003853, Validation Loss=0.980021\n",
      "Epoch 174 Training Loss=1.003775, Validation Loss=0.980099\n",
      "Epoch 175 Training Loss=1.003697, Validation Loss=0.980176\n",
      "Epoch 176 Training Loss=1.003619, Validation Loss=0.980254\n",
      "Epoch 177 Training Loss=1.003541, Validation Loss=0.980331\n",
      "Epoch 178 Training Loss=1.003463, Validation Loss=0.980409\n",
      "Epoch 179 Training Loss=1.003386, Validation Loss=0.980487\n",
      "Epoch 180 Training Loss=1.003308, Validation Loss=0.980564\n",
      "Epoch 181 Training Loss=1.003230, Validation Loss=0.980642\n",
      "Epoch 182 Training Loss=1.003152, Validation Loss=0.980720\n",
      "Epoch 183 Training Loss=1.003074, Validation Loss=0.980797\n",
      "Epoch 184 Training Loss=1.002996, Validation Loss=0.980875\n",
      "Epoch 185 Training Loss=1.002919, Validation Loss=0.980953\n",
      "Epoch 186 Training Loss=1.002841, Validation Loss=0.981030\n",
      "Epoch 187 Training Loss=1.002763, Validation Loss=0.981108\n",
      "Epoch 188 Training Loss=1.002685, Validation Loss=0.981186\n",
      "Epoch 189 Training Loss=1.002608, Validation Loss=0.981263\n",
      "Epoch 190 Training Loss=1.002530, Validation Loss=0.981341\n",
      "Epoch 191 Training Loss=1.002452, Validation Loss=0.981419\n",
      "Epoch 192 Training Loss=1.002375, Validation Loss=0.981497\n",
      "Epoch 193 Training Loss=1.002297, Validation Loss=0.981575\n",
      "Epoch 194 Training Loss=1.002219, Validation Loss=0.981653\n",
      "Epoch 195 Training Loss=1.002142, Validation Loss=0.981731\n",
      "Epoch 196 Training Loss=1.002064, Validation Loss=0.981809\n",
      "Epoch 197 Training Loss=1.001986, Validation Loss=0.981887\n",
      "Epoch 198 Training Loss=1.001909, Validation Loss=0.981966\n",
      "Epoch 199 Training Loss=1.001831, Validation Loss=0.982044\n",
      "Epoch 0 Training Loss=1.084207, Validation Loss=1.004203\n",
      "Epoch 1 Training Loss=1.044460, Validation Loss=0.958331\n",
      "Epoch 2 Training Loss=1.034511, Validation Loss=0.940216\n",
      "Epoch 3 Training Loss=1.031242, Validation Loss=0.932754\n",
      "Epoch 4 Training Loss=1.029687, Validation Loss=0.929981\n",
      "Epoch 5 Training Loss=1.028667, Validation Loss=0.929416\n",
      "Epoch 6 Training Loss=1.027846, Validation Loss=0.929925\n",
      "Epoch 7 Training Loss=1.027118, Validation Loss=0.930955\n",
      "Epoch 8 Training Loss=1.026448, Validation Loss=0.932233\n",
      "Epoch 9 Training Loss=1.025824, Validation Loss=0.933614\n",
      "Epoch 10 Training Loss=1.025241, Validation Loss=0.935024\n",
      "Epoch 11 Training Loss=1.024693, Validation Loss=0.936425\n",
      "Epoch 12 Training Loss=1.024178, Validation Loss=0.937794\n",
      "Epoch 13 Training Loss=1.023694, Validation Loss=0.939123\n",
      "Epoch 14 Training Loss=1.023238, Validation Loss=0.940404\n",
      "Epoch 15 Training Loss=1.022807, Validation Loss=0.941637\n",
      "Epoch 16 Training Loss=1.022399, Validation Loss=0.942822\n",
      "Epoch 17 Training Loss=1.022012, Validation Loss=0.943958\n",
      "Epoch 18 Training Loss=1.021643, Validation Loss=0.945047\n",
      "Epoch 19 Training Loss=1.021292, Validation Loss=0.946091\n",
      "Epoch 20 Training Loss=1.020956, Validation Loss=0.947092\n",
      "Epoch 21 Training Loss=1.020635, Validation Loss=0.948051\n",
      "Epoch 22 Training Loss=1.020326, Validation Loss=0.948970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training Loss=1.020030, Validation Loss=0.949850\n",
      "Epoch 24 Training Loss=1.019744, Validation Loss=0.950695\n",
      "Epoch 25 Training Loss=1.019468, Validation Loss=0.951504\n",
      "Epoch 26 Training Loss=1.019202, Validation Loss=0.952281\n",
      "Epoch 27 Training Loss=1.018944, Validation Loss=0.953026\n",
      "Epoch 28 Training Loss=1.018693, Validation Loss=0.953741\n",
      "Epoch 29 Training Loss=1.018450, Validation Loss=0.954428\n",
      "Epoch 30 Training Loss=1.018213, Validation Loss=0.955088\n",
      "Epoch 31 Training Loss=1.017983, Validation Loss=0.955722\n",
      "Epoch 32 Training Loss=1.017758, Validation Loss=0.956332\n",
      "Epoch 33 Training Loss=1.017539, Validation Loss=0.956919\n",
      "Epoch 34 Training Loss=1.017325, Validation Loss=0.957484\n",
      "Epoch 35 Training Loss=1.017116, Validation Loss=0.958028\n",
      "Epoch 36 Training Loss=1.016911, Validation Loss=0.958552\n",
      "Epoch 37 Training Loss=1.016710, Validation Loss=0.959058\n",
      "Epoch 38 Training Loss=1.016513, Validation Loss=0.959546\n",
      "Epoch 39 Training Loss=1.016320, Validation Loss=0.960016\n",
      "Epoch 40 Training Loss=1.016131, Validation Loss=0.960471\n",
      "Epoch 41 Training Loss=1.015944, Validation Loss=0.960911\n",
      "Epoch 42 Training Loss=1.015761, Validation Loss=0.961336\n",
      "Epoch 43 Training Loss=1.015581, Validation Loss=0.961747\n",
      "Epoch 44 Training Loss=1.015404, Validation Loss=0.962145\n",
      "Epoch 45 Training Loss=1.015230, Validation Loss=0.962531\n",
      "Epoch 46 Training Loss=1.015058, Validation Loss=0.962905\n",
      "Epoch 47 Training Loss=1.014889, Validation Loss=0.963267\n",
      "Epoch 48 Training Loss=1.014723, Validation Loss=0.963619\n",
      "Epoch 49 Training Loss=1.014558, Validation Loss=0.963961\n",
      "Epoch 50 Training Loss=1.014396, Validation Loss=0.964293\n",
      "Epoch 51 Training Loss=1.014236, Validation Loss=0.964616\n",
      "Epoch 52 Training Loss=1.014078, Validation Loss=0.964930\n",
      "Epoch 53 Training Loss=1.013922, Validation Loss=0.965236\n",
      "Epoch 54 Training Loss=1.013768, Validation Loss=0.965534\n",
      "Epoch 55 Training Loss=1.013616, Validation Loss=0.965824\n",
      "Epoch 56 Training Loss=1.013466, Validation Loss=0.966107\n",
      "Epoch 57 Training Loss=1.013317, Validation Loss=0.966384\n",
      "Epoch 58 Training Loss=1.013170, Validation Loss=0.966653\n",
      "Epoch 59 Training Loss=1.013025, Validation Loss=0.966916\n",
      "Epoch 60 Training Loss=1.012881, Validation Loss=0.967174\n",
      "Epoch 61 Training Loss=1.012739, Validation Loss=0.967425\n",
      "Epoch 62 Training Loss=1.012598, Validation Loss=0.967671\n",
      "Epoch 63 Training Loss=1.012459, Validation Loss=0.967912\n",
      "Epoch 64 Training Loss=1.012321, Validation Loss=0.968148\n",
      "Epoch 65 Training Loss=1.012184, Validation Loss=0.968379\n",
      "Epoch 66 Training Loss=1.012049, Validation Loss=0.968605\n",
      "Epoch 67 Training Loss=1.011915, Validation Loss=0.968827\n",
      "Epoch 68 Training Loss=1.011782, Validation Loss=0.969044\n",
      "Epoch 69 Training Loss=1.011650, Validation Loss=0.969258\n",
      "Epoch 70 Training Loss=1.011520, Validation Loss=0.969467\n",
      "Epoch 71 Training Loss=1.011390, Validation Loss=0.969673\n",
      "Epoch 72 Training Loss=1.011262, Validation Loss=0.969875\n",
      "Epoch 73 Training Loss=1.011135, Validation Loss=0.970074\n",
      "Epoch 74 Training Loss=1.011009, Validation Loss=0.970269\n",
      "Epoch 75 Training Loss=1.010883, Validation Loss=0.970461\n",
      "Epoch 76 Training Loss=1.010759, Validation Loss=0.970651\n",
      "Epoch 77 Training Loss=1.010636, Validation Loss=0.970836\n",
      "Epoch 78 Training Loss=1.010514, Validation Loss=0.971020\n",
      "Epoch 79 Training Loss=1.010392, Validation Loss=0.971200\n",
      "Epoch 80 Training Loss=1.010272, Validation Loss=0.971378\n",
      "Epoch 81 Training Loss=1.010152, Validation Loss=0.971553\n",
      "Epoch 82 Training Loss=1.010034, Validation Loss=0.971725\n",
      "Epoch 83 Training Loss=1.009916, Validation Loss=0.971896\n",
      "Epoch 84 Training Loss=1.009799, Validation Loss=0.972063\n",
      "Epoch 85 Training Loss=1.009682, Validation Loss=0.972229\n",
      "Epoch 86 Training Loss=1.009567, Validation Loss=0.972392\n",
      "Epoch 87 Training Loss=1.009452, Validation Loss=0.972553\n",
      "Epoch 88 Training Loss=1.009338, Validation Loss=0.972713\n",
      "Epoch 89 Training Loss=1.009224, Validation Loss=0.972870\n",
      "Epoch 90 Training Loss=1.009112, Validation Loss=0.973025\n",
      "Epoch 91 Training Loss=1.009000, Validation Loss=0.973178\n",
      "Epoch 92 Training Loss=1.008889, Validation Loss=0.973330\n",
      "Epoch 93 Training Loss=1.008778, Validation Loss=0.973480\n",
      "Epoch 94 Training Loss=1.008668, Validation Loss=0.973628\n",
      "Epoch 95 Training Loss=1.008558, Validation Loss=0.973774\n",
      "Epoch 96 Training Loss=1.008450, Validation Loss=0.973919\n",
      "Epoch 97 Training Loss=1.008341, Validation Loss=0.974062\n",
      "Epoch 98 Training Loss=1.008234, Validation Loss=0.974204\n",
      "Epoch 99 Training Loss=1.008127, Validation Loss=0.974344\n",
      "Epoch 100 Training Loss=1.008020, Validation Loss=0.974482\n",
      "Epoch 101 Training Loss=1.007914, Validation Loss=0.974620\n",
      "Epoch 102 Training Loss=1.007809, Validation Loss=0.974756\n",
      "Epoch 103 Training Loss=1.007704, Validation Loss=0.974890\n",
      "Epoch 104 Training Loss=1.007600, Validation Loss=0.975023\n",
      "Epoch 105 Training Loss=1.007496, Validation Loss=0.975155\n",
      "Epoch 106 Training Loss=1.007392, Validation Loss=0.975286\n",
      "Epoch 107 Training Loss=1.007290, Validation Loss=0.975415\n",
      "Epoch 108 Training Loss=1.007187, Validation Loss=0.975544\n",
      "Epoch 109 Training Loss=1.007085, Validation Loss=0.975671\n",
      "Epoch 110 Training Loss=1.006984, Validation Loss=0.975797\n",
      "Epoch 111 Training Loss=1.006882, Validation Loss=0.975922\n",
      "Epoch 112 Training Loss=1.006782, Validation Loss=0.976046\n",
      "Epoch 113 Training Loss=1.006682, Validation Loss=0.976169\n",
      "Epoch 114 Training Loss=1.006582, Validation Loss=0.976291\n",
      "Epoch 115 Training Loss=1.006482, Validation Loss=0.976411\n",
      "Epoch 116 Training Loss=1.006383, Validation Loss=0.976531\n",
      "Epoch 117 Training Loss=1.006285, Validation Loss=0.976650\n",
      "Epoch 118 Training Loss=1.006187, Validation Loss=0.976768\n",
      "Epoch 119 Training Loss=1.006089, Validation Loss=0.976885\n",
      "Epoch 120 Training Loss=1.005991, Validation Loss=0.977001\n",
      "Epoch 121 Training Loss=1.005894, Validation Loss=0.977117\n",
      "Epoch 122 Training Loss=1.005798, Validation Loss=0.977231\n",
      "Epoch 123 Training Loss=1.005701, Validation Loss=0.977345\n",
      "Epoch 124 Training Loss=1.005605, Validation Loss=0.977458\n",
      "Epoch 125 Training Loss=1.005509, Validation Loss=0.977570\n",
      "Epoch 126 Training Loss=1.005414, Validation Loss=0.977681\n",
      "Epoch 127 Training Loss=1.005319, Validation Loss=0.977791\n",
      "Epoch 128 Training Loss=1.005224, Validation Loss=0.977901\n",
      "Epoch 129 Training Loss=1.005130, Validation Loss=0.978010\n",
      "Epoch 130 Training Loss=1.005036, Validation Loss=0.978118\n",
      "Epoch 131 Training Loss=1.004942, Validation Loss=0.978226\n",
      "Epoch 132 Training Loss=1.004848, Validation Loss=0.978333\n",
      "Epoch 133 Training Loss=1.004755, Validation Loss=0.978439\n",
      "Epoch 134 Training Loss=1.004662, Validation Loss=0.978545\n",
      "Epoch 135 Training Loss=1.004570, Validation Loss=0.978650\n",
      "Epoch 136 Training Loss=1.004477, Validation Loss=0.978754\n",
      "Epoch 137 Training Loss=1.004385, Validation Loss=0.978858\n",
      "Epoch 138 Training Loss=1.004293, Validation Loss=0.978961\n",
      "Epoch 139 Training Loss=1.004202, Validation Loss=0.979064\n",
      "Epoch 140 Training Loss=1.004111, Validation Loss=0.979166\n",
      "Epoch 141 Training Loss=1.004020, Validation Loss=0.979267\n",
      "Epoch 142 Training Loss=1.003929, Validation Loss=0.979368\n",
      "Epoch 143 Training Loss=1.003838, Validation Loss=0.979469\n",
      "Epoch 144 Training Loss=1.003748, Validation Loss=0.979568\n",
      "Epoch 145 Training Loss=1.003658, Validation Loss=0.979668\n",
      "Epoch 146 Training Loss=1.003568, Validation Loss=0.979767\n",
      "Epoch 147 Training Loss=1.003479, Validation Loss=0.979865\n",
      "Epoch 148 Training Loss=1.003389, Validation Loss=0.979963\n",
      "Epoch 149 Training Loss=1.003300, Validation Loss=0.980060\n",
      "Epoch 150 Training Loss=1.003211, Validation Loss=0.980157\n",
      "Epoch 151 Training Loss=1.003123, Validation Loss=0.980254\n",
      "Epoch 152 Training Loss=1.003034, Validation Loss=0.980350\n",
      "Epoch 153 Training Loss=1.002946, Validation Loss=0.980445\n",
      "Epoch 154 Training Loss=1.002858, Validation Loss=0.980541\n",
      "Epoch 155 Training Loss=1.002770, Validation Loss=0.980635\n",
      "Epoch 156 Training Loss=1.002682, Validation Loss=0.980730\n",
      "Epoch 157 Training Loss=1.002595, Validation Loss=0.980824\n",
      "Epoch 158 Training Loss=1.002508, Validation Loss=0.980917\n",
      "Epoch 159 Training Loss=1.002421, Validation Loss=0.981011\n",
      "Epoch 160 Training Loss=1.002334, Validation Loss=0.981104\n",
      "Epoch 161 Training Loss=1.002247, Validation Loss=0.981196\n",
      "Epoch 162 Training Loss=1.002161, Validation Loss=0.981288\n",
      "Epoch 163 Training Loss=1.002074, Validation Loss=0.981380\n",
      "Epoch 164 Training Loss=1.001988, Validation Loss=0.981472\n",
      "Epoch 165 Training Loss=1.001902, Validation Loss=0.981563\n",
      "Epoch 166 Training Loss=1.001817, Validation Loss=0.981654\n",
      "Epoch 167 Training Loss=1.001731, Validation Loss=0.981744\n",
      "Epoch 168 Training Loss=1.001646, Validation Loss=0.981835\n",
      "Epoch 169 Training Loss=1.001560, Validation Loss=0.981924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 Training Loss=1.001475, Validation Loss=0.982014\n",
      "Epoch 171 Training Loss=1.001391, Validation Loss=0.982104\n",
      "Epoch 172 Training Loss=1.001306, Validation Loss=0.982193\n",
      "Epoch 173 Training Loss=1.001221, Validation Loss=0.982282\n",
      "Epoch 174 Training Loss=1.001137, Validation Loss=0.982370\n",
      "Epoch 175 Training Loss=1.001053, Validation Loss=0.982458\n",
      "Epoch 176 Training Loss=1.000968, Validation Loss=0.982546\n",
      "Epoch 177 Training Loss=1.000885, Validation Loss=0.982634\n",
      "Epoch 178 Training Loss=1.000801, Validation Loss=0.982722\n",
      "Epoch 179 Training Loss=1.000717, Validation Loss=0.982809\n",
      "Epoch 180 Training Loss=1.000634, Validation Loss=0.982896\n",
      "Epoch 181 Training Loss=1.000550, Validation Loss=0.982983\n",
      "Epoch 182 Training Loss=1.000467, Validation Loss=0.983070\n",
      "Epoch 183 Training Loss=1.000384, Validation Loss=0.983156\n",
      "Epoch 184 Training Loss=1.000301, Validation Loss=0.983242\n",
      "Epoch 185 Training Loss=1.000218, Validation Loss=0.983329\n",
      "Epoch 186 Training Loss=1.000136, Validation Loss=0.983414\n",
      "Epoch 187 Training Loss=1.000053, Validation Loss=0.983500\n",
      "Epoch 188 Training Loss=0.999971, Validation Loss=0.983586\n",
      "Epoch 189 Training Loss=0.999888, Validation Loss=0.983671\n",
      "Epoch 190 Training Loss=0.999806, Validation Loss=0.983756\n",
      "Epoch 191 Training Loss=0.999724, Validation Loss=0.983841\n",
      "Epoch 192 Training Loss=0.999643, Validation Loss=0.983926\n",
      "Epoch 193 Training Loss=0.999561, Validation Loss=0.984010\n",
      "Epoch 194 Training Loss=0.999479, Validation Loss=0.984095\n",
      "Epoch 195 Training Loss=0.999398, Validation Loss=0.984179\n",
      "Epoch 196 Training Loss=0.999316, Validation Loss=0.984263\n",
      "Epoch 197 Training Loss=0.999235, Validation Loss=0.984347\n",
      "Epoch 198 Training Loss=0.999154, Validation Loss=0.984431\n",
      "Epoch 199 Training Loss=0.999073, Validation Loss=0.984515\n",
      "Epoch 0 Training Loss=1.056739, Validation Loss=0.940042\n",
      "Epoch 1 Training Loss=1.038740, Validation Loss=0.934750\n",
      "Epoch 2 Training Loss=1.031295, Validation Loss=0.932922\n",
      "Epoch 3 Training Loss=1.027475, Validation Loss=0.932814\n",
      "Epoch 4 Training Loss=1.025186, Validation Loss=0.933657\n",
      "Epoch 5 Training Loss=1.023649, Validation Loss=0.935015\n",
      "Epoch 6 Training Loss=1.022525, Validation Loss=0.936632\n",
      "Epoch 7 Training Loss=1.021648, Validation Loss=0.938361\n",
      "Epoch 8 Training Loss=1.020930, Validation Loss=0.940113\n",
      "Epoch 9 Training Loss=1.020322, Validation Loss=0.941841\n",
      "Epoch 10 Training Loss=1.019794, Validation Loss=0.943516\n",
      "Epoch 11 Training Loss=1.019326, Validation Loss=0.945123\n",
      "Epoch 12 Training Loss=1.018905, Validation Loss=0.946655\n",
      "Epoch 13 Training Loss=1.018521, Validation Loss=0.948108\n",
      "Epoch 14 Training Loss=1.018168, Validation Loss=0.949484\n",
      "Epoch 15 Training Loss=1.017841, Validation Loss=0.950783\n",
      "Epoch 16 Training Loss=1.017534, Validation Loss=0.952010\n",
      "Epoch 17 Training Loss=1.017246, Validation Loss=0.953167\n",
      "Epoch 18 Training Loss=1.016973, Validation Loss=0.954258\n",
      "Epoch 19 Training Loss=1.016713, Validation Loss=0.955287\n",
      "Epoch 20 Training Loss=1.016464, Validation Loss=0.956258\n",
      "Epoch 21 Training Loss=1.016225, Validation Loss=0.957175\n",
      "Epoch 22 Training Loss=1.015995, Validation Loss=0.958040\n",
      "Epoch 23 Training Loss=1.015772, Validation Loss=0.958858\n",
      "Epoch 24 Training Loss=1.015555, Validation Loss=0.959631\n",
      "Epoch 25 Training Loss=1.015345, Validation Loss=0.960363\n",
      "Epoch 26 Training Loss=1.015139, Validation Loss=0.961057\n",
      "Epoch 27 Training Loss=1.014939, Validation Loss=0.961714\n",
      "Epoch 28 Training Loss=1.014742, Validation Loss=0.962339\n",
      "Epoch 29 Training Loss=1.014549, Validation Loss=0.962932\n",
      "Epoch 30 Training Loss=1.014359, Validation Loss=0.963497\n",
      "Epoch 31 Training Loss=1.014173, Validation Loss=0.964034\n",
      "Epoch 32 Training Loss=1.013989, Validation Loss=0.964547\n",
      "Epoch 33 Training Loss=1.013808, Validation Loss=0.965037\n",
      "Epoch 34 Training Loss=1.013629, Validation Loss=0.965506\n",
      "Epoch 35 Training Loss=1.013453, Validation Loss=0.965954\n",
      "Epoch 36 Training Loss=1.013278, Validation Loss=0.966384\n",
      "Epoch 37 Training Loss=1.013105, Validation Loss=0.966796\n",
      "Epoch 38 Training Loss=1.012934, Validation Loss=0.967193\n",
      "Epoch 39 Training Loss=1.012765, Validation Loss=0.967575\n",
      "Epoch 40 Training Loss=1.012597, Validation Loss=0.967942\n",
      "Epoch 41 Training Loss=1.012431, Validation Loss=0.968297\n",
      "Epoch 42 Training Loss=1.012266, Validation Loss=0.968640\n",
      "Epoch 43 Training Loss=1.012103, Validation Loss=0.968971\n",
      "Epoch 44 Training Loss=1.011941, Validation Loss=0.969293\n",
      "Epoch 45 Training Loss=1.011780, Validation Loss=0.969604\n",
      "Epoch 46 Training Loss=1.011620, Validation Loss=0.969906\n",
      "Epoch 47 Training Loss=1.011462, Validation Loss=0.970200\n",
      "Epoch 48 Training Loss=1.011304, Validation Loss=0.970486\n",
      "Epoch 49 Training Loss=1.011148, Validation Loss=0.970764\n",
      "Epoch 50 Training Loss=1.010992, Validation Loss=0.971035\n",
      "Epoch 51 Training Loss=1.010838, Validation Loss=0.971300\n",
      "Epoch 52 Training Loss=1.010684, Validation Loss=0.971559\n",
      "Epoch 53 Training Loss=1.010531, Validation Loss=0.971812\n",
      "Epoch 54 Training Loss=1.010380, Validation Loss=0.972060\n",
      "Epoch 55 Training Loss=1.010229, Validation Loss=0.972302\n",
      "Epoch 56 Training Loss=1.010078, Validation Loss=0.972540\n",
      "Epoch 57 Training Loss=1.009929, Validation Loss=0.972773\n",
      "Epoch 58 Training Loss=1.009780, Validation Loss=0.973003\n",
      "Epoch 59 Training Loss=1.009633, Validation Loss=0.973228\n",
      "Epoch 60 Training Loss=1.009485, Validation Loss=0.973449\n",
      "Epoch 61 Training Loss=1.009339, Validation Loss=0.973667\n",
      "Epoch 62 Training Loss=1.009193, Validation Loss=0.973881\n",
      "Epoch 63 Training Loss=1.009048, Validation Loss=0.974092\n",
      "Epoch 64 Training Loss=1.008904, Validation Loss=0.974301\n",
      "Epoch 65 Training Loss=1.008760, Validation Loss=0.974506\n",
      "Epoch 66 Training Loss=1.008617, Validation Loss=0.974708\n",
      "Epoch 67 Training Loss=1.008474, Validation Loss=0.974908\n",
      "Epoch 68 Training Loss=1.008332, Validation Loss=0.975106\n",
      "Epoch 69 Training Loss=1.008190, Validation Loss=0.975301\n",
      "Epoch 70 Training Loss=1.008049, Validation Loss=0.975494\n",
      "Epoch 71 Training Loss=1.007909, Validation Loss=0.975685\n",
      "Epoch 72 Training Loss=1.007769, Validation Loss=0.975873\n",
      "Epoch 73 Training Loss=1.007630, Validation Loss=0.976060\n",
      "Epoch 74 Training Loss=1.007491, Validation Loss=0.976244\n",
      "Epoch 75 Training Loss=1.007353, Validation Loss=0.976428\n",
      "Epoch 76 Training Loss=1.007215, Validation Loss=0.976609\n",
      "Epoch 77 Training Loss=1.007077, Validation Loss=0.976788\n",
      "Epoch 78 Training Loss=1.006940, Validation Loss=0.976966\n",
      "Epoch 79 Training Loss=1.006804, Validation Loss=0.977142\n",
      "Epoch 80 Training Loss=1.006667, Validation Loss=0.977317\n",
      "Epoch 81 Training Loss=1.006532, Validation Loss=0.977491\n",
      "Epoch 82 Training Loss=1.006396, Validation Loss=0.977663\n",
      "Epoch 83 Training Loss=1.006261, Validation Loss=0.977834\n",
      "Epoch 84 Training Loss=1.006127, Validation Loss=0.978003\n",
      "Epoch 85 Training Loss=1.005993, Validation Loss=0.978171\n",
      "Epoch 86 Training Loss=1.005859, Validation Loss=0.978338\n",
      "Epoch 87 Training Loss=1.005725, Validation Loss=0.978504\n",
      "Epoch 88 Training Loss=1.005592, Validation Loss=0.978669\n",
      "Epoch 89 Training Loss=1.005460, Validation Loss=0.978832\n",
      "Epoch 90 Training Loss=1.005327, Validation Loss=0.978995\n",
      "Epoch 91 Training Loss=1.005195, Validation Loss=0.979156\n",
      "Epoch 92 Training Loss=1.005063, Validation Loss=0.979316\n",
      "Epoch 93 Training Loss=1.004932, Validation Loss=0.979476\n",
      "Epoch 94 Training Loss=1.004801, Validation Loss=0.979634\n",
      "Epoch 95 Training Loss=1.004670, Validation Loss=0.979792\n",
      "Epoch 96 Training Loss=1.004539, Validation Loss=0.979948\n",
      "Epoch 97 Training Loss=1.004409, Validation Loss=0.980104\n",
      "Epoch 98 Training Loss=1.004279, Validation Loss=0.980259\n",
      "Epoch 99 Training Loss=1.004149, Validation Loss=0.980413\n",
      "Epoch 100 Training Loss=1.004020, Validation Loss=0.980567\n",
      "Epoch 101 Training Loss=1.003891, Validation Loss=0.980719\n",
      "Epoch 102 Training Loss=1.003762, Validation Loss=0.980871\n",
      "Epoch 103 Training Loss=1.003633, Validation Loss=0.981022\n",
      "Epoch 104 Training Loss=1.003505, Validation Loss=0.981172\n",
      "Epoch 105 Training Loss=1.003377, Validation Loss=0.981322\n",
      "Epoch 106 Training Loss=1.003249, Validation Loss=0.981471\n",
      "Epoch 107 Training Loss=1.003121, Validation Loss=0.981619\n",
      "Epoch 108 Training Loss=1.002994, Validation Loss=0.981767\n",
      "Epoch 109 Training Loss=1.002867, Validation Loss=0.981914\n",
      "Epoch 110 Training Loss=1.002740, Validation Loss=0.982060\n",
      "Epoch 111 Training Loss=1.002613, Validation Loss=0.982206\n",
      "Epoch 112 Training Loss=1.002486, Validation Loss=0.982351\n",
      "Epoch 113 Training Loss=1.002360, Validation Loss=0.982496\n",
      "Epoch 114 Training Loss=1.002234, Validation Loss=0.982640\n",
      "Epoch 115 Training Loss=1.002108, Validation Loss=0.982783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 Training Loss=1.001982, Validation Loss=0.982926\n",
      "Epoch 117 Training Loss=1.001857, Validation Loss=0.983069\n",
      "Epoch 118 Training Loss=1.001731, Validation Loss=0.983211\n",
      "Epoch 119 Training Loss=1.001606, Validation Loss=0.983352\n",
      "Epoch 120 Training Loss=1.001481, Validation Loss=0.983493\n",
      "Epoch 121 Training Loss=1.001356, Validation Loss=0.983634\n",
      "Epoch 122 Training Loss=1.001232, Validation Loss=0.983774\n",
      "Epoch 123 Training Loss=1.001107, Validation Loss=0.983914\n",
      "Epoch 124 Training Loss=1.000983, Validation Loss=0.984053\n",
      "Epoch 125 Training Loss=1.000859, Validation Loss=0.984192\n",
      "Epoch 126 Training Loss=1.000735, Validation Loss=0.984330\n",
      "Epoch 127 Training Loss=1.000612, Validation Loss=0.984468\n",
      "Epoch 128 Training Loss=1.000488, Validation Loss=0.984606\n",
      "Epoch 129 Training Loss=1.000365, Validation Loss=0.984743\n",
      "Epoch 130 Training Loss=1.000241, Validation Loss=0.984880\n",
      "Epoch 131 Training Loss=1.000118, Validation Loss=0.985017\n",
      "Epoch 132 Training Loss=0.999995, Validation Loss=0.985153\n",
      "Epoch 133 Training Loss=0.999873, Validation Loss=0.985289\n",
      "Epoch 134 Training Loss=0.999750, Validation Loss=0.985425\n",
      "Epoch 135 Training Loss=0.999627, Validation Loss=0.985560\n",
      "Epoch 136 Training Loss=0.999505, Validation Loss=0.985695\n",
      "Epoch 137 Training Loss=0.999383, Validation Loss=0.985830\n",
      "Epoch 138 Training Loss=0.999261, Validation Loss=0.985965\n",
      "Epoch 139 Training Loss=0.999139, Validation Loss=0.986099\n",
      "Epoch 140 Training Loss=0.999017, Validation Loss=0.986233\n",
      "Epoch 141 Training Loss=0.998896, Validation Loss=0.986367\n",
      "Epoch 142 Training Loss=0.998774, Validation Loss=0.986500\n",
      "Epoch 143 Training Loss=0.998653, Validation Loss=0.986634\n",
      "Epoch 144 Training Loss=0.998532, Validation Loss=0.986767\n",
      "Epoch 145 Training Loss=0.998411, Validation Loss=0.986899\n",
      "Epoch 146 Training Loss=0.998290, Validation Loss=0.987032\n",
      "Epoch 147 Training Loss=0.998169, Validation Loss=0.987165\n",
      "Epoch 148 Training Loss=0.998048, Validation Loss=0.987297\n",
      "Epoch 149 Training Loss=0.997928, Validation Loss=0.987429\n",
      "Epoch 150 Training Loss=0.997807, Validation Loss=0.987561\n",
      "Epoch 151 Training Loss=0.997687, Validation Loss=0.987692\n",
      "Epoch 152 Training Loss=0.997567, Validation Loss=0.987824\n",
      "Epoch 153 Training Loss=0.997446, Validation Loss=0.987955\n",
      "Epoch 154 Training Loss=0.997327, Validation Loss=0.988087\n",
      "Epoch 155 Training Loss=0.997207, Validation Loss=0.988218\n",
      "Epoch 156 Training Loss=0.997087, Validation Loss=0.988348\n",
      "Epoch 157 Training Loss=0.996967, Validation Loss=0.988480\n",
      "Epoch 158 Training Loss=0.996848, Validation Loss=0.988610\n",
      "Epoch 159 Training Loss=0.996729, Validation Loss=0.988741\n",
      "Epoch 160 Training Loss=0.996609, Validation Loss=0.988871\n",
      "Epoch 161 Training Loss=0.996490, Validation Loss=0.989001\n",
      "Epoch 162 Training Loss=0.996371, Validation Loss=0.989132\n",
      "Epoch 163 Training Loss=0.996252, Validation Loss=0.989262\n",
      "Epoch 164 Training Loss=0.996133, Validation Loss=0.989392\n",
      "Epoch 165 Training Loss=0.996015, Validation Loss=0.989522\n",
      "Epoch 166 Training Loss=0.995896, Validation Loss=0.989652\n",
      "Epoch 167 Training Loss=0.995778, Validation Loss=0.989782\n",
      "Epoch 168 Training Loss=0.995659, Validation Loss=0.989912\n",
      "Epoch 169 Training Loss=0.995541, Validation Loss=0.990041\n",
      "Epoch 170 Training Loss=0.995423, Validation Loss=0.990171\n",
      "Epoch 171 Training Loss=0.995305, Validation Loss=0.990301\n",
      "Epoch 172 Training Loss=0.995187, Validation Loss=0.990431\n",
      "Epoch 173 Training Loss=0.995069, Validation Loss=0.990560\n",
      "Epoch 174 Training Loss=0.994952, Validation Loss=0.990690\n",
      "Epoch 175 Training Loss=0.994834, Validation Loss=0.990819\n",
      "Epoch 176 Training Loss=0.994716, Validation Loss=0.990949\n",
      "Epoch 177 Training Loss=0.994599, Validation Loss=0.991078\n",
      "Epoch 178 Training Loss=0.994482, Validation Loss=0.991208\n",
      "Epoch 179 Training Loss=0.994364, Validation Loss=0.991337\n",
      "Epoch 180 Training Loss=0.994247, Validation Loss=0.991467\n",
      "Epoch 181 Training Loss=0.994130, Validation Loss=0.991596\n",
      "Epoch 182 Training Loss=0.994013, Validation Loss=0.991726\n",
      "Epoch 183 Training Loss=0.993897, Validation Loss=0.991855\n",
      "Epoch 184 Training Loss=0.993780, Validation Loss=0.991985\n",
      "Epoch 185 Training Loss=0.993663, Validation Loss=0.992114\n",
      "Epoch 186 Training Loss=0.993547, Validation Loss=0.992243\n",
      "Epoch 187 Training Loss=0.993430, Validation Loss=0.992373\n",
      "Epoch 188 Training Loss=0.993314, Validation Loss=0.992503\n",
      "Epoch 189 Training Loss=0.993198, Validation Loss=0.992632\n",
      "Epoch 190 Training Loss=0.993082, Validation Loss=0.992762\n",
      "Epoch 191 Training Loss=0.992966, Validation Loss=0.992891\n",
      "Epoch 192 Training Loss=0.992850, Validation Loss=0.993021\n",
      "Epoch 193 Training Loss=0.992734, Validation Loss=0.993151\n",
      "Epoch 194 Training Loss=0.992618, Validation Loss=0.993281\n",
      "Epoch 195 Training Loss=0.992503, Validation Loss=0.993411\n",
      "Epoch 196 Training Loss=0.992387, Validation Loss=0.993540\n",
      "Epoch 197 Training Loss=0.992272, Validation Loss=0.993670\n",
      "Epoch 198 Training Loss=0.992157, Validation Loss=0.993800\n",
      "Epoch 199 Training Loss=0.992041, Validation Loss=0.993930\n",
      "Epoch 0 Training Loss=1.090526, Validation Loss=1.010955\n",
      "Epoch 1 Training Loss=1.048535, Validation Loss=0.943532\n",
      "Epoch 2 Training Loss=1.034517, Validation Loss=0.921739\n",
      "Epoch 3 Training Loss=1.030653, Validation Loss=0.916821\n",
      "Epoch 4 Training Loss=1.029033, Validation Loss=0.916550\n",
      "Epoch 5 Training Loss=1.028022, Validation Loss=0.917434\n",
      "Epoch 6 Training Loss=1.027215, Validation Loss=0.918770\n",
      "Epoch 7 Training Loss=1.026503, Validation Loss=0.920381\n",
      "Epoch 8 Training Loss=1.025852, Validation Loss=0.922131\n",
      "Epoch 9 Training Loss=1.025250, Validation Loss=0.923916\n",
      "Epoch 10 Training Loss=1.024690, Validation Loss=0.925675\n",
      "Epoch 11 Training Loss=1.024168, Validation Loss=0.927378\n",
      "Epoch 12 Training Loss=1.023682, Validation Loss=0.929013\n",
      "Epoch 13 Training Loss=1.023227, Validation Loss=0.930576\n",
      "Epoch 14 Training Loss=1.022801, Validation Loss=0.932068\n",
      "Epoch 15 Training Loss=1.022401, Validation Loss=0.933489\n",
      "Epoch 16 Training Loss=1.022025, Validation Loss=0.934842\n",
      "Epoch 17 Training Loss=1.021669, Validation Loss=0.936131\n",
      "Epoch 18 Training Loss=1.021333, Validation Loss=0.937358\n",
      "Epoch 19 Training Loss=1.021013, Validation Loss=0.938528\n",
      "Epoch 20 Training Loss=1.020709, Validation Loss=0.939642\n",
      "Epoch 21 Training Loss=1.020419, Validation Loss=0.940704\n",
      "Epoch 22 Training Loss=1.020142, Validation Loss=0.941717\n",
      "Epoch 23 Training Loss=1.019876, Validation Loss=0.942684\n",
      "Epoch 24 Training Loss=1.019620, Validation Loss=0.943606\n",
      "Epoch 25 Training Loss=1.019374, Validation Loss=0.944488\n",
      "Epoch 26 Training Loss=1.019137, Validation Loss=0.945330\n",
      "Epoch 27 Training Loss=1.018908, Validation Loss=0.946136\n",
      "Epoch 28 Training Loss=1.018686, Validation Loss=0.946906\n",
      "Epoch 29 Training Loss=1.018471, Validation Loss=0.947644\n",
      "Epoch 30 Training Loss=1.018262, Validation Loss=0.948351\n",
      "Epoch 31 Training Loss=1.018058, Validation Loss=0.949028\n",
      "Epoch 32 Training Loss=1.017859, Validation Loss=0.949678\n",
      "Epoch 33 Training Loss=1.017666, Validation Loss=0.950302\n",
      "Epoch 34 Training Loss=1.017476, Validation Loss=0.950901\n",
      "Epoch 35 Training Loss=1.017291, Validation Loss=0.951476\n",
      "Epoch 36 Training Loss=1.017110, Validation Loss=0.952030\n",
      "Epoch 37 Training Loss=1.016932, Validation Loss=0.952563\n",
      "Epoch 38 Training Loss=1.016757, Validation Loss=0.953076\n",
      "Epoch 39 Training Loss=1.016585, Validation Loss=0.953570\n",
      "Epoch 40 Training Loss=1.016416, Validation Loss=0.954048\n",
      "Epoch 41 Training Loss=1.016250, Validation Loss=0.954508\n",
      "Epoch 42 Training Loss=1.016086, Validation Loss=0.954953\n",
      "Epoch 43 Training Loss=1.015924, Validation Loss=0.955384\n",
      "Epoch 44 Training Loss=1.015764, Validation Loss=0.955800\n",
      "Epoch 45 Training Loss=1.015607, Validation Loss=0.956203\n",
      "Epoch 46 Training Loss=1.015451, Validation Loss=0.956594\n",
      "Epoch 47 Training Loss=1.015297, Validation Loss=0.956973\n",
      "Epoch 48 Training Loss=1.015144, Validation Loss=0.957341\n",
      "Epoch 49 Training Loss=1.014993, Validation Loss=0.957699\n",
      "Epoch 50 Training Loss=1.014844, Validation Loss=0.958046\n",
      "Epoch 51 Training Loss=1.014695, Validation Loss=0.958385\n",
      "Epoch 52 Training Loss=1.014548, Validation Loss=0.958715\n",
      "Epoch 53 Training Loss=1.014402, Validation Loss=0.959036\n",
      "Epoch 54 Training Loss=1.014258, Validation Loss=0.959350\n",
      "Epoch 55 Training Loss=1.014114, Validation Loss=0.959656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training Loss=1.013971, Validation Loss=0.959955\n",
      "Epoch 57 Training Loss=1.013829, Validation Loss=0.960248\n",
      "Epoch 58 Training Loss=1.013688, Validation Loss=0.960534\n",
      "Epoch 59 Training Loss=1.013547, Validation Loss=0.960815\n",
      "Epoch 60 Training Loss=1.013407, Validation Loss=0.961091\n",
      "Epoch 61 Training Loss=1.013268, Validation Loss=0.961360\n",
      "Epoch 62 Training Loss=1.013130, Validation Loss=0.961626\n",
      "Epoch 63 Training Loss=1.012992, Validation Loss=0.961886\n",
      "Epoch 64 Training Loss=1.012854, Validation Loss=0.962143\n",
      "Epoch 65 Training Loss=1.012717, Validation Loss=0.962395\n",
      "Epoch 66 Training Loss=1.012581, Validation Loss=0.962643\n",
      "Epoch 67 Training Loss=1.012445, Validation Loss=0.962888\n",
      "Epoch 68 Training Loss=1.012309, Validation Loss=0.963129\n",
      "Epoch 69 Training Loss=1.012173, Validation Loss=0.963367\n",
      "Epoch 70 Training Loss=1.012038, Validation Loss=0.963602\n",
      "Epoch 71 Training Loss=1.011903, Validation Loss=0.963835\n",
      "Epoch 72 Training Loss=1.011769, Validation Loss=0.964064\n",
      "Epoch 73 Training Loss=1.011634, Validation Loss=0.964291\n",
      "Epoch 74 Training Loss=1.011500, Validation Loss=0.964516\n",
      "Epoch 75 Training Loss=1.011365, Validation Loss=0.964739\n",
      "Epoch 76 Training Loss=1.011231, Validation Loss=0.964959\n",
      "Epoch 77 Training Loss=1.011097, Validation Loss=0.965178\n",
      "Epoch 78 Training Loss=1.010963, Validation Loss=0.965394\n",
      "Epoch 79 Training Loss=1.010829, Validation Loss=0.965610\n",
      "Epoch 80 Training Loss=1.010696, Validation Loss=0.965823\n",
      "Epoch 81 Training Loss=1.010562, Validation Loss=0.966035\n",
      "Epoch 82 Training Loss=1.010428, Validation Loss=0.966246\n",
      "Epoch 83 Training Loss=1.010294, Validation Loss=0.966455\n",
      "Epoch 84 Training Loss=1.010160, Validation Loss=0.966663\n",
      "Epoch 85 Training Loss=1.010026, Validation Loss=0.966871\n",
      "Epoch 86 Training Loss=1.009891, Validation Loss=0.967077\n",
      "Epoch 87 Training Loss=1.009757, Validation Loss=0.967282\n",
      "Epoch 88 Training Loss=1.009623, Validation Loss=0.967486\n",
      "Epoch 89 Training Loss=1.009488, Validation Loss=0.967689\n",
      "Epoch 90 Training Loss=1.009353, Validation Loss=0.967892\n",
      "Epoch 91 Training Loss=1.009218, Validation Loss=0.968094\n",
      "Epoch 92 Training Loss=1.009083, Validation Loss=0.968296\n",
      "Epoch 93 Training Loss=1.008948, Validation Loss=0.968496\n",
      "Epoch 94 Training Loss=1.008812, Validation Loss=0.968697\n",
      "Epoch 95 Training Loss=1.008676, Validation Loss=0.968897\n",
      "Epoch 96 Training Loss=1.008540, Validation Loss=0.969096\n",
      "Epoch 97 Training Loss=1.008404, Validation Loss=0.969295\n",
      "Epoch 98 Training Loss=1.008267, Validation Loss=0.969494\n",
      "Epoch 99 Training Loss=1.008131, Validation Loss=0.969693\n",
      "Epoch 100 Training Loss=1.007993, Validation Loss=0.969891\n",
      "Epoch 101 Training Loss=1.007856, Validation Loss=0.970089\n",
      "Epoch 102 Training Loss=1.007718, Validation Loss=0.970287\n",
      "Epoch 103 Training Loss=1.007580, Validation Loss=0.970485\n",
      "Epoch 104 Training Loss=1.007442, Validation Loss=0.970683\n",
      "Epoch 105 Training Loss=1.007303, Validation Loss=0.970881\n",
      "Epoch 106 Training Loss=1.007164, Validation Loss=0.971078\n",
      "Epoch 107 Training Loss=1.007025, Validation Loss=0.971276\n",
      "Epoch 108 Training Loss=1.006885, Validation Loss=0.971474\n",
      "Epoch 109 Training Loss=1.006745, Validation Loss=0.971672\n",
      "Epoch 110 Training Loss=1.006605, Validation Loss=0.971870\n",
      "Epoch 111 Training Loss=1.006464, Validation Loss=0.972068\n",
      "Epoch 112 Training Loss=1.006323, Validation Loss=0.972266\n",
      "Epoch 113 Training Loss=1.006181, Validation Loss=0.972464\n",
      "Epoch 114 Training Loss=1.006040, Validation Loss=0.972663\n",
      "Epoch 115 Training Loss=1.005897, Validation Loss=0.972862\n",
      "Epoch 116 Training Loss=1.005755, Validation Loss=0.973061\n",
      "Epoch 117 Training Loss=1.005612, Validation Loss=0.973260\n",
      "Epoch 118 Training Loss=1.005469, Validation Loss=0.973459\n",
      "Epoch 119 Training Loss=1.005325, Validation Loss=0.973659\n",
      "Epoch 120 Training Loss=1.005181, Validation Loss=0.973859\n",
      "Epoch 121 Training Loss=1.005036, Validation Loss=0.974060\n",
      "Epoch 122 Training Loss=1.004892, Validation Loss=0.974260\n",
      "Epoch 123 Training Loss=1.004746, Validation Loss=0.974462\n",
      "Epoch 124 Training Loss=1.004601, Validation Loss=0.974663\n",
      "Epoch 125 Training Loss=1.004455, Validation Loss=0.974865\n",
      "Epoch 126 Training Loss=1.004309, Validation Loss=0.975067\n",
      "Epoch 127 Training Loss=1.004162, Validation Loss=0.975270\n",
      "Epoch 128 Training Loss=1.004015, Validation Loss=0.975473\n",
      "Epoch 129 Training Loss=1.003867, Validation Loss=0.975676\n",
      "Epoch 130 Training Loss=1.003720, Validation Loss=0.975880\n",
      "Epoch 131 Training Loss=1.003572, Validation Loss=0.976085\n",
      "Epoch 132 Training Loss=1.003423, Validation Loss=0.976290\n",
      "Epoch 133 Training Loss=1.003274, Validation Loss=0.976495\n",
      "Epoch 134 Training Loss=1.003125, Validation Loss=0.976701\n",
      "Epoch 135 Training Loss=1.002976, Validation Loss=0.976907\n",
      "Epoch 136 Training Loss=1.002826, Validation Loss=0.977114\n",
      "Epoch 137 Training Loss=1.002676, Validation Loss=0.977321\n",
      "Epoch 138 Training Loss=1.002525, Validation Loss=0.977529\n",
      "Epoch 139 Training Loss=1.002375, Validation Loss=0.977738\n",
      "Epoch 140 Training Loss=1.002224, Validation Loss=0.977947\n",
      "Epoch 141 Training Loss=1.002072, Validation Loss=0.978156\n",
      "Epoch 142 Training Loss=1.001921, Validation Loss=0.978366\n",
      "Epoch 143 Training Loss=1.001769, Validation Loss=0.978577\n",
      "Epoch 144 Training Loss=1.001617, Validation Loss=0.978788\n",
      "Epoch 145 Training Loss=1.001464, Validation Loss=0.978999\n",
      "Epoch 146 Training Loss=1.001311, Validation Loss=0.979212\n",
      "Epoch 147 Training Loss=1.001159, Validation Loss=0.979424\n",
      "Epoch 148 Training Loss=1.001005, Validation Loss=0.979638\n",
      "Epoch 149 Training Loss=1.000852, Validation Loss=0.979852\n",
      "Epoch 150 Training Loss=1.000698, Validation Loss=0.980066\n",
      "Epoch 151 Training Loss=1.000544, Validation Loss=0.980282\n",
      "Epoch 152 Training Loss=1.000390, Validation Loss=0.980497\n",
      "Epoch 153 Training Loss=1.000236, Validation Loss=0.980714\n",
      "Epoch 154 Training Loss=1.000082, Validation Loss=0.980930\n",
      "Epoch 155 Training Loss=0.999927, Validation Loss=0.981148\n",
      "Epoch 156 Training Loss=0.999772, Validation Loss=0.981366\n",
      "Epoch 157 Training Loss=0.999618, Validation Loss=0.981585\n",
      "Epoch 158 Training Loss=0.999463, Validation Loss=0.981804\n",
      "Epoch 159 Training Loss=0.999307, Validation Loss=0.982024\n",
      "Epoch 160 Training Loss=0.999152, Validation Loss=0.982244\n",
      "Epoch 161 Training Loss=0.998997, Validation Loss=0.982465\n",
      "Epoch 162 Training Loss=0.998841, Validation Loss=0.982687\n",
      "Epoch 163 Training Loss=0.998686, Validation Loss=0.982909\n",
      "Epoch 164 Training Loss=0.998530, Validation Loss=0.983131\n",
      "Epoch 165 Training Loss=0.998375, Validation Loss=0.983355\n",
      "Epoch 166 Training Loss=0.998219, Validation Loss=0.983578\n",
      "Epoch 167 Training Loss=0.998063, Validation Loss=0.983803\n",
      "Epoch 168 Training Loss=0.997907, Validation Loss=0.984028\n",
      "Epoch 169 Training Loss=0.997751, Validation Loss=0.984253\n",
      "Epoch 170 Training Loss=0.997596, Validation Loss=0.984479\n",
      "Epoch 171 Training Loss=0.997440, Validation Loss=0.984705\n",
      "Epoch 172 Training Loss=0.997284, Validation Loss=0.984933\n",
      "Epoch 173 Training Loss=0.997128, Validation Loss=0.985160\n",
      "Epoch 174 Training Loss=0.996973, Validation Loss=0.985388\n",
      "Epoch 175 Training Loss=0.996817, Validation Loss=0.985617\n",
      "Epoch 176 Training Loss=0.996662, Validation Loss=0.985846\n",
      "Epoch 177 Training Loss=0.996506, Validation Loss=0.986075\n",
      "Epoch 178 Training Loss=0.996351, Validation Loss=0.986305\n",
      "Epoch 179 Training Loss=0.996195, Validation Loss=0.986535\n",
      "Epoch 180 Training Loss=0.996040, Validation Loss=0.986766\n",
      "Epoch 181 Training Loss=0.995885, Validation Loss=0.986997\n",
      "Epoch 182 Training Loss=0.995730, Validation Loss=0.987229\n",
      "Epoch 183 Training Loss=0.995575, Validation Loss=0.987461\n",
      "Epoch 184 Training Loss=0.995421, Validation Loss=0.987694\n",
      "Epoch 185 Training Loss=0.995266, Validation Loss=0.987927\n",
      "Epoch 186 Training Loss=0.995112, Validation Loss=0.988160\n",
      "Epoch 187 Training Loss=0.994958, Validation Loss=0.988393\n",
      "Epoch 188 Training Loss=0.994804, Validation Loss=0.988627\n",
      "Epoch 189 Training Loss=0.994650, Validation Loss=0.988862\n",
      "Epoch 190 Training Loss=0.994497, Validation Loss=0.989096\n",
      "Epoch 191 Training Loss=0.994344, Validation Loss=0.989331\n",
      "Epoch 192 Training Loss=0.994191, Validation Loss=0.989566\n",
      "Epoch 193 Training Loss=0.994038, Validation Loss=0.989801\n",
      "Epoch 194 Training Loss=0.993885, Validation Loss=0.990037\n",
      "Epoch 195 Training Loss=0.993733, Validation Loss=0.990273\n",
      "Epoch 196 Training Loss=0.993581, Validation Loss=0.990509\n",
      "Epoch 197 Training Loss=0.993429, Validation Loss=0.990745\n",
      "Epoch 198 Training Loss=0.993278, Validation Loss=0.990981\n",
      "Epoch 199 Training Loss=0.993126, Validation Loss=0.991218\n",
      "Epoch 0 Training Loss=1.059305, Validation Loss=0.894196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss=1.042919, Validation Loss=0.906315\n",
      "Epoch 2 Training Loss=1.033295, Validation Loss=0.916051\n",
      "Epoch 3 Training Loss=1.028561, Validation Loss=0.922933\n",
      "Epoch 4 Training Loss=1.026054, Validation Loss=0.927948\n",
      "Epoch 5 Training Loss=1.024552, Validation Loss=0.931791\n",
      "Epoch 6 Training Loss=1.023539, Validation Loss=0.934848\n",
      "Epoch 7 Training Loss=1.022786, Validation Loss=0.937353\n",
      "Epoch 8 Training Loss=1.022184, Validation Loss=0.939462\n",
      "Epoch 9 Training Loss=1.021677, Validation Loss=0.941283\n",
      "Epoch 10 Training Loss=1.021233, Validation Loss=0.942891\n",
      "Epoch 11 Training Loss=1.020835, Validation Loss=0.944336\n",
      "Epoch 12 Training Loss=1.020471, Validation Loss=0.945655\n",
      "Epoch 13 Training Loss=1.020135, Validation Loss=0.946874\n",
      "Epoch 14 Training Loss=1.019822, Validation Loss=0.948010\n",
      "Epoch 15 Training Loss=1.019528, Validation Loss=0.949077\n",
      "Epoch 16 Training Loss=1.019251, Validation Loss=0.950087\n",
      "Epoch 17 Training Loss=1.018988, Validation Loss=0.951045\n",
      "Epoch 18 Training Loss=1.018738, Validation Loss=0.951957\n",
      "Epoch 19 Training Loss=1.018499, Validation Loss=0.952829\n",
      "Epoch 20 Training Loss=1.018270, Validation Loss=0.953664\n",
      "Epoch 21 Training Loss=1.018049, Validation Loss=0.954465\n",
      "Epoch 22 Training Loss=1.017837, Validation Loss=0.955234\n",
      "Epoch 23 Training Loss=1.017632, Validation Loss=0.955973\n",
      "Epoch 24 Training Loss=1.017434, Validation Loss=0.956685\n",
      "Epoch 25 Training Loss=1.017241, Validation Loss=0.957370\n",
      "Epoch 26 Training Loss=1.017053, Validation Loss=0.958030\n",
      "Epoch 27 Training Loss=1.016870, Validation Loss=0.958667\n",
      "Epoch 28 Training Loss=1.016692, Validation Loss=0.959282\n",
      "Epoch 29 Training Loss=1.016517, Validation Loss=0.959877\n",
      "Epoch 30 Training Loss=1.016346, Validation Loss=0.960451\n",
      "Epoch 31 Training Loss=1.016177, Validation Loss=0.961007\n",
      "Epoch 32 Training Loss=1.016012, Validation Loss=0.961544\n",
      "Epoch 33 Training Loss=1.015850, Validation Loss=0.962065\n",
      "Epoch 34 Training Loss=1.015689, Validation Loss=0.962571\n",
      "Epoch 35 Training Loss=1.015531, Validation Loss=0.963061\n",
      "Epoch 36 Training Loss=1.015375, Validation Loss=0.963536\n",
      "Epoch 37 Training Loss=1.015221, Validation Loss=0.963999\n",
      "Epoch 38 Training Loss=1.015068, Validation Loss=0.964448\n",
      "Epoch 39 Training Loss=1.014917, Validation Loss=0.964886\n",
      "Epoch 40 Training Loss=1.014767, Validation Loss=0.965312\n",
      "Epoch 41 Training Loss=1.014619, Validation Loss=0.965727\n",
      "Epoch 42 Training Loss=1.014471, Validation Loss=0.966132\n",
      "Epoch 43 Training Loss=1.014325, Validation Loss=0.966527\n",
      "Epoch 44 Training Loss=1.014179, Validation Loss=0.966914\n",
      "Epoch 45 Training Loss=1.014034, Validation Loss=0.967292\n",
      "Epoch 46 Training Loss=1.013890, Validation Loss=0.967661\n",
      "Epoch 47 Training Loss=1.013747, Validation Loss=0.968023\n",
      "Epoch 48 Training Loss=1.013604, Validation Loss=0.968378\n",
      "Epoch 49 Training Loss=1.013462, Validation Loss=0.968726\n",
      "Epoch 50 Training Loss=1.013320, Validation Loss=0.969068\n",
      "Epoch 51 Training Loss=1.013179, Validation Loss=0.969404\n",
      "Epoch 52 Training Loss=1.013038, Validation Loss=0.969733\n",
      "Epoch 53 Training Loss=1.012898, Validation Loss=0.970058\n",
      "Epoch 54 Training Loss=1.012758, Validation Loss=0.970378\n",
      "Epoch 55 Training Loss=1.012618, Validation Loss=0.970693\n",
      "Epoch 56 Training Loss=1.012478, Validation Loss=0.971003\n",
      "Epoch 57 Training Loss=1.012338, Validation Loss=0.971309\n",
      "Epoch 58 Training Loss=1.012199, Validation Loss=0.971612\n",
      "Epoch 59 Training Loss=1.012060, Validation Loss=0.971910\n",
      "Epoch 60 Training Loss=1.011920, Validation Loss=0.972205\n",
      "Epoch 61 Training Loss=1.011781, Validation Loss=0.972497\n",
      "Epoch 62 Training Loss=1.011642, Validation Loss=0.972786\n",
      "Epoch 63 Training Loss=1.011503, Validation Loss=0.973072\n",
      "Epoch 64 Training Loss=1.011364, Validation Loss=0.973355\n",
      "Epoch 65 Training Loss=1.011224, Validation Loss=0.973636\n",
      "Epoch 66 Training Loss=1.011085, Validation Loss=0.973914\n",
      "Epoch 67 Training Loss=1.010945, Validation Loss=0.974190\n",
      "Epoch 68 Training Loss=1.010806, Validation Loss=0.974464\n",
      "Epoch 69 Training Loss=1.010666, Validation Loss=0.974736\n",
      "Epoch 70 Training Loss=1.010526, Validation Loss=0.975006\n",
      "Epoch 71 Training Loss=1.010386, Validation Loss=0.975274\n",
      "Epoch 72 Training Loss=1.010246, Validation Loss=0.975541\n",
      "Epoch 73 Training Loss=1.010105, Validation Loss=0.975806\n",
      "Epoch 74 Training Loss=1.009964, Validation Loss=0.976070\n",
      "Epoch 75 Training Loss=1.009823, Validation Loss=0.976333\n",
      "Epoch 76 Training Loss=1.009682, Validation Loss=0.976594\n",
      "Epoch 77 Training Loss=1.009541, Validation Loss=0.976854\n",
      "Epoch 78 Training Loss=1.009399, Validation Loss=0.977113\n",
      "Epoch 79 Training Loss=1.009256, Validation Loss=0.977371\n",
      "Epoch 80 Training Loss=1.009114, Validation Loss=0.977628\n",
      "Epoch 81 Training Loss=1.008971, Validation Loss=0.977885\n",
      "Epoch 82 Training Loss=1.008828, Validation Loss=0.978140\n",
      "Epoch 83 Training Loss=1.008684, Validation Loss=0.978395\n",
      "Epoch 84 Training Loss=1.008540, Validation Loss=0.978649\n",
      "Epoch 85 Training Loss=1.008396, Validation Loss=0.978902\n",
      "Epoch 86 Training Loss=1.008251, Validation Loss=0.979155\n",
      "Epoch 87 Training Loss=1.008106, Validation Loss=0.979407\n",
      "Epoch 88 Training Loss=1.007961, Validation Loss=0.979659\n",
      "Epoch 89 Training Loss=1.007815, Validation Loss=0.979910\n",
      "Epoch 90 Training Loss=1.007668, Validation Loss=0.980161\n",
      "Epoch 91 Training Loss=1.007521, Validation Loss=0.980411\n",
      "Epoch 92 Training Loss=1.007374, Validation Loss=0.980661\n",
      "Epoch 93 Training Loss=1.007226, Validation Loss=0.980911\n",
      "Epoch 94 Training Loss=1.007078, Validation Loss=0.981160\n",
      "Epoch 95 Training Loss=1.006929, Validation Loss=0.981409\n",
      "Epoch 96 Training Loss=1.006780, Validation Loss=0.981658\n",
      "Epoch 97 Training Loss=1.006630, Validation Loss=0.981907\n",
      "Epoch 98 Training Loss=1.006480, Validation Loss=0.982155\n",
      "Epoch 99 Training Loss=1.006329, Validation Loss=0.982403\n",
      "Epoch 100 Training Loss=1.006178, Validation Loss=0.982651\n",
      "Epoch 101 Training Loss=1.006026, Validation Loss=0.982899\n",
      "Epoch 102 Training Loss=1.005874, Validation Loss=0.983147\n",
      "Epoch 103 Training Loss=1.005721, Validation Loss=0.983395\n",
      "Epoch 104 Training Loss=1.005568, Validation Loss=0.983642\n",
      "Epoch 105 Training Loss=1.005414, Validation Loss=0.983890\n",
      "Epoch 106 Training Loss=1.005260, Validation Loss=0.984137\n",
      "Epoch 107 Training Loss=1.005105, Validation Loss=0.984384\n",
      "Epoch 108 Training Loss=1.004949, Validation Loss=0.984632\n",
      "Epoch 109 Training Loss=1.004793, Validation Loss=0.984879\n",
      "Epoch 110 Training Loss=1.004636, Validation Loss=0.985127\n",
      "Epoch 111 Training Loss=1.004479, Validation Loss=0.985374\n",
      "Epoch 112 Training Loss=1.004321, Validation Loss=0.985621\n",
      "Epoch 113 Training Loss=1.004163, Validation Loss=0.985869\n",
      "Epoch 114 Training Loss=1.004004, Validation Loss=0.986116\n",
      "Epoch 115 Training Loss=1.003845, Validation Loss=0.986364\n",
      "Epoch 116 Training Loss=1.003684, Validation Loss=0.986612\n",
      "Epoch 117 Training Loss=1.003524, Validation Loss=0.986859\n",
      "Epoch 118 Training Loss=1.003363, Validation Loss=0.987107\n",
      "Epoch 119 Training Loss=1.003201, Validation Loss=0.987355\n",
      "Epoch 120 Training Loss=1.003038, Validation Loss=0.987603\n",
      "Epoch 121 Training Loss=1.002876, Validation Loss=0.987852\n",
      "Epoch 122 Training Loss=1.002712, Validation Loss=0.988100\n",
      "Epoch 123 Training Loss=1.002548, Validation Loss=0.988348\n",
      "Epoch 124 Training Loss=1.002383, Validation Loss=0.988597\n",
      "Epoch 125 Training Loss=1.002218, Validation Loss=0.988846\n",
      "Epoch 126 Training Loss=1.002052, Validation Loss=0.989095\n",
      "Epoch 127 Training Loss=1.001885, Validation Loss=0.989344\n",
      "Epoch 128 Training Loss=1.001718, Validation Loss=0.989594\n",
      "Epoch 129 Training Loss=1.001550, Validation Loss=0.989843\n",
      "Epoch 130 Training Loss=1.001382, Validation Loss=0.990093\n",
      "Epoch 131 Training Loss=1.001213, Validation Loss=0.990343\n",
      "Epoch 132 Training Loss=1.001044, Validation Loss=0.990594\n",
      "Epoch 133 Training Loss=1.000874, Validation Loss=0.990844\n",
      "Epoch 134 Training Loss=1.000703, Validation Loss=0.991095\n",
      "Epoch 135 Training Loss=1.000532, Validation Loss=0.991346\n",
      "Epoch 136 Training Loss=1.000360, Validation Loss=0.991598\n",
      "Epoch 137 Training Loss=1.000187, Validation Loss=0.991850\n",
      "Epoch 138 Training Loss=1.000014, Validation Loss=0.992102\n",
      "Epoch 139 Training Loss=0.999841, Validation Loss=0.992354\n",
      "Epoch 140 Training Loss=0.999666, Validation Loss=0.992607\n",
      "Epoch 141 Training Loss=0.999491, Validation Loss=0.992860\n",
      "Epoch 142 Training Loss=0.999316, Validation Loss=0.993114\n",
      "Epoch 143 Training Loss=0.999140, Validation Loss=0.993368\n",
      "Epoch 144 Training Loss=0.998963, Validation Loss=0.993622\n",
      "Epoch 145 Training Loss=0.998786, Validation Loss=0.993876\n",
      "Epoch 146 Training Loss=0.998608, Validation Loss=0.994131\n",
      "Epoch 147 Training Loss=0.998429, Validation Loss=0.994387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Training Loss=0.998250, Validation Loss=0.994643\n",
      "Epoch 149 Training Loss=0.998070, Validation Loss=0.994899\n",
      "Epoch 150 Training Loss=0.997889, Validation Loss=0.995156\n",
      "Epoch 151 Training Loss=0.997708, Validation Loss=0.995413\n",
      "Epoch 152 Training Loss=0.997527, Validation Loss=0.995671\n",
      "Epoch 153 Training Loss=0.997344, Validation Loss=0.995930\n",
      "Epoch 154 Training Loss=0.997161, Validation Loss=0.996189\n",
      "Epoch 155 Training Loss=0.996978, Validation Loss=0.996448\n",
      "Epoch 156 Training Loss=0.996794, Validation Loss=0.996708\n",
      "Epoch 157 Training Loss=0.996609, Validation Loss=0.996968\n",
      "Epoch 158 Training Loss=0.996423, Validation Loss=0.997229\n",
      "Epoch 159 Training Loss=0.996237, Validation Loss=0.997491\n",
      "Epoch 160 Training Loss=0.996050, Validation Loss=0.997754\n",
      "Epoch 161 Training Loss=0.995863, Validation Loss=0.998016\n",
      "Epoch 162 Training Loss=0.995675, Validation Loss=0.998280\n",
      "Epoch 163 Training Loss=0.995486, Validation Loss=0.998544\n",
      "Epoch 164 Training Loss=0.995296, Validation Loss=0.998809\n",
      "Epoch 165 Training Loss=0.995106, Validation Loss=0.999075\n",
      "Epoch 166 Training Loss=0.994915, Validation Loss=0.999341\n",
      "Epoch 167 Training Loss=0.994724, Validation Loss=0.999608\n",
      "Epoch 168 Training Loss=0.994532, Validation Loss=0.999876\n",
      "Epoch 169 Training Loss=0.994339, Validation Loss=1.000145\n",
      "Epoch 170 Training Loss=0.994146, Validation Loss=1.000414\n",
      "Epoch 171 Training Loss=0.993951, Validation Loss=1.000685\n",
      "Epoch 172 Training Loss=0.993757, Validation Loss=1.000956\n",
      "Epoch 173 Training Loss=0.993561, Validation Loss=1.001228\n",
      "Epoch 174 Training Loss=0.993365, Validation Loss=1.001501\n",
      "Epoch 175 Training Loss=0.993168, Validation Loss=1.001775\n",
      "Epoch 176 Training Loss=0.992970, Validation Loss=1.002049\n",
      "Epoch 177 Training Loss=0.992772, Validation Loss=1.002325\n",
      "Epoch 178 Training Loss=0.992573, Validation Loss=1.002602\n",
      "Epoch 179 Training Loss=0.992373, Validation Loss=1.002879\n",
      "Epoch 180 Training Loss=0.992173, Validation Loss=1.003158\n",
      "Epoch 181 Training Loss=0.991972, Validation Loss=1.003438\n",
      "Epoch 182 Training Loss=0.991770, Validation Loss=1.003718\n",
      "Epoch 183 Training Loss=0.991568, Validation Loss=1.004000\n",
      "Epoch 184 Training Loss=0.991364, Validation Loss=1.004283\n",
      "Epoch 185 Training Loss=0.991160, Validation Loss=1.004567\n",
      "Epoch 186 Training Loss=0.990956, Validation Loss=1.004853\n",
      "Epoch 187 Training Loss=0.990750, Validation Loss=1.005139\n",
      "Epoch 188 Training Loss=0.990544, Validation Loss=1.005427\n",
      "Epoch 189 Training Loss=0.990338, Validation Loss=1.005715\n",
      "Epoch 190 Training Loss=0.990130, Validation Loss=1.006006\n",
      "Epoch 191 Training Loss=0.989922, Validation Loss=1.006297\n",
      "Epoch 192 Training Loss=0.989713, Validation Loss=1.006590\n",
      "Epoch 193 Training Loss=0.989504, Validation Loss=1.006884\n",
      "Epoch 194 Training Loss=0.989293, Validation Loss=1.007179\n",
      "Epoch 195 Training Loss=0.989082, Validation Loss=1.007476\n",
      "Epoch 196 Training Loss=0.988871, Validation Loss=1.007774\n",
      "Epoch 197 Training Loss=0.988658, Validation Loss=1.008074\n",
      "Epoch 198 Training Loss=0.988445, Validation Loss=1.008374\n",
      "Epoch 199 Training Loss=0.988232, Validation Loss=1.008677\n",
      "Epoch 0 Training Loss=1.067131, Validation Loss=0.934751\n",
      "Epoch 1 Training Loss=1.029981, Validation Loss=0.954037\n",
      "Epoch 2 Training Loss=1.024061, Validation Loss=0.950999\n",
      "Epoch 3 Training Loss=1.023272, Validation Loss=0.949255\n",
      "Epoch 4 Training Loss=1.022778, Validation Loss=0.950984\n",
      "Epoch 5 Training Loss=1.022202, Validation Loss=0.953059\n",
      "Epoch 6 Training Loss=1.021703, Validation Loss=0.954870\n",
      "Epoch 7 Training Loss=1.021266, Validation Loss=0.956590\n",
      "Epoch 8 Training Loss=1.020854, Validation Loss=0.958214\n",
      "Epoch 9 Training Loss=1.020464, Validation Loss=0.959691\n",
      "Epoch 10 Training Loss=1.020096, Validation Loss=0.961019\n",
      "Epoch 11 Training Loss=1.019748, Validation Loss=0.962213\n",
      "Epoch 12 Training Loss=1.019418, Validation Loss=0.963288\n",
      "Epoch 13 Training Loss=1.019103, Validation Loss=0.964254\n",
      "Epoch 14 Training Loss=1.018800, Validation Loss=0.965124\n",
      "Epoch 15 Training Loss=1.018508, Validation Loss=0.965907\n",
      "Epoch 16 Training Loss=1.018226, Validation Loss=0.966613\n",
      "Epoch 17 Training Loss=1.017951, Validation Loss=0.967251\n",
      "Epoch 18 Training Loss=1.017684, Validation Loss=0.967829\n",
      "Epoch 19 Training Loss=1.017424, Validation Loss=0.968354\n",
      "Epoch 20 Training Loss=1.017170, Validation Loss=0.968832\n",
      "Epoch 21 Training Loss=1.016920, Validation Loss=0.969268\n",
      "Epoch 22 Training Loss=1.016676, Validation Loss=0.969667\n",
      "Epoch 23 Training Loss=1.016436, Validation Loss=0.970033\n",
      "Epoch 24 Training Loss=1.016201, Validation Loss=0.970371\n",
      "Epoch 25 Training Loss=1.015970, Validation Loss=0.970684\n",
      "Epoch 26 Training Loss=1.015742, Validation Loss=0.970973\n",
      "Epoch 27 Training Loss=1.015518, Validation Loss=0.971243\n",
      "Epoch 28 Training Loss=1.015297, Validation Loss=0.971495\n",
      "Epoch 29 Training Loss=1.015079, Validation Loss=0.971732\n",
      "Epoch 30 Training Loss=1.014864, Validation Loss=0.971955\n",
      "Epoch 31 Training Loss=1.014653, Validation Loss=0.972165\n",
      "Epoch 32 Training Loss=1.014444, Validation Loss=0.972365\n",
      "Epoch 33 Training Loss=1.014237, Validation Loss=0.972555\n",
      "Epoch 34 Training Loss=1.014033, Validation Loss=0.972736\n",
      "Epoch 35 Training Loss=1.013832, Validation Loss=0.972910\n",
      "Epoch 36 Training Loss=1.013632, Validation Loss=0.973077\n",
      "Epoch 37 Training Loss=1.013436, Validation Loss=0.973237\n",
      "Epoch 38 Training Loss=1.013241, Validation Loss=0.973393\n",
      "Epoch 39 Training Loss=1.013048, Validation Loss=0.973543\n",
      "Epoch 40 Training Loss=1.012857, Validation Loss=0.973689\n",
      "Epoch 41 Training Loss=1.012668, Validation Loss=0.973831\n",
      "Epoch 42 Training Loss=1.012481, Validation Loss=0.973970\n",
      "Epoch 43 Training Loss=1.012296, Validation Loss=0.974105\n",
      "Epoch 44 Training Loss=1.012112, Validation Loss=0.974237\n",
      "Epoch 45 Training Loss=1.011930, Validation Loss=0.974367\n",
      "Epoch 46 Training Loss=1.011750, Validation Loss=0.974495\n",
      "Epoch 47 Training Loss=1.011571, Validation Loss=0.974620\n",
      "Epoch 48 Training Loss=1.011394, Validation Loss=0.974744\n",
      "Epoch 49 Training Loss=1.011218, Validation Loss=0.974866\n",
      "Epoch 50 Training Loss=1.011043, Validation Loss=0.974986\n",
      "Epoch 51 Training Loss=1.010870, Validation Loss=0.975104\n",
      "Epoch 52 Training Loss=1.010698, Validation Loss=0.975222\n",
      "Epoch 53 Training Loss=1.010527, Validation Loss=0.975338\n",
      "Epoch 54 Training Loss=1.010357, Validation Loss=0.975453\n",
      "Epoch 55 Training Loss=1.010188, Validation Loss=0.975567\n",
      "Epoch 56 Training Loss=1.010020, Validation Loss=0.975679\n",
      "Epoch 57 Training Loss=1.009854, Validation Loss=0.975791\n",
      "Epoch 58 Training Loss=1.009688, Validation Loss=0.975903\n",
      "Epoch 59 Training Loss=1.009524, Validation Loss=0.976013\n",
      "Epoch 60 Training Loss=1.009360, Validation Loss=0.976122\n",
      "Epoch 61 Training Loss=1.009197, Validation Loss=0.976232\n",
      "Epoch 62 Training Loss=1.009035, Validation Loss=0.976340\n",
      "Epoch 63 Training Loss=1.008874, Validation Loss=0.976447\n",
      "Epoch 64 Training Loss=1.008713, Validation Loss=0.976555\n",
      "Epoch 65 Training Loss=1.008553, Validation Loss=0.976661\n",
      "Epoch 66 Training Loss=1.008394, Validation Loss=0.976767\n",
      "Epoch 67 Training Loss=1.008236, Validation Loss=0.976873\n",
      "Epoch 68 Training Loss=1.008078, Validation Loss=0.976978\n",
      "Epoch 69 Training Loss=1.007921, Validation Loss=0.977083\n",
      "Epoch 70 Training Loss=1.007765, Validation Loss=0.977187\n",
      "Epoch 71 Training Loss=1.007609, Validation Loss=0.977291\n",
      "Epoch 72 Training Loss=1.007453, Validation Loss=0.977395\n",
      "Epoch 73 Training Loss=1.007298, Validation Loss=0.977498\n",
      "Epoch 74 Training Loss=1.007144, Validation Loss=0.977601\n",
      "Epoch 75 Training Loss=1.006990, Validation Loss=0.977704\n",
      "Epoch 76 Training Loss=1.006837, Validation Loss=0.977806\n",
      "Epoch 77 Training Loss=1.006684, Validation Loss=0.977908\n",
      "Epoch 78 Training Loss=1.006531, Validation Loss=0.978010\n",
      "Epoch 79 Training Loss=1.006379, Validation Loss=0.978112\n",
      "Epoch 80 Training Loss=1.006227, Validation Loss=0.978213\n",
      "Epoch 81 Training Loss=1.006075, Validation Loss=0.978314\n",
      "Epoch 82 Training Loss=1.005924, Validation Loss=0.978415\n",
      "Epoch 83 Training Loss=1.005773, Validation Loss=0.978516\n",
      "Epoch 84 Training Loss=1.005623, Validation Loss=0.978616\n",
      "Epoch 85 Training Loss=1.005473, Validation Loss=0.978717\n",
      "Epoch 86 Training Loss=1.005323, Validation Loss=0.978817\n",
      "Epoch 87 Training Loss=1.005173, Validation Loss=0.978917\n",
      "Epoch 88 Training Loss=1.005023, Validation Loss=0.979017\n",
      "Epoch 89 Training Loss=1.004874, Validation Loss=0.979117\n",
      "Epoch 90 Training Loss=1.004725, Validation Loss=0.979217\n",
      "Epoch 91 Training Loss=1.004576, Validation Loss=0.979316\n",
      "Epoch 92 Training Loss=1.004427, Validation Loss=0.979416\n",
      "Epoch 93 Training Loss=1.004278, Validation Loss=0.979515\n",
      "Epoch 94 Training Loss=1.004130, Validation Loss=0.979614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Training Loss=1.003982, Validation Loss=0.979714\n",
      "Epoch 96 Training Loss=1.003833, Validation Loss=0.979813\n",
      "Epoch 97 Training Loss=1.003685, Validation Loss=0.979912\n",
      "Epoch 98 Training Loss=1.003537, Validation Loss=0.980011\n",
      "Epoch 99 Training Loss=1.003389, Validation Loss=0.980111\n",
      "Epoch 100 Training Loss=1.003241, Validation Loss=0.980210\n",
      "Epoch 101 Training Loss=1.003094, Validation Loss=0.980309\n",
      "Epoch 102 Training Loss=1.002946, Validation Loss=0.980408\n",
      "Epoch 103 Training Loss=1.002798, Validation Loss=0.980507\n",
      "Epoch 104 Training Loss=1.002651, Validation Loss=0.980606\n",
      "Epoch 105 Training Loss=1.002503, Validation Loss=0.980705\n",
      "Epoch 106 Training Loss=1.002355, Validation Loss=0.980805\n",
      "Epoch 107 Training Loss=1.002208, Validation Loss=0.980904\n",
      "Epoch 108 Training Loss=1.002060, Validation Loss=0.981003\n",
      "Epoch 109 Training Loss=1.001913, Validation Loss=0.981103\n",
      "Epoch 110 Training Loss=1.001765, Validation Loss=0.981202\n",
      "Epoch 111 Training Loss=1.001617, Validation Loss=0.981302\n",
      "Epoch 112 Training Loss=1.001470, Validation Loss=0.981401\n",
      "Epoch 113 Training Loss=1.001322, Validation Loss=0.981501\n",
      "Epoch 114 Training Loss=1.001174, Validation Loss=0.981601\n",
      "Epoch 115 Training Loss=1.001027, Validation Loss=0.981701\n",
      "Epoch 116 Training Loss=1.000879, Validation Loss=0.981801\n",
      "Epoch 117 Training Loss=1.000731, Validation Loss=0.981901\n",
      "Epoch 118 Training Loss=1.000583, Validation Loss=0.982001\n",
      "Epoch 119 Training Loss=1.000435, Validation Loss=0.982102\n",
      "Epoch 120 Training Loss=1.000287, Validation Loss=0.982203\n",
      "Epoch 121 Training Loss=1.000138, Validation Loss=0.982303\n",
      "Epoch 122 Training Loss=0.999990, Validation Loss=0.982404\n",
      "Epoch 123 Training Loss=0.999842, Validation Loss=0.982505\n",
      "Epoch 124 Training Loss=0.999693, Validation Loss=0.982607\n",
      "Epoch 125 Training Loss=0.999545, Validation Loss=0.982708\n",
      "Epoch 126 Training Loss=0.999396, Validation Loss=0.982810\n",
      "Epoch 127 Training Loss=0.999247, Validation Loss=0.982912\n",
      "Epoch 128 Training Loss=0.999098, Validation Loss=0.983014\n",
      "Epoch 129 Training Loss=0.998949, Validation Loss=0.983117\n",
      "Epoch 130 Training Loss=0.998800, Validation Loss=0.983219\n",
      "Epoch 131 Training Loss=0.998651, Validation Loss=0.983322\n",
      "Epoch 132 Training Loss=0.998501, Validation Loss=0.983425\n",
      "Epoch 133 Training Loss=0.998352, Validation Loss=0.983529\n",
      "Epoch 134 Training Loss=0.998202, Validation Loss=0.983632\n",
      "Epoch 135 Training Loss=0.998052, Validation Loss=0.983736\n",
      "Epoch 136 Training Loss=0.997902, Validation Loss=0.983840\n",
      "Epoch 137 Training Loss=0.997752, Validation Loss=0.983945\n",
      "Epoch 138 Training Loss=0.997601, Validation Loss=0.984050\n",
      "Epoch 139 Training Loss=0.997451, Validation Loss=0.984155\n",
      "Epoch 140 Training Loss=0.997300, Validation Loss=0.984260\n",
      "Epoch 141 Training Loss=0.997150, Validation Loss=0.984366\n",
      "Epoch 142 Training Loss=0.996999, Validation Loss=0.984472\n",
      "Epoch 143 Training Loss=0.996847, Validation Loss=0.984578\n",
      "Epoch 144 Training Loss=0.996696, Validation Loss=0.984685\n",
      "Epoch 145 Training Loss=0.996545, Validation Loss=0.984792\n",
      "Epoch 146 Training Loss=0.996393, Validation Loss=0.984899\n",
      "Epoch 147 Training Loss=0.996241, Validation Loss=0.985007\n",
      "Epoch 148 Training Loss=0.996089, Validation Loss=0.985115\n",
      "Epoch 149 Training Loss=0.995937, Validation Loss=0.985223\n",
      "Epoch 150 Training Loss=0.995785, Validation Loss=0.985332\n",
      "Epoch 151 Training Loss=0.995632, Validation Loss=0.985442\n",
      "Epoch 152 Training Loss=0.995480, Validation Loss=0.985551\n",
      "Epoch 153 Training Loss=0.995327, Validation Loss=0.985661\n",
      "Epoch 154 Training Loss=0.995174, Validation Loss=0.985772\n",
      "Epoch 155 Training Loss=0.995021, Validation Loss=0.985882\n",
      "Epoch 156 Training Loss=0.994867, Validation Loss=0.985994\n",
      "Epoch 157 Training Loss=0.994714, Validation Loss=0.986105\n",
      "Epoch 158 Training Loss=0.994560, Validation Loss=0.986217\n",
      "Epoch 159 Training Loss=0.994406, Validation Loss=0.986330\n",
      "Epoch 160 Training Loss=0.994252, Validation Loss=0.986443\n",
      "Epoch 161 Training Loss=0.994097, Validation Loss=0.986556\n",
      "Epoch 162 Training Loss=0.993943, Validation Loss=0.986670\n",
      "Epoch 163 Training Loss=0.993788, Validation Loss=0.986784\n",
      "Epoch 164 Training Loss=0.993633, Validation Loss=0.986899\n",
      "Epoch 165 Training Loss=0.993478, Validation Loss=0.987014\n",
      "Epoch 166 Training Loss=0.993323, Validation Loss=0.987130\n",
      "Epoch 167 Training Loss=0.993167, Validation Loss=0.987246\n",
      "Epoch 168 Training Loss=0.993012, Validation Loss=0.987363\n",
      "Epoch 169 Training Loss=0.992856, Validation Loss=0.987480\n",
      "Epoch 170 Training Loss=0.992700, Validation Loss=0.987597\n",
      "Epoch 171 Training Loss=0.992543, Validation Loss=0.987715\n",
      "Epoch 172 Training Loss=0.992387, Validation Loss=0.987834\n",
      "Epoch 173 Training Loss=0.992230, Validation Loss=0.987953\n",
      "Epoch 174 Training Loss=0.992074, Validation Loss=0.988073\n",
      "Epoch 175 Training Loss=0.991917, Validation Loss=0.988193\n",
      "Epoch 176 Training Loss=0.991759, Validation Loss=0.988314\n",
      "Epoch 177 Training Loss=0.991602, Validation Loss=0.988435\n",
      "Epoch 178 Training Loss=0.991445, Validation Loss=0.988557\n",
      "Epoch 179 Training Loss=0.991287, Validation Loss=0.988679\n",
      "Epoch 180 Training Loss=0.991129, Validation Loss=0.988802\n",
      "Epoch 181 Training Loss=0.990971, Validation Loss=0.988925\n",
      "Epoch 182 Training Loss=0.990813, Validation Loss=0.989049\n",
      "Epoch 183 Training Loss=0.990654, Validation Loss=0.989174\n",
      "Epoch 184 Training Loss=0.990495, Validation Loss=0.989298\n",
      "Epoch 185 Training Loss=0.990337, Validation Loss=0.989424\n",
      "Epoch 186 Training Loss=0.990178, Validation Loss=0.989550\n",
      "Epoch 187 Training Loss=0.990018, Validation Loss=0.989677\n",
      "Epoch 188 Training Loss=0.989859, Validation Loss=0.989804\n",
      "Epoch 189 Training Loss=0.989700, Validation Loss=0.989932\n",
      "Epoch 190 Training Loss=0.989540, Validation Loss=0.990061\n",
      "Epoch 191 Training Loss=0.989380, Validation Loss=0.990190\n",
      "Epoch 192 Training Loss=0.989220, Validation Loss=0.990319\n",
      "Epoch 193 Training Loss=0.989060, Validation Loss=0.990450\n",
      "Epoch 194 Training Loss=0.988899, Validation Loss=0.990580\n",
      "Epoch 195 Training Loss=0.988739, Validation Loss=0.990712\n",
      "Epoch 196 Training Loss=0.988578, Validation Loss=0.990844\n",
      "Epoch 197 Training Loss=0.988417, Validation Loss=0.990976\n",
      "Epoch 198 Training Loss=0.988256, Validation Loss=0.991110\n",
      "Epoch 199 Training Loss=0.988095, Validation Loss=0.991244\n",
      "Epoch 0 Training Loss=1.095105, Validation Loss=0.923445\n",
      "Epoch 1 Training Loss=1.031610, Validation Loss=0.939459\n",
      "Epoch 2 Training Loss=1.021387, Validation Loss=0.950543\n",
      "Epoch 3 Training Loss=1.021139, Validation Loss=0.951605\n",
      "Epoch 4 Training Loss=1.020823, Validation Loss=0.951686\n",
      "Epoch 5 Training Loss=1.020451, Validation Loss=0.952577\n",
      "Epoch 6 Training Loss=1.020103, Validation Loss=0.953809\n",
      "Epoch 7 Training Loss=1.019786, Validation Loss=0.955020\n",
      "Epoch 8 Training Loss=1.019490, Validation Loss=0.956124\n",
      "Epoch 9 Training Loss=1.019206, Validation Loss=0.957135\n",
      "Epoch 10 Training Loss=1.018933, Validation Loss=0.958071\n",
      "Epoch 11 Training Loss=1.018668, Validation Loss=0.958944\n",
      "Epoch 12 Training Loss=1.018410, Validation Loss=0.959759\n",
      "Epoch 13 Training Loss=1.018159, Validation Loss=0.960522\n",
      "Epoch 14 Training Loss=1.017913, Validation Loss=0.961239\n",
      "Epoch 15 Training Loss=1.017672, Validation Loss=0.961914\n",
      "Epoch 16 Training Loss=1.017435, Validation Loss=0.962550\n",
      "Epoch 17 Training Loss=1.017202, Validation Loss=0.963153\n",
      "Epoch 18 Training Loss=1.016972, Validation Loss=0.963725\n",
      "Epoch 19 Training Loss=1.016745, Validation Loss=0.964268\n",
      "Epoch 20 Training Loss=1.016521, Validation Loss=0.964787\n",
      "Epoch 21 Training Loss=1.016299, Validation Loss=0.965283\n",
      "Epoch 22 Training Loss=1.016080, Validation Loss=0.965758\n",
      "Epoch 23 Training Loss=1.015862, Validation Loss=0.966215\n",
      "Epoch 24 Training Loss=1.015647, Validation Loss=0.966654\n",
      "Epoch 25 Training Loss=1.015433, Validation Loss=0.967079\n",
      "Epoch 26 Training Loss=1.015221, Validation Loss=0.967489\n",
      "Epoch 27 Training Loss=1.015010, Validation Loss=0.967887\n",
      "Epoch 28 Training Loss=1.014800, Validation Loss=0.968274\n",
      "Epoch 29 Training Loss=1.014592, Validation Loss=0.968649\n",
      "Epoch 30 Training Loss=1.014385, Validation Loss=0.969016\n",
      "Epoch 31 Training Loss=1.014178, Validation Loss=0.969373\n",
      "Epoch 32 Training Loss=1.013973, Validation Loss=0.969723\n",
      "Epoch 33 Training Loss=1.013768, Validation Loss=0.970065\n",
      "Epoch 34 Training Loss=1.013564, Validation Loss=0.970400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training Loss=1.013360, Validation Loss=0.970730\n",
      "Epoch 36 Training Loss=1.013157, Validation Loss=0.971053\n",
      "Epoch 37 Training Loss=1.012955, Validation Loss=0.971372\n",
      "Epoch 38 Training Loss=1.012753, Validation Loss=0.971686\n",
      "Epoch 39 Training Loss=1.012551, Validation Loss=0.971995\n",
      "Epoch 40 Training Loss=1.012349, Validation Loss=0.972300\n",
      "Epoch 41 Training Loss=1.012148, Validation Loss=0.972602\n",
      "Epoch 42 Training Loss=1.011947, Validation Loss=0.972900\n",
      "Epoch 43 Training Loss=1.011746, Validation Loss=0.973195\n",
      "Epoch 44 Training Loss=1.011545, Validation Loss=0.973487\n",
      "Epoch 45 Training Loss=1.011344, Validation Loss=0.973777\n",
      "Epoch 46 Training Loss=1.011142, Validation Loss=0.974064\n",
      "Epoch 47 Training Loss=1.010941, Validation Loss=0.974349\n",
      "Epoch 48 Training Loss=1.010740, Validation Loss=0.974632\n",
      "Epoch 49 Training Loss=1.010539, Validation Loss=0.974912\n",
      "Epoch 50 Training Loss=1.010337, Validation Loss=0.975192\n",
      "Epoch 51 Training Loss=1.010135, Validation Loss=0.975469\n",
      "Epoch 52 Training Loss=1.009933, Validation Loss=0.975746\n",
      "Epoch 53 Training Loss=1.009730, Validation Loss=0.976020\n",
      "Epoch 54 Training Loss=1.009528, Validation Loss=0.976294\n",
      "Epoch 55 Training Loss=1.009324, Validation Loss=0.976567\n",
      "Epoch 56 Training Loss=1.009121, Validation Loss=0.976838\n",
      "Epoch 57 Training Loss=1.008917, Validation Loss=0.977109\n",
      "Epoch 58 Training Loss=1.008712, Validation Loss=0.977380\n",
      "Epoch 59 Training Loss=1.008507, Validation Loss=0.977649\n",
      "Epoch 60 Training Loss=1.008302, Validation Loss=0.977918\n",
      "Epoch 61 Training Loss=1.008096, Validation Loss=0.978187\n",
      "Epoch 62 Training Loss=1.007890, Validation Loss=0.978455\n",
      "Epoch 63 Training Loss=1.007683, Validation Loss=0.978723\n",
      "Epoch 64 Training Loss=1.007475, Validation Loss=0.978990\n",
      "Epoch 65 Training Loss=1.007267, Validation Loss=0.979258\n",
      "Epoch 66 Training Loss=1.007058, Validation Loss=0.979525\n",
      "Epoch 67 Training Loss=1.006848, Validation Loss=0.979793\n",
      "Epoch 68 Training Loss=1.006638, Validation Loss=0.980060\n",
      "Epoch 69 Training Loss=1.006428, Validation Loss=0.980328\n",
      "Epoch 70 Training Loss=1.006216, Validation Loss=0.980596\n",
      "Epoch 71 Training Loss=1.006004, Validation Loss=0.980864\n",
      "Epoch 72 Training Loss=1.005791, Validation Loss=0.981132\n",
      "Epoch 73 Training Loss=1.005578, Validation Loss=0.981401\n",
      "Epoch 74 Training Loss=1.005363, Validation Loss=0.981670\n",
      "Epoch 75 Training Loss=1.005148, Validation Loss=0.981940\n",
      "Epoch 76 Training Loss=1.004933, Validation Loss=0.982210\n",
      "Epoch 77 Training Loss=1.004716, Validation Loss=0.982481\n",
      "Epoch 78 Training Loss=1.004499, Validation Loss=0.982752\n",
      "Epoch 79 Training Loss=1.004281, Validation Loss=0.983024\n",
      "Epoch 80 Training Loss=1.004062, Validation Loss=0.983296\n",
      "Epoch 81 Training Loss=1.003842, Validation Loss=0.983570\n",
      "Epoch 82 Training Loss=1.003622, Validation Loss=0.983844\n",
      "Epoch 83 Training Loss=1.003401, Validation Loss=0.984119\n",
      "Epoch 84 Training Loss=1.003179, Validation Loss=0.984394\n",
      "Epoch 85 Training Loss=1.002956, Validation Loss=0.984671\n",
      "Epoch 86 Training Loss=1.002733, Validation Loss=0.984948\n",
      "Epoch 87 Training Loss=1.002508, Validation Loss=0.985226\n",
      "Epoch 88 Training Loss=1.002283, Validation Loss=0.985506\n",
      "Epoch 89 Training Loss=1.002057, Validation Loss=0.985786\n",
      "Epoch 90 Training Loss=1.001831, Validation Loss=0.986067\n",
      "Epoch 91 Training Loss=1.001603, Validation Loss=0.986350\n",
      "Epoch 92 Training Loss=1.001375, Validation Loss=0.986633\n",
      "Epoch 93 Training Loss=1.001146, Validation Loss=0.986918\n",
      "Epoch 94 Training Loss=1.000916, Validation Loss=0.987203\n",
      "Epoch 95 Training Loss=1.000685, Validation Loss=0.987490\n",
      "Epoch 96 Training Loss=1.000454, Validation Loss=0.987778\n",
      "Epoch 97 Training Loss=1.000221, Validation Loss=0.988067\n",
      "Epoch 98 Training Loss=0.999988, Validation Loss=0.988357\n",
      "Epoch 99 Training Loss=0.999754, Validation Loss=0.988648\n",
      "Epoch 100 Training Loss=0.999519, Validation Loss=0.988941\n",
      "Epoch 101 Training Loss=0.999284, Validation Loss=0.989234\n",
      "Epoch 102 Training Loss=0.999048, Validation Loss=0.989529\n",
      "Epoch 103 Training Loss=0.998811, Validation Loss=0.989826\n",
      "Epoch 104 Training Loss=0.998573, Validation Loss=0.990123\n",
      "Epoch 105 Training Loss=0.998334, Validation Loss=0.990422\n",
      "Epoch 106 Training Loss=0.998095, Validation Loss=0.990722\n",
      "Epoch 107 Training Loss=0.997855, Validation Loss=0.991024\n",
      "Epoch 108 Training Loss=0.997614, Validation Loss=0.991326\n",
      "Epoch 109 Training Loss=0.997373, Validation Loss=0.991630\n",
      "Epoch 110 Training Loss=0.997130, Validation Loss=0.991935\n",
      "Epoch 111 Training Loss=0.996887, Validation Loss=0.992242\n",
      "Epoch 112 Training Loss=0.996644, Validation Loss=0.992550\n",
      "Epoch 113 Training Loss=0.996399, Validation Loss=0.992859\n",
      "Epoch 114 Training Loss=0.996154, Validation Loss=0.993170\n",
      "Epoch 115 Training Loss=0.995908, Validation Loss=0.993481\n",
      "Epoch 116 Training Loss=0.995662, Validation Loss=0.993795\n",
      "Epoch 117 Training Loss=0.995415, Validation Loss=0.994109\n",
      "Epoch 118 Training Loss=0.995167, Validation Loss=0.994425\n",
      "Epoch 119 Training Loss=0.994918, Validation Loss=0.994742\n",
      "Epoch 120 Training Loss=0.994669, Validation Loss=0.995061\n",
      "Epoch 121 Training Loss=0.994420, Validation Loss=0.995380\n",
      "Epoch 122 Training Loss=0.994169, Validation Loss=0.995701\n",
      "Epoch 123 Training Loss=0.993918, Validation Loss=0.996024\n",
      "Epoch 124 Training Loss=0.993667, Validation Loss=0.996347\n",
      "Epoch 125 Training Loss=0.993415, Validation Loss=0.996672\n",
      "Epoch 126 Training Loss=0.993162, Validation Loss=0.996999\n",
      "Epoch 127 Training Loss=0.992909, Validation Loss=0.997326\n",
      "Epoch 128 Training Loss=0.992655, Validation Loss=0.997655\n",
      "Epoch 129 Training Loss=0.992401, Validation Loss=0.997985\n",
      "Epoch 130 Training Loss=0.992146, Validation Loss=0.998316\n",
      "Epoch 131 Training Loss=0.991891, Validation Loss=0.998649\n",
      "Epoch 132 Training Loss=0.991635, Validation Loss=0.998982\n",
      "Epoch 133 Training Loss=0.991379, Validation Loss=0.999317\n",
      "Epoch 134 Training Loss=0.991122, Validation Loss=0.999653\n",
      "Epoch 135 Training Loss=0.990865, Validation Loss=0.999990\n",
      "Epoch 136 Training Loss=0.990608, Validation Loss=1.000329\n",
      "Epoch 137 Training Loss=0.990350, Validation Loss=1.000668\n",
      "Epoch 138 Training Loss=0.990091, Validation Loss=1.001009\n",
      "Epoch 139 Training Loss=0.989832, Validation Loss=1.001351\n",
      "Epoch 140 Training Loss=0.989573, Validation Loss=1.001694\n",
      "Epoch 141 Training Loss=0.989314, Validation Loss=1.002038\n",
      "Epoch 142 Training Loss=0.989054, Validation Loss=1.002383\n",
      "Epoch 143 Training Loss=0.988794, Validation Loss=1.002729\n",
      "Epoch 144 Training Loss=0.988533, Validation Loss=1.003076\n",
      "Epoch 145 Training Loss=0.988272, Validation Loss=1.003425\n",
      "Epoch 146 Training Loss=0.988011, Validation Loss=1.003774\n",
      "Epoch 147 Training Loss=0.987750, Validation Loss=1.004124\n",
      "Epoch 148 Training Loss=0.987488, Validation Loss=1.004475\n",
      "Epoch 149 Training Loss=0.987227, Validation Loss=1.004827\n",
      "Epoch 150 Training Loss=0.986965, Validation Loss=1.005180\n",
      "Epoch 151 Training Loss=0.986702, Validation Loss=1.005534\n",
      "Epoch 152 Training Loss=0.986440, Validation Loss=1.005889\n",
      "Epoch 153 Training Loss=0.986177, Validation Loss=1.006244\n",
      "Epoch 154 Training Loss=0.985915, Validation Loss=1.006601\n",
      "Epoch 155 Training Loss=0.985652, Validation Loss=1.006958\n",
      "Epoch 156 Training Loss=0.985389, Validation Loss=1.007316\n",
      "Epoch 157 Training Loss=0.985126, Validation Loss=1.007675\n",
      "Epoch 158 Training Loss=0.984863, Validation Loss=1.008034\n",
      "Epoch 159 Training Loss=0.984599, Validation Loss=1.008395\n",
      "Epoch 160 Training Loss=0.984336, Validation Loss=1.008756\n",
      "Epoch 161 Training Loss=0.984073, Validation Loss=1.009118\n",
      "Epoch 162 Training Loss=0.983809, Validation Loss=1.009480\n",
      "Epoch 163 Training Loss=0.983546, Validation Loss=1.009843\n",
      "Epoch 164 Training Loss=0.983283, Validation Loss=1.010206\n",
      "Epoch 165 Training Loss=0.983019, Validation Loss=1.010571\n",
      "Epoch 166 Training Loss=0.982756, Validation Loss=1.010935\n",
      "Epoch 167 Training Loss=0.982493, Validation Loss=1.011300\n",
      "Epoch 168 Training Loss=0.982230, Validation Loss=1.011666\n",
      "Epoch 169 Training Loss=0.981967, Validation Loss=1.012033\n",
      "Epoch 170 Training Loss=0.981704, Validation Loss=1.012399\n",
      "Epoch 171 Training Loss=0.981441, Validation Loss=1.012766\n",
      "Epoch 172 Training Loss=0.981178, Validation Loss=1.013134\n",
      "Epoch 173 Training Loss=0.980915, Validation Loss=1.013502\n",
      "Epoch 174 Training Loss=0.980653, Validation Loss=1.013870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 Training Loss=0.980391, Validation Loss=1.014239\n",
      "Epoch 176 Training Loss=0.980129, Validation Loss=1.014608\n",
      "Epoch 177 Training Loss=0.979867, Validation Loss=1.014977\n",
      "Epoch 178 Training Loss=0.979605, Validation Loss=1.015347\n",
      "Epoch 179 Training Loss=0.979344, Validation Loss=1.015717\n",
      "Epoch 180 Training Loss=0.979082, Validation Loss=1.016087\n",
      "Epoch 181 Training Loss=0.978822, Validation Loss=1.016457\n",
      "Epoch 182 Training Loss=0.978561, Validation Loss=1.016827\n",
      "Epoch 183 Training Loss=0.978300, Validation Loss=1.017198\n",
      "Epoch 184 Training Loss=0.978040, Validation Loss=1.017568\n",
      "Epoch 185 Training Loss=0.977781, Validation Loss=1.017939\n",
      "Epoch 186 Training Loss=0.977521, Validation Loss=1.018310\n",
      "Epoch 187 Training Loss=0.977262, Validation Loss=1.018681\n",
      "Epoch 188 Training Loss=0.977003, Validation Loss=1.019052\n",
      "Epoch 189 Training Loss=0.976745, Validation Loss=1.019423\n",
      "Epoch 190 Training Loss=0.976487, Validation Loss=1.019794\n",
      "Epoch 191 Training Loss=0.976229, Validation Loss=1.020165\n",
      "Epoch 192 Training Loss=0.975972, Validation Loss=1.020536\n",
      "Epoch 193 Training Loss=0.975715, Validation Loss=1.020906\n",
      "Epoch 194 Training Loss=0.975458, Validation Loss=1.021277\n",
      "Epoch 195 Training Loss=0.975202, Validation Loss=1.021647\n",
      "Epoch 196 Training Loss=0.974946, Validation Loss=1.022018\n",
      "Epoch 197 Training Loss=0.974691, Validation Loss=1.022388\n",
      "Epoch 198 Training Loss=0.974436, Validation Loss=1.022758\n",
      "Epoch 199 Training Loss=0.974182, Validation Loss=1.023127\n",
      "Epoch 0 Training Loss=1.064661, Validation Loss=0.936402\n",
      "Epoch 1 Training Loss=1.028760, Validation Loss=0.938586\n",
      "Epoch 2 Training Loss=1.022874, Validation Loss=0.943698\n",
      "Epoch 3 Training Loss=1.021332, Validation Loss=0.948674\n",
      "Epoch 4 Training Loss=1.020082, Validation Loss=0.954204\n",
      "Epoch 5 Training Loss=1.019291, Validation Loss=0.957814\n",
      "Epoch 6 Training Loss=1.018704, Validation Loss=0.960781\n",
      "Epoch 7 Training Loss=1.018161, Validation Loss=0.963304\n",
      "Epoch 8 Training Loss=1.017666, Validation Loss=0.965312\n",
      "Epoch 9 Training Loss=1.017214, Validation Loss=0.966955\n",
      "Epoch 10 Training Loss=1.016788, Validation Loss=0.968318\n",
      "Epoch 11 Training Loss=1.016381, Validation Loss=0.969457\n",
      "Epoch 12 Training Loss=1.015989, Validation Loss=0.970421\n",
      "Epoch 13 Training Loss=1.015607, Validation Loss=0.971250\n",
      "Epoch 14 Training Loss=1.015235, Validation Loss=0.971971\n",
      "Epoch 15 Training Loss=1.014871, Validation Loss=0.972607\n",
      "Epoch 16 Training Loss=1.014514, Validation Loss=0.973177\n",
      "Epoch 17 Training Loss=1.014163, Validation Loss=0.973694\n",
      "Epoch 18 Training Loss=1.013818, Validation Loss=0.974168\n",
      "Epoch 19 Training Loss=1.013480, Validation Loss=0.974607\n",
      "Epoch 20 Training Loss=1.013146, Validation Loss=0.975020\n",
      "Epoch 21 Training Loss=1.012817, Validation Loss=0.975409\n",
      "Epoch 22 Training Loss=1.012493, Validation Loss=0.975779\n",
      "Epoch 23 Training Loss=1.012173, Validation Loss=0.976133\n",
      "Epoch 24 Training Loss=1.011858, Validation Loss=0.976475\n",
      "Epoch 25 Training Loss=1.011546, Validation Loss=0.976804\n",
      "Epoch 26 Training Loss=1.011239, Validation Loss=0.977124\n",
      "Epoch 27 Training Loss=1.010935, Validation Loss=0.977435\n",
      "Epoch 28 Training Loss=1.010635, Validation Loss=0.977739\n",
      "Epoch 29 Training Loss=1.010338, Validation Loss=0.978035\n",
      "Epoch 30 Training Loss=1.010044, Validation Loss=0.978326\n",
      "Epoch 31 Training Loss=1.009753, Validation Loss=0.978611\n",
      "Epoch 32 Training Loss=1.009466, Validation Loss=0.978891\n",
      "Epoch 33 Training Loss=1.009181, Validation Loss=0.979166\n",
      "Epoch 34 Training Loss=1.008900, Validation Loss=0.979437\n",
      "Epoch 35 Training Loss=1.008620, Validation Loss=0.979704\n",
      "Epoch 36 Training Loss=1.008344, Validation Loss=0.979968\n",
      "Epoch 37 Training Loss=1.008070, Validation Loss=0.980228\n",
      "Epoch 38 Training Loss=1.007798, Validation Loss=0.980485\n",
      "Epoch 39 Training Loss=1.007529, Validation Loss=0.980739\n",
      "Epoch 40 Training Loss=1.007262, Validation Loss=0.980990\n",
      "Epoch 41 Training Loss=1.006997, Validation Loss=0.981238\n",
      "Epoch 42 Training Loss=1.006734, Validation Loss=0.981484\n",
      "Epoch 43 Training Loss=1.006474, Validation Loss=0.981728\n",
      "Epoch 44 Training Loss=1.006215, Validation Loss=0.981970\n",
      "Epoch 45 Training Loss=1.005958, Validation Loss=0.982209\n",
      "Epoch 46 Training Loss=1.005703, Validation Loss=0.982447\n",
      "Epoch 47 Training Loss=1.005450, Validation Loss=0.982683\n",
      "Epoch 48 Training Loss=1.005199, Validation Loss=0.982917\n",
      "Epoch 49 Training Loss=1.004949, Validation Loss=0.983150\n",
      "Epoch 50 Training Loss=1.004701, Validation Loss=0.983381\n",
      "Epoch 51 Training Loss=1.004455, Validation Loss=0.983611\n",
      "Epoch 52 Training Loss=1.004210, Validation Loss=0.983839\n",
      "Epoch 53 Training Loss=1.003967, Validation Loss=0.984066\n",
      "Epoch 54 Training Loss=1.003725, Validation Loss=0.984293\n",
      "Epoch 55 Training Loss=1.003485, Validation Loss=0.984518\n",
      "Epoch 56 Training Loss=1.003246, Validation Loss=0.984742\n",
      "Epoch 57 Training Loss=1.003009, Validation Loss=0.984965\n",
      "Epoch 58 Training Loss=1.002773, Validation Loss=0.985188\n",
      "Epoch 59 Training Loss=1.002538, Validation Loss=0.985409\n",
      "Epoch 60 Training Loss=1.002305, Validation Loss=0.985630\n",
      "Epoch 61 Training Loss=1.002073, Validation Loss=0.985850\n",
      "Epoch 62 Training Loss=1.001842, Validation Loss=0.986070\n",
      "Epoch 63 Training Loss=1.001613, Validation Loss=0.986289\n",
      "Epoch 64 Training Loss=1.001384, Validation Loss=0.986508\n",
      "Epoch 65 Training Loss=1.001157, Validation Loss=0.986726\n",
      "Epoch 66 Training Loss=1.000931, Validation Loss=0.986943\n",
      "Epoch 67 Training Loss=1.000707, Validation Loss=0.987160\n",
      "Epoch 68 Training Loss=1.000483, Validation Loss=0.987377\n",
      "Epoch 69 Training Loss=1.000260, Validation Loss=0.987593\n",
      "Epoch 70 Training Loss=1.000039, Validation Loss=0.987809\n",
      "Epoch 71 Training Loss=0.999819, Validation Loss=0.988025\n",
      "Epoch 72 Training Loss=0.999599, Validation Loss=0.988241\n",
      "Epoch 73 Training Loss=0.999381, Validation Loss=0.988456\n",
      "Epoch 74 Training Loss=0.999164, Validation Loss=0.988671\n",
      "Epoch 75 Training Loss=0.998948, Validation Loss=0.988886\n",
      "Epoch 76 Training Loss=0.998732, Validation Loss=0.989101\n",
      "Epoch 77 Training Loss=0.998518, Validation Loss=0.989315\n",
      "Epoch 78 Training Loss=0.998305, Validation Loss=0.989529\n",
      "Epoch 79 Training Loss=0.998093, Validation Loss=0.989744\n",
      "Epoch 80 Training Loss=0.997881, Validation Loss=0.989958\n",
      "Epoch 81 Training Loss=0.997671, Validation Loss=0.990172\n",
      "Epoch 82 Training Loss=0.997462, Validation Loss=0.990386\n",
      "Epoch 83 Training Loss=0.997253, Validation Loss=0.990600\n",
      "Epoch 84 Training Loss=0.997046, Validation Loss=0.990814\n",
      "Epoch 85 Training Loss=0.996839, Validation Loss=0.991028\n",
      "Epoch 86 Training Loss=0.996633, Validation Loss=0.991241\n",
      "Epoch 87 Training Loss=0.996428, Validation Loss=0.991455\n",
      "Epoch 88 Training Loss=0.996224, Validation Loss=0.991669\n",
      "Epoch 89 Training Loss=0.996021, Validation Loss=0.991882\n",
      "Epoch 90 Training Loss=0.995819, Validation Loss=0.992096\n",
      "Epoch 91 Training Loss=0.995618, Validation Loss=0.992309\n",
      "Epoch 92 Training Loss=0.995417, Validation Loss=0.992523\n",
      "Epoch 93 Training Loss=0.995218, Validation Loss=0.992736\n",
      "Epoch 94 Training Loss=0.995019, Validation Loss=0.992950\n",
      "Epoch 95 Training Loss=0.994821, Validation Loss=0.993163\n",
      "Epoch 96 Training Loss=0.994624, Validation Loss=0.993376\n",
      "Epoch 97 Training Loss=0.994427, Validation Loss=0.993590\n",
      "Epoch 98 Training Loss=0.994232, Validation Loss=0.993803\n",
      "Epoch 99 Training Loss=0.994037, Validation Loss=0.994016\n",
      "Epoch 100 Training Loss=0.993843, Validation Loss=0.994230\n",
      "Epoch 101 Training Loss=0.993650, Validation Loss=0.994443\n",
      "Epoch 102 Training Loss=0.993458, Validation Loss=0.994656\n",
      "Epoch 103 Training Loss=0.993266, Validation Loss=0.994869\n",
      "Epoch 104 Training Loss=0.993075, Validation Loss=0.995082\n",
      "Epoch 105 Training Loss=0.992885, Validation Loss=0.995295\n",
      "Epoch 106 Training Loss=0.992696, Validation Loss=0.995508\n",
      "Epoch 107 Training Loss=0.992508, Validation Loss=0.995720\n",
      "Epoch 108 Training Loss=0.992320, Validation Loss=0.995933\n",
      "Epoch 109 Training Loss=0.992133, Validation Loss=0.996146\n",
      "Epoch 110 Training Loss=0.991947, Validation Loss=0.996358\n",
      "Epoch 111 Training Loss=0.991761, Validation Loss=0.996570\n",
      "Epoch 112 Training Loss=0.991577, Validation Loss=0.996783\n",
      "Epoch 113 Training Loss=0.991393, Validation Loss=0.996995\n",
      "Epoch 114 Training Loss=0.991209, Validation Loss=0.997207\n",
      "Epoch 115 Training Loss=0.991027, Validation Loss=0.997418\n",
      "Epoch 116 Training Loss=0.990845, Validation Loss=0.997630\n",
      "Epoch 117 Training Loss=0.990664, Validation Loss=0.997842\n",
      "Epoch 118 Training Loss=0.990483, Validation Loss=0.998053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 Training Loss=0.990303, Validation Loss=0.998264\n",
      "Epoch 120 Training Loss=0.990124, Validation Loss=0.998475\n",
      "Epoch 121 Training Loss=0.989946, Validation Loss=0.998686\n",
      "Epoch 122 Training Loss=0.989768, Validation Loss=0.998896\n",
      "Epoch 123 Training Loss=0.989591, Validation Loss=0.999107\n",
      "Epoch 124 Training Loss=0.989415, Validation Loss=0.999317\n",
      "Epoch 125 Training Loss=0.989239, Validation Loss=0.999527\n",
      "Epoch 126 Training Loss=0.989064, Validation Loss=0.999736\n",
      "Epoch 127 Training Loss=0.988890, Validation Loss=0.999946\n",
      "Epoch 128 Training Loss=0.988716, Validation Loss=1.000155\n",
      "Epoch 129 Training Loss=0.988543, Validation Loss=1.000363\n",
      "Epoch 130 Training Loss=0.988371, Validation Loss=1.000572\n",
      "Epoch 131 Training Loss=0.988199, Validation Loss=1.000780\n",
      "Epoch 132 Training Loss=0.988028, Validation Loss=1.000988\n",
      "Epoch 133 Training Loss=0.987858, Validation Loss=1.001196\n",
      "Epoch 134 Training Loss=0.987688, Validation Loss=1.001403\n",
      "Epoch 135 Training Loss=0.987518, Validation Loss=1.001610\n",
      "Epoch 136 Training Loss=0.987350, Validation Loss=1.001817\n",
      "Epoch 137 Training Loss=0.987182, Validation Loss=1.002023\n",
      "Epoch 138 Training Loss=0.987014, Validation Loss=1.002229\n",
      "Epoch 139 Training Loss=0.986847, Validation Loss=1.002435\n",
      "Epoch 140 Training Loss=0.986681, Validation Loss=1.002640\n",
      "Epoch 141 Training Loss=0.986515, Validation Loss=1.002845\n",
      "Epoch 142 Training Loss=0.986350, Validation Loss=1.003049\n",
      "Epoch 143 Training Loss=0.986185, Validation Loss=1.003253\n",
      "Epoch 144 Training Loss=0.986021, Validation Loss=1.003457\n",
      "Epoch 145 Training Loss=0.985858, Validation Loss=1.003660\n",
      "Epoch 146 Training Loss=0.985695, Validation Loss=1.003863\n",
      "Epoch 147 Training Loss=0.985533, Validation Loss=1.004066\n",
      "Epoch 148 Training Loss=0.985371, Validation Loss=1.004268\n",
      "Epoch 149 Training Loss=0.985209, Validation Loss=1.004469\n",
      "Epoch 150 Training Loss=0.985049, Validation Loss=1.004670\n",
      "Epoch 151 Training Loss=0.984888, Validation Loss=1.004871\n",
      "Epoch 152 Training Loss=0.984729, Validation Loss=1.005071\n",
      "Epoch 153 Training Loss=0.984569, Validation Loss=1.005271\n",
      "Epoch 154 Training Loss=0.984411, Validation Loss=1.005470\n",
      "Epoch 155 Training Loss=0.984253, Validation Loss=1.005669\n",
      "Epoch 156 Training Loss=0.984095, Validation Loss=1.005867\n",
      "Epoch 157 Training Loss=0.983937, Validation Loss=1.006065\n",
      "Epoch 158 Training Loss=0.983781, Validation Loss=1.006263\n",
      "Epoch 159 Training Loss=0.983624, Validation Loss=1.006459\n",
      "Epoch 160 Training Loss=0.983469, Validation Loss=1.006656\n",
      "Epoch 161 Training Loss=0.983313, Validation Loss=1.006852\n",
      "Epoch 162 Training Loss=0.983158, Validation Loss=1.007047\n",
      "Epoch 163 Training Loss=0.983004, Validation Loss=1.007242\n",
      "Epoch 164 Training Loss=0.982850, Validation Loss=1.007436\n",
      "Epoch 165 Training Loss=0.982696, Validation Loss=1.007630\n",
      "Epoch 166 Training Loss=0.982543, Validation Loss=1.007823\n",
      "Epoch 167 Training Loss=0.982390, Validation Loss=1.008016\n",
      "Epoch 168 Training Loss=0.982238, Validation Loss=1.008209\n",
      "Epoch 169 Training Loss=0.982086, Validation Loss=1.008400\n",
      "Epoch 170 Training Loss=0.981935, Validation Loss=1.008591\n",
      "Epoch 171 Training Loss=0.981784, Validation Loss=1.008782\n",
      "Epoch 172 Training Loss=0.981633, Validation Loss=1.008972\n",
      "Epoch 173 Training Loss=0.981483, Validation Loss=1.009162\n",
      "Epoch 174 Training Loss=0.981333, Validation Loss=1.009351\n",
      "Epoch 175 Training Loss=0.981184, Validation Loss=1.009539\n",
      "Epoch 176 Training Loss=0.981035, Validation Loss=1.009727\n",
      "Epoch 177 Training Loss=0.980886, Validation Loss=1.009914\n",
      "Epoch 178 Training Loss=0.980738, Validation Loss=1.010101\n",
      "Epoch 179 Training Loss=0.980590, Validation Loss=1.010288\n",
      "Epoch 180 Training Loss=0.980442, Validation Loss=1.010473\n",
      "Epoch 181 Training Loss=0.980295, Validation Loss=1.010658\n",
      "Epoch 182 Training Loss=0.980148, Validation Loss=1.010843\n",
      "Epoch 183 Training Loss=0.980001, Validation Loss=1.011027\n",
      "Epoch 184 Training Loss=0.979855, Validation Loss=1.011210\n",
      "Epoch 185 Training Loss=0.979709, Validation Loss=1.011393\n",
      "Epoch 186 Training Loss=0.979564, Validation Loss=1.011576\n",
      "Epoch 187 Training Loss=0.979418, Validation Loss=1.011758\n",
      "Epoch 188 Training Loss=0.979273, Validation Loss=1.011939\n",
      "Epoch 189 Training Loss=0.979129, Validation Loss=1.012120\n",
      "Epoch 190 Training Loss=0.978985, Validation Loss=1.012300\n",
      "Epoch 191 Training Loss=0.978841, Validation Loss=1.012479\n",
      "Epoch 192 Training Loss=0.978697, Validation Loss=1.012658\n",
      "Epoch 193 Training Loss=0.978554, Validation Loss=1.012837\n",
      "Epoch 194 Training Loss=0.978411, Validation Loss=1.013015\n",
      "Epoch 195 Training Loss=0.978268, Validation Loss=1.013192\n",
      "Epoch 196 Training Loss=0.978125, Validation Loss=1.013369\n",
      "Epoch 197 Training Loss=0.977983, Validation Loss=1.013546\n",
      "Epoch 198 Training Loss=0.977841, Validation Loss=1.013721\n",
      "Epoch 199 Training Loss=0.977700, Validation Loss=1.013897\n",
      "Epoch 0 Training Loss=1.051928, Validation Loss=0.914947\n",
      "Epoch 1 Training Loss=1.031954, Validation Loss=0.923202\n",
      "Epoch 2 Training Loss=1.029842, Validation Loss=0.925606\n",
      "Epoch 3 Training Loss=1.027648, Validation Loss=0.928880\n",
      "Epoch 4 Training Loss=1.026212, Validation Loss=0.932681\n",
      "Epoch 5 Training Loss=1.025259, Validation Loss=0.936014\n",
      "Epoch 6 Training Loss=1.024379, Validation Loss=0.938830\n",
      "Epoch 7 Training Loss=1.023541, Validation Loss=0.941265\n",
      "Epoch 8 Training Loss=1.022762, Validation Loss=0.943421\n",
      "Epoch 9 Training Loss=1.022031, Validation Loss=0.945356\n",
      "Epoch 10 Training Loss=1.021340, Validation Loss=0.947105\n",
      "Epoch 11 Training Loss=1.020681, Validation Loss=0.948702\n",
      "Epoch 12 Training Loss=1.020051, Validation Loss=0.950175\n",
      "Epoch 13 Training Loss=1.019447, Validation Loss=0.951547\n",
      "Epoch 14 Training Loss=1.018866, Validation Loss=0.952834\n",
      "Epoch 15 Training Loss=1.018306, Validation Loss=0.954049\n",
      "Epoch 16 Training Loss=1.017765, Validation Loss=0.955203\n",
      "Epoch 17 Training Loss=1.017241, Validation Loss=0.956305\n",
      "Epoch 18 Training Loss=1.016734, Validation Loss=0.957361\n",
      "Epoch 19 Training Loss=1.016241, Validation Loss=0.958376\n",
      "Epoch 20 Training Loss=1.015761, Validation Loss=0.959356\n",
      "Epoch 21 Training Loss=1.015294, Validation Loss=0.960303\n",
      "Epoch 22 Training Loss=1.014838, Validation Loss=0.961220\n",
      "Epoch 23 Training Loss=1.014393, Validation Loss=0.962111\n",
      "Epoch 24 Training Loss=1.013957, Validation Loss=0.962976\n",
      "Epoch 25 Training Loss=1.013531, Validation Loss=0.963818\n",
      "Epoch 26 Training Loss=1.013113, Validation Loss=0.964638\n",
      "Epoch 27 Training Loss=1.012702, Validation Loss=0.965438\n",
      "Epoch 28 Training Loss=1.012299, Validation Loss=0.966219\n",
      "Epoch 29 Training Loss=1.011902, Validation Loss=0.966981\n",
      "Epoch 30 Training Loss=1.011512, Validation Loss=0.967726\n",
      "Epoch 31 Training Loss=1.011127, Validation Loss=0.968455\n",
      "Epoch 32 Training Loss=1.010748, Validation Loss=0.969167\n",
      "Epoch 33 Training Loss=1.010373, Validation Loss=0.969866\n",
      "Epoch 34 Training Loss=1.010003, Validation Loss=0.970550\n",
      "Epoch 35 Training Loss=1.009638, Validation Loss=0.971220\n",
      "Epoch 36 Training Loss=1.009276, Validation Loss=0.971877\n",
      "Epoch 37 Training Loss=1.008918, Validation Loss=0.972523\n",
      "Epoch 38 Training Loss=1.008564, Validation Loss=0.973156\n",
      "Epoch 39 Training Loss=1.008213, Validation Loss=0.973779\n",
      "Epoch 40 Training Loss=1.007865, Validation Loss=0.974390\n",
      "Epoch 41 Training Loss=1.007520, Validation Loss=0.974992\n",
      "Epoch 42 Training Loss=1.007178, Validation Loss=0.975584\n",
      "Epoch 43 Training Loss=1.006838, Validation Loss=0.976167\n",
      "Epoch 44 Training Loss=1.006501, Validation Loss=0.976740\n",
      "Epoch 45 Training Loss=1.006166, Validation Loss=0.977306\n",
      "Epoch 46 Training Loss=1.005834, Validation Loss=0.977863\n",
      "Epoch 47 Training Loss=1.005503, Validation Loss=0.978413\n",
      "Epoch 48 Training Loss=1.005174, Validation Loss=0.978956\n",
      "Epoch 49 Training Loss=1.004847, Validation Loss=0.979492\n",
      "Epoch 50 Training Loss=1.004522, Validation Loss=0.980021\n",
      "Epoch 51 Training Loss=1.004198, Validation Loss=0.980544\n",
      "Epoch 52 Training Loss=1.003876, Validation Loss=0.981061\n",
      "Epoch 53 Training Loss=1.003556, Validation Loss=0.981573\n",
      "Epoch 54 Training Loss=1.003236, Validation Loss=0.982079\n",
      "Epoch 55 Training Loss=1.002919, Validation Loss=0.982580\n",
      "Epoch 56 Training Loss=1.002602, Validation Loss=0.983076\n",
      "Epoch 57 Training Loss=1.002287, Validation Loss=0.983568\n",
      "Epoch 58 Training Loss=1.001973, Validation Loss=0.984056\n",
      "Epoch 59 Training Loss=1.001660, Validation Loss=0.984539\n",
      "Epoch 60 Training Loss=1.001348, Validation Loss=0.985019\n",
      "Epoch 61 Training Loss=1.001037, Validation Loss=0.985495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Training Loss=1.000728, Validation Loss=0.985968\n",
      "Epoch 63 Training Loss=1.000419, Validation Loss=0.986437\n",
      "Epoch 64 Training Loss=1.000111, Validation Loss=0.986904\n",
      "Epoch 65 Training Loss=0.999804, Validation Loss=0.987367\n",
      "Epoch 66 Training Loss=0.999498, Validation Loss=0.987828\n",
      "Epoch 67 Training Loss=0.999193, Validation Loss=0.988286\n",
      "Epoch 68 Training Loss=0.998888, Validation Loss=0.988742\n",
      "Epoch 69 Training Loss=0.998585, Validation Loss=0.989196\n",
      "Epoch 70 Training Loss=0.998282, Validation Loss=0.989647\n",
      "Epoch 71 Training Loss=0.997980, Validation Loss=0.990096\n",
      "Epoch 72 Training Loss=0.997679, Validation Loss=0.990544\n",
      "Epoch 73 Training Loss=0.997378, Validation Loss=0.990990\n",
      "Epoch 74 Training Loss=0.997079, Validation Loss=0.991434\n",
      "Epoch 75 Training Loss=0.996779, Validation Loss=0.991876\n",
      "Epoch 76 Training Loss=0.996481, Validation Loss=0.992317\n",
      "Epoch 77 Training Loss=0.996183, Validation Loss=0.992757\n",
      "Epoch 78 Training Loss=0.995886, Validation Loss=0.993195\n",
      "Epoch 79 Training Loss=0.995590, Validation Loss=0.993632\n",
      "Epoch 80 Training Loss=0.995294, Validation Loss=0.994068\n",
      "Epoch 81 Training Loss=0.994999, Validation Loss=0.994503\n",
      "Epoch 82 Training Loss=0.994704, Validation Loss=0.994937\n",
      "Epoch 83 Training Loss=0.994410, Validation Loss=0.995370\n",
      "Epoch 84 Training Loss=0.994117, Validation Loss=0.995803\n",
      "Epoch 85 Training Loss=0.993824, Validation Loss=0.996234\n",
      "Epoch 86 Training Loss=0.993532, Validation Loss=0.996664\n",
      "Epoch 87 Training Loss=0.993240, Validation Loss=0.997094\n",
      "Epoch 88 Training Loss=0.992949, Validation Loss=0.997523\n",
      "Epoch 89 Training Loss=0.992658, Validation Loss=0.997951\n",
      "Epoch 90 Training Loss=0.992368, Validation Loss=0.998379\n",
      "Epoch 91 Training Loss=0.992079, Validation Loss=0.998806\n",
      "Epoch 92 Training Loss=0.991790, Validation Loss=0.999233\n",
      "Epoch 93 Training Loss=0.991502, Validation Loss=0.999659\n",
      "Epoch 94 Training Loss=0.991214, Validation Loss=1.000085\n",
      "Epoch 95 Training Loss=0.990926, Validation Loss=1.000510\n",
      "Epoch 96 Training Loss=0.990640, Validation Loss=1.000934\n",
      "Epoch 97 Training Loss=0.990353, Validation Loss=1.001358\n",
      "Epoch 98 Training Loss=0.990067, Validation Loss=1.001782\n",
      "Epoch 99 Training Loss=0.989782, Validation Loss=1.002205\n",
      "Epoch 100 Training Loss=0.989497, Validation Loss=1.002628\n",
      "Epoch 101 Training Loss=0.989213, Validation Loss=1.003050\n",
      "Epoch 102 Training Loss=0.988929, Validation Loss=1.003472\n",
      "Epoch 103 Training Loss=0.988645, Validation Loss=1.003894\n",
      "Epoch 104 Training Loss=0.988362, Validation Loss=1.004315\n",
      "Epoch 105 Training Loss=0.988080, Validation Loss=1.004736\n",
      "Epoch 106 Training Loss=0.987798, Validation Loss=1.005156\n",
      "Epoch 107 Training Loss=0.987516, Validation Loss=1.005576\n",
      "Epoch 108 Training Loss=0.987235, Validation Loss=1.005995\n",
      "Epoch 109 Training Loss=0.986954, Validation Loss=1.006414\n",
      "Epoch 110 Training Loss=0.986674, Validation Loss=1.006833\n",
      "Epoch 111 Training Loss=0.986394, Validation Loss=1.007251\n",
      "Epoch 112 Training Loss=0.986114, Validation Loss=1.007668\n",
      "Epoch 113 Training Loss=0.985835, Validation Loss=1.008086\n",
      "Epoch 114 Training Loss=0.985556, Validation Loss=1.008502\n",
      "Epoch 115 Training Loss=0.985278, Validation Loss=1.008919\n",
      "Epoch 116 Training Loss=0.985000, Validation Loss=1.009334\n",
      "Epoch 117 Training Loss=0.984722, Validation Loss=1.009749\n",
      "Epoch 118 Training Loss=0.984445, Validation Loss=1.010164\n",
      "Epoch 119 Training Loss=0.984168, Validation Loss=1.010578\n",
      "Epoch 120 Training Loss=0.983891, Validation Loss=1.010991\n",
      "Epoch 121 Training Loss=0.983615, Validation Loss=1.011405\n",
      "Epoch 122 Training Loss=0.983339, Validation Loss=1.011817\n",
      "Epoch 123 Training Loss=0.983063, Validation Loss=1.012229\n",
      "Epoch 124 Training Loss=0.982788, Validation Loss=1.012640\n",
      "Epoch 125 Training Loss=0.982513, Validation Loss=1.013050\n",
      "Epoch 126 Training Loss=0.982238, Validation Loss=1.013460\n",
      "Epoch 127 Training Loss=0.981964, Validation Loss=1.013869\n",
      "Epoch 128 Training Loss=0.981690, Validation Loss=1.014278\n",
      "Epoch 129 Training Loss=0.981416, Validation Loss=1.014686\n",
      "Epoch 130 Training Loss=0.981142, Validation Loss=1.015093\n",
      "Epoch 131 Training Loss=0.980869, Validation Loss=1.015499\n",
      "Epoch 132 Training Loss=0.980596, Validation Loss=1.015905\n",
      "Epoch 133 Training Loss=0.980323, Validation Loss=1.016309\n",
      "Epoch 134 Training Loss=0.980050, Validation Loss=1.016713\n",
      "Epoch 135 Training Loss=0.979778, Validation Loss=1.017117\n",
      "Epoch 136 Training Loss=0.979506, Validation Loss=1.017519\n",
      "Epoch 137 Training Loss=0.979234, Validation Loss=1.017920\n",
      "Epoch 138 Training Loss=0.978962, Validation Loss=1.018321\n",
      "Epoch 139 Training Loss=0.978690, Validation Loss=1.018721\n",
      "Epoch 140 Training Loss=0.978418, Validation Loss=1.019120\n",
      "Epoch 141 Training Loss=0.978147, Validation Loss=1.019518\n",
      "Epoch 142 Training Loss=0.977876, Validation Loss=1.019915\n",
      "Epoch 143 Training Loss=0.977605, Validation Loss=1.020311\n",
      "Epoch 144 Training Loss=0.977334, Validation Loss=1.020707\n",
      "Epoch 145 Training Loss=0.977063, Validation Loss=1.021101\n",
      "Epoch 146 Training Loss=0.976792, Validation Loss=1.021495\n",
      "Epoch 147 Training Loss=0.976521, Validation Loss=1.021887\n",
      "Epoch 148 Training Loss=0.976251, Validation Loss=1.022278\n",
      "Epoch 149 Training Loss=0.975980, Validation Loss=1.022669\n",
      "Epoch 150 Training Loss=0.975710, Validation Loss=1.023058\n",
      "Epoch 151 Training Loss=0.975439, Validation Loss=1.023447\n",
      "Epoch 152 Training Loss=0.975169, Validation Loss=1.023834\n",
      "Epoch 153 Training Loss=0.974899, Validation Loss=1.024221\n",
      "Epoch 154 Training Loss=0.974628, Validation Loss=1.024606\n",
      "Epoch 155 Training Loss=0.974358, Validation Loss=1.024990\n",
      "Epoch 156 Training Loss=0.974088, Validation Loss=1.025374\n",
      "Epoch 157 Training Loss=0.973818, Validation Loss=1.025756\n",
      "Epoch 158 Training Loss=0.973548, Validation Loss=1.026137\n",
      "Epoch 159 Training Loss=0.973277, Validation Loss=1.026517\n",
      "Epoch 160 Training Loss=0.973007, Validation Loss=1.026896\n",
      "Epoch 161 Training Loss=0.972737, Validation Loss=1.027274\n",
      "Epoch 162 Training Loss=0.972466, Validation Loss=1.027651\n",
      "Epoch 163 Training Loss=0.972196, Validation Loss=1.028027\n",
      "Epoch 164 Training Loss=0.971926, Validation Loss=1.028401\n",
      "Epoch 165 Training Loss=0.971655, Validation Loss=1.028775\n",
      "Epoch 166 Training Loss=0.971385, Validation Loss=1.029148\n",
      "Epoch 167 Training Loss=0.971114, Validation Loss=1.029519\n",
      "Epoch 168 Training Loss=0.970843, Validation Loss=1.029889\n",
      "Epoch 169 Training Loss=0.970573, Validation Loss=1.030259\n",
      "Epoch 170 Training Loss=0.970302, Validation Loss=1.030627\n",
      "Epoch 171 Training Loss=0.970031, Validation Loss=1.030994\n",
      "Epoch 172 Training Loss=0.969760, Validation Loss=1.031360\n",
      "Epoch 173 Training Loss=0.969489, Validation Loss=1.031724\n",
      "Epoch 174 Training Loss=0.969217, Validation Loss=1.032088\n",
      "Epoch 175 Training Loss=0.968946, Validation Loss=1.032451\n",
      "Epoch 176 Training Loss=0.968674, Validation Loss=1.032812\n",
      "Epoch 177 Training Loss=0.968402, Validation Loss=1.033173\n",
      "Epoch 178 Training Loss=0.968131, Validation Loss=1.033533\n",
      "Epoch 179 Training Loss=0.967859, Validation Loss=1.033891\n",
      "Epoch 180 Training Loss=0.967586, Validation Loss=1.034248\n",
      "Epoch 181 Training Loss=0.967314, Validation Loss=1.034604\n",
      "Epoch 182 Training Loss=0.967042, Validation Loss=1.034959\n",
      "Epoch 183 Training Loss=0.966769, Validation Loss=1.035313\n",
      "Epoch 184 Training Loss=0.966496, Validation Loss=1.035666\n",
      "Epoch 185 Training Loss=0.966223, Validation Loss=1.036018\n",
      "Epoch 186 Training Loss=0.965950, Validation Loss=1.036369\n",
      "Epoch 187 Training Loss=0.965677, Validation Loss=1.036719\n",
      "Epoch 188 Training Loss=0.965403, Validation Loss=1.037068\n",
      "Epoch 189 Training Loss=0.965130, Validation Loss=1.037415\n",
      "Epoch 190 Training Loss=0.964856, Validation Loss=1.037762\n",
      "Epoch 191 Training Loss=0.964582, Validation Loss=1.038108\n",
      "Epoch 192 Training Loss=0.964307, Validation Loss=1.038453\n",
      "Epoch 193 Training Loss=0.964033, Validation Loss=1.038797\n",
      "Epoch 194 Training Loss=0.963758, Validation Loss=1.039139\n",
      "Epoch 195 Training Loss=0.963483, Validation Loss=1.039481\n",
      "Epoch 196 Training Loss=0.963208, Validation Loss=1.039822\n",
      "Epoch 197 Training Loss=0.962933, Validation Loss=1.040162\n",
      "Epoch 198 Training Loss=0.962657, Validation Loss=1.040501\n",
      "Epoch 199 Training Loss=0.962382, Validation Loss=1.040838\n",
      "Epoch 0 Training Loss=1.054361, Validation Loss=0.907014\n",
      "Epoch 1 Training Loss=1.036127, Validation Loss=0.911828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss=1.033444, Validation Loss=0.916430\n",
      "Epoch 3 Training Loss=1.031632, Validation Loss=0.920150\n",
      "Epoch 4 Training Loss=1.030190, Validation Loss=0.923426\n",
      "Epoch 5 Training Loss=1.029006, Validation Loss=0.926440\n",
      "Epoch 6 Training Loss=1.028014, Validation Loss=0.929246\n",
      "Epoch 7 Training Loss=1.027167, Validation Loss=0.931859\n",
      "Epoch 8 Training Loss=1.026432, Validation Loss=0.934289\n",
      "Epoch 9 Training Loss=1.025786, Validation Loss=0.936546\n",
      "Epoch 10 Training Loss=1.025212, Validation Loss=0.938642\n",
      "Epoch 11 Training Loss=1.024695, Validation Loss=0.940588\n",
      "Epoch 12 Training Loss=1.024225, Validation Loss=0.942395\n",
      "Epoch 13 Training Loss=1.023793, Validation Loss=0.944076\n",
      "Epoch 14 Training Loss=1.023392, Validation Loss=0.945641\n",
      "Epoch 15 Training Loss=1.023018, Validation Loss=0.947099\n",
      "Epoch 16 Training Loss=1.022666, Validation Loss=0.948462\n",
      "Epoch 17 Training Loss=1.022332, Validation Loss=0.949736\n",
      "Epoch 18 Training Loss=1.022014, Validation Loss=0.950930\n",
      "Epoch 19 Training Loss=1.021709, Validation Loss=0.952052\n",
      "Epoch 20 Training Loss=1.021415, Validation Loss=0.953108\n",
      "Epoch 21 Training Loss=1.021131, Validation Loss=0.954104\n",
      "Epoch 22 Training Loss=1.020856, Validation Loss=0.955045\n",
      "Epoch 23 Training Loss=1.020588, Validation Loss=0.955937\n",
      "Epoch 24 Training Loss=1.020327, Validation Loss=0.956784\n",
      "Epoch 25 Training Loss=1.020071, Validation Loss=0.957590\n",
      "Epoch 26 Training Loss=1.019821, Validation Loss=0.958359\n",
      "Epoch 27 Training Loss=1.019575, Validation Loss=0.959095\n",
      "Epoch 28 Training Loss=1.019334, Validation Loss=0.959800\n",
      "Epoch 29 Training Loss=1.019097, Validation Loss=0.960477\n",
      "Epoch 30 Training Loss=1.018862, Validation Loss=0.961129\n",
      "Epoch 31 Training Loss=1.018631, Validation Loss=0.961758\n",
      "Epoch 32 Training Loss=1.018403, Validation Loss=0.962365\n",
      "Epoch 33 Training Loss=1.018178, Validation Loss=0.962954\n",
      "Epoch 34 Training Loss=1.017955, Validation Loss=0.963524\n",
      "Epoch 35 Training Loss=1.017734, Validation Loss=0.964079\n",
      "Epoch 36 Training Loss=1.017515, Validation Loss=0.964619\n",
      "Epoch 37 Training Loss=1.017299, Validation Loss=0.965145\n",
      "Epoch 38 Training Loss=1.017084, Validation Loss=0.965659\n",
      "Epoch 39 Training Loss=1.016870, Validation Loss=0.966161\n",
      "Epoch 40 Training Loss=1.016658, Validation Loss=0.966652\n",
      "Epoch 41 Training Loss=1.016448, Validation Loss=0.967133\n",
      "Epoch 42 Training Loss=1.016239, Validation Loss=0.967605\n",
      "Epoch 43 Training Loss=1.016031, Validation Loss=0.968069\n",
      "Epoch 44 Training Loss=1.015824, Validation Loss=0.968525\n",
      "Epoch 45 Training Loss=1.015619, Validation Loss=0.968972\n",
      "Epoch 46 Training Loss=1.015414, Validation Loss=0.969413\n",
      "Epoch 47 Training Loss=1.015210, Validation Loss=0.969848\n",
      "Epoch 48 Training Loss=1.015007, Validation Loss=0.970276\n",
      "Epoch 49 Training Loss=1.014805, Validation Loss=0.970698\n",
      "Epoch 50 Training Loss=1.014604, Validation Loss=0.971114\n",
      "Epoch 51 Training Loss=1.014403, Validation Loss=0.971525\n",
      "Epoch 52 Training Loss=1.014203, Validation Loss=0.971931\n",
      "Epoch 53 Training Loss=1.014003, Validation Loss=0.972333\n",
      "Epoch 54 Training Loss=1.013804, Validation Loss=0.972729\n",
      "Epoch 55 Training Loss=1.013605, Validation Loss=0.973121\n",
      "Epoch 56 Training Loss=1.013407, Validation Loss=0.973509\n",
      "Epoch 57 Training Loss=1.013209, Validation Loss=0.973893\n",
      "Epoch 58 Training Loss=1.013011, Validation Loss=0.974273\n",
      "Epoch 59 Training Loss=1.012813, Validation Loss=0.974649\n",
      "Epoch 60 Training Loss=1.012616, Validation Loss=0.975021\n",
      "Epoch 61 Training Loss=1.012419, Validation Loss=0.975390\n",
      "Epoch 62 Training Loss=1.012222, Validation Loss=0.975756\n",
      "Epoch 63 Training Loss=1.012026, Validation Loss=0.976118\n",
      "Epoch 64 Training Loss=1.011829, Validation Loss=0.976476\n",
      "Epoch 65 Training Loss=1.011632, Validation Loss=0.976832\n",
      "Epoch 66 Training Loss=1.011436, Validation Loss=0.977185\n",
      "Epoch 67 Training Loss=1.011239, Validation Loss=0.977534\n",
      "Epoch 68 Training Loss=1.011042, Validation Loss=0.977881\n",
      "Epoch 69 Training Loss=1.010845, Validation Loss=0.978225\n",
      "Epoch 70 Training Loss=1.010648, Validation Loss=0.978566\n",
      "Epoch 71 Training Loss=1.010451, Validation Loss=0.978904\n",
      "Epoch 72 Training Loss=1.010254, Validation Loss=0.979240\n",
      "Epoch 73 Training Loss=1.010057, Validation Loss=0.979574\n",
      "Epoch 74 Training Loss=1.009859, Validation Loss=0.979905\n",
      "Epoch 75 Training Loss=1.009661, Validation Loss=0.980233\n",
      "Epoch 76 Training Loss=1.009463, Validation Loss=0.980559\n",
      "Epoch 77 Training Loss=1.009265, Validation Loss=0.980883\n",
      "Epoch 78 Training Loss=1.009066, Validation Loss=0.981204\n",
      "Epoch 79 Training Loss=1.008867, Validation Loss=0.981524\n",
      "Epoch 80 Training Loss=1.008667, Validation Loss=0.981841\n",
      "Epoch 81 Training Loss=1.008467, Validation Loss=0.982156\n",
      "Epoch 82 Training Loss=1.008267, Validation Loss=0.982469\n",
      "Epoch 83 Training Loss=1.008066, Validation Loss=0.982780\n",
      "Epoch 84 Training Loss=1.007864, Validation Loss=0.983089\n",
      "Epoch 85 Training Loss=1.007663, Validation Loss=0.983396\n",
      "Epoch 86 Training Loss=1.007460, Validation Loss=0.983702\n",
      "Epoch 87 Training Loss=1.007257, Validation Loss=0.984005\n",
      "Epoch 88 Training Loss=1.007054, Validation Loss=0.984307\n",
      "Epoch 89 Training Loss=1.006850, Validation Loss=0.984607\n",
      "Epoch 90 Training Loss=1.006645, Validation Loss=0.984906\n",
      "Epoch 91 Training Loss=1.006440, Validation Loss=0.985203\n",
      "Epoch 92 Training Loss=1.006234, Validation Loss=0.985498\n",
      "Epoch 93 Training Loss=1.006027, Validation Loss=0.985792\n",
      "Epoch 94 Training Loss=1.005820, Validation Loss=0.986085\n",
      "Epoch 95 Training Loss=1.005612, Validation Loss=0.986376\n",
      "Epoch 96 Training Loss=1.005404, Validation Loss=0.986666\n",
      "Epoch 97 Training Loss=1.005194, Validation Loss=0.986954\n",
      "Epoch 98 Training Loss=1.004984, Validation Loss=0.987241\n",
      "Epoch 99 Training Loss=1.004774, Validation Loss=0.987527\n",
      "Epoch 100 Training Loss=1.004562, Validation Loss=0.987812\n",
      "Epoch 101 Training Loss=1.004350, Validation Loss=0.988096\n",
      "Epoch 102 Training Loss=1.004137, Validation Loss=0.988379\n",
      "Epoch 103 Training Loss=1.003923, Validation Loss=0.988660\n",
      "Epoch 104 Training Loss=1.003709, Validation Loss=0.988941\n",
      "Epoch 105 Training Loss=1.003494, Validation Loss=0.989221\n",
      "Epoch 106 Training Loss=1.003278, Validation Loss=0.989500\n",
      "Epoch 107 Training Loss=1.003061, Validation Loss=0.989779\n",
      "Epoch 108 Training Loss=1.002843, Validation Loss=0.990056\n",
      "Epoch 109 Training Loss=1.002625, Validation Loss=0.990333\n",
      "Epoch 110 Training Loss=1.002406, Validation Loss=0.990609\n",
      "Epoch 111 Training Loss=1.002187, Validation Loss=0.990885\n",
      "Epoch 112 Training Loss=1.001966, Validation Loss=0.991161\n",
      "Epoch 113 Training Loss=1.001745, Validation Loss=0.991435\n",
      "Epoch 114 Training Loss=1.001524, Validation Loss=0.991710\n",
      "Epoch 115 Training Loss=1.001301, Validation Loss=0.991984\n",
      "Epoch 116 Training Loss=1.001078, Validation Loss=0.992258\n",
      "Epoch 117 Training Loss=1.000855, Validation Loss=0.992532\n",
      "Epoch 118 Training Loss=1.000630, Validation Loss=0.992805\n",
      "Epoch 119 Training Loss=1.000406, Validation Loss=0.993079\n",
      "Epoch 120 Training Loss=1.000180, Validation Loss=0.993352\n",
      "Epoch 121 Training Loss=0.999954, Validation Loss=0.993626\n",
      "Epoch 122 Training Loss=0.999728, Validation Loss=0.993899\n",
      "Epoch 123 Training Loss=0.999501, Validation Loss=0.994173\n",
      "Epoch 124 Training Loss=0.999273, Validation Loss=0.994447\n",
      "Epoch 125 Training Loss=0.999045, Validation Loss=0.994721\n",
      "Epoch 126 Training Loss=0.998817, Validation Loss=0.994996\n",
      "Epoch 127 Training Loss=0.998589, Validation Loss=0.995271\n",
      "Epoch 128 Training Loss=0.998360, Validation Loss=0.995546\n",
      "Epoch 129 Training Loss=0.998130, Validation Loss=0.995822\n",
      "Epoch 130 Training Loss=0.997901, Validation Loss=0.996099\n",
      "Epoch 131 Training Loss=0.997671, Validation Loss=0.996376\n",
      "Epoch 132 Training Loss=0.997441, Validation Loss=0.996653\n",
      "Epoch 133 Training Loss=0.997211, Validation Loss=0.996932\n",
      "Epoch 134 Training Loss=0.996981, Validation Loss=0.997211\n",
      "Epoch 135 Training Loss=0.996751, Validation Loss=0.997491\n",
      "Epoch 136 Training Loss=0.996521, Validation Loss=0.997772\n",
      "Epoch 137 Training Loss=0.996290, Validation Loss=0.998053\n",
      "Epoch 138 Training Loss=0.996060, Validation Loss=0.998336\n",
      "Epoch 139 Training Loss=0.995830, Validation Loss=0.998619\n",
      "Epoch 140 Training Loss=0.995600, Validation Loss=0.998904\n",
      "Epoch 141 Training Loss=0.995370, Validation Loss=0.999190\n",
      "Epoch 142 Training Loss=0.995141, Validation Loss=0.999476\n",
      "Epoch 143 Training Loss=0.994911, Validation Loss=0.999764\n",
      "Epoch 144 Training Loss=0.994682, Validation Loss=1.000053\n",
      "Epoch 145 Training Loss=0.994453, Validation Loss=1.000343\n",
      "Epoch 146 Training Loss=0.994225, Validation Loss=1.000634\n",
      "Epoch 147 Training Loss=0.993997, Validation Loss=1.000927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Training Loss=0.993769, Validation Loss=1.001221\n",
      "Epoch 149 Training Loss=0.993542, Validation Loss=1.001516\n",
      "Epoch 150 Training Loss=0.993315, Validation Loss=1.001812\n",
      "Epoch 151 Training Loss=0.993089, Validation Loss=1.002109\n",
      "Epoch 152 Training Loss=0.992863, Validation Loss=1.002408\n",
      "Epoch 153 Training Loss=0.992638, Validation Loss=1.002708\n",
      "Epoch 154 Training Loss=0.992413, Validation Loss=1.003010\n",
      "Epoch 155 Training Loss=0.992189, Validation Loss=1.003312\n",
      "Epoch 156 Training Loss=0.991966, Validation Loss=1.003616\n",
      "Epoch 157 Training Loss=0.991743, Validation Loss=1.003922\n",
      "Epoch 158 Training Loss=0.991521, Validation Loss=1.004228\n",
      "Epoch 159 Training Loss=0.991300, Validation Loss=1.004536\n",
      "Epoch 160 Training Loss=0.991080, Validation Loss=1.004845\n",
      "Epoch 161 Training Loss=0.990860, Validation Loss=1.005156\n",
      "Epoch 162 Training Loss=0.990641, Validation Loss=1.005467\n",
      "Epoch 163 Training Loss=0.990422, Validation Loss=1.005780\n",
      "Epoch 164 Training Loss=0.990205, Validation Loss=1.006095\n",
      "Epoch 165 Training Loss=0.989988, Validation Loss=1.006410\n",
      "Epoch 166 Training Loss=0.989772, Validation Loss=1.006726\n",
      "Epoch 167 Training Loss=0.989556, Validation Loss=1.007044\n",
      "Epoch 168 Training Loss=0.989342, Validation Loss=1.007362\n",
      "Epoch 169 Training Loss=0.989128, Validation Loss=1.007682\n",
      "Epoch 170 Training Loss=0.988915, Validation Loss=1.008003\n",
      "Epoch 171 Training Loss=0.988703, Validation Loss=1.008325\n",
      "Epoch 172 Training Loss=0.988492, Validation Loss=1.008648\n",
      "Epoch 173 Training Loss=0.988281, Validation Loss=1.008971\n",
      "Epoch 174 Training Loss=0.988071, Validation Loss=1.009296\n",
      "Epoch 175 Training Loss=0.987862, Validation Loss=1.009622\n",
      "Epoch 176 Training Loss=0.987654, Validation Loss=1.009948\n",
      "Epoch 177 Training Loss=0.987447, Validation Loss=1.010275\n",
      "Epoch 178 Training Loss=0.987240, Validation Loss=1.010603\n",
      "Epoch 179 Training Loss=0.987034, Validation Loss=1.010931\n",
      "Epoch 180 Training Loss=0.986829, Validation Loss=1.011260\n",
      "Epoch 181 Training Loss=0.986624, Validation Loss=1.011590\n",
      "Epoch 182 Training Loss=0.986421, Validation Loss=1.011920\n",
      "Epoch 183 Training Loss=0.986218, Validation Loss=1.012251\n",
      "Epoch 184 Training Loss=0.986015, Validation Loss=1.012582\n",
      "Epoch 185 Training Loss=0.985814, Validation Loss=1.012913\n",
      "Epoch 186 Training Loss=0.985613, Validation Loss=1.013245\n",
      "Epoch 187 Training Loss=0.985413, Validation Loss=1.013577\n",
      "Epoch 188 Training Loss=0.985213, Validation Loss=1.013909\n",
      "Epoch 189 Training Loss=0.985014, Validation Loss=1.014241\n",
      "Epoch 190 Training Loss=0.984816, Validation Loss=1.014574\n",
      "Epoch 191 Training Loss=0.984619, Validation Loss=1.014906\n",
      "Epoch 192 Training Loss=0.984422, Validation Loss=1.015239\n",
      "Epoch 193 Training Loss=0.984226, Validation Loss=1.015571\n",
      "Epoch 194 Training Loss=0.984030, Validation Loss=1.015903\n",
      "Epoch 195 Training Loss=0.983835, Validation Loss=1.016235\n",
      "Epoch 196 Training Loss=0.983641, Validation Loss=1.016566\n",
      "Epoch 197 Training Loss=0.983447, Validation Loss=1.016897\n",
      "Epoch 198 Training Loss=0.983254, Validation Loss=1.017228\n",
      "Epoch 199 Training Loss=0.983062, Validation Loss=1.017558\n",
      "Epoch 0 Training Loss=1.057418, Validation Loss=0.919971\n",
      "Epoch 1 Training Loss=1.037912, Validation Loss=0.921959\n",
      "Epoch 2 Training Loss=1.032308, Validation Loss=0.925521\n",
      "Epoch 3 Training Loss=1.029709, Validation Loss=0.928648\n",
      "Epoch 4 Training Loss=1.028226, Validation Loss=0.931255\n",
      "Epoch 5 Training Loss=1.027252, Validation Loss=0.933449\n",
      "Epoch 6 Training Loss=1.026539, Validation Loss=0.935329\n",
      "Epoch 7 Training Loss=1.025971, Validation Loss=0.936965\n",
      "Epoch 8 Training Loss=1.025489, Validation Loss=0.938407\n",
      "Epoch 9 Training Loss=1.025063, Validation Loss=0.939692\n",
      "Epoch 10 Training Loss=1.024675, Validation Loss=0.940847\n",
      "Epoch 11 Training Loss=1.024315, Validation Loss=0.941894\n",
      "Epoch 12 Training Loss=1.023975, Validation Loss=0.942850\n",
      "Epoch 13 Training Loss=1.023652, Validation Loss=0.943728\n",
      "Epoch 14 Training Loss=1.023342, Validation Loss=0.944540\n",
      "Epoch 15 Training Loss=1.023044, Validation Loss=0.945295\n",
      "Epoch 16 Training Loss=1.022754, Validation Loss=0.946001\n",
      "Epoch 17 Training Loss=1.022472, Validation Loss=0.946664\n",
      "Epoch 18 Training Loss=1.022198, Validation Loss=0.947290\n",
      "Epoch 19 Training Loss=1.021929, Validation Loss=0.947884\n",
      "Epoch 20 Training Loss=1.021665, Validation Loss=0.948450\n",
      "Epoch 21 Training Loss=1.021406, Validation Loss=0.948991\n",
      "Epoch 22 Training Loss=1.021151, Validation Loss=0.949512\n",
      "Epoch 23 Training Loss=1.020899, Validation Loss=0.950014\n",
      "Epoch 24 Training Loss=1.020650, Validation Loss=0.950501\n",
      "Epoch 25 Training Loss=1.020404, Validation Loss=0.950973\n",
      "Epoch 26 Training Loss=1.020160, Validation Loss=0.951434\n",
      "Epoch 27 Training Loss=1.019918, Validation Loss=0.951884\n",
      "Epoch 28 Training Loss=1.019677, Validation Loss=0.952326\n",
      "Epoch 29 Training Loss=1.019438, Validation Loss=0.952760\n",
      "Epoch 30 Training Loss=1.019200, Validation Loss=0.953187\n",
      "Epoch 31 Training Loss=1.018963, Validation Loss=0.953609\n",
      "Epoch 32 Training Loss=1.018726, Validation Loss=0.954027\n",
      "Epoch 33 Training Loss=1.018490, Validation Loss=0.954441\n",
      "Epoch 34 Training Loss=1.018254, Validation Loss=0.954852\n",
      "Epoch 35 Training Loss=1.018018, Validation Loss=0.955260\n",
      "Epoch 36 Training Loss=1.017782, Validation Loss=0.955667\n",
      "Epoch 37 Training Loss=1.017545, Validation Loss=0.956072\n",
      "Epoch 38 Training Loss=1.017309, Validation Loss=0.956477\n",
      "Epoch 39 Training Loss=1.017071, Validation Loss=0.956881\n",
      "Epoch 40 Training Loss=1.016834, Validation Loss=0.957285\n",
      "Epoch 41 Training Loss=1.016595, Validation Loss=0.957690\n",
      "Epoch 42 Training Loss=1.016355, Validation Loss=0.958095\n",
      "Epoch 43 Training Loss=1.016115, Validation Loss=0.958501\n",
      "Epoch 44 Training Loss=1.015873, Validation Loss=0.958908\n",
      "Epoch 45 Training Loss=1.015631, Validation Loss=0.959317\n",
      "Epoch 46 Training Loss=1.015387, Validation Loss=0.959727\n",
      "Epoch 47 Training Loss=1.015142, Validation Loss=0.960140\n",
      "Epoch 48 Training Loss=1.014896, Validation Loss=0.960554\n",
      "Epoch 49 Training Loss=1.014648, Validation Loss=0.960970\n",
      "Epoch 50 Training Loss=1.014399, Validation Loss=0.961389\n",
      "Epoch 51 Training Loss=1.014148, Validation Loss=0.961810\n",
      "Epoch 52 Training Loss=1.013896, Validation Loss=0.962234\n",
      "Epoch 53 Training Loss=1.013642, Validation Loss=0.962660\n",
      "Epoch 54 Training Loss=1.013387, Validation Loss=0.963089\n",
      "Epoch 55 Training Loss=1.013130, Validation Loss=0.963521\n",
      "Epoch 56 Training Loss=1.012872, Validation Loss=0.963956\n",
      "Epoch 57 Training Loss=1.012612, Validation Loss=0.964393\n",
      "Epoch 58 Training Loss=1.012350, Validation Loss=0.964834\n",
      "Epoch 59 Training Loss=1.012086, Validation Loss=0.965277\n",
      "Epoch 60 Training Loss=1.011821, Validation Loss=0.965724\n",
      "Epoch 61 Training Loss=1.011554, Validation Loss=0.966173\n",
      "Epoch 62 Training Loss=1.011286, Validation Loss=0.966626\n",
      "Epoch 63 Training Loss=1.011015, Validation Loss=0.967082\n",
      "Epoch 64 Training Loss=1.010743, Validation Loss=0.967540\n",
      "Epoch 65 Training Loss=1.010469, Validation Loss=0.968002\n",
      "Epoch 66 Training Loss=1.010193, Validation Loss=0.968467\n",
      "Epoch 67 Training Loss=1.009916, Validation Loss=0.968934\n",
      "Epoch 68 Training Loss=1.009636, Validation Loss=0.969405\n",
      "Epoch 69 Training Loss=1.009355, Validation Loss=0.969878\n",
      "Epoch 70 Training Loss=1.009072, Validation Loss=0.970355\n",
      "Epoch 71 Training Loss=1.008787, Validation Loss=0.970834\n",
      "Epoch 72 Training Loss=1.008501, Validation Loss=0.971316\n",
      "Epoch 73 Training Loss=1.008212, Validation Loss=0.971800\n",
      "Epoch 74 Training Loss=1.007921, Validation Loss=0.972288\n",
      "Epoch 75 Training Loss=1.007629, Validation Loss=0.972777\n",
      "Epoch 76 Training Loss=1.007335, Validation Loss=0.973270\n",
      "Epoch 77 Training Loss=1.007038, Validation Loss=0.973765\n",
      "Epoch 78 Training Loss=1.006740, Validation Loss=0.974262\n",
      "Epoch 79 Training Loss=1.006439, Validation Loss=0.974762\n",
      "Epoch 80 Training Loss=1.006137, Validation Loss=0.975264\n",
      "Epoch 81 Training Loss=1.005832, Validation Loss=0.975768\n",
      "Epoch 82 Training Loss=1.005526, Validation Loss=0.976274\n",
      "Epoch 83 Training Loss=1.005217, Validation Loss=0.976783\n",
      "Epoch 84 Training Loss=1.004906, Validation Loss=0.977293\n",
      "Epoch 85 Training Loss=1.004593, Validation Loss=0.977805\n",
      "Epoch 86 Training Loss=1.004277, Validation Loss=0.978320\n",
      "Epoch 87 Training Loss=1.003960, Validation Loss=0.978836\n",
      "Epoch 88 Training Loss=1.003640, Validation Loss=0.979354\n",
      "Epoch 89 Training Loss=1.003317, Validation Loss=0.979873\n",
      "Epoch 90 Training Loss=1.002993, Validation Loss=0.980395\n",
      "Epoch 91 Training Loss=1.002666, Validation Loss=0.980918\n",
      "Epoch 92 Training Loss=1.002336, Validation Loss=0.981442\n",
      "Epoch 93 Training Loss=1.002004, Validation Loss=0.981968\n",
      "Epoch 94 Training Loss=1.001670, Validation Loss=0.982496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Training Loss=1.001333, Validation Loss=0.983025\n",
      "Epoch 96 Training Loss=1.000993, Validation Loss=0.983556\n",
      "Epoch 97 Training Loss=1.000651, Validation Loss=0.984088\n",
      "Epoch 98 Training Loss=1.000306, Validation Loss=0.984621\n",
      "Epoch 99 Training Loss=0.999959, Validation Loss=0.985156\n",
      "Epoch 100 Training Loss=0.999609, Validation Loss=0.985692\n",
      "Epoch 101 Training Loss=0.999257, Validation Loss=0.986229\n",
      "Epoch 102 Training Loss=0.998901, Validation Loss=0.986768\n",
      "Epoch 103 Training Loss=0.998543, Validation Loss=0.987308\n",
      "Epoch 104 Training Loss=0.998183, Validation Loss=0.987850\n",
      "Epoch 105 Training Loss=0.997820, Validation Loss=0.988392\n",
      "Epoch 106 Training Loss=0.997454, Validation Loss=0.988937\n",
      "Epoch 107 Training Loss=0.997085, Validation Loss=0.989482\n",
      "Epoch 108 Training Loss=0.996714, Validation Loss=0.990029\n",
      "Epoch 109 Training Loss=0.996340, Validation Loss=0.990577\n",
      "Epoch 110 Training Loss=0.995963, Validation Loss=0.991127\n",
      "Epoch 111 Training Loss=0.995584, Validation Loss=0.991678\n",
      "Epoch 112 Training Loss=0.995203, Validation Loss=0.992231\n",
      "Epoch 113 Training Loss=0.994818, Validation Loss=0.992785\n",
      "Epoch 114 Training Loss=0.994432, Validation Loss=0.993341\n",
      "Epoch 115 Training Loss=0.994042, Validation Loss=0.993899\n",
      "Epoch 116 Training Loss=0.993651, Validation Loss=0.994457\n",
      "Epoch 117 Training Loss=0.993257, Validation Loss=0.995018\n",
      "Epoch 118 Training Loss=0.992860, Validation Loss=0.995580\n",
      "Epoch 119 Training Loss=0.992462, Validation Loss=0.996144\n",
      "Epoch 120 Training Loss=0.992061, Validation Loss=0.996710\n",
      "Epoch 121 Training Loss=0.991658, Validation Loss=0.997278\n",
      "Epoch 122 Training Loss=0.991253, Validation Loss=0.997847\n",
      "Epoch 123 Training Loss=0.990846, Validation Loss=0.998418\n",
      "Epoch 124 Training Loss=0.990437, Validation Loss=0.998991\n",
      "Epoch 125 Training Loss=0.990027, Validation Loss=0.999567\n",
      "Epoch 126 Training Loss=0.989615, Validation Loss=1.000143\n",
      "Epoch 127 Training Loss=0.989201, Validation Loss=1.000722\n",
      "Epoch 128 Training Loss=0.988785, Validation Loss=1.001303\n",
      "Epoch 129 Training Loss=0.988368, Validation Loss=1.001886\n",
      "Epoch 130 Training Loss=0.987950, Validation Loss=1.002471\n",
      "Epoch 131 Training Loss=0.987531, Validation Loss=1.003058\n",
      "Epoch 132 Training Loss=0.987110, Validation Loss=1.003646\n",
      "Epoch 133 Training Loss=0.986688, Validation Loss=1.004237\n",
      "Epoch 134 Training Loss=0.986266, Validation Loss=1.004830\n",
      "Epoch 135 Training Loss=0.985842, Validation Loss=1.005424\n",
      "Epoch 136 Training Loss=0.985418, Validation Loss=1.006021\n",
      "Epoch 137 Training Loss=0.984994, Validation Loss=1.006619\n",
      "Epoch 138 Training Loss=0.984569, Validation Loss=1.007219\n",
      "Epoch 139 Training Loss=0.984143, Validation Loss=1.007821\n",
      "Epoch 140 Training Loss=0.983718, Validation Loss=1.008424\n",
      "Epoch 141 Training Loss=0.983292, Validation Loss=1.009029\n",
      "Epoch 142 Training Loss=0.982866, Validation Loss=1.009635\n",
      "Epoch 143 Training Loss=0.982440, Validation Loss=1.010243\n",
      "Epoch 144 Training Loss=0.982014, Validation Loss=1.010852\n",
      "Epoch 145 Training Loss=0.981589, Validation Loss=1.011462\n",
      "Epoch 146 Training Loss=0.981164, Validation Loss=1.012073\n",
      "Epoch 147 Training Loss=0.980739, Validation Loss=1.012684\n",
      "Epoch 148 Training Loss=0.980315, Validation Loss=1.013297\n",
      "Epoch 149 Training Loss=0.979892, Validation Loss=1.013910\n",
      "Epoch 150 Training Loss=0.979469, Validation Loss=1.014523\n",
      "Epoch 151 Training Loss=0.979047, Validation Loss=1.015137\n",
      "Epoch 152 Training Loss=0.978626, Validation Loss=1.015751\n",
      "Epoch 153 Training Loss=0.978206, Validation Loss=1.016364\n",
      "Epoch 154 Training Loss=0.977787, Validation Loss=1.016978\n",
      "Epoch 155 Training Loss=0.977369, Validation Loss=1.017590\n",
      "Epoch 156 Training Loss=0.976952, Validation Loss=1.018202\n",
      "Epoch 157 Training Loss=0.976537, Validation Loss=1.018813\n",
      "Epoch 158 Training Loss=0.976122, Validation Loss=1.019423\n",
      "Epoch 159 Training Loss=0.975709, Validation Loss=1.020032\n",
      "Epoch 160 Training Loss=0.975297, Validation Loss=1.020639\n",
      "Epoch 161 Training Loss=0.974887, Validation Loss=1.021244\n",
      "Epoch 162 Training Loss=0.974478, Validation Loss=1.021848\n",
      "Epoch 163 Training Loss=0.974070, Validation Loss=1.022449\n",
      "Epoch 164 Training Loss=0.973664, Validation Loss=1.023048\n",
      "Epoch 165 Training Loss=0.973259, Validation Loss=1.023644\n",
      "Epoch 166 Training Loss=0.972856, Validation Loss=1.024237\n",
      "Epoch 167 Training Loss=0.972454, Validation Loss=1.024828\n",
      "Epoch 168 Training Loss=0.972053, Validation Loss=1.025415\n",
      "Epoch 169 Training Loss=0.971654, Validation Loss=1.025998\n",
      "Epoch 170 Training Loss=0.971257, Validation Loss=1.026579\n",
      "Epoch 171 Training Loss=0.970860, Validation Loss=1.027155\n",
      "Epoch 172 Training Loss=0.970466, Validation Loss=1.027728\n",
      "Epoch 173 Training Loss=0.970072, Validation Loss=1.028296\n",
      "Epoch 174 Training Loss=0.969680, Validation Loss=1.028860\n",
      "Epoch 175 Training Loss=0.969289, Validation Loss=1.029420\n",
      "Epoch 176 Training Loss=0.968899, Validation Loss=1.029975\n",
      "Epoch 177 Training Loss=0.968511, Validation Loss=1.030526\n",
      "Epoch 178 Training Loss=0.968124, Validation Loss=1.031072\n",
      "Epoch 179 Training Loss=0.967738, Validation Loss=1.031612\n",
      "Epoch 180 Training Loss=0.967353, Validation Loss=1.032148\n",
      "Epoch 181 Training Loss=0.966969, Validation Loss=1.032679\n",
      "Epoch 182 Training Loss=0.966586, Validation Loss=1.033205\n",
      "Epoch 183 Training Loss=0.966204, Validation Loss=1.033725\n",
      "Epoch 184 Training Loss=0.965823, Validation Loss=1.034240\n",
      "Epoch 185 Training Loss=0.965443, Validation Loss=1.034750\n",
      "Epoch 186 Training Loss=0.965064, Validation Loss=1.035254\n",
      "Epoch 187 Training Loss=0.964685, Validation Loss=1.035753\n",
      "Epoch 188 Training Loss=0.964308, Validation Loss=1.036247\n",
      "Epoch 189 Training Loss=0.963931, Validation Loss=1.036736\n",
      "Epoch 190 Training Loss=0.963554, Validation Loss=1.037219\n",
      "Epoch 191 Training Loss=0.963178, Validation Loss=1.037696\n",
      "Epoch 192 Training Loss=0.962803, Validation Loss=1.038169\n",
      "Epoch 193 Training Loss=0.962428, Validation Loss=1.038636\n",
      "Epoch 194 Training Loss=0.962053, Validation Loss=1.039098\n",
      "Epoch 195 Training Loss=0.961679, Validation Loss=1.039555\n",
      "Epoch 196 Training Loss=0.961306, Validation Loss=1.040007\n",
      "Epoch 197 Training Loss=0.960932, Validation Loss=1.040454\n",
      "Epoch 198 Training Loss=0.960559, Validation Loss=1.040896\n",
      "Epoch 199 Training Loss=0.960185, Validation Loss=1.041334\n",
      "Epoch 0 Training Loss=1.050585, Validation Loss=0.915404\n",
      "Epoch 1 Training Loss=1.039905, Validation Loss=0.921745\n",
      "Epoch 2 Training Loss=1.038443, Validation Loss=0.926224\n",
      "Epoch 3 Training Loss=1.037064, Validation Loss=0.929956\n",
      "Epoch 4 Training Loss=1.035829, Validation Loss=0.933145\n",
      "Epoch 5 Training Loss=1.034719, Validation Loss=0.935895\n",
      "Epoch 6 Training Loss=1.033710, Validation Loss=0.938290\n",
      "Epoch 7 Training Loss=1.032782, Validation Loss=0.940393\n",
      "Epoch 8 Training Loss=1.031920, Validation Loss=0.942259\n",
      "Epoch 9 Training Loss=1.031115, Validation Loss=0.943930\n",
      "Epoch 10 Training Loss=1.030357, Validation Loss=0.945441\n",
      "Epoch 11 Training Loss=1.029641, Validation Loss=0.946820\n",
      "Epoch 12 Training Loss=1.028962, Validation Loss=0.948088\n",
      "Epoch 13 Training Loss=1.028317, Validation Loss=0.949266\n",
      "Epoch 14 Training Loss=1.027701, Validation Loss=0.950367\n",
      "Epoch 15 Training Loss=1.027112, Validation Loss=0.951402\n",
      "Epoch 16 Training Loss=1.026548, Validation Loss=0.952383\n",
      "Epoch 17 Training Loss=1.026005, Validation Loss=0.953315\n",
      "Epoch 18 Training Loss=1.025483, Validation Loss=0.954207\n",
      "Epoch 19 Training Loss=1.024980, Validation Loss=0.955064\n",
      "Epoch 20 Training Loss=1.024493, Validation Loss=0.955888\n",
      "Epoch 21 Training Loss=1.024023, Validation Loss=0.956686\n",
      "Epoch 22 Training Loss=1.023566, Validation Loss=0.957458\n",
      "Epoch 23 Training Loss=1.023123, Validation Loss=0.958207\n",
      "Epoch 24 Training Loss=1.022691, Validation Loss=0.958937\n",
      "Epoch 25 Training Loss=1.022271, Validation Loss=0.959649\n",
      "Epoch 26 Training Loss=1.021862, Validation Loss=0.960344\n",
      "Epoch 27 Training Loss=1.021461, Validation Loss=0.961024\n",
      "Epoch 28 Training Loss=1.021069, Validation Loss=0.961689\n",
      "Epoch 29 Training Loss=1.020686, Validation Loss=0.962342\n",
      "Epoch 30 Training Loss=1.020310, Validation Loss=0.962982\n",
      "Epoch 31 Training Loss=1.019940, Validation Loss=0.963611\n",
      "Epoch 32 Training Loss=1.019577, Validation Loss=0.964230\n",
      "Epoch 33 Training Loss=1.019220, Validation Loss=0.964839\n",
      "Epoch 34 Training Loss=1.018868, Validation Loss=0.965439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training Loss=1.018522, Validation Loss=0.966031\n",
      "Epoch 36 Training Loss=1.018179, Validation Loss=0.966614\n",
      "Epoch 37 Training Loss=1.017841, Validation Loss=0.967190\n",
      "Epoch 38 Training Loss=1.017507, Validation Loss=0.967759\n",
      "Epoch 39 Training Loss=1.017177, Validation Loss=0.968322\n",
      "Epoch 40 Training Loss=1.016849, Validation Loss=0.968879\n",
      "Epoch 41 Training Loss=1.016525, Validation Loss=0.969429\n",
      "Epoch 42 Training Loss=1.016204, Validation Loss=0.969975\n",
      "Epoch 43 Training Loss=1.015886, Validation Loss=0.970515\n",
      "Epoch 44 Training Loss=1.015569, Validation Loss=0.971051\n",
      "Epoch 45 Training Loss=1.015255, Validation Loss=0.971583\n",
      "Epoch 46 Training Loss=1.014944, Validation Loss=0.972110\n",
      "Epoch 47 Training Loss=1.014634, Validation Loss=0.972634\n",
      "Epoch 48 Training Loss=1.014326, Validation Loss=0.973154\n",
      "Epoch 49 Training Loss=1.014019, Validation Loss=0.973671\n",
      "Epoch 50 Training Loss=1.013714, Validation Loss=0.974185\n",
      "Epoch 51 Training Loss=1.013410, Validation Loss=0.974696\n",
      "Epoch 52 Training Loss=1.013108, Validation Loss=0.975205\n",
      "Epoch 53 Training Loss=1.012807, Validation Loss=0.975711\n",
      "Epoch 54 Training Loss=1.012507, Validation Loss=0.976216\n",
      "Epoch 55 Training Loss=1.012208, Validation Loss=0.976718\n",
      "Epoch 56 Training Loss=1.011910, Validation Loss=0.977218\n",
      "Epoch 57 Training Loss=1.011613, Validation Loss=0.977717\n",
      "Epoch 58 Training Loss=1.011317, Validation Loss=0.978214\n",
      "Epoch 59 Training Loss=1.011022, Validation Loss=0.978710\n",
      "Epoch 60 Training Loss=1.010727, Validation Loss=0.979205\n",
      "Epoch 61 Training Loss=1.010433, Validation Loss=0.979699\n",
      "Epoch 62 Training Loss=1.010140, Validation Loss=0.980192\n",
      "Epoch 63 Training Loss=1.009847, Validation Loss=0.980684\n",
      "Epoch 64 Training Loss=1.009555, Validation Loss=0.981175\n",
      "Epoch 65 Training Loss=1.009263, Validation Loss=0.981665\n",
      "Epoch 66 Training Loss=1.008972, Validation Loss=0.982155\n",
      "Epoch 67 Training Loss=1.008682, Validation Loss=0.982645\n",
      "Epoch 68 Training Loss=1.008392, Validation Loss=0.983134\n",
      "Epoch 69 Training Loss=1.008102, Validation Loss=0.983623\n",
      "Epoch 70 Training Loss=1.007813, Validation Loss=0.984112\n",
      "Epoch 71 Training Loss=1.007524, Validation Loss=0.984600\n",
      "Epoch 72 Training Loss=1.007236, Validation Loss=0.985088\n",
      "Epoch 73 Training Loss=1.006948, Validation Loss=0.985577\n",
      "Epoch 74 Training Loss=1.006661, Validation Loss=0.986065\n",
      "Epoch 75 Training Loss=1.006374, Validation Loss=0.986553\n",
      "Epoch 76 Training Loss=1.006087, Validation Loss=0.987041\n",
      "Epoch 77 Training Loss=1.005800, Validation Loss=0.987530\n",
      "Epoch 78 Training Loss=1.005514, Validation Loss=0.988018\n",
      "Epoch 79 Training Loss=1.005229, Validation Loss=0.988506\n",
      "Epoch 80 Training Loss=1.004944, Validation Loss=0.988995\n",
      "Epoch 81 Training Loss=1.004659, Validation Loss=0.989483\n",
      "Epoch 82 Training Loss=1.004374, Validation Loss=0.989972\n",
      "Epoch 83 Training Loss=1.004090, Validation Loss=0.990461\n",
      "Epoch 84 Training Loss=1.003806, Validation Loss=0.990950\n",
      "Epoch 85 Training Loss=1.003523, Validation Loss=0.991439\n",
      "Epoch 86 Training Loss=1.003240, Validation Loss=0.991928\n",
      "Epoch 87 Training Loss=1.002957, Validation Loss=0.992417\n",
      "Epoch 88 Training Loss=1.002675, Validation Loss=0.992906\n",
      "Epoch 89 Training Loss=1.002393, Validation Loss=0.993395\n",
      "Epoch 90 Training Loss=1.002111, Validation Loss=0.993884\n",
      "Epoch 91 Training Loss=1.001830, Validation Loss=0.994373\n",
      "Epoch 92 Training Loss=1.001549, Validation Loss=0.994862\n",
      "Epoch 93 Training Loss=1.001269, Validation Loss=0.995351\n",
      "Epoch 94 Training Loss=1.000989, Validation Loss=0.995839\n",
      "Epoch 95 Training Loss=1.000710, Validation Loss=0.996327\n",
      "Epoch 96 Training Loss=1.000431, Validation Loss=0.996815\n",
      "Epoch 97 Training Loss=1.000152, Validation Loss=0.997303\n",
      "Epoch 98 Training Loss=0.999874, Validation Loss=0.997790\n",
      "Epoch 99 Training Loss=0.999597, Validation Loss=0.998277\n",
      "Epoch 100 Training Loss=0.999320, Validation Loss=0.998763\n",
      "Epoch 101 Training Loss=0.999043, Validation Loss=0.999249\n",
      "Epoch 102 Training Loss=0.998767, Validation Loss=0.999734\n",
      "Epoch 103 Training Loss=0.998492, Validation Loss=1.000218\n",
      "Epoch 104 Training Loss=0.998217, Validation Loss=1.000702\n",
      "Epoch 105 Training Loss=0.997943, Validation Loss=1.001184\n",
      "Epoch 106 Training Loss=0.997669, Validation Loss=1.001666\n",
      "Epoch 107 Training Loss=0.997396, Validation Loss=1.002147\n",
      "Epoch 108 Training Loss=0.997124, Validation Loss=1.002626\n",
      "Epoch 109 Training Loss=0.996852, Validation Loss=1.003105\n",
      "Epoch 110 Training Loss=0.996580, Validation Loss=1.003583\n",
      "Epoch 111 Training Loss=0.996310, Validation Loss=1.004059\n",
      "Epoch 112 Training Loss=0.996040, Validation Loss=1.004534\n",
      "Epoch 113 Training Loss=0.995771, Validation Loss=1.005007\n",
      "Epoch 114 Training Loss=0.995502, Validation Loss=1.005479\n",
      "Epoch 115 Training Loss=0.995235, Validation Loss=1.005950\n",
      "Epoch 116 Training Loss=0.994968, Validation Loss=1.006419\n",
      "Epoch 117 Training Loss=0.994702, Validation Loss=1.006886\n",
      "Epoch 118 Training Loss=0.994436, Validation Loss=1.007352\n",
      "Epoch 119 Training Loss=0.994171, Validation Loss=1.007815\n",
      "Epoch 120 Training Loss=0.993908, Validation Loss=1.008277\n",
      "Epoch 121 Training Loss=0.993645, Validation Loss=1.008737\n",
      "Epoch 122 Training Loss=0.993383, Validation Loss=1.009195\n",
      "Epoch 123 Training Loss=0.993121, Validation Loss=1.009650\n",
      "Epoch 124 Training Loss=0.992861, Validation Loss=1.010104\n",
      "Epoch 125 Training Loss=0.992601, Validation Loss=1.010555\n",
      "Epoch 126 Training Loss=0.992343, Validation Loss=1.011004\n",
      "Epoch 127 Training Loss=0.992085, Validation Loss=1.011451\n",
      "Epoch 128 Training Loss=0.991828, Validation Loss=1.011895\n",
      "Epoch 129 Training Loss=0.991572, Validation Loss=1.012337\n",
      "Epoch 130 Training Loss=0.991317, Validation Loss=1.012776\n",
      "Epoch 131 Training Loss=0.991063, Validation Loss=1.013213\n",
      "Epoch 132 Training Loss=0.990811, Validation Loss=1.013647\n",
      "Epoch 133 Training Loss=0.990559, Validation Loss=1.014079\n",
      "Epoch 134 Training Loss=0.990308, Validation Loss=1.014508\n",
      "Epoch 135 Training Loss=0.990058, Validation Loss=1.014934\n",
      "Epoch 136 Training Loss=0.989809, Validation Loss=1.015357\n",
      "Epoch 137 Training Loss=0.989561, Validation Loss=1.015777\n",
      "Epoch 138 Training Loss=0.989314, Validation Loss=1.016194\n",
      "Epoch 139 Training Loss=0.989068, Validation Loss=1.016608\n",
      "Epoch 140 Training Loss=0.988824, Validation Loss=1.017020\n",
      "Epoch 141 Training Loss=0.988580, Validation Loss=1.017428\n",
      "Epoch 142 Training Loss=0.988337, Validation Loss=1.017833\n",
      "Epoch 143 Training Loss=0.988096, Validation Loss=1.018236\n",
      "Epoch 144 Training Loss=0.987855, Validation Loss=1.018634\n",
      "Epoch 145 Training Loss=0.987616, Validation Loss=1.019030\n",
      "Epoch 146 Training Loss=0.987378, Validation Loss=1.019423\n",
      "Epoch 147 Training Loss=0.987141, Validation Loss=1.019812\n",
      "Epoch 148 Training Loss=0.986905, Validation Loss=1.020198\n",
      "Epoch 149 Training Loss=0.986670, Validation Loss=1.020581\n",
      "Epoch 150 Training Loss=0.986436, Validation Loss=1.020960\n",
      "Epoch 151 Training Loss=0.986203, Validation Loss=1.021336\n",
      "Epoch 152 Training Loss=0.985972, Validation Loss=1.021709\n",
      "Epoch 153 Training Loss=0.985741, Validation Loss=1.022078\n",
      "Epoch 154 Training Loss=0.985512, Validation Loss=1.022444\n",
      "Epoch 155 Training Loss=0.985284, Validation Loss=1.022807\n",
      "Epoch 156 Training Loss=0.985057, Validation Loss=1.023166\n",
      "Epoch 157 Training Loss=0.984831, Validation Loss=1.023522\n",
      "Epoch 158 Training Loss=0.984606, Validation Loss=1.023874\n",
      "Epoch 159 Training Loss=0.984382, Validation Loss=1.024222\n",
      "Epoch 160 Training Loss=0.984160, Validation Loss=1.024568\n",
      "Epoch 161 Training Loss=0.983938, Validation Loss=1.024909\n",
      "Epoch 162 Training Loss=0.983718, Validation Loss=1.025248\n",
      "Epoch 163 Training Loss=0.983499, Validation Loss=1.025582\n",
      "Epoch 164 Training Loss=0.983281, Validation Loss=1.025914\n",
      "Epoch 165 Training Loss=0.983063, Validation Loss=1.026241\n",
      "Epoch 166 Training Loss=0.982848, Validation Loss=1.026566\n",
      "Epoch 167 Training Loss=0.982633, Validation Loss=1.026887\n",
      "Epoch 168 Training Loss=0.982419, Validation Loss=1.027204\n",
      "Epoch 169 Training Loss=0.982206, Validation Loss=1.027518\n",
      "Epoch 170 Training Loss=0.981994, Validation Loss=1.027828\n",
      "Epoch 171 Training Loss=0.981783, Validation Loss=1.028135\n",
      "Epoch 172 Training Loss=0.981574, Validation Loss=1.028439\n",
      "Epoch 173 Training Loss=0.981365, Validation Loss=1.028738\n",
      "Epoch 174 Training Loss=0.981157, Validation Loss=1.029035\n",
      "Epoch 175 Training Loss=0.980951, Validation Loss=1.029328\n",
      "Epoch 176 Training Loss=0.980745, Validation Loss=1.029618\n",
      "Epoch 177 Training Loss=0.980540, Validation Loss=1.029904\n",
      "Epoch 178 Training Loss=0.980337, Validation Loss=1.030187\n",
      "Epoch 179 Training Loss=0.980134, Validation Loss=1.030467\n",
      "Epoch 180 Training Loss=0.979932, Validation Loss=1.030743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181 Training Loss=0.979731, Validation Loss=1.031016\n",
      "Epoch 182 Training Loss=0.979531, Validation Loss=1.031286\n",
      "Epoch 183 Training Loss=0.979332, Validation Loss=1.031552\n",
      "Epoch 184 Training Loss=0.979133, Validation Loss=1.031815\n",
      "Epoch 185 Training Loss=0.978936, Validation Loss=1.032075\n",
      "Epoch 186 Training Loss=0.978739, Validation Loss=1.032332\n",
      "Epoch 187 Training Loss=0.978543, Validation Loss=1.032586\n",
      "Epoch 188 Training Loss=0.978348, Validation Loss=1.032836\n",
      "Epoch 189 Training Loss=0.978154, Validation Loss=1.033083\n",
      "Epoch 190 Training Loss=0.977961, Validation Loss=1.033327\n",
      "Epoch 191 Training Loss=0.977768, Validation Loss=1.033569\n",
      "Epoch 192 Training Loss=0.977576, Validation Loss=1.033807\n",
      "Epoch 193 Training Loss=0.977385, Validation Loss=1.034042\n",
      "Epoch 194 Training Loss=0.977194, Validation Loss=1.034274\n",
      "Epoch 195 Training Loss=0.977005, Validation Loss=1.034503\n",
      "Epoch 196 Training Loss=0.976816, Validation Loss=1.034729\n",
      "Epoch 197 Training Loss=0.976627, Validation Loss=1.034953\n",
      "Epoch 198 Training Loss=0.976439, Validation Loss=1.035174\n",
      "Epoch 199 Training Loss=0.976252, Validation Loss=1.035391\n",
      "Epoch 0 Training Loss=1.070428, Validation Loss=0.963585\n",
      "Epoch 1 Training Loss=1.032839, Validation Loss=0.947183\n",
      "Epoch 2 Training Loss=1.031928, Validation Loss=0.948214\n",
      "Epoch 3 Training Loss=1.031402, Validation Loss=0.951469\n",
      "Epoch 4 Training Loss=1.030743, Validation Loss=0.954690\n",
      "Epoch 5 Training Loss=1.030105, Validation Loss=0.957513\n",
      "Epoch 6 Training Loss=1.029521, Validation Loss=0.959925\n",
      "Epoch 7 Training Loss=1.028985, Validation Loss=0.961978\n",
      "Epoch 8 Training Loss=1.028485, Validation Loss=0.963734\n",
      "Epoch 9 Training Loss=1.028012, Validation Loss=0.965247\n",
      "Epoch 10 Training Loss=1.027559, Validation Loss=0.966562\n",
      "Epoch 11 Training Loss=1.027122, Validation Loss=0.967719\n",
      "Epoch 12 Training Loss=1.026697, Validation Loss=0.968747\n",
      "Epoch 13 Training Loss=1.026282, Validation Loss=0.969671\n",
      "Epoch 14 Training Loss=1.025876, Validation Loss=0.970510\n",
      "Epoch 15 Training Loss=1.025478, Validation Loss=0.971281\n",
      "Epoch 16 Training Loss=1.025087, Validation Loss=0.971997\n",
      "Epoch 17 Training Loss=1.024702, Validation Loss=0.972668\n",
      "Epoch 18 Training Loss=1.024322, Validation Loss=0.973301\n",
      "Epoch 19 Training Loss=1.023948, Validation Loss=0.973904\n",
      "Epoch 20 Training Loss=1.023578, Validation Loss=0.974482\n",
      "Epoch 21 Training Loss=1.023212, Validation Loss=0.975040\n",
      "Epoch 22 Training Loss=1.022850, Validation Loss=0.975579\n",
      "Epoch 23 Training Loss=1.022491, Validation Loss=0.976105\n",
      "Epoch 24 Training Loss=1.022135, Validation Loss=0.976617\n",
      "Epoch 25 Training Loss=1.021782, Validation Loss=0.977120\n",
      "Epoch 26 Training Loss=1.021430, Validation Loss=0.977613\n",
      "Epoch 27 Training Loss=1.021081, Validation Loss=0.978099\n",
      "Epoch 28 Training Loss=1.020734, Validation Loss=0.978579\n",
      "Epoch 29 Training Loss=1.020388, Validation Loss=0.979053\n",
      "Epoch 30 Training Loss=1.020043, Validation Loss=0.979522\n",
      "Epoch 31 Training Loss=1.019699, Validation Loss=0.979987\n",
      "Epoch 32 Training Loss=1.019355, Validation Loss=0.980448\n",
      "Epoch 33 Training Loss=1.019012, Validation Loss=0.980906\n",
      "Epoch 34 Training Loss=1.018669, Validation Loss=0.981362\n",
      "Epoch 35 Training Loss=1.018326, Validation Loss=0.981816\n",
      "Epoch 36 Training Loss=1.017983, Validation Loss=0.982268\n",
      "Epoch 37 Training Loss=1.017639, Validation Loss=0.982719\n",
      "Epoch 38 Training Loss=1.017295, Validation Loss=0.983168\n",
      "Epoch 39 Training Loss=1.016950, Validation Loss=0.983617\n",
      "Epoch 40 Training Loss=1.016604, Validation Loss=0.984065\n",
      "Epoch 41 Training Loss=1.016257, Validation Loss=0.984514\n",
      "Epoch 42 Training Loss=1.015909, Validation Loss=0.984962\n",
      "Epoch 43 Training Loss=1.015560, Validation Loss=0.985410\n",
      "Epoch 44 Training Loss=1.015209, Validation Loss=0.985860\n",
      "Epoch 45 Training Loss=1.014857, Validation Loss=0.986310\n",
      "Epoch 46 Training Loss=1.014503, Validation Loss=0.986760\n",
      "Epoch 47 Training Loss=1.014147, Validation Loss=0.987213\n",
      "Epoch 48 Training Loss=1.013789, Validation Loss=0.987666\n",
      "Epoch 49 Training Loss=1.013429, Validation Loss=0.988121\n",
      "Epoch 50 Training Loss=1.013067, Validation Loss=0.988578\n",
      "Epoch 51 Training Loss=1.012703, Validation Loss=0.989038\n",
      "Epoch 52 Training Loss=1.012337, Validation Loss=0.989499\n",
      "Epoch 53 Training Loss=1.011968, Validation Loss=0.989962\n",
      "Epoch 54 Training Loss=1.011597, Validation Loss=0.990428\n",
      "Epoch 55 Training Loss=1.011223, Validation Loss=0.990897\n",
      "Epoch 56 Training Loss=1.010847, Validation Loss=0.991369\n",
      "Epoch 57 Training Loss=1.010468, Validation Loss=0.991843\n",
      "Epoch 58 Training Loss=1.010087, Validation Loss=0.992321\n",
      "Epoch 59 Training Loss=1.009702, Validation Loss=0.992801\n",
      "Epoch 60 Training Loss=1.009315, Validation Loss=0.993286\n",
      "Epoch 61 Training Loss=1.008926, Validation Loss=0.993773\n",
      "Epoch 62 Training Loss=1.008533, Validation Loss=0.994265\n",
      "Epoch 63 Training Loss=1.008137, Validation Loss=0.994760\n",
      "Epoch 64 Training Loss=1.007739, Validation Loss=0.995258\n",
      "Epoch 65 Training Loss=1.007337, Validation Loss=0.995761\n",
      "Epoch 66 Training Loss=1.006932, Validation Loss=0.996267\n",
      "Epoch 67 Training Loss=1.006525, Validation Loss=0.996778\n",
      "Epoch 68 Training Loss=1.006114, Validation Loss=0.997293\n",
      "Epoch 69 Training Loss=1.005700, Validation Loss=0.997811\n",
      "Epoch 70 Training Loss=1.005283, Validation Loss=0.998334\n",
      "Epoch 71 Training Loss=1.004863, Validation Loss=0.998861\n",
      "Epoch 72 Training Loss=1.004440, Validation Loss=0.999392\n",
      "Epoch 73 Training Loss=1.004013, Validation Loss=0.999928\n",
      "Epoch 74 Training Loss=1.003584, Validation Loss=1.000467\n",
      "Epoch 75 Training Loss=1.003151, Validation Loss=1.001011\n",
      "Epoch 76 Training Loss=1.002715, Validation Loss=1.001559\n",
      "Epoch 77 Training Loss=1.002275, Validation Loss=1.002111\n",
      "Epoch 78 Training Loss=1.001833, Validation Loss=1.002668\n",
      "Epoch 79 Training Loss=1.001387, Validation Loss=1.003228\n",
      "Epoch 80 Training Loss=1.000938, Validation Loss=1.003792\n",
      "Epoch 81 Training Loss=1.000486, Validation Loss=1.004360\n",
      "Epoch 82 Training Loss=1.000030, Validation Loss=1.004931\n",
      "Epoch 83 Training Loss=0.999572, Validation Loss=1.005507\n",
      "Epoch 84 Training Loss=0.999110, Validation Loss=1.006085\n",
      "Epoch 85 Training Loss=0.998645, Validation Loss=1.006667\n",
      "Epoch 86 Training Loss=0.998177, Validation Loss=1.007252\n",
      "Epoch 87 Training Loss=0.997705, Validation Loss=1.007840\n",
      "Epoch 88 Training Loss=0.997231, Validation Loss=1.008431\n",
      "Epoch 89 Training Loss=0.996753, Validation Loss=1.009025\n",
      "Epoch 90 Training Loss=0.996273, Validation Loss=1.009621\n",
      "Epoch 91 Training Loss=0.995789, Validation Loss=1.010219\n",
      "Epoch 92 Training Loss=0.995303, Validation Loss=1.010819\n",
      "Epoch 93 Training Loss=0.994813, Validation Loss=1.011421\n",
      "Epoch 94 Training Loss=0.994321, Validation Loss=1.012024\n",
      "Epoch 95 Training Loss=0.993826, Validation Loss=1.012629\n",
      "Epoch 96 Training Loss=0.993329, Validation Loss=1.013234\n",
      "Epoch 97 Training Loss=0.992828, Validation Loss=1.013841\n",
      "Epoch 98 Training Loss=0.992325, Validation Loss=1.014447\n",
      "Epoch 99 Training Loss=0.991820, Validation Loss=1.015054\n",
      "Epoch 100 Training Loss=0.991312, Validation Loss=1.015661\n",
      "Epoch 101 Training Loss=0.990802, Validation Loss=1.016268\n",
      "Epoch 102 Training Loss=0.990290, Validation Loss=1.016874\n",
      "Epoch 103 Training Loss=0.989776, Validation Loss=1.017479\n",
      "Epoch 104 Training Loss=0.989260, Validation Loss=1.018083\n",
      "Epoch 105 Training Loss=0.988742, Validation Loss=1.018686\n",
      "Epoch 106 Training Loss=0.988223, Validation Loss=1.019287\n",
      "Epoch 107 Training Loss=0.987702, Validation Loss=1.019886\n",
      "Epoch 108 Training Loss=0.987180, Validation Loss=1.020484\n",
      "Epoch 109 Training Loss=0.986656, Validation Loss=1.021079\n",
      "Epoch 110 Training Loss=0.986132, Validation Loss=1.021672\n",
      "Epoch 111 Training Loss=0.985606, Validation Loss=1.022262\n",
      "Epoch 112 Training Loss=0.985080, Validation Loss=1.022850\n",
      "Epoch 113 Training Loss=0.984553, Validation Loss=1.023434\n",
      "Epoch 114 Training Loss=0.984026, Validation Loss=1.024016\n",
      "Epoch 115 Training Loss=0.983498, Validation Loss=1.024594\n",
      "Epoch 116 Training Loss=0.982971, Validation Loss=1.025169\n",
      "Epoch 117 Training Loss=0.982443, Validation Loss=1.025741\n",
      "Epoch 118 Training Loss=0.981916, Validation Loss=1.026309\n",
      "Epoch 119 Training Loss=0.981389, Validation Loss=1.026874\n",
      "Epoch 120 Training Loss=0.980863, Validation Loss=1.027435\n",
      "Epoch 121 Training Loss=0.980337, Validation Loss=1.027993\n",
      "Epoch 122 Training Loss=0.979812, Validation Loss=1.028547\n",
      "Epoch 123 Training Loss=0.979288, Validation Loss=1.029097\n",
      "Epoch 124 Training Loss=0.978765, Validation Loss=1.029643\n",
      "Epoch 125 Training Loss=0.978243, Validation Loss=1.030185\n",
      "Epoch 126 Training Loss=0.977723, Validation Loss=1.030724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Training Loss=0.977204, Validation Loss=1.031258\n",
      "Epoch 128 Training Loss=0.976687, Validation Loss=1.031789\n",
      "Epoch 129 Training Loss=0.976172, Validation Loss=1.032316\n",
      "Epoch 130 Training Loss=0.975658, Validation Loss=1.032839\n",
      "Epoch 131 Training Loss=0.975146, Validation Loss=1.033358\n",
      "Epoch 132 Training Loss=0.974636, Validation Loss=1.033874\n",
      "Epoch 133 Training Loss=0.974128, Validation Loss=1.034385\n",
      "Epoch 134 Training Loss=0.973622, Validation Loss=1.034893\n",
      "Epoch 135 Training Loss=0.973119, Validation Loss=1.035397\n",
      "Epoch 136 Training Loss=0.972617, Validation Loss=1.035897\n",
      "Epoch 137 Training Loss=0.972118, Validation Loss=1.036393\n",
      "Epoch 138 Training Loss=0.971622, Validation Loss=1.036885\n",
      "Epoch 139 Training Loss=0.971128, Validation Loss=1.037374\n",
      "Epoch 140 Training Loss=0.970636, Validation Loss=1.037859\n",
      "Epoch 141 Training Loss=0.970147, Validation Loss=1.038341\n",
      "Epoch 142 Training Loss=0.969660, Validation Loss=1.038818\n",
      "Epoch 143 Training Loss=0.969176, Validation Loss=1.039292\n",
      "Epoch 144 Training Loss=0.968694, Validation Loss=1.039762\n",
      "Epoch 145 Training Loss=0.968215, Validation Loss=1.040228\n",
      "Epoch 146 Training Loss=0.967739, Validation Loss=1.040691\n",
      "Epoch 147 Training Loss=0.967265, Validation Loss=1.041150\n",
      "Epoch 148 Training Loss=0.966795, Validation Loss=1.041606\n",
      "Epoch 149 Training Loss=0.966326, Validation Loss=1.042058\n",
      "Epoch 150 Training Loss=0.965860, Validation Loss=1.042506\n",
      "Epoch 151 Training Loss=0.965397, Validation Loss=1.042951\n",
      "Epoch 152 Training Loss=0.964937, Validation Loss=1.043393\n",
      "Epoch 153 Training Loss=0.964479, Validation Loss=1.043831\n",
      "Epoch 154 Training Loss=0.964024, Validation Loss=1.044265\n",
      "Epoch 155 Training Loss=0.963572, Validation Loss=1.044696\n",
      "Epoch 156 Training Loss=0.963122, Validation Loss=1.045124\n",
      "Epoch 157 Training Loss=0.962675, Validation Loss=1.045548\n",
      "Epoch 158 Training Loss=0.962230, Validation Loss=1.045968\n",
      "Epoch 159 Training Loss=0.961788, Validation Loss=1.046386\n",
      "Epoch 160 Training Loss=0.961348, Validation Loss=1.046800\n",
      "Epoch 161 Training Loss=0.960911, Validation Loss=1.047211\n",
      "Epoch 162 Training Loss=0.960477, Validation Loss=1.047619\n",
      "Epoch 163 Training Loss=0.960044, Validation Loss=1.048023\n",
      "Epoch 164 Training Loss=0.959615, Validation Loss=1.048425\n",
      "Epoch 165 Training Loss=0.959187, Validation Loss=1.048823\n",
      "Epoch 166 Training Loss=0.958763, Validation Loss=1.049219\n",
      "Epoch 167 Training Loss=0.958340, Validation Loss=1.049611\n",
      "Epoch 168 Training Loss=0.957920, Validation Loss=1.050000\n",
      "Epoch 169 Training Loss=0.957502, Validation Loss=1.050387\n",
      "Epoch 170 Training Loss=0.957086, Validation Loss=1.050771\n",
      "Epoch 171 Training Loss=0.956673, Validation Loss=1.051151\n",
      "Epoch 172 Training Loss=0.956261, Validation Loss=1.051530\n",
      "Epoch 173 Training Loss=0.955852, Validation Loss=1.051905\n",
      "Epoch 174 Training Loss=0.955446, Validation Loss=1.052278\n",
      "Epoch 175 Training Loss=0.955041, Validation Loss=1.052648\n",
      "Epoch 176 Training Loss=0.954638, Validation Loss=1.053016\n",
      "Epoch 177 Training Loss=0.954237, Validation Loss=1.053382\n",
      "Epoch 178 Training Loss=0.953839, Validation Loss=1.053745\n",
      "Epoch 179 Training Loss=0.953442, Validation Loss=1.054105\n",
      "Epoch 180 Training Loss=0.953047, Validation Loss=1.054463\n",
      "Epoch 181 Training Loss=0.952655, Validation Loss=1.054820\n",
      "Epoch 182 Training Loss=0.952264, Validation Loss=1.055173\n",
      "Epoch 183 Training Loss=0.951875, Validation Loss=1.055525\n",
      "Epoch 184 Training Loss=0.951488, Validation Loss=1.055875\n",
      "Epoch 185 Training Loss=0.951103, Validation Loss=1.056223\n",
      "Epoch 186 Training Loss=0.950719, Validation Loss=1.056568\n",
      "Epoch 187 Training Loss=0.950338, Validation Loss=1.056912\n",
      "Epoch 188 Training Loss=0.949958, Validation Loss=1.057254\n",
      "Epoch 189 Training Loss=0.949580, Validation Loss=1.057594\n",
      "Epoch 190 Training Loss=0.949203, Validation Loss=1.057932\n",
      "Epoch 191 Training Loss=0.948828, Validation Loss=1.058269\n",
      "Epoch 192 Training Loss=0.948455, Validation Loss=1.058603\n",
      "Epoch 193 Training Loss=0.948084, Validation Loss=1.058937\n",
      "Epoch 194 Training Loss=0.947714, Validation Loss=1.059268\n",
      "Epoch 195 Training Loss=0.947345, Validation Loss=1.059598\n",
      "Epoch 196 Training Loss=0.946979, Validation Loss=1.059926\n",
      "Epoch 197 Training Loss=0.946613, Validation Loss=1.060253\n",
      "Epoch 198 Training Loss=0.946250, Validation Loss=1.060578\n",
      "Epoch 199 Training Loss=0.945887, Validation Loss=1.060902\n",
      "Epoch 0 Training Loss=1.057378, Validation Loss=0.937233\n",
      "Epoch 1 Training Loss=1.047569, Validation Loss=0.949555\n",
      "Epoch 2 Training Loss=1.045945, Validation Loss=0.957936\n",
      "Epoch 3 Training Loss=1.044567, Validation Loss=0.963179\n",
      "Epoch 4 Training Loss=1.043353, Validation Loss=0.966551\n",
      "Epoch 5 Training Loss=1.042230, Validation Loss=0.968842\n",
      "Epoch 6 Training Loss=1.041168, Validation Loss=0.970508\n",
      "Epoch 7 Training Loss=1.040154, Validation Loss=0.971807\n",
      "Epoch 8 Training Loss=1.039184, Validation Loss=0.972882\n",
      "Epoch 9 Training Loss=1.038254, Validation Loss=0.973816\n",
      "Epoch 10 Training Loss=1.037360, Validation Loss=0.974655\n",
      "Epoch 11 Training Loss=1.036498, Validation Loss=0.975426\n",
      "Epoch 12 Training Loss=1.035666, Validation Loss=0.976146\n",
      "Epoch 13 Training Loss=1.034861, Validation Loss=0.976826\n",
      "Epoch 14 Training Loss=1.034081, Validation Loss=0.977472\n",
      "Epoch 15 Training Loss=1.033323, Validation Loss=0.978090\n",
      "Epoch 16 Training Loss=1.032585, Validation Loss=0.978683\n",
      "Epoch 17 Training Loss=1.031867, Validation Loss=0.979256\n",
      "Epoch 18 Training Loss=1.031166, Validation Loss=0.979809\n",
      "Epoch 19 Training Loss=1.030481, Validation Loss=0.980347\n",
      "Epoch 20 Training Loss=1.029812, Validation Loss=0.980869\n",
      "Epoch 21 Training Loss=1.029157, Validation Loss=0.981380\n",
      "Epoch 22 Training Loss=1.028515, Validation Loss=0.981879\n",
      "Epoch 23 Training Loss=1.027886, Validation Loss=0.982368\n",
      "Epoch 24 Training Loss=1.027269, Validation Loss=0.982850\n",
      "Epoch 25 Training Loss=1.026663, Validation Loss=0.983323\n",
      "Epoch 26 Training Loss=1.026068, Validation Loss=0.983791\n",
      "Epoch 27 Training Loss=1.025484, Validation Loss=0.984253\n",
      "Epoch 28 Training Loss=1.024909, Validation Loss=0.984711\n",
      "Epoch 29 Training Loss=1.024343, Validation Loss=0.985164\n",
      "Epoch 30 Training Loss=1.023786, Validation Loss=0.985615\n",
      "Epoch 31 Training Loss=1.023238, Validation Loss=0.986063\n",
      "Epoch 32 Training Loss=1.022699, Validation Loss=0.986509\n",
      "Epoch 33 Training Loss=1.022167, Validation Loss=0.986953\n",
      "Epoch 34 Training Loss=1.021643, Validation Loss=0.987396\n",
      "Epoch 35 Training Loss=1.021127, Validation Loss=0.987838\n",
      "Epoch 36 Training Loss=1.020618, Validation Loss=0.988280\n",
      "Epoch 37 Training Loss=1.020116, Validation Loss=0.988721\n",
      "Epoch 38 Training Loss=1.019621, Validation Loss=0.989163\n",
      "Epoch 39 Training Loss=1.019132, Validation Loss=0.989604\n",
      "Epoch 40 Training Loss=1.018650, Validation Loss=0.990046\n",
      "Epoch 41 Training Loss=1.018174, Validation Loss=0.990488\n",
      "Epoch 42 Training Loss=1.017704, Validation Loss=0.990930\n",
      "Epoch 43 Training Loss=1.017240, Validation Loss=0.991374\n",
      "Epoch 44 Training Loss=1.016782, Validation Loss=0.991818\n",
      "Epoch 45 Training Loss=1.016329, Validation Loss=0.992262\n",
      "Epoch 46 Training Loss=1.015882, Validation Loss=0.992708\n",
      "Epoch 47 Training Loss=1.015441, Validation Loss=0.993154\n",
      "Epoch 48 Training Loss=1.015004, Validation Loss=0.993601\n",
      "Epoch 49 Training Loss=1.014573, Validation Loss=0.994049\n",
      "Epoch 50 Training Loss=1.014147, Validation Loss=0.994498\n",
      "Epoch 51 Training Loss=1.013725, Validation Loss=0.994947\n",
      "Epoch 52 Training Loss=1.013308, Validation Loss=0.995398\n",
      "Epoch 53 Training Loss=1.012896, Validation Loss=0.995848\n",
      "Epoch 54 Training Loss=1.012489, Validation Loss=0.996300\n",
      "Epoch 55 Training Loss=1.012085, Validation Loss=0.996751\n",
      "Epoch 56 Training Loss=1.011687, Validation Loss=0.997204\n",
      "Epoch 57 Training Loss=1.011292, Validation Loss=0.997657\n",
      "Epoch 58 Training Loss=1.010901, Validation Loss=0.998109\n",
      "Epoch 59 Training Loss=1.010515, Validation Loss=0.998563\n",
      "Epoch 60 Training Loss=1.010132, Validation Loss=0.999016\n",
      "Epoch 61 Training Loss=1.009753, Validation Loss=0.999469\n",
      "Epoch 62 Training Loss=1.009378, Validation Loss=0.999923\n",
      "Epoch 63 Training Loss=1.009007, Validation Loss=1.000376\n",
      "Epoch 64 Training Loss=1.008639, Validation Loss=1.000829\n",
      "Epoch 65 Training Loss=1.008274, Validation Loss=1.001282\n",
      "Epoch 66 Training Loss=1.007913, Validation Loss=1.001734\n",
      "Epoch 67 Training Loss=1.007555, Validation Loss=1.002186\n",
      "Epoch 68 Training Loss=1.007200, Validation Loss=1.002637\n",
      "Epoch 69 Training Loss=1.006848, Validation Loss=1.003087\n",
      "Epoch 70 Training Loss=1.006500, Validation Loss=1.003537\n",
      "Epoch 71 Training Loss=1.006154, Validation Loss=1.003986\n",
      "Epoch 72 Training Loss=1.005811, Validation Loss=1.004434\n",
      "Epoch 73 Training Loss=1.005471, Validation Loss=1.004881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Training Loss=1.005133, Validation Loss=1.005327\n",
      "Epoch 75 Training Loss=1.004798, Validation Loss=1.005772\n",
      "Epoch 76 Training Loss=1.004466, Validation Loss=1.006216\n",
      "Epoch 77 Training Loss=1.004136, Validation Loss=1.006658\n",
      "Epoch 78 Training Loss=1.003809, Validation Loss=1.007099\n",
      "Epoch 79 Training Loss=1.003484, Validation Loss=1.007539\n",
      "Epoch 80 Training Loss=1.003161, Validation Loss=1.007977\n",
      "Epoch 81 Training Loss=1.002841, Validation Loss=1.008414\n",
      "Epoch 82 Training Loss=1.002522, Validation Loss=1.008849\n",
      "Epoch 83 Training Loss=1.002206, Validation Loss=1.009282\n",
      "Epoch 84 Training Loss=1.001892, Validation Loss=1.009714\n",
      "Epoch 85 Training Loss=1.001580, Validation Loss=1.010145\n",
      "Epoch 86 Training Loss=1.001270, Validation Loss=1.010573\n",
      "Epoch 87 Training Loss=1.000962, Validation Loss=1.011000\n",
      "Epoch 88 Training Loss=1.000655, Validation Loss=1.011425\n",
      "Epoch 89 Training Loss=1.000351, Validation Loss=1.011848\n",
      "Epoch 90 Training Loss=1.000048, Validation Loss=1.012269\n",
      "Epoch 91 Training Loss=0.999747, Validation Loss=1.012689\n",
      "Epoch 92 Training Loss=0.999448, Validation Loss=1.013106\n",
      "Epoch 93 Training Loss=0.999150, Validation Loss=1.013522\n",
      "Epoch 94 Training Loss=0.998854, Validation Loss=1.013935\n",
      "Epoch 95 Training Loss=0.998560, Validation Loss=1.014347\n",
      "Epoch 96 Training Loss=0.998267, Validation Loss=1.014756\n",
      "Epoch 97 Training Loss=0.997976, Validation Loss=1.015164\n",
      "Epoch 98 Training Loss=0.997686, Validation Loss=1.015570\n",
      "Epoch 99 Training Loss=0.997398, Validation Loss=1.015974\n",
      "Epoch 100 Training Loss=0.997111, Validation Loss=1.016375\n",
      "Epoch 101 Training Loss=0.996826, Validation Loss=1.016775\n",
      "Epoch 102 Training Loss=0.996542, Validation Loss=1.017173\n",
      "Epoch 103 Training Loss=0.996260, Validation Loss=1.017568\n",
      "Epoch 104 Training Loss=0.995979, Validation Loss=1.017962\n",
      "Epoch 105 Training Loss=0.995699, Validation Loss=1.018353\n",
      "Epoch 106 Training Loss=0.995421, Validation Loss=1.018743\n",
      "Epoch 107 Training Loss=0.995144, Validation Loss=1.019130\n",
      "Epoch 108 Training Loss=0.994869, Validation Loss=1.019516\n",
      "Epoch 109 Training Loss=0.994595, Validation Loss=1.019899\n",
      "Epoch 110 Training Loss=0.994322, Validation Loss=1.020280\n",
      "Epoch 111 Training Loss=0.994050, Validation Loss=1.020660\n",
      "Epoch 112 Training Loss=0.993780, Validation Loss=1.021037\n",
      "Epoch 113 Training Loss=0.993511, Validation Loss=1.021412\n",
      "Epoch 114 Training Loss=0.993244, Validation Loss=1.021785\n",
      "Epoch 115 Training Loss=0.992977, Validation Loss=1.022156\n",
      "Epoch 116 Training Loss=0.992712, Validation Loss=1.022525\n",
      "Epoch 117 Training Loss=0.992449, Validation Loss=1.022892\n",
      "Epoch 118 Training Loss=0.992186, Validation Loss=1.023256\n",
      "Epoch 119 Training Loss=0.991925, Validation Loss=1.023619\n",
      "Epoch 120 Training Loss=0.991665, Validation Loss=1.023979\n",
      "Epoch 121 Training Loss=0.991407, Validation Loss=1.024337\n",
      "Epoch 122 Training Loss=0.991150, Validation Loss=1.024694\n",
      "Epoch 123 Training Loss=0.990894, Validation Loss=1.025048\n",
      "Epoch 124 Training Loss=0.990639, Validation Loss=1.025399\n",
      "Epoch 125 Training Loss=0.990386, Validation Loss=1.025749\n",
      "Epoch 126 Training Loss=0.990134, Validation Loss=1.026096\n",
      "Epoch 127 Training Loss=0.989883, Validation Loss=1.026442\n",
      "Epoch 128 Training Loss=0.989634, Validation Loss=1.026785\n",
      "Epoch 129 Training Loss=0.989386, Validation Loss=1.027125\n",
      "Epoch 130 Training Loss=0.989139, Validation Loss=1.027464\n",
      "Epoch 131 Training Loss=0.988893, Validation Loss=1.027800\n",
      "Epoch 132 Training Loss=0.988649, Validation Loss=1.028134\n",
      "Epoch 133 Training Loss=0.988406, Validation Loss=1.028465\n",
      "Epoch 134 Training Loss=0.988165, Validation Loss=1.028794\n",
      "Epoch 135 Training Loss=0.987925, Validation Loss=1.029121\n",
      "Epoch 136 Training Loss=0.987686, Validation Loss=1.029446\n",
      "Epoch 137 Training Loss=0.987448, Validation Loss=1.029768\n",
      "Epoch 138 Training Loss=0.987212, Validation Loss=1.030087\n",
      "Epoch 139 Training Loss=0.986978, Validation Loss=1.030404\n",
      "Epoch 140 Training Loss=0.986744, Validation Loss=1.030718\n",
      "Epoch 141 Training Loss=0.986512, Validation Loss=1.031030\n",
      "Epoch 142 Training Loss=0.986281, Validation Loss=1.031340\n",
      "Epoch 143 Training Loss=0.986052, Validation Loss=1.031646\n",
      "Epoch 144 Training Loss=0.985824, Validation Loss=1.031951\n",
      "Epoch 145 Training Loss=0.985597, Validation Loss=1.032252\n",
      "Epoch 146 Training Loss=0.985372, Validation Loss=1.032551\n",
      "Epoch 147 Training Loss=0.985148, Validation Loss=1.032847\n",
      "Epoch 148 Training Loss=0.984926, Validation Loss=1.033140\n",
      "Epoch 149 Training Loss=0.984704, Validation Loss=1.033430\n",
      "Epoch 150 Training Loss=0.984485, Validation Loss=1.033718\n",
      "Epoch 151 Training Loss=0.984266, Validation Loss=1.034003\n",
      "Epoch 152 Training Loss=0.984049, Validation Loss=1.034285\n",
      "Epoch 153 Training Loss=0.983833, Validation Loss=1.034564\n",
      "Epoch 154 Training Loss=0.983619, Validation Loss=1.034840\n",
      "Epoch 155 Training Loss=0.983406, Validation Loss=1.035113\n",
      "Epoch 156 Training Loss=0.983194, Validation Loss=1.035384\n",
      "Epoch 157 Training Loss=0.982984, Validation Loss=1.035651\n",
      "Epoch 158 Training Loss=0.982775, Validation Loss=1.035915\n",
      "Epoch 159 Training Loss=0.982567, Validation Loss=1.036176\n",
      "Epoch 160 Training Loss=0.982361, Validation Loss=1.036435\n",
      "Epoch 161 Training Loss=0.982156, Validation Loss=1.036690\n",
      "Epoch 162 Training Loss=0.981952, Validation Loss=1.036941\n",
      "Epoch 163 Training Loss=0.981750, Validation Loss=1.037190\n",
      "Epoch 164 Training Loss=0.981549, Validation Loss=1.037436\n",
      "Epoch 165 Training Loss=0.981349, Validation Loss=1.037678\n",
      "Epoch 166 Training Loss=0.981151, Validation Loss=1.037917\n",
      "Epoch 167 Training Loss=0.980954, Validation Loss=1.038153\n",
      "Epoch 168 Training Loss=0.980758, Validation Loss=1.038386\n",
      "Epoch 169 Training Loss=0.980563, Validation Loss=1.038616\n",
      "Epoch 170 Training Loss=0.980370, Validation Loss=1.038842\n",
      "Epoch 171 Training Loss=0.980178, Validation Loss=1.039065\n",
      "Epoch 172 Training Loss=0.979987, Validation Loss=1.039285\n",
      "Epoch 173 Training Loss=0.979797, Validation Loss=1.039501\n",
      "Epoch 174 Training Loss=0.979609, Validation Loss=1.039715\n",
      "Epoch 175 Training Loss=0.979421, Validation Loss=1.039925\n",
      "Epoch 176 Training Loss=0.979235, Validation Loss=1.040131\n",
      "Epoch 177 Training Loss=0.979050, Validation Loss=1.040335\n",
      "Epoch 178 Training Loss=0.978867, Validation Loss=1.040535\n",
      "Epoch 179 Training Loss=0.978684, Validation Loss=1.040732\n",
      "Epoch 180 Training Loss=0.978503, Validation Loss=1.040925\n",
      "Epoch 181 Training Loss=0.978322, Validation Loss=1.041116\n",
      "Epoch 182 Training Loss=0.978143, Validation Loss=1.041303\n",
      "Epoch 183 Training Loss=0.977965, Validation Loss=1.041486\n",
      "Epoch 184 Training Loss=0.977788, Validation Loss=1.041667\n",
      "Epoch 185 Training Loss=0.977612, Validation Loss=1.041844\n",
      "Epoch 186 Training Loss=0.977437, Validation Loss=1.042018\n",
      "Epoch 187 Training Loss=0.977263, Validation Loss=1.042189\n",
      "Epoch 188 Training Loss=0.977090, Validation Loss=1.042357\n",
      "Epoch 189 Training Loss=0.976919, Validation Loss=1.042521\n",
      "Epoch 190 Training Loss=0.976748, Validation Loss=1.042683\n",
      "Epoch 191 Training Loss=0.976578, Validation Loss=1.042841\n",
      "Epoch 192 Training Loss=0.976409, Validation Loss=1.042996\n",
      "Epoch 193 Training Loss=0.976241, Validation Loss=1.043148\n",
      "Epoch 194 Training Loss=0.976074, Validation Loss=1.043297\n",
      "Epoch 195 Training Loss=0.975908, Validation Loss=1.043443\n",
      "Epoch 196 Training Loss=0.975742, Validation Loss=1.043586\n",
      "Epoch 197 Training Loss=0.975578, Validation Loss=1.043726\n",
      "Epoch 198 Training Loss=0.975414, Validation Loss=1.043863\n",
      "Epoch 199 Training Loss=0.975252, Validation Loss=1.043997\n",
      "Epoch 0 Training Loss=1.057262, Validation Loss=0.919395\n",
      "Epoch 1 Training Loss=1.049248, Validation Loss=0.928106\n",
      "Epoch 2 Training Loss=1.047338, Validation Loss=0.935888\n",
      "Epoch 3 Training Loss=1.045620, Validation Loss=0.941700\n",
      "Epoch 4 Training Loss=1.044178, Validation Loss=0.946070\n",
      "Epoch 5 Training Loss=1.042915, Validation Loss=0.949446\n",
      "Epoch 6 Training Loss=1.041768, Validation Loss=0.952145\n",
      "Epoch 7 Training Loss=1.040705, Validation Loss=0.954380\n",
      "Epoch 8 Training Loss=1.039709, Validation Loss=0.956293\n",
      "Epoch 9 Training Loss=1.038770, Validation Loss=0.957980\n",
      "Epoch 10 Training Loss=1.037878, Validation Loss=0.959502\n",
      "Epoch 11 Training Loss=1.037027, Validation Loss=0.960902\n",
      "Epoch 12 Training Loss=1.036212, Validation Loss=0.962207\n",
      "Epoch 13 Training Loss=1.035429, Validation Loss=0.963437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training Loss=1.034672, Validation Loss=0.964606\n",
      "Epoch 15 Training Loss=1.033940, Validation Loss=0.965722\n",
      "Epoch 16 Training Loss=1.033228, Validation Loss=0.966794\n",
      "Epoch 17 Training Loss=1.032535, Validation Loss=0.967827\n",
      "Epoch 18 Training Loss=1.031858, Validation Loss=0.968825\n",
      "Epoch 19 Training Loss=1.031195, Validation Loss=0.969793\n",
      "Epoch 20 Training Loss=1.030545, Validation Loss=0.970733\n",
      "Epoch 21 Training Loss=1.029905, Validation Loss=0.971648\n",
      "Epoch 22 Training Loss=1.029276, Validation Loss=0.972541\n",
      "Epoch 23 Training Loss=1.028656, Validation Loss=0.973414\n",
      "Epoch 24 Training Loss=1.028044, Validation Loss=0.974270\n",
      "Epoch 25 Training Loss=1.027439, Validation Loss=0.975109\n",
      "Epoch 26 Training Loss=1.026840, Validation Loss=0.975934\n",
      "Epoch 27 Training Loss=1.026247, Validation Loss=0.976747\n",
      "Epoch 28 Training Loss=1.025660, Validation Loss=0.977548\n",
      "Epoch 29 Training Loss=1.025078, Validation Loss=0.978339\n",
      "Epoch 30 Training Loss=1.024500, Validation Loss=0.979122\n",
      "Epoch 31 Training Loss=1.023927, Validation Loss=0.979897\n",
      "Epoch 32 Training Loss=1.023357, Validation Loss=0.980666\n",
      "Epoch 33 Training Loss=1.022791, Validation Loss=0.981428\n",
      "Epoch 34 Training Loss=1.022229, Validation Loss=0.982186\n",
      "Epoch 35 Training Loss=1.021669, Validation Loss=0.982940\n",
      "Epoch 36 Training Loss=1.021112, Validation Loss=0.983691\n",
      "Epoch 37 Training Loss=1.020558, Validation Loss=0.984438\n",
      "Epoch 38 Training Loss=1.020007, Validation Loss=0.985184\n",
      "Epoch 39 Training Loss=1.019458, Validation Loss=0.985928\n",
      "Epoch 40 Training Loss=1.018911, Validation Loss=0.986671\n",
      "Epoch 41 Training Loss=1.018366, Validation Loss=0.987412\n",
      "Epoch 42 Training Loss=1.017824, Validation Loss=0.988154\n",
      "Epoch 43 Training Loss=1.017283, Validation Loss=0.988895\n",
      "Epoch 44 Training Loss=1.016744, Validation Loss=0.989636\n",
      "Epoch 45 Training Loss=1.016207, Validation Loss=0.990378\n",
      "Epoch 46 Training Loss=1.015671, Validation Loss=0.991120\n",
      "Epoch 47 Training Loss=1.015137, Validation Loss=0.991863\n",
      "Epoch 48 Training Loss=1.014604, Validation Loss=0.992607\n",
      "Epoch 49 Training Loss=1.014073, Validation Loss=0.993352\n",
      "Epoch 50 Training Loss=1.013543, Validation Loss=0.994098\n",
      "Epoch 51 Training Loss=1.013014, Validation Loss=0.994845\n",
      "Epoch 52 Training Loss=1.012487, Validation Loss=0.995593\n",
      "Epoch 53 Training Loss=1.011961, Validation Loss=0.996342\n",
      "Epoch 54 Training Loss=1.011435, Validation Loss=0.997093\n",
      "Epoch 55 Training Loss=1.010911, Validation Loss=0.997845\n",
      "Epoch 56 Training Loss=1.010388, Validation Loss=0.998598\n",
      "Epoch 57 Training Loss=1.009866, Validation Loss=0.999352\n",
      "Epoch 58 Training Loss=1.009344, Validation Loss=1.000108\n",
      "Epoch 59 Training Loss=1.008824, Validation Loss=1.000865\n",
      "Epoch 60 Training Loss=1.008304, Validation Loss=1.001622\n",
      "Epoch 61 Training Loss=1.007785, Validation Loss=1.002381\n",
      "Epoch 62 Training Loss=1.007267, Validation Loss=1.003141\n",
      "Epoch 63 Training Loss=1.006749, Validation Loss=1.003901\n",
      "Epoch 64 Training Loss=1.006232, Validation Loss=1.004662\n",
      "Epoch 65 Training Loss=1.005716, Validation Loss=1.005424\n",
      "Epoch 66 Training Loss=1.005200, Validation Loss=1.006187\n",
      "Epoch 67 Training Loss=1.004684, Validation Loss=1.006950\n",
      "Epoch 68 Training Loss=1.004169, Validation Loss=1.007714\n",
      "Epoch 69 Training Loss=1.003655, Validation Loss=1.008478\n",
      "Epoch 70 Training Loss=1.003140, Validation Loss=1.009242\n",
      "Epoch 71 Training Loss=1.002627, Validation Loss=1.010006\n",
      "Epoch 72 Training Loss=1.002113, Validation Loss=1.010771\n",
      "Epoch 73 Training Loss=1.001600, Validation Loss=1.011535\n",
      "Epoch 74 Training Loss=1.001087, Validation Loss=1.012300\n",
      "Epoch 75 Training Loss=1.000574, Validation Loss=1.013064\n",
      "Epoch 76 Training Loss=1.000062, Validation Loss=1.013828\n",
      "Epoch 77 Training Loss=0.999549, Validation Loss=1.014592\n",
      "Epoch 78 Training Loss=0.999037, Validation Loss=1.015355\n",
      "Epoch 79 Training Loss=0.998525, Validation Loss=1.016118\n",
      "Epoch 80 Training Loss=0.998013, Validation Loss=1.016880\n",
      "Epoch 81 Training Loss=0.997501, Validation Loss=1.017642\n",
      "Epoch 82 Training Loss=0.996989, Validation Loss=1.018403\n",
      "Epoch 83 Training Loss=0.996477, Validation Loss=1.019164\n",
      "Epoch 84 Training Loss=0.995965, Validation Loss=1.019924\n",
      "Epoch 85 Training Loss=0.995453, Validation Loss=1.020683\n",
      "Epoch 86 Training Loss=0.994941, Validation Loss=1.021441\n",
      "Epoch 87 Training Loss=0.994429, Validation Loss=1.022198\n",
      "Epoch 88 Training Loss=0.993917, Validation Loss=1.022955\n",
      "Epoch 89 Training Loss=0.993405, Validation Loss=1.023710\n",
      "Epoch 90 Training Loss=0.992893, Validation Loss=1.024465\n",
      "Epoch 91 Training Loss=0.992381, Validation Loss=1.025218\n",
      "Epoch 92 Training Loss=0.991868, Validation Loss=1.025971\n",
      "Epoch 93 Training Loss=0.991356, Validation Loss=1.026723\n",
      "Epoch 94 Training Loss=0.990843, Validation Loss=1.027474\n",
      "Epoch 95 Training Loss=0.990331, Validation Loss=1.028223\n",
      "Epoch 96 Training Loss=0.989818, Validation Loss=1.028972\n",
      "Epoch 97 Training Loss=0.989306, Validation Loss=1.029720\n",
      "Epoch 98 Training Loss=0.988793, Validation Loss=1.030467\n",
      "Epoch 99 Training Loss=0.988280, Validation Loss=1.031212\n",
      "Epoch 100 Training Loss=0.987767, Validation Loss=1.031957\n",
      "Epoch 101 Training Loss=0.987254, Validation Loss=1.032701\n",
      "Epoch 102 Training Loss=0.986741, Validation Loss=1.033443\n",
      "Epoch 103 Training Loss=0.986228, Validation Loss=1.034185\n",
      "Epoch 104 Training Loss=0.985715, Validation Loss=1.034926\n",
      "Epoch 105 Training Loss=0.985202, Validation Loss=1.035666\n",
      "Epoch 106 Training Loss=0.984689, Validation Loss=1.036405\n",
      "Epoch 107 Training Loss=0.984176, Validation Loss=1.037143\n",
      "Epoch 108 Training Loss=0.983664, Validation Loss=1.037880\n",
      "Epoch 109 Training Loss=0.983151, Validation Loss=1.038617\n",
      "Epoch 110 Training Loss=0.982638, Validation Loss=1.039352\n",
      "Epoch 111 Training Loss=0.982126, Validation Loss=1.040087\n",
      "Epoch 112 Training Loss=0.981613, Validation Loss=1.040821\n",
      "Epoch 113 Training Loss=0.981101, Validation Loss=1.041554\n",
      "Epoch 114 Training Loss=0.980589, Validation Loss=1.042286\n",
      "Epoch 115 Training Loss=0.980077, Validation Loss=1.043017\n",
      "Epoch 116 Training Loss=0.979565, Validation Loss=1.043747\n",
      "Epoch 117 Training Loss=0.979054, Validation Loss=1.044477\n",
      "Epoch 118 Training Loss=0.978543, Validation Loss=1.045206\n",
      "Epoch 119 Training Loss=0.978032, Validation Loss=1.045934\n",
      "Epoch 120 Training Loss=0.977522, Validation Loss=1.046662\n",
      "Epoch 121 Training Loss=0.977012, Validation Loss=1.047388\n",
      "Epoch 122 Training Loss=0.976502, Validation Loss=1.048114\n",
      "Epoch 123 Training Loss=0.975993, Validation Loss=1.048839\n",
      "Epoch 124 Training Loss=0.975485, Validation Loss=1.049563\n",
      "Epoch 125 Training Loss=0.974976, Validation Loss=1.050287\n",
      "Epoch 126 Training Loss=0.974468, Validation Loss=1.051010\n",
      "Epoch 127 Training Loss=0.973961, Validation Loss=1.051731\n",
      "Epoch 128 Training Loss=0.973454, Validation Loss=1.052452\n",
      "Epoch 129 Training Loss=0.972948, Validation Loss=1.053173\n",
      "Epoch 130 Training Loss=0.972443, Validation Loss=1.053892\n",
      "Epoch 131 Training Loss=0.971938, Validation Loss=1.054610\n",
      "Epoch 132 Training Loss=0.971433, Validation Loss=1.055328\n",
      "Epoch 133 Training Loss=0.970929, Validation Loss=1.056045\n",
      "Epoch 134 Training Loss=0.970426, Validation Loss=1.056761\n",
      "Epoch 135 Training Loss=0.969924, Validation Loss=1.057475\n",
      "Epoch 136 Training Loss=0.969423, Validation Loss=1.058190\n",
      "Epoch 137 Training Loss=0.968922, Validation Loss=1.058902\n",
      "Epoch 138 Training Loss=0.968421, Validation Loss=1.059614\n",
      "Epoch 139 Training Loss=0.967922, Validation Loss=1.060325\n",
      "Epoch 140 Training Loss=0.967424, Validation Loss=1.061035\n",
      "Epoch 141 Training Loss=0.966926, Validation Loss=1.061744\n",
      "Epoch 142 Training Loss=0.966429, Validation Loss=1.062451\n",
      "Epoch 143 Training Loss=0.965933, Validation Loss=1.063158\n",
      "Epoch 144 Training Loss=0.965437, Validation Loss=1.063863\n",
      "Epoch 145 Training Loss=0.964943, Validation Loss=1.064567\n",
      "Epoch 146 Training Loss=0.964450, Validation Loss=1.065270\n",
      "Epoch 147 Training Loss=0.963957, Validation Loss=1.065971\n",
      "Epoch 148 Training Loss=0.963465, Validation Loss=1.066671\n",
      "Epoch 149 Training Loss=0.962974, Validation Loss=1.067370\n",
      "Epoch 150 Training Loss=0.962485, Validation Loss=1.068067\n",
      "Epoch 151 Training Loss=0.961996, Validation Loss=1.068763\n",
      "Epoch 152 Training Loss=0.961508, Validation Loss=1.069458\n",
      "Epoch 153 Training Loss=0.961021, Validation Loss=1.070151\n",
      "Epoch 154 Training Loss=0.960535, Validation Loss=1.070842\n",
      "Epoch 155 Training Loss=0.960050, Validation Loss=1.071532\n",
      "Epoch 156 Training Loss=0.959566, Validation Loss=1.072221\n",
      "Epoch 157 Training Loss=0.959082, Validation Loss=1.072907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 Training Loss=0.958600, Validation Loss=1.073592\n",
      "Epoch 159 Training Loss=0.958119, Validation Loss=1.074276\n",
      "Epoch 160 Training Loss=0.957639, Validation Loss=1.074957\n",
      "Epoch 161 Training Loss=0.957160, Validation Loss=1.075637\n",
      "Epoch 162 Training Loss=0.956682, Validation Loss=1.076315\n",
      "Epoch 163 Training Loss=0.956205, Validation Loss=1.076991\n",
      "Epoch 164 Training Loss=0.955728, Validation Loss=1.077665\n",
      "Epoch 165 Training Loss=0.955253, Validation Loss=1.078338\n",
      "Epoch 166 Training Loss=0.954779, Validation Loss=1.079008\n",
      "Epoch 167 Training Loss=0.954306, Validation Loss=1.079677\n",
      "Epoch 168 Training Loss=0.953834, Validation Loss=1.080343\n",
      "Epoch 169 Training Loss=0.953363, Validation Loss=1.081007\n",
      "Epoch 170 Training Loss=0.952893, Validation Loss=1.081670\n",
      "Epoch 171 Training Loss=0.952424, Validation Loss=1.082330\n",
      "Epoch 172 Training Loss=0.951956, Validation Loss=1.082988\n",
      "Epoch 173 Training Loss=0.951489, Validation Loss=1.083644\n",
      "Epoch 174 Training Loss=0.951023, Validation Loss=1.084297\n",
      "Epoch 175 Training Loss=0.950557, Validation Loss=1.084949\n",
      "Epoch 176 Training Loss=0.950093, Validation Loss=1.085598\n",
      "Epoch 177 Training Loss=0.949630, Validation Loss=1.086245\n",
      "Epoch 178 Training Loss=0.949168, Validation Loss=1.086889\n",
      "Epoch 179 Training Loss=0.948707, Validation Loss=1.087531\n",
      "Epoch 180 Training Loss=0.948246, Validation Loss=1.088171\n",
      "Epoch 181 Training Loss=0.947787, Validation Loss=1.088808\n",
      "Epoch 182 Training Loss=0.947329, Validation Loss=1.089443\n",
      "Epoch 183 Training Loss=0.946871, Validation Loss=1.090075\n",
      "Epoch 184 Training Loss=0.946415, Validation Loss=1.090705\n",
      "Epoch 185 Training Loss=0.945959, Validation Loss=1.091332\n",
      "Epoch 186 Training Loss=0.945504, Validation Loss=1.091957\n",
      "Epoch 187 Training Loss=0.945050, Validation Loss=1.092579\n",
      "Epoch 188 Training Loss=0.944597, Validation Loss=1.093198\n",
      "Epoch 189 Training Loss=0.944145, Validation Loss=1.093815\n",
      "Epoch 190 Training Loss=0.943694, Validation Loss=1.094429\n",
      "Epoch 191 Training Loss=0.943243, Validation Loss=1.095041\n",
      "Epoch 192 Training Loss=0.942794, Validation Loss=1.095649\n",
      "Epoch 193 Training Loss=0.942345, Validation Loss=1.096255\n",
      "Epoch 194 Training Loss=0.941897, Validation Loss=1.096858\n",
      "Epoch 195 Training Loss=0.941450, Validation Loss=1.097459\n",
      "Epoch 196 Training Loss=0.941003, Validation Loss=1.098056\n",
      "Epoch 197 Training Loss=0.940558, Validation Loss=1.098651\n",
      "Epoch 198 Training Loss=0.940113, Validation Loss=1.099243\n",
      "Epoch 199 Training Loss=0.939668, Validation Loss=1.099832\n",
      "Epoch 0 Training Loss=1.051380, Validation Loss=0.964343\n",
      "Epoch 1 Training Loss=1.035160, Validation Loss=0.960273\n",
      "Epoch 2 Training Loss=1.033868, Validation Loss=0.960390\n",
      "Epoch 3 Training Loss=1.032991, Validation Loss=0.961194\n",
      "Epoch 4 Training Loss=1.032160, Validation Loss=0.962095\n",
      "Epoch 5 Training Loss=1.031372, Validation Loss=0.962939\n",
      "Epoch 6 Training Loss=1.030634, Validation Loss=0.963693\n",
      "Epoch 7 Training Loss=1.029946, Validation Loss=0.964361\n",
      "Epoch 8 Training Loss=1.029305, Validation Loss=0.964953\n",
      "Epoch 9 Training Loss=1.028705, Validation Loss=0.965482\n",
      "Epoch 10 Training Loss=1.028144, Validation Loss=0.965958\n",
      "Epoch 11 Training Loss=1.027616, Validation Loss=0.966392\n",
      "Epoch 12 Training Loss=1.027118, Validation Loss=0.966791\n",
      "Epoch 13 Training Loss=1.026647, Validation Loss=0.967162\n",
      "Epoch 14 Training Loss=1.026200, Validation Loss=0.967510\n",
      "Epoch 15 Training Loss=1.025774, Validation Loss=0.967839\n",
      "Epoch 16 Training Loss=1.025368, Validation Loss=0.968153\n",
      "Epoch 17 Training Loss=1.024980, Validation Loss=0.968454\n",
      "Epoch 18 Training Loss=1.024608, Validation Loss=0.968746\n",
      "Epoch 19 Training Loss=1.024250, Validation Loss=0.969030\n",
      "Epoch 20 Training Loss=1.023905, Validation Loss=0.969308\n",
      "Epoch 21 Training Loss=1.023571, Validation Loss=0.969580\n",
      "Epoch 22 Training Loss=1.023249, Validation Loss=0.969849\n",
      "Epoch 23 Training Loss=1.022936, Validation Loss=0.970115\n",
      "Epoch 24 Training Loss=1.022631, Validation Loss=0.970379\n",
      "Epoch 25 Training Loss=1.022335, Validation Loss=0.970642\n",
      "Epoch 26 Training Loss=1.022045, Validation Loss=0.970903\n",
      "Epoch 27 Training Loss=1.021762, Validation Loss=0.971164\n",
      "Epoch 28 Training Loss=1.021484, Validation Loss=0.971425\n",
      "Epoch 29 Training Loss=1.021212, Validation Loss=0.971686\n",
      "Epoch 30 Training Loss=1.020944, Validation Loss=0.971948\n",
      "Epoch 31 Training Loss=1.020680, Validation Loss=0.972210\n",
      "Epoch 32 Training Loss=1.020420, Validation Loss=0.972474\n",
      "Epoch 33 Training Loss=1.020163, Validation Loss=0.972739\n",
      "Epoch 34 Training Loss=1.019909, Validation Loss=0.973005\n",
      "Epoch 35 Training Loss=1.019657, Validation Loss=0.973272\n",
      "Epoch 36 Training Loss=1.019408, Validation Loss=0.973541\n",
      "Epoch 37 Training Loss=1.019160, Validation Loss=0.973812\n",
      "Epoch 38 Training Loss=1.018914, Validation Loss=0.974084\n",
      "Epoch 39 Training Loss=1.018670, Validation Loss=0.974359\n",
      "Epoch 40 Training Loss=1.018427, Validation Loss=0.974636\n",
      "Epoch 41 Training Loss=1.018185, Validation Loss=0.974914\n",
      "Epoch 42 Training Loss=1.017943, Validation Loss=0.975195\n",
      "Epoch 43 Training Loss=1.017703, Validation Loss=0.975478\n",
      "Epoch 44 Training Loss=1.017463, Validation Loss=0.975763\n",
      "Epoch 45 Training Loss=1.017223, Validation Loss=0.976050\n",
      "Epoch 46 Training Loss=1.016984, Validation Loss=0.976339\n",
      "Epoch 47 Training Loss=1.016745, Validation Loss=0.976631\n",
      "Epoch 48 Training Loss=1.016507, Validation Loss=0.976924\n",
      "Epoch 49 Training Loss=1.016268, Validation Loss=0.977220\n",
      "Epoch 50 Training Loss=1.016030, Validation Loss=0.977518\n",
      "Epoch 51 Training Loss=1.015791, Validation Loss=0.977818\n",
      "Epoch 52 Training Loss=1.015553, Validation Loss=0.978120\n",
      "Epoch 53 Training Loss=1.015314, Validation Loss=0.978423\n",
      "Epoch 54 Training Loss=1.015075, Validation Loss=0.978729\n",
      "Epoch 55 Training Loss=1.014836, Validation Loss=0.979036\n",
      "Epoch 56 Training Loss=1.014597, Validation Loss=0.979344\n",
      "Epoch 57 Training Loss=1.014358, Validation Loss=0.979654\n",
      "Epoch 58 Training Loss=1.014119, Validation Loss=0.979966\n",
      "Epoch 59 Training Loss=1.013879, Validation Loss=0.980278\n",
      "Epoch 60 Training Loss=1.013639, Validation Loss=0.980591\n",
      "Epoch 61 Training Loss=1.013399, Validation Loss=0.980906\n",
      "Epoch 62 Training Loss=1.013158, Validation Loss=0.981221\n",
      "Epoch 63 Training Loss=1.012917, Validation Loss=0.981536\n",
      "Epoch 64 Training Loss=1.012676, Validation Loss=0.981852\n",
      "Epoch 65 Training Loss=1.012435, Validation Loss=0.982168\n",
      "Epoch 66 Training Loss=1.012193, Validation Loss=0.982484\n",
      "Epoch 67 Training Loss=1.011951, Validation Loss=0.982800\n",
      "Epoch 68 Training Loss=1.011708, Validation Loss=0.983116\n",
      "Epoch 69 Training Loss=1.011465, Validation Loss=0.983432\n",
      "Epoch 70 Training Loss=1.011221, Validation Loss=0.983746\n",
      "Epoch 71 Training Loss=1.010977, Validation Loss=0.984061\n",
      "Epoch 72 Training Loss=1.010733, Validation Loss=0.984374\n",
      "Epoch 73 Training Loss=1.010488, Validation Loss=0.984686\n",
      "Epoch 74 Training Loss=1.010242, Validation Loss=0.984998\n",
      "Epoch 75 Training Loss=1.009995, Validation Loss=0.985308\n",
      "Epoch 76 Training Loss=1.009748, Validation Loss=0.985617\n",
      "Epoch 77 Training Loss=1.009500, Validation Loss=0.985925\n",
      "Epoch 78 Training Loss=1.009251, Validation Loss=0.986231\n",
      "Epoch 79 Training Loss=1.009001, Validation Loss=0.986536\n",
      "Epoch 80 Training Loss=1.008751, Validation Loss=0.986839\n",
      "Epoch 81 Training Loss=1.008499, Validation Loss=0.987140\n",
      "Epoch 82 Training Loss=1.008246, Validation Loss=0.987440\n",
      "Epoch 83 Training Loss=1.007992, Validation Loss=0.987739\n",
      "Epoch 84 Training Loss=1.007737, Validation Loss=0.988036\n",
      "Epoch 85 Training Loss=1.007481, Validation Loss=0.988331\n",
      "Epoch 86 Training Loss=1.007224, Validation Loss=0.988625\n",
      "Epoch 87 Training Loss=1.006964, Validation Loss=0.988917\n",
      "Epoch 88 Training Loss=1.006704, Validation Loss=0.989208\n",
      "Epoch 89 Training Loss=1.006442, Validation Loss=0.989498\n",
      "Epoch 90 Training Loss=1.006179, Validation Loss=0.989786\n",
      "Epoch 91 Training Loss=1.005913, Validation Loss=0.990073\n",
      "Epoch 92 Training Loss=1.005647, Validation Loss=0.990359\n",
      "Epoch 93 Training Loss=1.005378, Validation Loss=0.990644\n",
      "Epoch 94 Training Loss=1.005108, Validation Loss=0.990929\n",
      "Epoch 95 Training Loss=1.004835, Validation Loss=0.991212\n",
      "Epoch 96 Training Loss=1.004561, Validation Loss=0.991495\n",
      "Epoch 97 Training Loss=1.004285, Validation Loss=0.991778\n",
      "Epoch 98 Training Loss=1.004007, Validation Loss=0.992060\n",
      "Epoch 99 Training Loss=1.003727, Validation Loss=0.992343\n",
      "Epoch 100 Training Loss=1.003444, Validation Loss=0.992625\n",
      "Epoch 101 Training Loss=1.003160, Validation Loss=0.992908\n",
      "Epoch 102 Training Loss=1.002873, Validation Loss=0.993191\n",
      "Epoch 103 Training Loss=1.002585, Validation Loss=0.993474\n",
      "Epoch 104 Training Loss=1.002294, Validation Loss=0.993759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 Training Loss=1.002001, Validation Loss=0.994044\n",
      "Epoch 106 Training Loss=1.001706, Validation Loss=0.994330\n",
      "Epoch 107 Training Loss=1.001409, Validation Loss=0.994617\n",
      "Epoch 108 Training Loss=1.001110, Validation Loss=0.994906\n",
      "Epoch 109 Training Loss=1.000809, Validation Loss=0.995196\n",
      "Epoch 110 Training Loss=1.000506, Validation Loss=0.995487\n",
      "Epoch 111 Training Loss=1.000201, Validation Loss=0.995781\n",
      "Epoch 112 Training Loss=0.999894, Validation Loss=0.996076\n",
      "Epoch 113 Training Loss=0.999585, Validation Loss=0.996373\n",
      "Epoch 114 Training Loss=0.999274, Validation Loss=0.996671\n",
      "Epoch 115 Training Loss=0.998961, Validation Loss=0.996972\n",
      "Epoch 116 Training Loss=0.998647, Validation Loss=0.997275\n",
      "Epoch 117 Training Loss=0.998331, Validation Loss=0.997580\n",
      "Epoch 118 Training Loss=0.998014, Validation Loss=0.997887\n",
      "Epoch 119 Training Loss=0.997695, Validation Loss=0.998197\n",
      "Epoch 120 Training Loss=0.997375, Validation Loss=0.998509\n",
      "Epoch 121 Training Loss=0.997054, Validation Loss=0.998822\n",
      "Epoch 122 Training Loss=0.996731, Validation Loss=0.999138\n",
      "Epoch 123 Training Loss=0.996408, Validation Loss=0.999456\n",
      "Epoch 124 Training Loss=0.996084, Validation Loss=0.999776\n",
      "Epoch 125 Training Loss=0.995758, Validation Loss=1.000097\n",
      "Epoch 126 Training Loss=0.995433, Validation Loss=1.000421\n",
      "Epoch 127 Training Loss=0.995106, Validation Loss=1.000746\n",
      "Epoch 128 Training Loss=0.994780, Validation Loss=1.001073\n",
      "Epoch 129 Training Loss=0.994453, Validation Loss=1.001401\n",
      "Epoch 130 Training Loss=0.994126, Validation Loss=1.001730\n",
      "Epoch 131 Training Loss=0.993798, Validation Loss=1.002061\n",
      "Epoch 132 Training Loss=0.993471, Validation Loss=1.002393\n",
      "Epoch 133 Training Loss=0.993144, Validation Loss=1.002725\n",
      "Epoch 134 Training Loss=0.992818, Validation Loss=1.003058\n",
      "Epoch 135 Training Loss=0.992491, Validation Loss=1.003392\n",
      "Epoch 136 Training Loss=0.992166, Validation Loss=1.003725\n",
      "Epoch 137 Training Loss=0.991840, Validation Loss=1.004059\n",
      "Epoch 138 Training Loss=0.991516, Validation Loss=1.004393\n",
      "Epoch 139 Training Loss=0.991192, Validation Loss=1.004726\n",
      "Epoch 140 Training Loss=0.990870, Validation Loss=1.005058\n",
      "Epoch 141 Training Loss=0.990548, Validation Loss=1.005390\n",
      "Epoch 142 Training Loss=0.990228, Validation Loss=1.005721\n",
      "Epoch 143 Training Loss=0.989909, Validation Loss=1.006051\n",
      "Epoch 144 Training Loss=0.989591, Validation Loss=1.006379\n",
      "Epoch 145 Training Loss=0.989274, Validation Loss=1.006706\n",
      "Epoch 146 Training Loss=0.988959, Validation Loss=1.007030\n",
      "Epoch 147 Training Loss=0.988645, Validation Loss=1.007354\n",
      "Epoch 148 Training Loss=0.988333, Validation Loss=1.007674\n",
      "Epoch 149 Training Loss=0.988023, Validation Loss=1.007993\n",
      "Epoch 150 Training Loss=0.987714, Validation Loss=1.008309\n",
      "Epoch 151 Training Loss=0.987407, Validation Loss=1.008622\n",
      "Epoch 152 Training Loss=0.987102, Validation Loss=1.008933\n",
      "Epoch 153 Training Loss=0.986799, Validation Loss=1.009240\n",
      "Epoch 154 Training Loss=0.986498, Validation Loss=1.009545\n",
      "Epoch 155 Training Loss=0.986198, Validation Loss=1.009846\n",
      "Epoch 156 Training Loss=0.985900, Validation Loss=1.010144\n",
      "Epoch 157 Training Loss=0.985605, Validation Loss=1.010439\n",
      "Epoch 158 Training Loss=0.985311, Validation Loss=1.010730\n",
      "Epoch 159 Training Loss=0.985019, Validation Loss=1.011017\n",
      "Epoch 160 Training Loss=0.984729, Validation Loss=1.011301\n",
      "Epoch 161 Training Loss=0.984441, Validation Loss=1.011581\n",
      "Epoch 162 Training Loss=0.984155, Validation Loss=1.011857\n",
      "Epoch 163 Training Loss=0.983872, Validation Loss=1.012129\n",
      "Epoch 164 Training Loss=0.983590, Validation Loss=1.012398\n",
      "Epoch 165 Training Loss=0.983309, Validation Loss=1.012662\n",
      "Epoch 166 Training Loss=0.983031, Validation Loss=1.012922\n",
      "Epoch 167 Training Loss=0.982755, Validation Loss=1.013178\n",
      "Epoch 168 Training Loss=0.982481, Validation Loss=1.013430\n",
      "Epoch 169 Training Loss=0.982208, Validation Loss=1.013678\n",
      "Epoch 170 Training Loss=0.981937, Validation Loss=1.013922\n",
      "Epoch 171 Training Loss=0.981668, Validation Loss=1.014162\n",
      "Epoch 172 Training Loss=0.981401, Validation Loss=1.014398\n",
      "Epoch 173 Training Loss=0.981135, Validation Loss=1.014630\n",
      "Epoch 174 Training Loss=0.980871, Validation Loss=1.014857\n",
      "Epoch 175 Training Loss=0.980608, Validation Loss=1.015081\n",
      "Epoch 176 Training Loss=0.980347, Validation Loss=1.015301\n",
      "Epoch 177 Training Loss=0.980088, Validation Loss=1.015516\n",
      "Epoch 178 Training Loss=0.979830, Validation Loss=1.015728\n",
      "Epoch 179 Training Loss=0.979573, Validation Loss=1.015936\n",
      "Epoch 180 Training Loss=0.979317, Validation Loss=1.016140\n",
      "Epoch 181 Training Loss=0.979063, Validation Loss=1.016340\n",
      "Epoch 182 Training Loss=0.978810, Validation Loss=1.016536\n",
      "Epoch 183 Training Loss=0.978558, Validation Loss=1.016729\n",
      "Epoch 184 Training Loss=0.978307, Validation Loss=1.016918\n",
      "Epoch 185 Training Loss=0.978057, Validation Loss=1.017104\n",
      "Epoch 186 Training Loss=0.977808, Validation Loss=1.017286\n",
      "Epoch 187 Training Loss=0.977559, Validation Loss=1.017464\n",
      "Epoch 188 Training Loss=0.977312, Validation Loss=1.017639\n",
      "Epoch 189 Training Loss=0.977065, Validation Loss=1.017811\n",
      "Epoch 190 Training Loss=0.976819, Validation Loss=1.017980\n",
      "Epoch 191 Training Loss=0.976573, Validation Loss=1.018145\n",
      "Epoch 192 Training Loss=0.976328, Validation Loss=1.018307\n",
      "Epoch 193 Training Loss=0.976083, Validation Loss=1.018466\n",
      "Epoch 194 Training Loss=0.975838, Validation Loss=1.018622\n",
      "Epoch 195 Training Loss=0.975594, Validation Loss=1.018775\n",
      "Epoch 196 Training Loss=0.975350, Validation Loss=1.018926\n",
      "Epoch 197 Training Loss=0.975106, Validation Loss=1.019073\n",
      "Epoch 198 Training Loss=0.974862, Validation Loss=1.019218\n",
      "Epoch 199 Training Loss=0.974617, Validation Loss=1.019360\n",
      "Epoch 0 Training Loss=1.061508, Validation Loss=0.912483\n",
      "Epoch 1 Training Loss=1.035680, Validation Loss=0.916316\n",
      "Epoch 2 Training Loss=1.033051, Validation Loss=0.922530\n",
      "Epoch 3 Training Loss=1.030749, Validation Loss=0.928346\n",
      "Epoch 4 Training Loss=1.028902, Validation Loss=0.933567\n",
      "Epoch 5 Training Loss=1.027407, Validation Loss=0.938229\n",
      "Epoch 6 Training Loss=1.026156, Validation Loss=0.942384\n",
      "Epoch 7 Training Loss=1.025079, Validation Loss=0.946087\n",
      "Epoch 8 Training Loss=1.024128, Validation Loss=0.949390\n",
      "Epoch 9 Training Loss=1.023270, Validation Loss=0.952343\n",
      "Epoch 10 Training Loss=1.022482, Validation Loss=0.954991\n",
      "Epoch 11 Training Loss=1.021747, Validation Loss=0.957375\n",
      "Epoch 12 Training Loss=1.021055, Validation Loss=0.959530\n",
      "Epoch 13 Training Loss=1.020397, Validation Loss=0.961487\n",
      "Epoch 14 Training Loss=1.019766, Validation Loss=0.963274\n",
      "Epoch 15 Training Loss=1.019157, Validation Loss=0.964914\n",
      "Epoch 16 Training Loss=1.018568, Validation Loss=0.966427\n",
      "Epoch 17 Training Loss=1.017994, Validation Loss=0.967831\n",
      "Epoch 18 Training Loss=1.017433, Validation Loss=0.969139\n",
      "Epoch 19 Training Loss=1.016884, Validation Loss=0.970364\n",
      "Epoch 20 Training Loss=1.016345, Validation Loss=0.971517\n",
      "Epoch 21 Training Loss=1.015815, Validation Loss=0.972607\n",
      "Epoch 22 Training Loss=1.015291, Validation Loss=0.973641\n",
      "Epoch 23 Training Loss=1.014774, Validation Loss=0.974627\n",
      "Epoch 24 Training Loss=1.014262, Validation Loss=0.975569\n",
      "Epoch 25 Training Loss=1.013754, Validation Loss=0.976474\n",
      "Epoch 26 Training Loss=1.013250, Validation Loss=0.977344\n",
      "Epoch 27 Training Loss=1.012748, Validation Loss=0.978184\n",
      "Epoch 28 Training Loss=1.012248, Validation Loss=0.978998\n",
      "Epoch 29 Training Loss=1.011751, Validation Loss=0.979788\n",
      "Epoch 30 Training Loss=1.011254, Validation Loss=0.980557\n",
      "Epoch 31 Training Loss=1.010758, Validation Loss=0.981308\n",
      "Epoch 32 Training Loss=1.010262, Validation Loss=0.982043\n",
      "Epoch 33 Training Loss=1.009766, Validation Loss=0.982763\n",
      "Epoch 34 Training Loss=1.009269, Validation Loss=0.983471\n",
      "Epoch 35 Training Loss=1.008772, Validation Loss=0.984169\n",
      "Epoch 36 Training Loss=1.008274, Validation Loss=0.984859\n",
      "Epoch 37 Training Loss=1.007774, Validation Loss=0.985541\n",
      "Epoch 38 Training Loss=1.007273, Validation Loss=0.986218\n",
      "Epoch 39 Training Loss=1.006771, Validation Loss=0.986892\n",
      "Epoch 40 Training Loss=1.006267, Validation Loss=0.987563\n",
      "Epoch 41 Training Loss=1.005762, Validation Loss=0.988232\n",
      "Epoch 42 Training Loss=1.005255, Validation Loss=0.988903\n",
      "Epoch 43 Training Loss=1.004746, Validation Loss=0.989574\n",
      "Epoch 44 Training Loss=1.004236, Validation Loss=0.990249\n",
      "Epoch 45 Training Loss=1.003724, Validation Loss=0.990928\n",
      "Epoch 46 Training Loss=1.003210, Validation Loss=0.991611\n",
      "Epoch 47 Training Loss=1.002695, Validation Loss=0.992301\n",
      "Epoch 48 Training Loss=1.002179, Validation Loss=0.992998\n",
      "Epoch 49 Training Loss=1.001662, Validation Loss=0.993703\n",
      "Epoch 50 Training Loss=1.001144, Validation Loss=0.994417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training Loss=1.000625, Validation Loss=0.995140\n",
      "Epoch 52 Training Loss=1.000105, Validation Loss=0.995874\n",
      "Epoch 53 Training Loss=0.999585, Validation Loss=0.996618\n",
      "Epoch 54 Training Loss=0.999065, Validation Loss=0.997373\n",
      "Epoch 55 Training Loss=0.998545, Validation Loss=0.998141\n",
      "Epoch 56 Training Loss=0.998026, Validation Loss=0.998919\n",
      "Epoch 57 Training Loss=0.997506, Validation Loss=0.999711\n",
      "Epoch 58 Training Loss=0.996988, Validation Loss=1.000514\n",
      "Epoch 59 Training Loss=0.996471, Validation Loss=1.001330\n",
      "Epoch 60 Training Loss=0.995954, Validation Loss=1.002158\n",
      "Epoch 61 Training Loss=0.995439, Validation Loss=1.002997\n",
      "Epoch 62 Training Loss=0.994925, Validation Loss=1.003849\n",
      "Epoch 63 Training Loss=0.994413, Validation Loss=1.004712\n",
      "Epoch 64 Training Loss=0.993903, Validation Loss=1.005585\n",
      "Epoch 65 Training Loss=0.993395, Validation Loss=1.006470\n",
      "Epoch 66 Training Loss=0.992889, Validation Loss=1.007364\n",
      "Epoch 67 Training Loss=0.992385, Validation Loss=1.008268\n",
      "Epoch 68 Training Loss=0.991883, Validation Loss=1.009180\n",
      "Epoch 69 Training Loss=0.991383, Validation Loss=1.010101\n",
      "Epoch 70 Training Loss=0.990886, Validation Loss=1.011029\n",
      "Epoch 71 Training Loss=0.990391, Validation Loss=1.011963\n",
      "Epoch 72 Training Loss=0.989898, Validation Loss=1.012904\n",
      "Epoch 73 Training Loss=0.989408, Validation Loss=1.013850\n",
      "Epoch 74 Training Loss=0.988920, Validation Loss=1.014800\n",
      "Epoch 75 Training Loss=0.988434, Validation Loss=1.015754\n",
      "Epoch 76 Training Loss=0.987950, Validation Loss=1.016711\n",
      "Epoch 77 Training Loss=0.987469, Validation Loss=1.017670\n",
      "Epoch 78 Training Loss=0.986990, Validation Loss=1.018631\n",
      "Epoch 79 Training Loss=0.986512, Validation Loss=1.019592\n",
      "Epoch 80 Training Loss=0.986037, Validation Loss=1.020554\n",
      "Epoch 81 Training Loss=0.985563, Validation Loss=1.021515\n",
      "Epoch 82 Training Loss=0.985091, Validation Loss=1.022474\n",
      "Epoch 83 Training Loss=0.984620, Validation Loss=1.023432\n",
      "Epoch 84 Training Loss=0.984151, Validation Loss=1.024388\n",
      "Epoch 85 Training Loss=0.983683, Validation Loss=1.025340\n",
      "Epoch 86 Training Loss=0.983215, Validation Loss=1.026290\n",
      "Epoch 87 Training Loss=0.982749, Validation Loss=1.027235\n",
      "Epoch 88 Training Loss=0.982283, Validation Loss=1.028176\n",
      "Epoch 89 Training Loss=0.981818, Validation Loss=1.029113\n",
      "Epoch 90 Training Loss=0.981352, Validation Loss=1.030044\n",
      "Epoch 91 Training Loss=0.980887, Validation Loss=1.030971\n",
      "Epoch 92 Training Loss=0.980422, Validation Loss=1.031891\n",
      "Epoch 93 Training Loss=0.979956, Validation Loss=1.032807\n",
      "Epoch 94 Training Loss=0.979490, Validation Loss=1.033716\n",
      "Epoch 95 Training Loss=0.979023, Validation Loss=1.034620\n",
      "Epoch 96 Training Loss=0.978555, Validation Loss=1.035517\n",
      "Epoch 97 Training Loss=0.978086, Validation Loss=1.036409\n",
      "Epoch 98 Training Loss=0.977615, Validation Loss=1.037294\n",
      "Epoch 99 Training Loss=0.977143, Validation Loss=1.038174\n",
      "Epoch 100 Training Loss=0.976669, Validation Loss=1.039047\n",
      "Epoch 101 Training Loss=0.976193, Validation Loss=1.039915\n",
      "Epoch 102 Training Loss=0.975715, Validation Loss=1.040778\n",
      "Epoch 103 Training Loss=0.975235, Validation Loss=1.041634\n",
      "Epoch 104 Training Loss=0.974752, Validation Loss=1.042486\n",
      "Epoch 105 Training Loss=0.974267, Validation Loss=1.043333\n",
      "Epoch 106 Training Loss=0.973779, Validation Loss=1.044175\n",
      "Epoch 107 Training Loss=0.973288, Validation Loss=1.045012\n",
      "Epoch 108 Training Loss=0.972794, Validation Loss=1.045846\n",
      "Epoch 109 Training Loss=0.972297, Validation Loss=1.046675\n",
      "Epoch 110 Training Loss=0.971798, Validation Loss=1.047500\n",
      "Epoch 111 Training Loss=0.971294, Validation Loss=1.048322\n",
      "Epoch 112 Training Loss=0.970788, Validation Loss=1.049141\n",
      "Epoch 113 Training Loss=0.970278, Validation Loss=1.049956\n",
      "Epoch 114 Training Loss=0.969765, Validation Loss=1.050768\n",
      "Epoch 115 Training Loss=0.969249, Validation Loss=1.051578\n",
      "Epoch 116 Training Loss=0.968729, Validation Loss=1.052385\n",
      "Epoch 117 Training Loss=0.968205, Validation Loss=1.053188\n",
      "Epoch 118 Training Loss=0.967679, Validation Loss=1.053989\n",
      "Epoch 119 Training Loss=0.967148, Validation Loss=1.054787\n",
      "Epoch 120 Training Loss=0.966614, Validation Loss=1.055582\n",
      "Epoch 121 Training Loss=0.966076, Validation Loss=1.056373\n",
      "Epoch 122 Training Loss=0.965535, Validation Loss=1.057160\n",
      "Epoch 123 Training Loss=0.964990, Validation Loss=1.057944\n",
      "Epoch 124 Training Loss=0.964441, Validation Loss=1.058722\n",
      "Epoch 125 Training Loss=0.963888, Validation Loss=1.059495\n",
      "Epoch 126 Training Loss=0.963332, Validation Loss=1.060263\n",
      "Epoch 127 Training Loss=0.962771, Validation Loss=1.061025\n",
      "Epoch 128 Training Loss=0.962206, Validation Loss=1.061779\n",
      "Epoch 129 Training Loss=0.961637, Validation Loss=1.062526\n",
      "Epoch 130 Training Loss=0.961065, Validation Loss=1.063266\n",
      "Epoch 131 Training Loss=0.960488, Validation Loss=1.063996\n",
      "Epoch 132 Training Loss=0.959908, Validation Loss=1.064718\n",
      "Epoch 133 Training Loss=0.959325, Validation Loss=1.065431\n",
      "Epoch 134 Training Loss=0.958738, Validation Loss=1.066134\n",
      "Epoch 135 Training Loss=0.958149, Validation Loss=1.066829\n",
      "Epoch 136 Training Loss=0.957558, Validation Loss=1.067513\n",
      "Epoch 137 Training Loss=0.956966, Validation Loss=1.068189\n",
      "Epoch 138 Training Loss=0.956372, Validation Loss=1.068856\n",
      "Epoch 139 Training Loss=0.955778, Validation Loss=1.069514\n",
      "Epoch 140 Training Loss=0.955184, Validation Loss=1.070164\n",
      "Epoch 141 Training Loss=0.954591, Validation Loss=1.070807\n",
      "Epoch 142 Training Loss=0.953999, Validation Loss=1.071443\n",
      "Epoch 143 Training Loss=0.953410, Validation Loss=1.072073\n",
      "Epoch 144 Training Loss=0.952823, Validation Loss=1.072696\n",
      "Epoch 145 Training Loss=0.952239, Validation Loss=1.073314\n",
      "Epoch 146 Training Loss=0.951658, Validation Loss=1.073927\n",
      "Epoch 147 Training Loss=0.951081, Validation Loss=1.074535\n",
      "Epoch 148 Training Loss=0.950508, Validation Loss=1.075137\n",
      "Epoch 149 Training Loss=0.949940, Validation Loss=1.075734\n",
      "Epoch 150 Training Loss=0.949375, Validation Loss=1.076327\n",
      "Epoch 151 Training Loss=0.948815, Validation Loss=1.076915\n",
      "Epoch 152 Training Loss=0.948260, Validation Loss=1.077497\n",
      "Epoch 153 Training Loss=0.947709, Validation Loss=1.078074\n",
      "Epoch 154 Training Loss=0.947163, Validation Loss=1.078644\n",
      "Epoch 155 Training Loss=0.946621, Validation Loss=1.079209\n",
      "Epoch 156 Training Loss=0.946083, Validation Loss=1.079768\n",
      "Epoch 157 Training Loss=0.945550, Validation Loss=1.080319\n",
      "Epoch 158 Training Loss=0.945022, Validation Loss=1.080863\n",
      "Epoch 159 Training Loss=0.944497, Validation Loss=1.081400\n",
      "Epoch 160 Training Loss=0.943976, Validation Loss=1.081928\n",
      "Epoch 161 Training Loss=0.943459, Validation Loss=1.082449\n",
      "Epoch 162 Training Loss=0.942946, Validation Loss=1.082960\n",
      "Epoch 163 Training Loss=0.942437, Validation Loss=1.083463\n",
      "Epoch 164 Training Loss=0.941931, Validation Loss=1.083956\n",
      "Epoch 165 Training Loss=0.941428, Validation Loss=1.084440\n",
      "Epoch 166 Training Loss=0.940928, Validation Loss=1.084914\n",
      "Epoch 167 Training Loss=0.940431, Validation Loss=1.085378\n",
      "Epoch 168 Training Loss=0.939937, Validation Loss=1.085832\n",
      "Epoch 169 Training Loss=0.939445, Validation Loss=1.086275\n",
      "Epoch 170 Training Loss=0.938956, Validation Loss=1.086708\n",
      "Epoch 171 Training Loss=0.938469, Validation Loss=1.087131\n",
      "Epoch 172 Training Loss=0.937984, Validation Loss=1.087543\n",
      "Epoch 173 Training Loss=0.937502, Validation Loss=1.087945\n",
      "Epoch 174 Training Loss=0.937021, Validation Loss=1.088336\n",
      "Epoch 175 Training Loss=0.936542, Validation Loss=1.088717\n",
      "Epoch 176 Training Loss=0.936064, Validation Loss=1.089088\n",
      "Epoch 177 Training Loss=0.935588, Validation Loss=1.089448\n",
      "Epoch 178 Training Loss=0.935113, Validation Loss=1.089798\n",
      "Epoch 179 Training Loss=0.934639, Validation Loss=1.090139\n",
      "Epoch 180 Training Loss=0.934167, Validation Loss=1.090470\n",
      "Epoch 181 Training Loss=0.933695, Validation Loss=1.090791\n",
      "Epoch 182 Training Loss=0.933224, Validation Loss=1.091104\n",
      "Epoch 183 Training Loss=0.932754, Validation Loss=1.091407\n",
      "Epoch 184 Training Loss=0.932284, Validation Loss=1.091702\n",
      "Epoch 185 Training Loss=0.931815, Validation Loss=1.091988\n",
      "Epoch 186 Training Loss=0.931347, Validation Loss=1.092266\n",
      "Epoch 187 Training Loss=0.930878, Validation Loss=1.092537\n",
      "Epoch 188 Training Loss=0.930410, Validation Loss=1.092800\n",
      "Epoch 189 Training Loss=0.929943, Validation Loss=1.093056\n",
      "Epoch 190 Training Loss=0.929475, Validation Loss=1.093305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191 Training Loss=0.929007, Validation Loss=1.093547\n",
      "Epoch 192 Training Loss=0.928540, Validation Loss=1.093784\n",
      "Epoch 193 Training Loss=0.928072, Validation Loss=1.094015\n",
      "Epoch 194 Training Loss=0.927604, Validation Loss=1.094240\n",
      "Epoch 195 Training Loss=0.927136, Validation Loss=1.094461\n",
      "Epoch 196 Training Loss=0.926668, Validation Loss=1.094677\n",
      "Epoch 197 Training Loss=0.926200, Validation Loss=1.094889\n",
      "Epoch 198 Training Loss=0.925731, Validation Loss=1.095096\n",
      "Epoch 199 Training Loss=0.925262, Validation Loss=1.095301\n",
      "Epoch 0 Training Loss=1.085333, Validation Loss=0.930319\n",
      "Epoch 1 Training Loss=1.044474, Validation Loss=0.933208\n",
      "Epoch 2 Training Loss=1.043869, Validation Loss=0.938669\n",
      "Epoch 3 Training Loss=1.042404, Validation Loss=0.942781\n",
      "Epoch 4 Training Loss=1.040979, Validation Loss=0.946111\n",
      "Epoch 5 Training Loss=1.039664, Validation Loss=0.948908\n",
      "Epoch 6 Training Loss=1.038452, Validation Loss=0.951334\n",
      "Epoch 7 Training Loss=1.037325, Validation Loss=0.953495\n",
      "Epoch 8 Training Loss=1.036272, Validation Loss=0.955462\n",
      "Epoch 9 Training Loss=1.035281, Validation Loss=0.957283\n",
      "Epoch 10 Training Loss=1.034345, Validation Loss=0.958989\n",
      "Epoch 11 Training Loss=1.033456, Validation Loss=0.960601\n",
      "Epoch 12 Training Loss=1.032610, Validation Loss=0.962135\n",
      "Epoch 13 Training Loss=1.031801, Validation Loss=0.963601\n",
      "Epoch 14 Training Loss=1.031025, Validation Loss=0.965007\n",
      "Epoch 15 Training Loss=1.030278, Validation Loss=0.966359\n",
      "Epoch 16 Training Loss=1.029558, Validation Loss=0.967662\n",
      "Epoch 17 Training Loss=1.028861, Validation Loss=0.968919\n",
      "Epoch 18 Training Loss=1.028184, Validation Loss=0.970134\n",
      "Epoch 19 Training Loss=1.027527, Validation Loss=0.971310\n",
      "Epoch 20 Training Loss=1.026888, Validation Loss=0.972449\n",
      "Epoch 21 Training Loss=1.026264, Validation Loss=0.973553\n",
      "Epoch 22 Training Loss=1.025654, Validation Loss=0.974624\n",
      "Epoch 23 Training Loss=1.025057, Validation Loss=0.975664\n",
      "Epoch 24 Training Loss=1.024473, Validation Loss=0.976675\n",
      "Epoch 25 Training Loss=1.023899, Validation Loss=0.977658\n",
      "Epoch 26 Training Loss=1.023336, Validation Loss=0.978615\n",
      "Epoch 27 Training Loss=1.022782, Validation Loss=0.979547\n",
      "Epoch 28 Training Loss=1.022237, Validation Loss=0.980456\n",
      "Epoch 29 Training Loss=1.021700, Validation Loss=0.981342\n",
      "Epoch 30 Training Loss=1.021172, Validation Loss=0.982208\n",
      "Epoch 31 Training Loss=1.020650, Validation Loss=0.983054\n",
      "Epoch 32 Training Loss=1.020135, Validation Loss=0.983882\n",
      "Epoch 33 Training Loss=1.019627, Validation Loss=0.984691\n",
      "Epoch 34 Training Loss=1.019125, Validation Loss=0.985484\n",
      "Epoch 35 Training Loss=1.018629, Validation Loss=0.986262\n",
      "Epoch 36 Training Loss=1.018138, Validation Loss=0.987025\n",
      "Epoch 37 Training Loss=1.017653, Validation Loss=0.987774\n",
      "Epoch 38 Training Loss=1.017172, Validation Loss=0.988509\n",
      "Epoch 39 Training Loss=1.016697, Validation Loss=0.989233\n",
      "Epoch 40 Training Loss=1.016226, Validation Loss=0.989944\n",
      "Epoch 41 Training Loss=1.015759, Validation Loss=0.990645\n",
      "Epoch 42 Training Loss=1.015297, Validation Loss=0.991336\n",
      "Epoch 43 Training Loss=1.014839, Validation Loss=0.992017\n",
      "Epoch 44 Training Loss=1.014385, Validation Loss=0.992689\n",
      "Epoch 45 Training Loss=1.013935, Validation Loss=0.993353\n",
      "Epoch 46 Training Loss=1.013489, Validation Loss=0.994009\n",
      "Epoch 47 Training Loss=1.013046, Validation Loss=0.994658\n",
      "Epoch 48 Training Loss=1.012607, Validation Loss=0.995299\n",
      "Epoch 49 Training Loss=1.012171, Validation Loss=0.995934\n",
      "Epoch 50 Training Loss=1.011739, Validation Loss=0.996563\n",
      "Epoch 51 Training Loss=1.011309, Validation Loss=0.997187\n",
      "Epoch 52 Training Loss=1.010883, Validation Loss=0.997805\n",
      "Epoch 53 Training Loss=1.010460, Validation Loss=0.998418\n",
      "Epoch 54 Training Loss=1.010041, Validation Loss=0.999026\n",
      "Epoch 55 Training Loss=1.009624, Validation Loss=0.999630\n",
      "Epoch 56 Training Loss=1.009210, Validation Loss=1.000230\n",
      "Epoch 57 Training Loss=1.008799, Validation Loss=1.000825\n",
      "Epoch 58 Training Loss=1.008391, Validation Loss=1.001417\n",
      "Epoch 59 Training Loss=1.007985, Validation Loss=1.002005\n",
      "Epoch 60 Training Loss=1.007583, Validation Loss=1.002590\n",
      "Epoch 61 Training Loss=1.007183, Validation Loss=1.003171\n",
      "Epoch 62 Training Loss=1.006786, Validation Loss=1.003749\n",
      "Epoch 63 Training Loss=1.006391, Validation Loss=1.004324\n",
      "Epoch 64 Training Loss=1.006000, Validation Loss=1.004895\n",
      "Epoch 65 Training Loss=1.005611, Validation Loss=1.005464\n",
      "Epoch 66 Training Loss=1.005224, Validation Loss=1.006029\n",
      "Epoch 67 Training Loss=1.004841, Validation Loss=1.006592\n",
      "Epoch 68 Training Loss=1.004459, Validation Loss=1.007151\n",
      "Epoch 69 Training Loss=1.004081, Validation Loss=1.007707\n",
      "Epoch 70 Training Loss=1.003705, Validation Loss=1.008260\n",
      "Epoch 71 Training Loss=1.003332, Validation Loss=1.008810\n",
      "Epoch 72 Training Loss=1.002961, Validation Loss=1.009356\n",
      "Epoch 73 Training Loss=1.002593, Validation Loss=1.009899\n",
      "Epoch 74 Training Loss=1.002228, Validation Loss=1.010440\n",
      "Epoch 75 Training Loss=1.001865, Validation Loss=1.010976\n",
      "Epoch 76 Training Loss=1.001505, Validation Loss=1.011509\n",
      "Epoch 77 Training Loss=1.001147, Validation Loss=1.012038\n",
      "Epoch 78 Training Loss=1.000792, Validation Loss=1.012564\n",
      "Epoch 79 Training Loss=1.000439, Validation Loss=1.013086\n",
      "Epoch 80 Training Loss=1.000089, Validation Loss=1.013603\n",
      "Epoch 81 Training Loss=0.999741, Validation Loss=1.014117\n",
      "Epoch 82 Training Loss=0.999396, Validation Loss=1.014627\n",
      "Epoch 83 Training Loss=0.999054, Validation Loss=1.015132\n",
      "Epoch 84 Training Loss=0.998714, Validation Loss=1.015633\n",
      "Epoch 85 Training Loss=0.998376, Validation Loss=1.016130\n",
      "Epoch 86 Training Loss=0.998041, Validation Loss=1.016622\n",
      "Epoch 87 Training Loss=0.997708, Validation Loss=1.017109\n",
      "Epoch 88 Training Loss=0.997377, Validation Loss=1.017592\n",
      "Epoch 89 Training Loss=0.997049, Validation Loss=1.018070\n",
      "Epoch 90 Training Loss=0.996723, Validation Loss=1.018542\n",
      "Epoch 91 Training Loss=0.996399, Validation Loss=1.019010\n",
      "Epoch 92 Training Loss=0.996078, Validation Loss=1.019472\n",
      "Epoch 93 Training Loss=0.995758, Validation Loss=1.019929\n",
      "Epoch 94 Training Loss=0.995441, Validation Loss=1.020381\n",
      "Epoch 95 Training Loss=0.995125, Validation Loss=1.020828\n",
      "Epoch 96 Training Loss=0.994812, Validation Loss=1.021269\n",
      "Epoch 97 Training Loss=0.994500, Validation Loss=1.021704\n",
      "Epoch 98 Training Loss=0.994191, Validation Loss=1.022134\n",
      "Epoch 99 Training Loss=0.993883, Validation Loss=1.022559\n",
      "Epoch 100 Training Loss=0.993577, Validation Loss=1.022977\n",
      "Epoch 101 Training Loss=0.993272, Validation Loss=1.023390\n",
      "Epoch 102 Training Loss=0.992969, Validation Loss=1.023798\n",
      "Epoch 103 Training Loss=0.992668, Validation Loss=1.024199\n",
      "Epoch 104 Training Loss=0.992368, Validation Loss=1.024595\n",
      "Epoch 105 Training Loss=0.992069, Validation Loss=1.024986\n",
      "Epoch 106 Training Loss=0.991771, Validation Loss=1.025370\n",
      "Epoch 107 Training Loss=0.991475, Validation Loss=1.025749\n",
      "Epoch 108 Training Loss=0.991180, Validation Loss=1.026122\n",
      "Epoch 109 Training Loss=0.990886, Validation Loss=1.026489\n",
      "Epoch 110 Training Loss=0.990592, Validation Loss=1.026851\n",
      "Epoch 111 Training Loss=0.990300, Validation Loss=1.027207\n",
      "Epoch 112 Training Loss=0.990008, Validation Loss=1.027558\n",
      "Epoch 113 Training Loss=0.989718, Validation Loss=1.027903\n",
      "Epoch 114 Training Loss=0.989427, Validation Loss=1.028242\n",
      "Epoch 115 Training Loss=0.989137, Validation Loss=1.028577\n",
      "Epoch 116 Training Loss=0.988848, Validation Loss=1.028905\n",
      "Epoch 117 Training Loss=0.988559, Validation Loss=1.029229\n",
      "Epoch 118 Training Loss=0.988271, Validation Loss=1.029547\n",
      "Epoch 119 Training Loss=0.987982, Validation Loss=1.029860\n",
      "Epoch 120 Training Loss=0.987694, Validation Loss=1.030168\n",
      "Epoch 121 Training Loss=0.987406, Validation Loss=1.030471\n",
      "Epoch 122 Training Loss=0.987118, Validation Loss=1.030769\n",
      "Epoch 123 Training Loss=0.986829, Validation Loss=1.031062\n",
      "Epoch 124 Training Loss=0.986541, Validation Loss=1.031350\n",
      "Epoch 125 Training Loss=0.986252, Validation Loss=1.031634\n",
      "Epoch 126 Training Loss=0.985963, Validation Loss=1.031913\n",
      "Epoch 127 Training Loss=0.985674, Validation Loss=1.032188\n",
      "Epoch 128 Training Loss=0.985385, Validation Loss=1.032458\n",
      "Epoch 129 Training Loss=0.985095, Validation Loss=1.032724\n",
      "Epoch 130 Training Loss=0.984804, Validation Loss=1.032987\n",
      "Epoch 131 Training Loss=0.984513, Validation Loss=1.033244\n",
      "Epoch 132 Training Loss=0.984222, Validation Loss=1.033499\n",
      "Epoch 133 Training Loss=0.983929, Validation Loss=1.033749\n",
      "Epoch 134 Training Loss=0.983637, Validation Loss=1.033996\n",
      "Epoch 135 Training Loss=0.983343, Validation Loss=1.034239\n",
      "Epoch 136 Training Loss=0.983049, Validation Loss=1.034479\n",
      "Epoch 137 Training Loss=0.982754, Validation Loss=1.034715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 Training Loss=0.982459, Validation Loss=1.034948\n",
      "Epoch 139 Training Loss=0.982163, Validation Loss=1.035178\n",
      "Epoch 140 Training Loss=0.981866, Validation Loss=1.035406\n",
      "Epoch 141 Training Loss=0.981568, Validation Loss=1.035630\n",
      "Epoch 142 Training Loss=0.981270, Validation Loss=1.035852\n",
      "Epoch 143 Training Loss=0.980971, Validation Loss=1.036071\n",
      "Epoch 144 Training Loss=0.980672, Validation Loss=1.036287\n",
      "Epoch 145 Training Loss=0.980372, Validation Loss=1.036502\n",
      "Epoch 146 Training Loss=0.980072, Validation Loss=1.036714\n",
      "Epoch 147 Training Loss=0.979771, Validation Loss=1.036924\n",
      "Epoch 148 Training Loss=0.979469, Validation Loss=1.037132\n",
      "Epoch 149 Training Loss=0.979168, Validation Loss=1.037338\n",
      "Epoch 150 Training Loss=0.978866, Validation Loss=1.037542\n",
      "Epoch 151 Training Loss=0.978563, Validation Loss=1.037744\n",
      "Epoch 152 Training Loss=0.978261, Validation Loss=1.037945\n",
      "Epoch 153 Training Loss=0.977958, Validation Loss=1.038144\n",
      "Epoch 154 Training Loss=0.977656, Validation Loss=1.038342\n",
      "Epoch 155 Training Loss=0.977353, Validation Loss=1.038538\n",
      "Epoch 156 Training Loss=0.977050, Validation Loss=1.038733\n",
      "Epoch 157 Training Loss=0.976748, Validation Loss=1.038926\n",
      "Epoch 158 Training Loss=0.976446, Validation Loss=1.039119\n",
      "Epoch 159 Training Loss=0.976144, Validation Loss=1.039310\n",
      "Epoch 160 Training Loss=0.975843, Validation Loss=1.039499\n",
      "Epoch 161 Training Loss=0.975542, Validation Loss=1.039688\n",
      "Epoch 162 Training Loss=0.975241, Validation Loss=1.039876\n",
      "Epoch 163 Training Loss=0.974942, Validation Loss=1.040063\n",
      "Epoch 164 Training Loss=0.974642, Validation Loss=1.040248\n",
      "Epoch 165 Training Loss=0.974344, Validation Loss=1.040433\n",
      "Epoch 166 Training Loss=0.974046, Validation Loss=1.040616\n",
      "Epoch 167 Training Loss=0.973750, Validation Loss=1.040799\n",
      "Epoch 168 Training Loss=0.973454, Validation Loss=1.040980\n",
      "Epoch 169 Training Loss=0.973159, Validation Loss=1.041161\n",
      "Epoch 170 Training Loss=0.972866, Validation Loss=1.041341\n",
      "Epoch 171 Training Loss=0.972573, Validation Loss=1.041520\n",
      "Epoch 172 Training Loss=0.972281, Validation Loss=1.041698\n",
      "Epoch 173 Training Loss=0.971991, Validation Loss=1.041875\n",
      "Epoch 174 Training Loss=0.971702, Validation Loss=1.042051\n",
      "Epoch 175 Training Loss=0.971414, Validation Loss=1.042226\n",
      "Epoch 176 Training Loss=0.971127, Validation Loss=1.042401\n",
      "Epoch 177 Training Loss=0.970842, Validation Loss=1.042574\n",
      "Epoch 178 Training Loss=0.970558, Validation Loss=1.042747\n",
      "Epoch 179 Training Loss=0.970275, Validation Loss=1.042919\n",
      "Epoch 180 Training Loss=0.969994, Validation Loss=1.043089\n",
      "Epoch 181 Training Loss=0.969714, Validation Loss=1.043259\n",
      "Epoch 182 Training Loss=0.969436, Validation Loss=1.043428\n",
      "Epoch 183 Training Loss=0.969158, Validation Loss=1.043596\n",
      "Epoch 184 Training Loss=0.968883, Validation Loss=1.043763\n",
      "Epoch 185 Training Loss=0.968608, Validation Loss=1.043930\n",
      "Epoch 186 Training Loss=0.968336, Validation Loss=1.044095\n",
      "Epoch 187 Training Loss=0.968064, Validation Loss=1.044259\n",
      "Epoch 188 Training Loss=0.967794, Validation Loss=1.044423\n",
      "Epoch 189 Training Loss=0.967525, Validation Loss=1.044586\n",
      "Epoch 190 Training Loss=0.967258, Validation Loss=1.044747\n",
      "Epoch 191 Training Loss=0.966992, Validation Loss=1.044908\n",
      "Epoch 192 Training Loss=0.966728, Validation Loss=1.045068\n",
      "Epoch 193 Training Loss=0.966465, Validation Loss=1.045227\n",
      "Epoch 194 Training Loss=0.966203, Validation Loss=1.045385\n",
      "Epoch 195 Training Loss=0.965943, Validation Loss=1.045543\n",
      "Epoch 196 Training Loss=0.965684, Validation Loss=1.045699\n",
      "Epoch 197 Training Loss=0.965427, Validation Loss=1.045855\n",
      "Epoch 198 Training Loss=0.965170, Validation Loss=1.046010\n",
      "Epoch 199 Training Loss=0.964915, Validation Loss=1.046164\n",
      "Epoch 0 Training Loss=1.049387, Validation Loss=0.923361\n",
      "Epoch 1 Training Loss=1.045027, Validation Loss=0.929284\n",
      "Epoch 2 Training Loss=1.042960, Validation Loss=0.934279\n",
      "Epoch 3 Training Loss=1.041746, Validation Loss=0.938213\n",
      "Epoch 4 Training Loss=1.040694, Validation Loss=0.941323\n",
      "Epoch 5 Training Loss=1.039723, Validation Loss=0.943832\n",
      "Epoch 6 Training Loss=1.038807, Validation Loss=0.945909\n",
      "Epoch 7 Training Loss=1.037933, Validation Loss=0.947673\n",
      "Epoch 8 Training Loss=1.037094, Validation Loss=0.949213\n",
      "Epoch 9 Training Loss=1.036284, Validation Loss=0.950589\n",
      "Epoch 10 Training Loss=1.035501, Validation Loss=0.951847\n",
      "Epoch 11 Training Loss=1.034741, Validation Loss=0.953017\n",
      "Epoch 12 Training Loss=1.034002, Validation Loss=0.954123\n",
      "Epoch 13 Training Loss=1.033283, Validation Loss=0.955179\n",
      "Epoch 14 Training Loss=1.032580, Validation Loss=0.956198\n",
      "Epoch 15 Training Loss=1.031892, Validation Loss=0.957189\n",
      "Epoch 16 Training Loss=1.031218, Validation Loss=0.958158\n",
      "Epoch 17 Training Loss=1.030555, Validation Loss=0.959110\n",
      "Epoch 18 Training Loss=1.029904, Validation Loss=0.960048\n",
      "Epoch 19 Training Loss=1.029263, Validation Loss=0.960975\n",
      "Epoch 20 Training Loss=1.028630, Validation Loss=0.961894\n",
      "Epoch 21 Training Loss=1.028005, Validation Loss=0.962806\n",
      "Epoch 22 Training Loss=1.027386, Validation Loss=0.963713\n",
      "Epoch 23 Training Loss=1.026774, Validation Loss=0.964616\n",
      "Epoch 24 Training Loss=1.026168, Validation Loss=0.965517\n",
      "Epoch 25 Training Loss=1.025567, Validation Loss=0.966416\n",
      "Epoch 26 Training Loss=1.024970, Validation Loss=0.967314\n",
      "Epoch 27 Training Loss=1.024378, Validation Loss=0.968211\n",
      "Epoch 28 Training Loss=1.023789, Validation Loss=0.969109\n",
      "Epoch 29 Training Loss=1.023204, Validation Loss=0.970008\n",
      "Epoch 30 Training Loss=1.022621, Validation Loss=0.970909\n",
      "Epoch 31 Training Loss=1.022042, Validation Loss=0.971812\n",
      "Epoch 32 Training Loss=1.021466, Validation Loss=0.972717\n",
      "Epoch 33 Training Loss=1.020892, Validation Loss=0.973624\n",
      "Epoch 34 Training Loss=1.020321, Validation Loss=0.974535\n",
      "Epoch 35 Training Loss=1.019752, Validation Loss=0.975449\n",
      "Epoch 36 Training Loss=1.019185, Validation Loss=0.976367\n",
      "Epoch 37 Training Loss=1.018620, Validation Loss=0.977288\n",
      "Epoch 38 Training Loss=1.018058, Validation Loss=0.978213\n",
      "Epoch 39 Training Loss=1.017498, Validation Loss=0.979143\n",
      "Epoch 40 Training Loss=1.016940, Validation Loss=0.980076\n",
      "Epoch 41 Training Loss=1.016385, Validation Loss=0.981014\n",
      "Epoch 42 Training Loss=1.015831, Validation Loss=0.981955\n",
      "Epoch 43 Training Loss=1.015280, Validation Loss=0.982901\n",
      "Epoch 44 Training Loss=1.014731, Validation Loss=0.983850\n",
      "Epoch 45 Training Loss=1.014184, Validation Loss=0.984804\n",
      "Epoch 46 Training Loss=1.013640, Validation Loss=0.985761\n",
      "Epoch 47 Training Loss=1.013098, Validation Loss=0.986722\n",
      "Epoch 48 Training Loss=1.012558, Validation Loss=0.987687\n",
      "Epoch 49 Training Loss=1.012021, Validation Loss=0.988654\n",
      "Epoch 50 Training Loss=1.011487, Validation Loss=0.989625\n",
      "Epoch 51 Training Loss=1.010955, Validation Loss=0.990598\n",
      "Epoch 52 Training Loss=1.010426, Validation Loss=0.991573\n",
      "Epoch 53 Training Loss=1.009899, Validation Loss=0.992551\n",
      "Epoch 54 Training Loss=1.009375, Validation Loss=0.993530\n",
      "Epoch 55 Training Loss=1.008854, Validation Loss=0.994510\n",
      "Epoch 56 Training Loss=1.008336, Validation Loss=0.995491\n",
      "Epoch 57 Training Loss=1.007820, Validation Loss=0.996472\n",
      "Epoch 58 Training Loss=1.007308, Validation Loss=0.997454\n",
      "Epoch 59 Training Loss=1.006798, Validation Loss=0.998435\n",
      "Epoch 60 Training Loss=1.006291, Validation Loss=0.999415\n",
      "Epoch 61 Training Loss=1.005786, Validation Loss=1.000394\n",
      "Epoch 62 Training Loss=1.005285, Validation Loss=1.001371\n",
      "Epoch 63 Training Loss=1.004786, Validation Loss=1.002346\n",
      "Epoch 64 Training Loss=1.004290, Validation Loss=1.003319\n",
      "Epoch 65 Training Loss=1.003797, Validation Loss=1.004288\n",
      "Epoch 66 Training Loss=1.003306, Validation Loss=1.005254\n",
      "Epoch 67 Training Loss=1.002818, Validation Loss=1.006216\n",
      "Epoch 68 Training Loss=1.002332, Validation Loss=1.007174\n",
      "Epoch 69 Training Loss=1.001849, Validation Loss=1.008127\n",
      "Epoch 70 Training Loss=1.001368, Validation Loss=1.009075\n",
      "Epoch 71 Training Loss=1.000889, Validation Loss=1.010018\n",
      "Epoch 72 Training Loss=1.000413, Validation Loss=1.010954\n",
      "Epoch 73 Training Loss=0.999938, Validation Loss=1.011885\n",
      "Epoch 74 Training Loss=0.999466, Validation Loss=1.012809\n",
      "Epoch 75 Training Loss=0.998995, Validation Loss=1.013726\n",
      "Epoch 76 Training Loss=0.998526, Validation Loss=1.014636\n",
      "Epoch 77 Training Loss=0.998059, Validation Loss=1.015539\n",
      "Epoch 78 Training Loss=0.997593, Validation Loss=1.016434\n",
      "Epoch 79 Training Loss=0.997129, Validation Loss=1.017321\n",
      "Epoch 80 Training Loss=0.996666, Validation Loss=1.018200\n",
      "Epoch 81 Training Loss=0.996204, Validation Loss=1.019071\n",
      "Epoch 82 Training Loss=0.995743, Validation Loss=1.019933\n",
      "Epoch 83 Training Loss=0.995283, Validation Loss=1.020786\n",
      "Epoch 84 Training Loss=0.994824, Validation Loss=1.021631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Training Loss=0.994365, Validation Loss=1.022467\n",
      "Epoch 86 Training Loss=0.993907, Validation Loss=1.023294\n",
      "Epoch 87 Training Loss=0.993449, Validation Loss=1.024113\n",
      "Epoch 88 Training Loss=0.992991, Validation Loss=1.024922\n",
      "Epoch 89 Training Loss=0.992534, Validation Loss=1.025722\n",
      "Epoch 90 Training Loss=0.992076, Validation Loss=1.026514\n",
      "Epoch 91 Training Loss=0.991618, Validation Loss=1.027297\n",
      "Epoch 92 Training Loss=0.991160, Validation Loss=1.028071\n",
      "Epoch 93 Training Loss=0.990702, Validation Loss=1.028836\n",
      "Epoch 94 Training Loss=0.990243, Validation Loss=1.029593\n",
      "Epoch 95 Training Loss=0.989783, Validation Loss=1.030341\n",
      "Epoch 96 Training Loss=0.989323, Validation Loss=1.031082\n",
      "Epoch 97 Training Loss=0.988861, Validation Loss=1.031814\n",
      "Epoch 98 Training Loss=0.988399, Validation Loss=1.032539\n",
      "Epoch 99 Training Loss=0.987936, Validation Loss=1.033256\n",
      "Epoch 100 Training Loss=0.987472, Validation Loss=1.033966\n",
      "Epoch 101 Training Loss=0.987006, Validation Loss=1.034669\n",
      "Epoch 102 Training Loss=0.986539, Validation Loss=1.035365\n",
      "Epoch 103 Training Loss=0.986071, Validation Loss=1.036054\n",
      "Epoch 104 Training Loss=0.985601, Validation Loss=1.036738\n",
      "Epoch 105 Training Loss=0.985130, Validation Loss=1.037415\n",
      "Epoch 106 Training Loss=0.984657, Validation Loss=1.038086\n",
      "Epoch 107 Training Loss=0.984183, Validation Loss=1.038753\n",
      "Epoch 108 Training Loss=0.983707, Validation Loss=1.039414\n",
      "Epoch 109 Training Loss=0.983229, Validation Loss=1.040070\n",
      "Epoch 110 Training Loss=0.982749, Validation Loss=1.040722\n",
      "Epoch 111 Training Loss=0.982268, Validation Loss=1.041369\n",
      "Epoch 112 Training Loss=0.981784, Validation Loss=1.042012\n",
      "Epoch 113 Training Loss=0.981299, Validation Loss=1.042652\n",
      "Epoch 114 Training Loss=0.980812, Validation Loss=1.043288\n",
      "Epoch 115 Training Loss=0.980322, Validation Loss=1.043921\n",
      "Epoch 116 Training Loss=0.979831, Validation Loss=1.044551\n",
      "Epoch 117 Training Loss=0.979338, Validation Loss=1.045178\n",
      "Epoch 118 Training Loss=0.978842, Validation Loss=1.045802\n",
      "Epoch 119 Training Loss=0.978345, Validation Loss=1.046425\n",
      "Epoch 120 Training Loss=0.977845, Validation Loss=1.047045\n",
      "Epoch 121 Training Loss=0.977343, Validation Loss=1.047662\n",
      "Epoch 122 Training Loss=0.976838, Validation Loss=1.048279\n",
      "Epoch 123 Training Loss=0.976332, Validation Loss=1.048894\n",
      "Epoch 124 Training Loss=0.975823, Validation Loss=1.049507\n",
      "Epoch 125 Training Loss=0.975312, Validation Loss=1.050119\n",
      "Epoch 126 Training Loss=0.974798, Validation Loss=1.050730\n",
      "Epoch 127 Training Loss=0.974283, Validation Loss=1.051339\n",
      "Epoch 128 Training Loss=0.973765, Validation Loss=1.051948\n",
      "Epoch 129 Training Loss=0.973244, Validation Loss=1.052556\n",
      "Epoch 130 Training Loss=0.972721, Validation Loss=1.053164\n",
      "Epoch 131 Training Loss=0.972196, Validation Loss=1.053771\n",
      "Epoch 132 Training Loss=0.971668, Validation Loss=1.054377\n",
      "Epoch 133 Training Loss=0.971137, Validation Loss=1.054982\n",
      "Epoch 134 Training Loss=0.970605, Validation Loss=1.055588\n",
      "Epoch 135 Training Loss=0.970069, Validation Loss=1.056193\n",
      "Epoch 136 Training Loss=0.969531, Validation Loss=1.056798\n",
      "Epoch 137 Training Loss=0.968991, Validation Loss=1.057402\n",
      "Epoch 138 Training Loss=0.968448, Validation Loss=1.058007\n",
      "Epoch 139 Training Loss=0.967903, Validation Loss=1.058612\n",
      "Epoch 140 Training Loss=0.967355, Validation Loss=1.059216\n",
      "Epoch 141 Training Loss=0.966805, Validation Loss=1.059821\n",
      "Epoch 142 Training Loss=0.966252, Validation Loss=1.060425\n",
      "Epoch 143 Training Loss=0.965696, Validation Loss=1.061030\n",
      "Epoch 144 Training Loss=0.965139, Validation Loss=1.061635\n",
      "Epoch 145 Training Loss=0.964578, Validation Loss=1.062240\n",
      "Epoch 146 Training Loss=0.964016, Validation Loss=1.062846\n",
      "Epoch 147 Training Loss=0.963451, Validation Loss=1.063452\n",
      "Epoch 148 Training Loss=0.962883, Validation Loss=1.064059\n",
      "Epoch 149 Training Loss=0.962313, Validation Loss=1.064667\n",
      "Epoch 150 Training Loss=0.961741, Validation Loss=1.065275\n",
      "Epoch 151 Training Loss=0.961167, Validation Loss=1.065884\n",
      "Epoch 152 Training Loss=0.960590, Validation Loss=1.066494\n",
      "Epoch 153 Training Loss=0.960012, Validation Loss=1.067105\n",
      "Epoch 154 Training Loss=0.959431, Validation Loss=1.067717\n",
      "Epoch 155 Training Loss=0.958848, Validation Loss=1.068331\n",
      "Epoch 156 Training Loss=0.958263, Validation Loss=1.068946\n",
      "Epoch 157 Training Loss=0.957677, Validation Loss=1.069562\n",
      "Epoch 158 Training Loss=0.957088, Validation Loss=1.070181\n",
      "Epoch 159 Training Loss=0.956498, Validation Loss=1.070801\n",
      "Epoch 160 Training Loss=0.955906, Validation Loss=1.071423\n",
      "Epoch 161 Training Loss=0.955312, Validation Loss=1.072047\n",
      "Epoch 162 Training Loss=0.954717, Validation Loss=1.072673\n",
      "Epoch 163 Training Loss=0.954120, Validation Loss=1.073302\n",
      "Epoch 164 Training Loss=0.953522, Validation Loss=1.073933\n",
      "Epoch 165 Training Loss=0.952923, Validation Loss=1.074566\n",
      "Epoch 166 Training Loss=0.952322, Validation Loss=1.075202\n",
      "Epoch 167 Training Loss=0.951720, Validation Loss=1.075841\n",
      "Epoch 168 Training Loss=0.951117, Validation Loss=1.076482\n",
      "Epoch 169 Training Loss=0.950512, Validation Loss=1.077126\n",
      "Epoch 170 Training Loss=0.949907, Validation Loss=1.077773\n",
      "Epoch 171 Training Loss=0.949300, Validation Loss=1.078422\n",
      "Epoch 172 Training Loss=0.948693, Validation Loss=1.079075\n",
      "Epoch 173 Training Loss=0.948085, Validation Loss=1.079730\n",
      "Epoch 174 Training Loss=0.947476, Validation Loss=1.080387\n",
      "Epoch 175 Training Loss=0.946866, Validation Loss=1.081048\n",
      "Epoch 176 Training Loss=0.946256, Validation Loss=1.081710\n",
      "Epoch 177 Training Loss=0.945644, Validation Loss=1.082376\n",
      "Epoch 178 Training Loss=0.945033, Validation Loss=1.083044\n",
      "Epoch 179 Training Loss=0.944420, Validation Loss=1.083714\n",
      "Epoch 180 Training Loss=0.943807, Validation Loss=1.084387\n",
      "Epoch 181 Training Loss=0.943193, Validation Loss=1.085061\n",
      "Epoch 182 Training Loss=0.942579, Validation Loss=1.085738\n",
      "Epoch 183 Training Loss=0.941965, Validation Loss=1.086417\n",
      "Epoch 184 Training Loss=0.941350, Validation Loss=1.087097\n",
      "Epoch 185 Training Loss=0.940734, Validation Loss=1.087779\n",
      "Epoch 186 Training Loss=0.940118, Validation Loss=1.088462\n",
      "Epoch 187 Training Loss=0.939502, Validation Loss=1.089146\n",
      "Epoch 188 Training Loss=0.938885, Validation Loss=1.089832\n",
      "Epoch 189 Training Loss=0.938268, Validation Loss=1.090518\n",
      "Epoch 190 Training Loss=0.937651, Validation Loss=1.091205\n",
      "Epoch 191 Training Loss=0.937033, Validation Loss=1.091893\n",
      "Epoch 192 Training Loss=0.936414, Validation Loss=1.092581\n",
      "Epoch 193 Training Loss=0.935795, Validation Loss=1.093268\n",
      "Epoch 194 Training Loss=0.935176, Validation Loss=1.093956\n",
      "Epoch 195 Training Loss=0.934557, Validation Loss=1.094643\n",
      "Epoch 196 Training Loss=0.933936, Validation Loss=1.095330\n",
      "Epoch 197 Training Loss=0.933316, Validation Loss=1.096016\n",
      "Epoch 198 Training Loss=0.932695, Validation Loss=1.096701\n",
      "Epoch 199 Training Loss=0.932073, Validation Loss=1.097385\n",
      "Epoch 0 Training Loss=1.090693, Validation Loss=0.931605\n",
      "Epoch 1 Training Loss=1.066960, Validation Loss=0.951604\n",
      "Epoch 2 Training Loss=1.064810, Validation Loss=0.959680\n",
      "Epoch 3 Training Loss=1.062734, Validation Loss=0.963819\n",
      "Epoch 4 Training Loss=1.060813, Validation Loss=0.966337\n",
      "Epoch 5 Training Loss=1.059047, Validation Loss=0.968111\n",
      "Epoch 6 Training Loss=1.057425, Validation Loss=0.969494\n",
      "Epoch 7 Training Loss=1.055929, Validation Loss=0.970641\n",
      "Epoch 8 Training Loss=1.054539, Validation Loss=0.971623\n",
      "Epoch 9 Training Loss=1.053238, Validation Loss=0.972484\n",
      "Epoch 10 Training Loss=1.052013, Validation Loss=0.973249\n",
      "Epoch 11 Training Loss=1.050852, Validation Loss=0.973938\n",
      "Epoch 12 Training Loss=1.049746, Validation Loss=0.974566\n",
      "Epoch 13 Training Loss=1.048689, Validation Loss=0.975144\n",
      "Epoch 14 Training Loss=1.047674, Validation Loss=0.975683\n",
      "Epoch 15 Training Loss=1.046697, Validation Loss=0.976190\n",
      "Epoch 16 Training Loss=1.045753, Validation Loss=0.976672\n",
      "Epoch 17 Training Loss=1.044839, Validation Loss=0.977134\n",
      "Epoch 18 Training Loss=1.043953, Validation Loss=0.977580\n",
      "Epoch 19 Training Loss=1.043092, Validation Loss=0.978014\n",
      "Epoch 20 Training Loss=1.042255, Validation Loss=0.978439\n",
      "Epoch 21 Training Loss=1.041438, Validation Loss=0.978856\n",
      "Epoch 22 Training Loss=1.040641, Validation Loss=0.979269\n",
      "Epoch 23 Training Loss=1.039863, Validation Loss=0.979677\n",
      "Epoch 24 Training Loss=1.039102, Validation Loss=0.980083\n",
      "Epoch 25 Training Loss=1.038357, Validation Loss=0.980486\n",
      "Epoch 26 Training Loss=1.037628, Validation Loss=0.980888\n",
      "Epoch 27 Training Loss=1.036913, Validation Loss=0.981290\n",
      "Epoch 28 Training Loss=1.036212, Validation Loss=0.981690\n",
      "Epoch 29 Training Loss=1.035524, Validation Loss=0.982091\n",
      "Epoch 30 Training Loss=1.034849, Validation Loss=0.982492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training Loss=1.034185, Validation Loss=0.982893\n",
      "Epoch 32 Training Loss=1.033533, Validation Loss=0.983294\n",
      "Epoch 33 Training Loss=1.032892, Validation Loss=0.983695\n",
      "Epoch 34 Training Loss=1.032262, Validation Loss=0.984096\n",
      "Epoch 35 Training Loss=1.031641, Validation Loss=0.984498\n",
      "Epoch 36 Training Loss=1.031031, Validation Loss=0.984900\n",
      "Epoch 37 Training Loss=1.030430, Validation Loss=0.985302\n",
      "Epoch 38 Training Loss=1.029838, Validation Loss=0.985704\n",
      "Epoch 39 Training Loss=1.029255, Validation Loss=0.986107\n",
      "Epoch 40 Training Loss=1.028680, Validation Loss=0.986509\n",
      "Epoch 41 Training Loss=1.028114, Validation Loss=0.986912\n",
      "Epoch 42 Training Loss=1.027555, Validation Loss=0.987315\n",
      "Epoch 43 Training Loss=1.027004, Validation Loss=0.987719\n",
      "Epoch 44 Training Loss=1.026460, Validation Loss=0.988122\n",
      "Epoch 45 Training Loss=1.025923, Validation Loss=0.988526\n",
      "Epoch 46 Training Loss=1.025393, Validation Loss=0.988930\n",
      "Epoch 47 Training Loss=1.024870, Validation Loss=0.989334\n",
      "Epoch 48 Training Loss=1.024354, Validation Loss=0.989739\n",
      "Epoch 49 Training Loss=1.023843, Validation Loss=0.990144\n",
      "Epoch 50 Training Loss=1.023338, Validation Loss=0.990549\n",
      "Epoch 51 Training Loss=1.022840, Validation Loss=0.990955\n",
      "Epoch 52 Training Loss=1.022347, Validation Loss=0.991360\n",
      "Epoch 53 Training Loss=1.021859, Validation Loss=0.991767\n",
      "Epoch 54 Training Loss=1.021377, Validation Loss=0.992174\n",
      "Epoch 55 Training Loss=1.020900, Validation Loss=0.992581\n",
      "Epoch 56 Training Loss=1.020428, Validation Loss=0.992989\n",
      "Epoch 57 Training Loss=1.019960, Validation Loss=0.993397\n",
      "Epoch 58 Training Loss=1.019498, Validation Loss=0.993806\n",
      "Epoch 59 Training Loss=1.019040, Validation Loss=0.994215\n",
      "Epoch 60 Training Loss=1.018587, Validation Loss=0.994624\n",
      "Epoch 61 Training Loss=1.018138, Validation Loss=0.995034\n",
      "Epoch 62 Training Loss=1.017694, Validation Loss=0.995445\n",
      "Epoch 63 Training Loss=1.017254, Validation Loss=0.995855\n",
      "Epoch 64 Training Loss=1.016818, Validation Loss=0.996266\n",
      "Epoch 65 Training Loss=1.016386, Validation Loss=0.996677\n",
      "Epoch 66 Training Loss=1.015958, Validation Loss=0.997089\n",
      "Epoch 67 Training Loss=1.015534, Validation Loss=0.997501\n",
      "Epoch 68 Training Loss=1.015114, Validation Loss=0.997912\n",
      "Epoch 69 Training Loss=1.014697, Validation Loss=0.998324\n",
      "Epoch 70 Training Loss=1.014285, Validation Loss=0.998736\n",
      "Epoch 71 Training Loss=1.013876, Validation Loss=0.999147\n",
      "Epoch 72 Training Loss=1.013470, Validation Loss=0.999559\n",
      "Epoch 73 Training Loss=1.013068, Validation Loss=0.999970\n",
      "Epoch 74 Training Loss=1.012670, Validation Loss=1.000380\n",
      "Epoch 75 Training Loss=1.012275, Validation Loss=1.000791\n",
      "Epoch 76 Training Loss=1.011884, Validation Loss=1.001200\n",
      "Epoch 77 Training Loss=1.011495, Validation Loss=1.001609\n",
      "Epoch 78 Training Loss=1.011111, Validation Loss=1.002018\n",
      "Epoch 79 Training Loss=1.010729, Validation Loss=1.002426\n",
      "Epoch 80 Training Loss=1.010351, Validation Loss=1.002832\n",
      "Epoch 81 Training Loss=1.009976, Validation Loss=1.003238\n",
      "Epoch 82 Training Loss=1.009604, Validation Loss=1.003643\n",
      "Epoch 83 Training Loss=1.009236, Validation Loss=1.004046\n",
      "Epoch 84 Training Loss=1.008870, Validation Loss=1.004449\n",
      "Epoch 85 Training Loss=1.008508, Validation Loss=1.004850\n",
      "Epoch 86 Training Loss=1.008149, Validation Loss=1.005249\n",
      "Epoch 87 Training Loss=1.007792, Validation Loss=1.005647\n",
      "Epoch 88 Training Loss=1.007439, Validation Loss=1.006044\n",
      "Epoch 89 Training Loss=1.007089, Validation Loss=1.006439\n",
      "Epoch 90 Training Loss=1.006742, Validation Loss=1.006832\n",
      "Epoch 91 Training Loss=1.006397, Validation Loss=1.007223\n",
      "Epoch 92 Training Loss=1.006056, Validation Loss=1.007613\n",
      "Epoch 93 Training Loss=1.005717, Validation Loss=1.008000\n",
      "Epoch 94 Training Loss=1.005381, Validation Loss=1.008385\n",
      "Epoch 95 Training Loss=1.005048, Validation Loss=1.008769\n",
      "Epoch 96 Training Loss=1.004718, Validation Loss=1.009150\n",
      "Epoch 97 Training Loss=1.004390, Validation Loss=1.009529\n",
      "Epoch 98 Training Loss=1.004065, Validation Loss=1.009905\n",
      "Epoch 99 Training Loss=1.003743, Validation Loss=1.010280\n",
      "Epoch 100 Training Loss=1.003423, Validation Loss=1.010651\n",
      "Epoch 101 Training Loss=1.003106, Validation Loss=1.011021\n",
      "Epoch 102 Training Loss=1.002792, Validation Loss=1.011388\n",
      "Epoch 103 Training Loss=1.002480, Validation Loss=1.011752\n",
      "Epoch 104 Training Loss=1.002170, Validation Loss=1.012114\n",
      "Epoch 105 Training Loss=1.001863, Validation Loss=1.012473\n",
      "Epoch 106 Training Loss=1.001558, Validation Loss=1.012829\n",
      "Epoch 107 Training Loss=1.001256, Validation Loss=1.013183\n",
      "Epoch 108 Training Loss=1.000955, Validation Loss=1.013534\n",
      "Epoch 109 Training Loss=1.000657, Validation Loss=1.013882\n",
      "Epoch 110 Training Loss=1.000362, Validation Loss=1.014228\n",
      "Epoch 111 Training Loss=1.000068, Validation Loss=1.014570\n",
      "Epoch 112 Training Loss=0.999776, Validation Loss=1.014910\n",
      "Epoch 113 Training Loss=0.999487, Validation Loss=1.015247\n",
      "Epoch 114 Training Loss=0.999199, Validation Loss=1.015581\n",
      "Epoch 115 Training Loss=0.998914, Validation Loss=1.015913\n",
      "Epoch 116 Training Loss=0.998630, Validation Loss=1.016241\n",
      "Epoch 117 Training Loss=0.998348, Validation Loss=1.016567\n",
      "Epoch 118 Training Loss=0.998068, Validation Loss=1.016889\n",
      "Epoch 119 Training Loss=0.997789, Validation Loss=1.017209\n",
      "Epoch 120 Training Loss=0.997513, Validation Loss=1.017527\n",
      "Epoch 121 Training Loss=0.997238, Validation Loss=1.017841\n",
      "Epoch 122 Training Loss=0.996964, Validation Loss=1.018152\n",
      "Epoch 123 Training Loss=0.996693, Validation Loss=1.018461\n",
      "Epoch 124 Training Loss=0.996422, Validation Loss=1.018766\n",
      "Epoch 125 Training Loss=0.996153, Validation Loss=1.019069\n",
      "Epoch 126 Training Loss=0.995886, Validation Loss=1.019369\n",
      "Epoch 127 Training Loss=0.995619, Validation Loss=1.019667\n",
      "Epoch 128 Training Loss=0.995354, Validation Loss=1.019962\n",
      "Epoch 129 Training Loss=0.995091, Validation Loss=1.020254\n",
      "Epoch 130 Training Loss=0.994828, Validation Loss=1.020543\n",
      "Epoch 131 Training Loss=0.994567, Validation Loss=1.020830\n",
      "Epoch 132 Training Loss=0.994307, Validation Loss=1.021114\n",
      "Epoch 133 Training Loss=0.994047, Validation Loss=1.021396\n",
      "Epoch 134 Training Loss=0.993789, Validation Loss=1.021676\n",
      "Epoch 135 Training Loss=0.993532, Validation Loss=1.021952\n",
      "Epoch 136 Training Loss=0.993276, Validation Loss=1.022227\n",
      "Epoch 137 Training Loss=0.993020, Validation Loss=1.022499\n",
      "Epoch 138 Training Loss=0.992765, Validation Loss=1.022768\n",
      "Epoch 139 Training Loss=0.992511, Validation Loss=1.023035\n",
      "Epoch 140 Training Loss=0.992258, Validation Loss=1.023300\n",
      "Epoch 141 Training Loss=0.992006, Validation Loss=1.023563\n",
      "Epoch 142 Training Loss=0.991754, Validation Loss=1.023823\n",
      "Epoch 143 Training Loss=0.991503, Validation Loss=1.024082\n",
      "Epoch 144 Training Loss=0.991252, Validation Loss=1.024338\n",
      "Epoch 145 Training Loss=0.991002, Validation Loss=1.024592\n",
      "Epoch 146 Training Loss=0.990752, Validation Loss=1.024844\n",
      "Epoch 147 Training Loss=0.990503, Validation Loss=1.025094\n",
      "Epoch 148 Training Loss=0.990254, Validation Loss=1.025342\n",
      "Epoch 149 Training Loss=0.990006, Validation Loss=1.025588\n",
      "Epoch 150 Training Loss=0.989758, Validation Loss=1.025833\n",
      "Epoch 151 Training Loss=0.989510, Validation Loss=1.026075\n",
      "Epoch 152 Training Loss=0.989263, Validation Loss=1.026315\n",
      "Epoch 153 Training Loss=0.989016, Validation Loss=1.026554\n",
      "Epoch 154 Training Loss=0.988769, Validation Loss=1.026791\n",
      "Epoch 155 Training Loss=0.988522, Validation Loss=1.027026\n",
      "Epoch 156 Training Loss=0.988275, Validation Loss=1.027260\n",
      "Epoch 157 Training Loss=0.988029, Validation Loss=1.027492\n",
      "Epoch 158 Training Loss=0.987782, Validation Loss=1.027722\n",
      "Epoch 159 Training Loss=0.987536, Validation Loss=1.027950\n",
      "Epoch 160 Training Loss=0.987290, Validation Loss=1.028177\n",
      "Epoch 161 Training Loss=0.987043, Validation Loss=1.028403\n",
      "Epoch 162 Training Loss=0.986797, Validation Loss=1.028627\n",
      "Epoch 163 Training Loss=0.986550, Validation Loss=1.028849\n",
      "Epoch 164 Training Loss=0.986304, Validation Loss=1.029070\n",
      "Epoch 165 Training Loss=0.986057, Validation Loss=1.029290\n",
      "Epoch 166 Training Loss=0.985811, Validation Loss=1.029508\n",
      "Epoch 167 Training Loss=0.985564, Validation Loss=1.029724\n",
      "Epoch 168 Training Loss=0.985317, Validation Loss=1.029940\n",
      "Epoch 169 Training Loss=0.985069, Validation Loss=1.030154\n",
      "Epoch 170 Training Loss=0.984822, Validation Loss=1.030366\n",
      "Epoch 171 Training Loss=0.984574, Validation Loss=1.030578\n",
      "Epoch 172 Training Loss=0.984326, Validation Loss=1.030787\n",
      "Epoch 173 Training Loss=0.984078, Validation Loss=1.030996\n",
      "Epoch 174 Training Loss=0.983829, Validation Loss=1.031204\n",
      "Epoch 175 Training Loss=0.983581, Validation Loss=1.031410\n",
      "Epoch 176 Training Loss=0.983331, Validation Loss=1.031614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177 Training Loss=0.983082, Validation Loss=1.031818\n",
      "Epoch 178 Training Loss=0.982832, Validation Loss=1.032020\n",
      "Epoch 179 Training Loss=0.982581, Validation Loss=1.032221\n",
      "Epoch 180 Training Loss=0.982331, Validation Loss=1.032421\n",
      "Epoch 181 Training Loss=0.982079, Validation Loss=1.032620\n",
      "Epoch 182 Training Loss=0.981828, Validation Loss=1.032817\n",
      "Epoch 183 Training Loss=0.981576, Validation Loss=1.033013\n",
      "Epoch 184 Training Loss=0.981323, Validation Loss=1.033208\n",
      "Epoch 185 Training Loss=0.981070, Validation Loss=1.033402\n",
      "Epoch 186 Training Loss=0.980816, Validation Loss=1.033594\n",
      "Epoch 187 Training Loss=0.980562, Validation Loss=1.033785\n",
      "Epoch 188 Training Loss=0.980308, Validation Loss=1.033975\n",
      "Epoch 189 Training Loss=0.980053, Validation Loss=1.034164\n",
      "Epoch 190 Training Loss=0.979797, Validation Loss=1.034351\n",
      "Epoch 191 Training Loss=0.979541, Validation Loss=1.034538\n",
      "Epoch 192 Training Loss=0.979285, Validation Loss=1.034723\n",
      "Epoch 193 Training Loss=0.979027, Validation Loss=1.034906\n",
      "Epoch 194 Training Loss=0.978770, Validation Loss=1.035089\n",
      "Epoch 195 Training Loss=0.978511, Validation Loss=1.035270\n",
      "Epoch 196 Training Loss=0.978253, Validation Loss=1.035450\n",
      "Epoch 197 Training Loss=0.977993, Validation Loss=1.035628\n",
      "Epoch 198 Training Loss=0.977733, Validation Loss=1.035806\n",
      "Epoch 199 Training Loss=0.977473, Validation Loss=1.035982\n",
      "Epoch 0 Training Loss=1.078079, Validation Loss=0.921531\n",
      "Epoch 1 Training Loss=1.058928, Validation Loss=0.936658\n",
      "Epoch 2 Training Loss=1.057131, Validation Loss=0.944843\n",
      "Epoch 3 Training Loss=1.056035, Validation Loss=0.949134\n",
      "Epoch 4 Training Loss=1.054907, Validation Loss=0.951733\n",
      "Epoch 5 Training Loss=1.053777, Validation Loss=0.953590\n",
      "Epoch 6 Training Loss=1.052679, Validation Loss=0.955094\n",
      "Epoch 7 Training Loss=1.051624, Validation Loss=0.956406\n",
      "Epoch 8 Training Loss=1.050610, Validation Loss=0.957599\n",
      "Epoch 9 Training Loss=1.049631, Validation Loss=0.958708\n",
      "Epoch 10 Training Loss=1.048683, Validation Loss=0.959755\n",
      "Epoch 11 Training Loss=1.047760, Validation Loss=0.960754\n",
      "Epoch 12 Training Loss=1.046859, Validation Loss=0.961717\n",
      "Epoch 13 Training Loss=1.045976, Validation Loss=0.962651\n",
      "Epoch 14 Training Loss=1.045108, Validation Loss=0.963566\n",
      "Epoch 15 Training Loss=1.044253, Validation Loss=0.964466\n",
      "Epoch 16 Training Loss=1.043410, Validation Loss=0.965359\n",
      "Epoch 17 Training Loss=1.042576, Validation Loss=0.966248\n",
      "Epoch 18 Training Loss=1.041751, Validation Loss=0.967138\n",
      "Epoch 19 Training Loss=1.040934, Validation Loss=0.968032\n",
      "Epoch 20 Training Loss=1.040123, Validation Loss=0.968933\n",
      "Epoch 21 Training Loss=1.039318, Validation Loss=0.969842\n",
      "Epoch 22 Training Loss=1.038518, Validation Loss=0.970763\n",
      "Epoch 23 Training Loss=1.037723, Validation Loss=0.971696\n",
      "Epoch 24 Training Loss=1.036933, Validation Loss=0.972642\n",
      "Epoch 25 Training Loss=1.036146, Validation Loss=0.973603\n",
      "Epoch 26 Training Loss=1.035363, Validation Loss=0.974578\n",
      "Epoch 27 Training Loss=1.034583, Validation Loss=0.975569\n",
      "Epoch 28 Training Loss=1.033807, Validation Loss=0.976575\n",
      "Epoch 29 Training Loss=1.033033, Validation Loss=0.977596\n",
      "Epoch 30 Training Loss=1.032262, Validation Loss=0.978632\n",
      "Epoch 31 Training Loss=1.031494, Validation Loss=0.979682\n",
      "Epoch 32 Training Loss=1.030728, Validation Loss=0.980747\n",
      "Epoch 33 Training Loss=1.029965, Validation Loss=0.981825\n",
      "Epoch 34 Training Loss=1.029204, Validation Loss=0.982916\n",
      "Epoch 35 Training Loss=1.028445, Validation Loss=0.984018\n",
      "Epoch 36 Training Loss=1.027688, Validation Loss=0.985132\n",
      "Epoch 37 Training Loss=1.026934, Validation Loss=0.986256\n",
      "Epoch 38 Training Loss=1.026181, Validation Loss=0.987389\n",
      "Epoch 39 Training Loss=1.025431, Validation Loss=0.988530\n",
      "Epoch 40 Training Loss=1.024682, Validation Loss=0.989679\n",
      "Epoch 41 Training Loss=1.023936, Validation Loss=0.990834\n",
      "Epoch 42 Training Loss=1.023191, Validation Loss=0.991994\n",
      "Epoch 43 Training Loss=1.022449, Validation Loss=0.993159\n",
      "Epoch 44 Training Loss=1.021708, Validation Loss=0.994327\n",
      "Epoch 45 Training Loss=1.020969, Validation Loss=0.995497\n",
      "Epoch 46 Training Loss=1.020232, Validation Loss=0.996669\n",
      "Epoch 47 Training Loss=1.019496, Validation Loss=0.997841\n",
      "Epoch 48 Training Loss=1.018761, Validation Loss=0.999012\n",
      "Epoch 49 Training Loss=1.018028, Validation Loss=1.000182\n",
      "Epoch 50 Training Loss=1.017297, Validation Loss=1.001350\n",
      "Epoch 51 Training Loss=1.016566, Validation Loss=1.002515\n",
      "Epoch 52 Training Loss=1.015837, Validation Loss=1.003677\n",
      "Epoch 53 Training Loss=1.015108, Validation Loss=1.004834\n",
      "Epoch 54 Training Loss=1.014380, Validation Loss=1.005986\n",
      "Epoch 55 Training Loss=1.013653, Validation Loss=1.007133\n",
      "Epoch 56 Training Loss=1.012926, Validation Loss=1.008273\n",
      "Epoch 57 Training Loss=1.012199, Validation Loss=1.009406\n",
      "Epoch 58 Training Loss=1.011472, Validation Loss=1.010533\n",
      "Epoch 59 Training Loss=1.010746, Validation Loss=1.011652\n",
      "Epoch 60 Training Loss=1.010019, Validation Loss=1.012763\n",
      "Epoch 61 Training Loss=1.009291, Validation Loss=1.013865\n",
      "Epoch 62 Training Loss=1.008563, Validation Loss=1.014959\n",
      "Epoch 63 Training Loss=1.007833, Validation Loss=1.016045\n",
      "Epoch 64 Training Loss=1.007103, Validation Loss=1.017121\n",
      "Epoch 65 Training Loss=1.006371, Validation Loss=1.018189\n",
      "Epoch 66 Training Loss=1.005638, Validation Loss=1.019247\n",
      "Epoch 67 Training Loss=1.004903, Validation Loss=1.020297\n",
      "Epoch 68 Training Loss=1.004167, Validation Loss=1.021337\n",
      "Epoch 69 Training Loss=1.003428, Validation Loss=1.022367\n",
      "Epoch 70 Training Loss=1.002687, Validation Loss=1.023389\n",
      "Epoch 71 Training Loss=1.001943, Validation Loss=1.024402\n",
      "Epoch 72 Training Loss=1.001198, Validation Loss=1.025406\n",
      "Epoch 73 Training Loss=1.000449, Validation Loss=1.026401\n",
      "Epoch 74 Training Loss=0.999698, Validation Loss=1.027388\n",
      "Epoch 75 Training Loss=0.998943, Validation Loss=1.028366\n",
      "Epoch 76 Training Loss=0.998186, Validation Loss=1.029337\n",
      "Epoch 77 Training Loss=0.997425, Validation Loss=1.030300\n",
      "Epoch 78 Training Loss=0.996661, Validation Loss=1.031255\n",
      "Epoch 79 Training Loss=0.995894, Validation Loss=1.032204\n",
      "Epoch 80 Training Loss=0.995123, Validation Loss=1.033146\n",
      "Epoch 81 Training Loss=0.994349, Validation Loss=1.034082\n",
      "Epoch 82 Training Loss=0.993571, Validation Loss=1.035012\n",
      "Epoch 83 Training Loss=0.992790, Validation Loss=1.035937\n",
      "Epoch 84 Training Loss=0.992005, Validation Loss=1.036858\n",
      "Epoch 85 Training Loss=0.991216, Validation Loss=1.037774\n",
      "Epoch 86 Training Loss=0.990424, Validation Loss=1.038687\n",
      "Epoch 87 Training Loss=0.989627, Validation Loss=1.039596\n",
      "Epoch 88 Training Loss=0.988828, Validation Loss=1.040503\n",
      "Epoch 89 Training Loss=0.988024, Validation Loss=1.041408\n",
      "Epoch 90 Training Loss=0.987216, Validation Loss=1.042311\n",
      "Epoch 91 Training Loss=0.986405, Validation Loss=1.043213\n",
      "Epoch 92 Training Loss=0.985590, Validation Loss=1.044116\n",
      "Epoch 93 Training Loss=0.984771, Validation Loss=1.045018\n",
      "Epoch 94 Training Loss=0.983948, Validation Loss=1.045921\n",
      "Epoch 95 Training Loss=0.983122, Validation Loss=1.046826\n",
      "Epoch 96 Training Loss=0.982292, Validation Loss=1.047732\n",
      "Epoch 97 Training Loss=0.981458, Validation Loss=1.048641\n",
      "Epoch 98 Training Loss=0.980620, Validation Loss=1.049553\n",
      "Epoch 99 Training Loss=0.979779, Validation Loss=1.050469\n",
      "Epoch 100 Training Loss=0.978934, Validation Loss=1.051388\n",
      "Epoch 101 Training Loss=0.978085, Validation Loss=1.052312\n",
      "Epoch 102 Training Loss=0.977233, Validation Loss=1.053240\n",
      "Epoch 103 Training Loss=0.976377, Validation Loss=1.054174\n",
      "Epoch 104 Training Loss=0.975517, Validation Loss=1.055113\n",
      "Epoch 105 Training Loss=0.974654, Validation Loss=1.056059\n",
      "Epoch 106 Training Loss=0.973788, Validation Loss=1.057011\n",
      "Epoch 107 Training Loss=0.972917, Validation Loss=1.057969\n",
      "Epoch 108 Training Loss=0.972044, Validation Loss=1.058934\n",
      "Epoch 109 Training Loss=0.971167, Validation Loss=1.059906\n",
      "Epoch 110 Training Loss=0.970286, Validation Loss=1.060886\n",
      "Epoch 111 Training Loss=0.969402, Validation Loss=1.061873\n",
      "Epoch 112 Training Loss=0.968515, Validation Loss=1.062868\n",
      "Epoch 113 Training Loss=0.967625, Validation Loss=1.063870\n",
      "Epoch 114 Training Loss=0.966732, Validation Loss=1.064880\n",
      "Epoch 115 Training Loss=0.965836, Validation Loss=1.065899\n",
      "Epoch 116 Training Loss=0.964937, Validation Loss=1.066924\n",
      "Epoch 117 Training Loss=0.964035, Validation Loss=1.067958\n",
      "Epoch 118 Training Loss=0.963130, Validation Loss=1.068999\n",
      "Epoch 119 Training Loss=0.962223, Validation Loss=1.070047\n",
      "Epoch 120 Training Loss=0.961314, Validation Loss=1.071103\n",
      "Epoch 121 Training Loss=0.960403, Validation Loss=1.072166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 Training Loss=0.959490, Validation Loss=1.073236\n",
      "Epoch 123 Training Loss=0.958575, Validation Loss=1.074312\n",
      "Epoch 124 Training Loss=0.957659, Validation Loss=1.075394\n",
      "Epoch 125 Training Loss=0.956741, Validation Loss=1.076483\n",
      "Epoch 126 Training Loss=0.955822, Validation Loss=1.077577\n",
      "Epoch 127 Training Loss=0.954903, Validation Loss=1.078676\n",
      "Epoch 128 Training Loss=0.953983, Validation Loss=1.079780\n",
      "Epoch 129 Training Loss=0.953062, Validation Loss=1.080889\n",
      "Epoch 130 Training Loss=0.952141, Validation Loss=1.082002\n",
      "Epoch 131 Training Loss=0.951221, Validation Loss=1.083118\n",
      "Epoch 132 Training Loss=0.950300, Validation Loss=1.084238\n",
      "Epoch 133 Training Loss=0.949380, Validation Loss=1.085361\n",
      "Epoch 134 Training Loss=0.948461, Validation Loss=1.086487\n",
      "Epoch 135 Training Loss=0.947542, Validation Loss=1.087615\n",
      "Epoch 136 Training Loss=0.946624, Validation Loss=1.088745\n",
      "Epoch 137 Training Loss=0.945707, Validation Loss=1.089877\n",
      "Epoch 138 Training Loss=0.944792, Validation Loss=1.091011\n",
      "Epoch 139 Training Loss=0.943878, Validation Loss=1.092146\n",
      "Epoch 140 Training Loss=0.942965, Validation Loss=1.093282\n",
      "Epoch 141 Training Loss=0.942054, Validation Loss=1.094419\n",
      "Epoch 142 Training Loss=0.941145, Validation Loss=1.095555\n",
      "Epoch 143 Training Loss=0.940238, Validation Loss=1.096693\n",
      "Epoch 144 Training Loss=0.939333, Validation Loss=1.097830\n",
      "Epoch 145 Training Loss=0.938429, Validation Loss=1.098967\n",
      "Epoch 146 Training Loss=0.937529, Validation Loss=1.100103\n",
      "Epoch 147 Training Loss=0.936630, Validation Loss=1.101238\n",
      "Epoch 148 Training Loss=0.935733, Validation Loss=1.102373\n",
      "Epoch 149 Training Loss=0.934840, Validation Loss=1.103505\n",
      "Epoch 150 Training Loss=0.933948, Validation Loss=1.104636\n",
      "Epoch 151 Training Loss=0.933060, Validation Loss=1.105765\n",
      "Epoch 152 Training Loss=0.932173, Validation Loss=1.106892\n",
      "Epoch 153 Training Loss=0.931290, Validation Loss=1.108016\n",
      "Epoch 154 Training Loss=0.930409, Validation Loss=1.109136\n",
      "Epoch 155 Training Loss=0.929531, Validation Loss=1.110254\n",
      "Epoch 156 Training Loss=0.928656, Validation Loss=1.111368\n",
      "Epoch 157 Training Loss=0.927784, Validation Loss=1.112478\n",
      "Epoch 158 Training Loss=0.926915, Validation Loss=1.113583\n",
      "Epoch 159 Training Loss=0.926049, Validation Loss=1.114684\n",
      "Epoch 160 Training Loss=0.925185, Validation Loss=1.115780\n",
      "Epoch 161 Training Loss=0.924325, Validation Loss=1.116870\n",
      "Epoch 162 Training Loss=0.923468, Validation Loss=1.117955\n",
      "Epoch 163 Training Loss=0.922613, Validation Loss=1.119034\n",
      "Epoch 164 Training Loss=0.921762, Validation Loss=1.120107\n",
      "Epoch 165 Training Loss=0.920913, Validation Loss=1.121173\n",
      "Epoch 166 Training Loss=0.920068, Validation Loss=1.122232\n",
      "Epoch 167 Training Loss=0.919226, Validation Loss=1.123284\n",
      "Epoch 168 Training Loss=0.918386, Validation Loss=1.124329\n",
      "Epoch 169 Training Loss=0.917550, Validation Loss=1.125366\n",
      "Epoch 170 Training Loss=0.916716, Validation Loss=1.126395\n",
      "Epoch 171 Training Loss=0.915885, Validation Loss=1.127416\n",
      "Epoch 172 Training Loss=0.915058, Validation Loss=1.128429\n",
      "Epoch 173 Training Loss=0.914233, Validation Loss=1.129433\n",
      "Epoch 174 Training Loss=0.913410, Validation Loss=1.130428\n",
      "Epoch 175 Training Loss=0.912591, Validation Loss=1.131414\n",
      "Epoch 176 Training Loss=0.911774, Validation Loss=1.132391\n",
      "Epoch 177 Training Loss=0.910960, Validation Loss=1.133358\n",
      "Epoch 178 Training Loss=0.910149, Validation Loss=1.134316\n",
      "Epoch 179 Training Loss=0.909340, Validation Loss=1.135265\n",
      "Epoch 180 Training Loss=0.908534, Validation Loss=1.136203\n",
      "Epoch 181 Training Loss=0.907730, Validation Loss=1.137131\n",
      "Epoch 182 Training Loss=0.906928, Validation Loss=1.138049\n",
      "Epoch 183 Training Loss=0.906129, Validation Loss=1.138958\n",
      "Epoch 184 Training Loss=0.905332, Validation Loss=1.139855\n",
      "Epoch 185 Training Loss=0.904537, Validation Loss=1.140742\n",
      "Epoch 186 Training Loss=0.903744, Validation Loss=1.141619\n",
      "Epoch 187 Training Loss=0.902953, Validation Loss=1.142485\n",
      "Epoch 188 Training Loss=0.902164, Validation Loss=1.143341\n",
      "Epoch 189 Training Loss=0.901377, Validation Loss=1.144185\n",
      "Epoch 190 Training Loss=0.900592, Validation Loss=1.145019\n",
      "Epoch 191 Training Loss=0.899809, Validation Loss=1.145842\n",
      "Epoch 192 Training Loss=0.899027, Validation Loss=1.146654\n",
      "Epoch 193 Training Loss=0.898247, Validation Loss=1.147456\n",
      "Epoch 194 Training Loss=0.897468, Validation Loss=1.148247\n",
      "Epoch 195 Training Loss=0.896691, Validation Loss=1.149026\n",
      "Epoch 196 Training Loss=0.895916, Validation Loss=1.149795\n",
      "Epoch 197 Training Loss=0.895142, Validation Loss=1.150553\n",
      "Epoch 198 Training Loss=0.894369, Validation Loss=1.151300\n",
      "Epoch 199 Training Loss=0.893597, Validation Loss=1.152037\n",
      "Epoch 0 Training Loss=1.072509, Validation Loss=0.938435\n",
      "Epoch 1 Training Loss=1.052370, Validation Loss=0.927848\n",
      "Epoch 2 Training Loss=1.051765, Validation Loss=0.935357\n",
      "Epoch 3 Training Loss=1.042725, Validation Loss=0.938732\n",
      "Epoch 4 Training Loss=1.039996, Validation Loss=0.939502\n",
      "Epoch 5 Training Loss=1.038538, Validation Loss=0.941829\n",
      "Epoch 6 Training Loss=1.036510, Validation Loss=0.943817\n",
      "Epoch 7 Training Loss=1.034914, Validation Loss=0.945438\n",
      "Epoch 8 Training Loss=1.033496, Validation Loss=0.947053\n",
      "Epoch 9 Training Loss=1.032189, Validation Loss=0.948573\n",
      "Epoch 10 Training Loss=1.030980, Validation Loss=0.950035\n",
      "Epoch 11 Training Loss=1.029846, Validation Loss=0.951454\n",
      "Epoch 12 Training Loss=1.028773, Validation Loss=0.952842\n",
      "Epoch 13 Training Loss=1.027746, Validation Loss=0.954210\n",
      "Epoch 14 Training Loss=1.026758, Validation Loss=0.955564\n",
      "Epoch 15 Training Loss=1.025802, Validation Loss=0.956910\n",
      "Epoch 16 Training Loss=1.024871, Validation Loss=0.958252\n",
      "Epoch 17 Training Loss=1.023960, Validation Loss=0.959593\n",
      "Epoch 18 Training Loss=1.023067, Validation Loss=0.960936\n",
      "Epoch 19 Training Loss=1.022188, Validation Loss=0.962280\n",
      "Epoch 20 Training Loss=1.021321, Validation Loss=0.963626\n",
      "Epoch 21 Training Loss=1.020463, Validation Loss=0.964973\n",
      "Epoch 22 Training Loss=1.019613, Validation Loss=0.966321\n",
      "Epoch 23 Training Loss=1.018769, Validation Loss=0.967668\n",
      "Epoch 24 Training Loss=1.017930, Validation Loss=0.969013\n",
      "Epoch 25 Training Loss=1.017096, Validation Loss=0.970357\n",
      "Epoch 26 Training Loss=1.016266, Validation Loss=0.971698\n",
      "Epoch 27 Training Loss=1.015441, Validation Loss=0.973036\n",
      "Epoch 28 Training Loss=1.014620, Validation Loss=0.974371\n",
      "Epoch 29 Training Loss=1.013806, Validation Loss=0.975703\n",
      "Epoch 30 Training Loss=1.012999, Validation Loss=0.977031\n",
      "Epoch 31 Training Loss=1.012203, Validation Loss=0.978356\n",
      "Epoch 32 Training Loss=1.011417, Validation Loss=0.979677\n",
      "Epoch 33 Training Loss=1.010645, Validation Loss=0.980994\n",
      "Epoch 34 Training Loss=1.009889, Validation Loss=0.982304\n",
      "Epoch 35 Training Loss=1.009150, Validation Loss=0.983607\n",
      "Epoch 36 Training Loss=1.008429, Validation Loss=0.984900\n",
      "Epoch 37 Training Loss=1.007728, Validation Loss=0.986181\n",
      "Epoch 38 Training Loss=1.007047, Validation Loss=0.987448\n",
      "Epoch 39 Training Loss=1.006387, Validation Loss=0.988698\n",
      "Epoch 40 Training Loss=1.005747, Validation Loss=0.989927\n",
      "Epoch 41 Training Loss=1.005127, Validation Loss=0.991134\n",
      "Epoch 42 Training Loss=1.004526, Validation Loss=0.992315\n",
      "Epoch 43 Training Loss=1.003943, Validation Loss=0.993467\n",
      "Epoch 44 Training Loss=1.003377, Validation Loss=0.994589\n",
      "Epoch 45 Training Loss=1.002827, Validation Loss=0.995679\n",
      "Epoch 46 Training Loss=1.002293, Validation Loss=0.996735\n",
      "Epoch 47 Training Loss=1.001772, Validation Loss=0.997756\n",
      "Epoch 48 Training Loss=1.001263, Validation Loss=0.998741\n",
      "Epoch 49 Training Loss=1.000767, Validation Loss=0.999689\n",
      "Epoch 50 Training Loss=1.000281, Validation Loss=1.000601\n",
      "Epoch 51 Training Loss=0.999805, Validation Loss=1.001475\n",
      "Epoch 52 Training Loss=0.999339, Validation Loss=1.002312\n",
      "Epoch 53 Training Loss=0.998881, Validation Loss=1.003112\n",
      "Epoch 54 Training Loss=0.998432, Validation Loss=1.003875\n",
      "Epoch 55 Training Loss=0.997990, Validation Loss=1.004601\n",
      "Epoch 56 Training Loss=0.997556, Validation Loss=1.005291\n",
      "Epoch 57 Training Loss=0.997129, Validation Loss=1.005944\n",
      "Epoch 58 Training Loss=0.996709, Validation Loss=1.006562\n",
      "Epoch 59 Training Loss=0.996295, Validation Loss=1.007145\n",
      "Epoch 60 Training Loss=0.995888, Validation Loss=1.007693\n",
      "Epoch 61 Training Loss=0.995487, Validation Loss=1.008207\n",
      "Epoch 62 Training Loss=0.995091, Validation Loss=1.008687\n",
      "Epoch 63 Training Loss=0.994701, Validation Loss=1.009136\n",
      "Epoch 64 Training Loss=0.994316, Validation Loss=1.009553\n",
      "Epoch 65 Training Loss=0.993935, Validation Loss=1.009939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Training Loss=0.993560, Validation Loss=1.010297\n",
      "Epoch 67 Training Loss=0.993188, Validation Loss=1.010626\n",
      "Epoch 68 Training Loss=0.992820, Validation Loss=1.010928\n",
      "Epoch 69 Training Loss=0.992456, Validation Loss=1.011205\n",
      "Epoch 70 Training Loss=0.992095, Validation Loss=1.011458\n",
      "Epoch 71 Training Loss=0.991737, Validation Loss=1.011688\n",
      "Epoch 72 Training Loss=0.991380, Validation Loss=1.011896\n",
      "Epoch 73 Training Loss=0.991026, Validation Loss=1.012083\n",
      "Epoch 74 Training Loss=0.990674, Validation Loss=1.012252\n",
      "Epoch 75 Training Loss=0.990322, Validation Loss=1.012403\n",
      "Epoch 76 Training Loss=0.989971, Validation Loss=1.012539\n",
      "Epoch 77 Training Loss=0.989620, Validation Loss=1.012659\n",
      "Epoch 78 Training Loss=0.989269, Validation Loss=1.012765\n",
      "Epoch 79 Training Loss=0.988917, Validation Loss=1.012859\n",
      "Epoch 80 Training Loss=0.988564, Validation Loss=1.012943\n",
      "Epoch 81 Training Loss=0.988209, Validation Loss=1.013016\n",
      "Epoch 82 Training Loss=0.987853, Validation Loss=1.013081\n",
      "Epoch 83 Training Loss=0.987494, Validation Loss=1.013139\n",
      "Epoch 84 Training Loss=0.987133, Validation Loss=1.013192\n",
      "Epoch 85 Training Loss=0.986768, Validation Loss=1.013240\n",
      "Epoch 86 Training Loss=0.986401, Validation Loss=1.013285\n",
      "Epoch 87 Training Loss=0.986030, Validation Loss=1.013328\n",
      "Epoch 88 Training Loss=0.985655, Validation Loss=1.013370\n",
      "Epoch 89 Training Loss=0.985277, Validation Loss=1.013414\n",
      "Epoch 90 Training Loss=0.984895, Validation Loss=1.013459\n",
      "Epoch 91 Training Loss=0.984509, Validation Loss=1.013508\n",
      "Epoch 92 Training Loss=0.984120, Validation Loss=1.013561\n",
      "Epoch 93 Training Loss=0.983727, Validation Loss=1.013621\n",
      "Epoch 94 Training Loss=0.983331, Validation Loss=1.013686\n",
      "Epoch 95 Training Loss=0.982931, Validation Loss=1.013760\n",
      "Epoch 96 Training Loss=0.982529, Validation Loss=1.013842\n",
      "Epoch 97 Training Loss=0.982124, Validation Loss=1.013934\n",
      "Epoch 98 Training Loss=0.981716, Validation Loss=1.014036\n",
      "Epoch 99 Training Loss=0.981307, Validation Loss=1.014149\n",
      "Epoch 100 Training Loss=0.980895, Validation Loss=1.014272\n",
      "Epoch 101 Training Loss=0.980482, Validation Loss=1.014407\n",
      "Epoch 102 Training Loss=0.980068, Validation Loss=1.014552\n",
      "Epoch 103 Training Loss=0.979653, Validation Loss=1.014710\n",
      "Epoch 104 Training Loss=0.979237, Validation Loss=1.014877\n",
      "Epoch 105 Training Loss=0.978820, Validation Loss=1.015056\n",
      "Epoch 106 Training Loss=0.978402, Validation Loss=1.015244\n",
      "Epoch 107 Training Loss=0.977984, Validation Loss=1.015441\n",
      "Epoch 108 Training Loss=0.977565, Validation Loss=1.015646\n",
      "Epoch 109 Training Loss=0.977146, Validation Loss=1.015859\n",
      "Epoch 110 Training Loss=0.976725, Validation Loss=1.016079\n",
      "Epoch 111 Training Loss=0.976304, Validation Loss=1.016304\n",
      "Epoch 112 Training Loss=0.975882, Validation Loss=1.016534\n",
      "Epoch 113 Training Loss=0.975459, Validation Loss=1.016767\n",
      "Epoch 114 Training Loss=0.975034, Validation Loss=1.017004\n",
      "Epoch 115 Training Loss=0.974608, Validation Loss=1.017243\n",
      "Epoch 116 Training Loss=0.974180, Validation Loss=1.017483\n",
      "Epoch 117 Training Loss=0.973750, Validation Loss=1.017725\n",
      "Epoch 118 Training Loss=0.973318, Validation Loss=1.017967\n",
      "Epoch 119 Training Loss=0.972884, Validation Loss=1.018211\n",
      "Epoch 120 Training Loss=0.972448, Validation Loss=1.018455\n",
      "Epoch 121 Training Loss=0.972010, Validation Loss=1.018701\n",
      "Epoch 122 Training Loss=0.971570, Validation Loss=1.018950\n",
      "Epoch 123 Training Loss=0.971129, Validation Loss=1.019201\n",
      "Epoch 124 Training Loss=0.970687, Validation Loss=1.019458\n",
      "Epoch 125 Training Loss=0.970246, Validation Loss=1.019721\n",
      "Epoch 126 Training Loss=0.969807, Validation Loss=1.019991\n",
      "Epoch 127 Training Loss=0.969369, Validation Loss=1.020270\n",
      "Epoch 128 Training Loss=0.968936, Validation Loss=1.020560\n",
      "Epoch 129 Training Loss=0.968507, Validation Loss=1.020862\n",
      "Epoch 130 Training Loss=0.968083, Validation Loss=1.021177\n",
      "Epoch 131 Training Loss=0.967666, Validation Loss=1.021505\n",
      "Epoch 132 Training Loss=0.967256, Validation Loss=1.021849\n",
      "Epoch 133 Training Loss=0.966854, Validation Loss=1.022208\n",
      "Epoch 134 Training Loss=0.966459, Validation Loss=1.022581\n",
      "Epoch 135 Training Loss=0.966072, Validation Loss=1.022970\n",
      "Epoch 136 Training Loss=0.965694, Validation Loss=1.023374\n",
      "Epoch 137 Training Loss=0.965324, Validation Loss=1.023792\n",
      "Epoch 138 Training Loss=0.964962, Validation Loss=1.024223\n",
      "Epoch 139 Training Loss=0.964608, Validation Loss=1.024667\n",
      "Epoch 140 Training Loss=0.964261, Validation Loss=1.025124\n",
      "Epoch 141 Training Loss=0.963921, Validation Loss=1.025591\n",
      "Epoch 142 Training Loss=0.963589, Validation Loss=1.026069\n",
      "Epoch 143 Training Loss=0.963263, Validation Loss=1.026556\n",
      "Epoch 144 Training Loss=0.962943, Validation Loss=1.027051\n",
      "Epoch 145 Training Loss=0.962628, Validation Loss=1.027555\n",
      "Epoch 146 Training Loss=0.962320, Validation Loss=1.028065\n",
      "Epoch 147 Training Loss=0.962016, Validation Loss=1.028582\n",
      "Epoch 148 Training Loss=0.961717, Validation Loss=1.029103\n",
      "Epoch 149 Training Loss=0.961423, Validation Loss=1.029630\n",
      "Epoch 150 Training Loss=0.961133, Validation Loss=1.030161\n",
      "Epoch 151 Training Loss=0.960847, Validation Loss=1.030696\n",
      "Epoch 152 Training Loss=0.960565, Validation Loss=1.031234\n",
      "Epoch 153 Training Loss=0.960287, Validation Loss=1.031774\n",
      "Epoch 154 Training Loss=0.960012, Validation Loss=1.032317\n",
      "Epoch 155 Training Loss=0.959740, Validation Loss=1.032861\n",
      "Epoch 156 Training Loss=0.959472, Validation Loss=1.033405\n",
      "Epoch 157 Training Loss=0.959208, Validation Loss=1.033950\n",
      "Epoch 158 Training Loss=0.958946, Validation Loss=1.034495\n",
      "Epoch 159 Training Loss=0.958688, Validation Loss=1.035039\n",
      "Epoch 160 Training Loss=0.958432, Validation Loss=1.035581\n",
      "Epoch 161 Training Loss=0.958180, Validation Loss=1.036122\n",
      "Epoch 162 Training Loss=0.957931, Validation Loss=1.036660\n",
      "Epoch 163 Training Loss=0.957685, Validation Loss=1.037194\n",
      "Epoch 164 Training Loss=0.957442, Validation Loss=1.037725\n",
      "Epoch 165 Training Loss=0.957203, Validation Loss=1.038252\n",
      "Epoch 166 Training Loss=0.956966, Validation Loss=1.038773\n",
      "Epoch 167 Training Loss=0.956733, Validation Loss=1.039289\n",
      "Epoch 168 Training Loss=0.956503, Validation Loss=1.039800\n",
      "Epoch 169 Training Loss=0.956276, Validation Loss=1.040304\n",
      "Epoch 170 Training Loss=0.956052, Validation Loss=1.040801\n",
      "Epoch 171 Training Loss=0.955831, Validation Loss=1.041292\n",
      "Epoch 172 Training Loss=0.955613, Validation Loss=1.041775\n",
      "Epoch 173 Training Loss=0.955399, Validation Loss=1.042251\n",
      "Epoch 174 Training Loss=0.955187, Validation Loss=1.042720\n",
      "Epoch 175 Training Loss=0.954979, Validation Loss=1.043182\n",
      "Epoch 176 Training Loss=0.954773, Validation Loss=1.043636\n",
      "Epoch 177 Training Loss=0.954570, Validation Loss=1.044082\n",
      "Epoch 178 Training Loss=0.954371, Validation Loss=1.044521\n",
      "Epoch 179 Training Loss=0.954173, Validation Loss=1.044953\n",
      "Epoch 180 Training Loss=0.953979, Validation Loss=1.045378\n",
      "Epoch 181 Training Loss=0.953787, Validation Loss=1.045797\n",
      "Epoch 182 Training Loss=0.953597, Validation Loss=1.046208\n",
      "Epoch 183 Training Loss=0.953410, Validation Loss=1.046614\n",
      "Epoch 184 Training Loss=0.953225, Validation Loss=1.047014\n",
      "Epoch 185 Training Loss=0.953042, Validation Loss=1.047408\n",
      "Epoch 186 Training Loss=0.952862, Validation Loss=1.047796\n",
      "Epoch 187 Training Loss=0.952682, Validation Loss=1.048181\n",
      "Epoch 188 Training Loss=0.952505, Validation Loss=1.048560\n",
      "Epoch 189 Training Loss=0.952329, Validation Loss=1.048936\n",
      "Epoch 190 Training Loss=0.952154, Validation Loss=1.049308\n",
      "Epoch 191 Training Loss=0.951981, Validation Loss=1.049677\n",
      "Epoch 192 Training Loss=0.951808, Validation Loss=1.050044\n",
      "Epoch 193 Training Loss=0.951637, Validation Loss=1.050409\n",
      "Epoch 194 Training Loss=0.951466, Validation Loss=1.050772\n",
      "Epoch 195 Training Loss=0.951295, Validation Loss=1.051134\n",
      "Epoch 196 Training Loss=0.951125, Validation Loss=1.051497\n",
      "Epoch 197 Training Loss=0.950954, Validation Loss=1.051859\n",
      "Epoch 198 Training Loss=0.950784, Validation Loss=1.052222\n",
      "Epoch 199 Training Loss=0.950613, Validation Loss=1.052587\n",
      "Epoch 0 Training Loss=1.074288, Validation Loss=0.970300\n",
      "Epoch 1 Training Loss=1.038612, Validation Loss=0.941474\n",
      "Epoch 2 Training Loss=1.037019, Validation Loss=0.956127\n",
      "Epoch 3 Training Loss=1.033062, Validation Loss=0.956203\n",
      "Epoch 4 Training Loss=1.030907, Validation Loss=0.958987\n",
      "Epoch 5 Training Loss=1.029755, Validation Loss=0.961024\n",
      "Epoch 6 Training Loss=1.027994, Validation Loss=0.962958\n",
      "Epoch 7 Training Loss=1.026573, Validation Loss=0.964716\n",
      "Epoch 8 Training Loss=1.025111, Validation Loss=0.966432\n",
      "Epoch 9 Training Loss=1.023682, Validation Loss=0.968117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Loss=1.022259, Validation Loss=0.969818\n",
      "Epoch 11 Training Loss=1.020845, Validation Loss=0.971539\n",
      "Epoch 12 Training Loss=1.019437, Validation Loss=0.973307\n",
      "Epoch 13 Training Loss=1.018034, Validation Loss=0.975136\n",
      "Epoch 14 Training Loss=1.016637, Validation Loss=0.977035\n",
      "Epoch 15 Training Loss=1.015243, Validation Loss=0.979013\n",
      "Epoch 16 Training Loss=1.013850, Validation Loss=0.981073\n",
      "Epoch 17 Training Loss=1.012456, Validation Loss=0.983215\n",
      "Epoch 18 Training Loss=1.011058, Validation Loss=0.985435\n",
      "Epoch 19 Training Loss=1.009653, Validation Loss=0.987727\n",
      "Epoch 20 Training Loss=1.008239, Validation Loss=0.990080\n",
      "Epoch 21 Training Loss=1.006815, Validation Loss=0.992483\n",
      "Epoch 22 Training Loss=1.005383, Validation Loss=0.994922\n",
      "Epoch 23 Training Loss=1.003942, Validation Loss=0.997381\n",
      "Epoch 24 Training Loss=1.002497, Validation Loss=0.999844\n",
      "Epoch 25 Training Loss=1.001050, Validation Loss=1.002295\n",
      "Epoch 26 Training Loss=0.999606, Validation Loss=1.004717\n",
      "Epoch 27 Training Loss=0.998168, Validation Loss=1.007094\n",
      "Epoch 28 Training Loss=0.996742, Validation Loss=1.009413\n",
      "Epoch 29 Training Loss=0.995332, Validation Loss=1.011662\n",
      "Epoch 30 Training Loss=0.993941, Validation Loss=1.013828\n",
      "Epoch 31 Training Loss=0.992573, Validation Loss=1.015903\n",
      "Epoch 32 Training Loss=0.991230, Validation Loss=1.017878\n",
      "Epoch 33 Training Loss=0.989913, Validation Loss=1.019745\n",
      "Epoch 34 Training Loss=0.988621, Validation Loss=1.021497\n",
      "Epoch 35 Training Loss=0.987354, Validation Loss=1.023129\n",
      "Epoch 36 Training Loss=0.986110, Validation Loss=1.024636\n",
      "Epoch 37 Training Loss=0.984888, Validation Loss=1.026015\n",
      "Epoch 38 Training Loss=0.983684, Validation Loss=1.027264\n",
      "Epoch 39 Training Loss=0.982497, Validation Loss=1.028384\n",
      "Epoch 40 Training Loss=0.981324, Validation Loss=1.029377\n",
      "Epoch 41 Training Loss=0.980161, Validation Loss=1.030249\n",
      "Epoch 42 Training Loss=0.979008, Validation Loss=1.031007\n",
      "Epoch 43 Training Loss=0.977862, Validation Loss=1.031661\n",
      "Epoch 44 Training Loss=0.976720, Validation Loss=1.032224\n",
      "Epoch 45 Training Loss=0.975582, Validation Loss=1.032709\n",
      "Epoch 46 Training Loss=0.974445, Validation Loss=1.033130\n",
      "Epoch 47 Training Loss=0.973308, Validation Loss=1.033502\n",
      "Epoch 48 Training Loss=0.972170, Validation Loss=1.033837\n",
      "Epoch 49 Training Loss=0.971029, Validation Loss=1.034150\n",
      "Epoch 50 Training Loss=0.969883, Validation Loss=1.034453\n",
      "Epoch 51 Training Loss=0.968731, Validation Loss=1.034754\n",
      "Epoch 52 Training Loss=0.967570, Validation Loss=1.035065\n",
      "Epoch 53 Training Loss=0.966399, Validation Loss=1.035392\n",
      "Epoch 54 Training Loss=0.965215, Validation Loss=1.035744\n",
      "Epoch 55 Training Loss=0.964016, Validation Loss=1.036124\n",
      "Epoch 56 Training Loss=0.962801, Validation Loss=1.036538\n",
      "Epoch 57 Training Loss=0.961569, Validation Loss=1.036989\n",
      "Epoch 58 Training Loss=0.960318, Validation Loss=1.037476\n",
      "Epoch 59 Training Loss=0.959049, Validation Loss=1.037998\n",
      "Epoch 60 Training Loss=0.957761, Validation Loss=1.038551\n",
      "Epoch 61 Training Loss=0.956458, Validation Loss=1.039131\n",
      "Epoch 62 Training Loss=0.955142, Validation Loss=1.039730\n",
      "Epoch 63 Training Loss=0.953816, Validation Loss=1.040346\n",
      "Epoch 64 Training Loss=0.952485, Validation Loss=1.040972\n",
      "Epoch 65 Training Loss=0.951154, Validation Loss=1.041609\n",
      "Epoch 66 Training Loss=0.949825, Validation Loss=1.042253\n",
      "Epoch 67 Training Loss=0.948501, Validation Loss=1.042904\n",
      "Epoch 68 Training Loss=0.947186, Validation Loss=1.043559\n",
      "Epoch 69 Training Loss=0.945879, Validation Loss=1.044217\n",
      "Epoch 70 Training Loss=0.944584, Validation Loss=1.044875\n",
      "Epoch 71 Training Loss=0.943301, Validation Loss=1.045532\n",
      "Epoch 72 Training Loss=0.942030, Validation Loss=1.046187\n",
      "Epoch 73 Training Loss=0.940774, Validation Loss=1.046837\n",
      "Epoch 74 Training Loss=0.939531, Validation Loss=1.047484\n",
      "Epoch 75 Training Loss=0.938305, Validation Loss=1.048127\n",
      "Epoch 76 Training Loss=0.937094, Validation Loss=1.048765\n",
      "Epoch 77 Training Loss=0.935899, Validation Loss=1.049399\n",
      "Epoch 78 Training Loss=0.934722, Validation Loss=1.050027\n",
      "Epoch 79 Training Loss=0.933561, Validation Loss=1.050650\n",
      "Epoch 80 Training Loss=0.932419, Validation Loss=1.051266\n",
      "Epoch 81 Training Loss=0.931294, Validation Loss=1.051873\n",
      "Epoch 82 Training Loss=0.930186, Validation Loss=1.052471\n",
      "Epoch 83 Training Loss=0.929097, Validation Loss=1.053055\n",
      "Epoch 84 Training Loss=0.928025, Validation Loss=1.053625\n",
      "Epoch 85 Training Loss=0.926970, Validation Loss=1.054178\n",
      "Epoch 86 Training Loss=0.925932, Validation Loss=1.054711\n",
      "Epoch 87 Training Loss=0.924910, Validation Loss=1.055222\n",
      "Epoch 88 Training Loss=0.923904, Validation Loss=1.055710\n",
      "Epoch 89 Training Loss=0.922913, Validation Loss=1.056172\n",
      "Epoch 90 Training Loss=0.921937, Validation Loss=1.056607\n",
      "Epoch 91 Training Loss=0.920974, Validation Loss=1.057012\n",
      "Epoch 92 Training Loss=0.920024, Validation Loss=1.057389\n",
      "Epoch 93 Training Loss=0.919086, Validation Loss=1.057735\n",
      "Epoch 94 Training Loss=0.918159, Validation Loss=1.058051\n",
      "Epoch 95 Training Loss=0.917242, Validation Loss=1.058337\n",
      "Epoch 96 Training Loss=0.916334, Validation Loss=1.058592\n",
      "Epoch 97 Training Loss=0.915434, Validation Loss=1.058818\n",
      "Epoch 98 Training Loss=0.914542, Validation Loss=1.059014\n",
      "Epoch 99 Training Loss=0.913656, Validation Loss=1.059183\n",
      "Epoch 100 Training Loss=0.912776, Validation Loss=1.059325\n",
      "Epoch 101 Training Loss=0.911901, Validation Loss=1.059442\n",
      "Epoch 102 Training Loss=0.911030, Validation Loss=1.059536\n",
      "Epoch 103 Training Loss=0.910163, Validation Loss=1.059607\n",
      "Epoch 104 Training Loss=0.909300, Validation Loss=1.059659\n",
      "Epoch 105 Training Loss=0.908439, Validation Loss=1.059693\n",
      "Epoch 106 Training Loss=0.907581, Validation Loss=1.059710\n",
      "Epoch 107 Training Loss=0.906725, Validation Loss=1.059714\n",
      "Epoch 108 Training Loss=0.905870, Validation Loss=1.059706\n",
      "Epoch 109 Training Loss=0.905017, Validation Loss=1.059688\n",
      "Epoch 110 Training Loss=0.904166, Validation Loss=1.059662\n",
      "Epoch 111 Training Loss=0.903316, Validation Loss=1.059631\n",
      "Epoch 112 Training Loss=0.902466, Validation Loss=1.059597\n",
      "Epoch 113 Training Loss=0.901618, Validation Loss=1.059561\n",
      "Epoch 114 Training Loss=0.900770, Validation Loss=1.059527\n",
      "Epoch 115 Training Loss=0.899923, Validation Loss=1.059495\n",
      "Epoch 116 Training Loss=0.899077, Validation Loss=1.059468\n",
      "Epoch 117 Training Loss=0.898231, Validation Loss=1.059448\n",
      "Epoch 118 Training Loss=0.897385, Validation Loss=1.059437\n",
      "Epoch 119 Training Loss=0.896540, Validation Loss=1.059437\n",
      "Epoch 120 Training Loss=0.895695, Validation Loss=1.059450\n",
      "Epoch 121 Training Loss=0.894850, Validation Loss=1.059478\n",
      "Epoch 122 Training Loss=0.894005, Validation Loss=1.059523\n",
      "Epoch 123 Training Loss=0.893161, Validation Loss=1.059587\n",
      "Epoch 124 Training Loss=0.892317, Validation Loss=1.059672\n",
      "Epoch 125 Training Loss=0.891473, Validation Loss=1.059778\n",
      "Epoch 126 Training Loss=0.890629, Validation Loss=1.059909\n",
      "Epoch 127 Training Loss=0.889785, Validation Loss=1.060065\n",
      "Epoch 128 Training Loss=0.888941, Validation Loss=1.060247\n",
      "Epoch 129 Training Loss=0.888098, Validation Loss=1.060456\n",
      "Epoch 130 Training Loss=0.887254, Validation Loss=1.060693\n",
      "Epoch 131 Training Loss=0.886411, Validation Loss=1.060958\n",
      "Epoch 132 Training Loss=0.885568, Validation Loss=1.061252\n",
      "Epoch 133 Training Loss=0.884724, Validation Loss=1.061574\n",
      "Epoch 134 Training Loss=0.883881, Validation Loss=1.061923\n",
      "Epoch 135 Training Loss=0.883037, Validation Loss=1.062300\n",
      "Epoch 136 Training Loss=0.882194, Validation Loss=1.062702\n",
      "Epoch 137 Training Loss=0.881350, Validation Loss=1.063130\n",
      "Epoch 138 Training Loss=0.880506, Validation Loss=1.063581\n",
      "Epoch 139 Training Loss=0.879662, Validation Loss=1.064055\n",
      "Epoch 140 Training Loss=0.878817, Validation Loss=1.064550\n",
      "Epoch 141 Training Loss=0.877972, Validation Loss=1.065064\n",
      "Epoch 142 Training Loss=0.877126, Validation Loss=1.065596\n",
      "Epoch 143 Training Loss=0.876279, Validation Loss=1.066145\n",
      "Epoch 144 Training Loss=0.875431, Validation Loss=1.066708\n",
      "Epoch 145 Training Loss=0.874583, Validation Loss=1.067284\n",
      "Epoch 146 Training Loss=0.873733, Validation Loss=1.067873\n",
      "Epoch 147 Training Loss=0.872882, Validation Loss=1.068472\n",
      "Epoch 148 Training Loss=0.872029, Validation Loss=1.069080\n",
      "Epoch 149 Training Loss=0.871175, Validation Loss=1.069697\n",
      "Epoch 150 Training Loss=0.870319, Validation Loss=1.070322\n",
      "Epoch 151 Training Loss=0.869461, Validation Loss=1.070954\n",
      "Epoch 152 Training Loss=0.868602, Validation Loss=1.071592\n",
      "Epoch 153 Training Loss=0.867742, Validation Loss=1.072236\n",
      "Epoch 154 Training Loss=0.866879, Validation Loss=1.072886\n",
      "Epoch 155 Training Loss=0.866016, Validation Loss=1.073541\n",
      "Epoch 156 Training Loss=0.865151, Validation Loss=1.074201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157 Training Loss=0.864285, Validation Loss=1.074865\n",
      "Epoch 158 Training Loss=0.863418, Validation Loss=1.075535\n",
      "Epoch 159 Training Loss=0.862550, Validation Loss=1.076209\n",
      "Epoch 160 Training Loss=0.861681, Validation Loss=1.076888\n",
      "Epoch 161 Training Loss=0.860812, Validation Loss=1.077571\n",
      "Epoch 162 Training Loss=0.859944, Validation Loss=1.078259\n",
      "Epoch 163 Training Loss=0.859076, Validation Loss=1.078950\n",
      "Epoch 164 Training Loss=0.858208, Validation Loss=1.079645\n",
      "Epoch 165 Training Loss=0.857342, Validation Loss=1.080343\n",
      "Epoch 166 Training Loss=0.856477, Validation Loss=1.081044\n",
      "Epoch 167 Training Loss=0.855614, Validation Loss=1.081747\n",
      "Epoch 168 Training Loss=0.854754, Validation Loss=1.082452\n",
      "Epoch 169 Training Loss=0.853896, Validation Loss=1.083158\n",
      "Epoch 170 Training Loss=0.853041, Validation Loss=1.083863\n",
      "Epoch 171 Training Loss=0.852191, Validation Loss=1.084569\n",
      "Epoch 172 Training Loss=0.851344, Validation Loss=1.085272\n",
      "Epoch 173 Training Loss=0.850502, Validation Loss=1.085973\n",
      "Epoch 174 Training Loss=0.849664, Validation Loss=1.086670\n",
      "Epoch 175 Training Loss=0.848832, Validation Loss=1.087363\n",
      "Epoch 176 Training Loss=0.848005, Validation Loss=1.088050\n",
      "Epoch 177 Training Loss=0.847184, Validation Loss=1.088730\n",
      "Epoch 178 Training Loss=0.846369, Validation Loss=1.089402\n",
      "Epoch 179 Training Loss=0.845560, Validation Loss=1.090065\n",
      "Epoch 180 Training Loss=0.844757, Validation Loss=1.090718\n",
      "Epoch 181 Training Loss=0.843961, Validation Loss=1.091361\n",
      "Epoch 182 Training Loss=0.843171, Validation Loss=1.091992\n",
      "Epoch 183 Training Loss=0.842388, Validation Loss=1.092611\n",
      "Epoch 184 Training Loss=0.841611, Validation Loss=1.093217\n",
      "Epoch 185 Training Loss=0.840841, Validation Loss=1.093810\n",
      "Epoch 186 Training Loss=0.840077, Validation Loss=1.094388\n",
      "Epoch 187 Training Loss=0.839319, Validation Loss=1.094951\n",
      "Epoch 188 Training Loss=0.838567, Validation Loss=1.095500\n",
      "Epoch 189 Training Loss=0.837821, Validation Loss=1.096033\n",
      "Epoch 190 Training Loss=0.837081, Validation Loss=1.096550\n",
      "Epoch 191 Training Loss=0.836346, Validation Loss=1.097051\n",
      "Epoch 192 Training Loss=0.835617, Validation Loss=1.097535\n",
      "Epoch 193 Training Loss=0.834893, Validation Loss=1.098003\n",
      "Epoch 194 Training Loss=0.834174, Validation Loss=1.098454\n",
      "Epoch 195 Training Loss=0.833460, Validation Loss=1.098889\n",
      "Epoch 196 Training Loss=0.832750, Validation Loss=1.099306\n",
      "Epoch 197 Training Loss=0.832046, Validation Loss=1.099706\n",
      "Epoch 198 Training Loss=0.831345, Validation Loss=1.100089\n",
      "Epoch 199 Training Loss=0.830649, Validation Loss=1.100455\n",
      "Epoch 0 Training Loss=1.057368, Validation Loss=0.918646\n",
      "Epoch 1 Training Loss=1.095707, Validation Loss=0.953047\n",
      "Epoch 2 Training Loss=1.090797, Validation Loss=0.963877\n",
      "Epoch 3 Training Loss=1.074251, Validation Loss=0.960949\n",
      "Epoch 4 Training Loss=1.064944, Validation Loss=0.962409\n",
      "Epoch 5 Training Loss=1.060130, Validation Loss=0.965087\n",
      "Epoch 6 Training Loss=1.055872, Validation Loss=0.966602\n",
      "Epoch 7 Training Loss=1.052138, Validation Loss=0.967738\n",
      "Epoch 8 Training Loss=1.049089, Validation Loss=0.968988\n",
      "Epoch 9 Training Loss=1.046420, Validation Loss=0.970142\n",
      "Epoch 10 Training Loss=1.044031, Validation Loss=0.971231\n",
      "Epoch 11 Training Loss=1.041885, Validation Loss=0.972306\n",
      "Epoch 12 Training Loss=1.039933, Validation Loss=0.973373\n",
      "Epoch 13 Training Loss=1.038139, Validation Loss=0.974438\n",
      "Epoch 14 Training Loss=1.036475, Validation Loss=0.975508\n",
      "Epoch 15 Training Loss=1.034917, Validation Loss=0.976587\n",
      "Epoch 16 Training Loss=1.033448, Validation Loss=0.977681\n",
      "Epoch 17 Training Loss=1.032052, Validation Loss=0.978793\n",
      "Epoch 18 Training Loss=1.030716, Validation Loss=0.979926\n",
      "Epoch 19 Training Loss=1.029429, Validation Loss=0.981084\n",
      "Epoch 20 Training Loss=1.028182, Validation Loss=0.982271\n",
      "Epoch 21 Training Loss=1.026967, Validation Loss=0.983488\n",
      "Epoch 22 Training Loss=1.025779, Validation Loss=0.984738\n",
      "Epoch 23 Training Loss=1.024611, Validation Loss=0.986023\n",
      "Epoch 24 Training Loss=1.023460, Validation Loss=0.987344\n",
      "Epoch 25 Training Loss=1.022322, Validation Loss=0.988701\n",
      "Epoch 26 Training Loss=1.021195, Validation Loss=0.990093\n",
      "Epoch 27 Training Loss=1.020078, Validation Loss=0.991519\n",
      "Epoch 28 Training Loss=1.018968, Validation Loss=0.992976\n",
      "Epoch 29 Training Loss=1.017867, Validation Loss=0.994461\n",
      "Epoch 30 Training Loss=1.016773, Validation Loss=0.995968\n",
      "Epoch 31 Training Loss=1.015688, Validation Loss=0.997490\n",
      "Epoch 32 Training Loss=1.014612, Validation Loss=0.999021\n",
      "Epoch 33 Training Loss=1.013546, Validation Loss=1.000553\n",
      "Epoch 34 Training Loss=1.012492, Validation Loss=1.002076\n",
      "Epoch 35 Training Loss=1.011450, Validation Loss=1.003581\n",
      "Epoch 36 Training Loss=1.010421, Validation Loss=1.005060\n",
      "Epoch 37 Training Loss=1.009407, Validation Loss=1.006503\n",
      "Epoch 38 Training Loss=1.008407, Validation Loss=1.007902\n",
      "Epoch 39 Training Loss=1.007423, Validation Loss=1.009249\n",
      "Epoch 40 Training Loss=1.006454, Validation Loss=1.010538\n",
      "Epoch 41 Training Loss=1.005502, Validation Loss=1.011762\n",
      "Epoch 42 Training Loss=1.004565, Validation Loss=1.012918\n",
      "Epoch 43 Training Loss=1.003644, Validation Loss=1.014001\n",
      "Epoch 44 Training Loss=1.002738, Validation Loss=1.015011\n",
      "Epoch 45 Training Loss=1.001847, Validation Loss=1.015946\n",
      "Epoch 46 Training Loss=1.000970, Validation Loss=1.016806\n",
      "Epoch 47 Training Loss=1.000105, Validation Loss=1.017592\n",
      "Epoch 48 Training Loss=0.999252, Validation Loss=1.018306\n",
      "Epoch 49 Training Loss=0.998409, Validation Loss=1.018952\n",
      "Epoch 50 Training Loss=0.997575, Validation Loss=1.019532\n",
      "Epoch 51 Training Loss=0.996748, Validation Loss=1.020050\n",
      "Epoch 52 Training Loss=0.995928, Validation Loss=1.020512\n",
      "Epoch 53 Training Loss=0.995112, Validation Loss=1.020922\n",
      "Epoch 54 Training Loss=0.994301, Validation Loss=1.021287\n",
      "Epoch 55 Training Loss=0.993491, Validation Loss=1.021611\n",
      "Epoch 56 Training Loss=0.992683, Validation Loss=1.021902\n",
      "Epoch 57 Training Loss=0.991875, Validation Loss=1.022166\n",
      "Epoch 58 Training Loss=0.991067, Validation Loss=1.022409\n",
      "Epoch 59 Training Loss=0.990258, Validation Loss=1.022638\n",
      "Epoch 60 Training Loss=0.989447, Validation Loss=1.022859\n",
      "Epoch 61 Training Loss=0.988635, Validation Loss=1.023080\n",
      "Epoch 62 Training Loss=0.987821, Validation Loss=1.023307\n",
      "Epoch 63 Training Loss=0.987005, Validation Loss=1.023545\n",
      "Epoch 64 Training Loss=0.986188, Validation Loss=1.023800\n",
      "Epoch 65 Training Loss=0.985370, Validation Loss=1.024079\n",
      "Epoch 66 Training Loss=0.984552, Validation Loss=1.024386\n",
      "Epoch 67 Training Loss=0.983735, Validation Loss=1.024724\n",
      "Epoch 68 Training Loss=0.982919, Validation Loss=1.025099\n",
      "Epoch 69 Training Loss=0.982105, Validation Loss=1.025513\n",
      "Epoch 70 Training Loss=0.981294, Validation Loss=1.025968\n",
      "Epoch 71 Training Loss=0.980487, Validation Loss=1.026465\n",
      "Epoch 72 Training Loss=0.979685, Validation Loss=1.027006\n",
      "Epoch 73 Training Loss=0.978888, Validation Loss=1.027591\n",
      "Epoch 74 Training Loss=0.978099, Validation Loss=1.028217\n",
      "Epoch 75 Training Loss=0.977316, Validation Loss=1.028884\n",
      "Epoch 76 Training Loss=0.976542, Validation Loss=1.029589\n",
      "Epoch 77 Training Loss=0.975776, Validation Loss=1.030330\n",
      "Epoch 78 Training Loss=0.975019, Validation Loss=1.031102\n",
      "Epoch 79 Training Loss=0.974272, Validation Loss=1.031903\n",
      "Epoch 80 Training Loss=0.973535, Validation Loss=1.032727\n",
      "Epoch 81 Training Loss=0.972809, Validation Loss=1.033572\n",
      "Epoch 82 Training Loss=0.972093, Validation Loss=1.034433\n",
      "Epoch 83 Training Loss=0.971388, Validation Loss=1.035306\n",
      "Epoch 84 Training Loss=0.970694, Validation Loss=1.036187\n",
      "Epoch 85 Training Loss=0.970011, Validation Loss=1.037074\n",
      "Epoch 86 Training Loss=0.969338, Validation Loss=1.037963\n",
      "Epoch 87 Training Loss=0.968676, Validation Loss=1.038851\n",
      "Epoch 88 Training Loss=0.968025, Validation Loss=1.039736\n",
      "Epoch 89 Training Loss=0.967384, Validation Loss=1.040615\n",
      "Epoch 90 Training Loss=0.966753, Validation Loss=1.041487\n",
      "Epoch 91 Training Loss=0.966133, Validation Loss=1.042351\n",
      "Epoch 92 Training Loss=0.965522, Validation Loss=1.043204\n",
      "Epoch 93 Training Loss=0.964921, Validation Loss=1.044046\n",
      "Epoch 94 Training Loss=0.964330, Validation Loss=1.044876\n",
      "Epoch 95 Training Loss=0.963747, Validation Loss=1.045693\n",
      "Epoch 96 Training Loss=0.963174, Validation Loss=1.046497\n",
      "Epoch 97 Training Loss=0.962610, Validation Loss=1.047287\n",
      "Epoch 98 Training Loss=0.962055, Validation Loss=1.048063\n",
      "Epoch 99 Training Loss=0.961507, Validation Loss=1.048825\n",
      "Epoch 100 Training Loss=0.960969, Validation Loss=1.049573\n",
      "Epoch 101 Training Loss=0.960438, Validation Loss=1.050306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 Training Loss=0.959915, Validation Loss=1.051026\n",
      "Epoch 103 Training Loss=0.959399, Validation Loss=1.051731\n",
      "Epoch 104 Training Loss=0.958891, Validation Loss=1.052423\n",
      "Epoch 105 Training Loss=0.958391, Validation Loss=1.053102\n",
      "Epoch 106 Training Loss=0.957897, Validation Loss=1.053768\n",
      "Epoch 107 Training Loss=0.957410, Validation Loss=1.054422\n",
      "Epoch 108 Training Loss=0.956930, Validation Loss=1.055064\n",
      "Epoch 109 Training Loss=0.956457, Validation Loss=1.055695\n",
      "Epoch 110 Training Loss=0.955990, Validation Loss=1.056315\n",
      "Epoch 111 Training Loss=0.955529, Validation Loss=1.056924\n",
      "Epoch 112 Training Loss=0.955075, Validation Loss=1.057523\n",
      "Epoch 113 Training Loss=0.954627, Validation Loss=1.058113\n",
      "Epoch 114 Training Loss=0.954185, Validation Loss=1.058694\n",
      "Epoch 115 Training Loss=0.953749, Validation Loss=1.059266\n",
      "Epoch 116 Training Loss=0.953319, Validation Loss=1.059830\n",
      "Epoch 117 Training Loss=0.952895, Validation Loss=1.060385\n",
      "Epoch 118 Training Loss=0.952477, Validation Loss=1.060933\n",
      "Epoch 119 Training Loss=0.952065, Validation Loss=1.061473\n",
      "Epoch 120 Training Loss=0.951660, Validation Loss=1.062006\n",
      "Epoch 121 Training Loss=0.951260, Validation Loss=1.062531\n",
      "Epoch 122 Training Loss=0.950866, Validation Loss=1.063049\n",
      "Epoch 123 Training Loss=0.950479, Validation Loss=1.063559\n",
      "Epoch 124 Training Loss=0.950098, Validation Loss=1.064062\n",
      "Epoch 125 Training Loss=0.949724, Validation Loss=1.064557\n",
      "Epoch 126 Training Loss=0.949355, Validation Loss=1.065044\n",
      "Epoch 127 Training Loss=0.948993, Validation Loss=1.065524\n",
      "Epoch 128 Training Loss=0.948637, Validation Loss=1.065996\n",
      "Epoch 129 Training Loss=0.948288, Validation Loss=1.066460\n",
      "Epoch 130 Training Loss=0.947945, Validation Loss=1.066915\n",
      "Epoch 131 Training Loss=0.947607, Validation Loss=1.067363\n",
      "Epoch 132 Training Loss=0.947276, Validation Loss=1.067802\n",
      "Epoch 133 Training Loss=0.946951, Validation Loss=1.068233\n",
      "Epoch 134 Training Loss=0.946631, Validation Loss=1.068656\n",
      "Epoch 135 Training Loss=0.946318, Validation Loss=1.069071\n",
      "Epoch 136 Training Loss=0.946009, Validation Loss=1.069477\n",
      "Epoch 137 Training Loss=0.945707, Validation Loss=1.069875\n",
      "Epoch 138 Training Loss=0.945410, Validation Loss=1.070266\n",
      "Epoch 139 Training Loss=0.945118, Validation Loss=1.070648\n",
      "Epoch 140 Training Loss=0.944831, Validation Loss=1.071022\n",
      "Epoch 141 Training Loss=0.944549, Validation Loss=1.071388\n",
      "Epoch 142 Training Loss=0.944272, Validation Loss=1.071747\n",
      "Epoch 143 Training Loss=0.944000, Validation Loss=1.072098\n",
      "Epoch 144 Training Loss=0.943733, Validation Loss=1.072442\n",
      "Epoch 145 Training Loss=0.943471, Validation Loss=1.072778\n",
      "Epoch 146 Training Loss=0.943213, Validation Loss=1.073106\n",
      "Epoch 147 Training Loss=0.942960, Validation Loss=1.073427\n",
      "Epoch 148 Training Loss=0.942711, Validation Loss=1.073740\n",
      "Epoch 149 Training Loss=0.942467, Validation Loss=1.074046\n",
      "Epoch 150 Training Loss=0.942226, Validation Loss=1.074345\n",
      "Epoch 151 Training Loss=0.941991, Validation Loss=1.074636\n",
      "Epoch 152 Training Loss=0.941759, Validation Loss=1.074920\n",
      "Epoch 153 Training Loss=0.941531, Validation Loss=1.075196\n",
      "Epoch 154 Training Loss=0.941308, Validation Loss=1.075465\n",
      "Epoch 155 Training Loss=0.941088, Validation Loss=1.075727\n",
      "Epoch 156 Training Loss=0.940873, Validation Loss=1.075981\n",
      "Epoch 157 Training Loss=0.940661, Validation Loss=1.076227\n",
      "Epoch 158 Training Loss=0.940454, Validation Loss=1.076466\n",
      "Epoch 159 Training Loss=0.940250, Validation Loss=1.076698\n",
      "Epoch 160 Training Loss=0.940050, Validation Loss=1.076921\n",
      "Epoch 161 Training Loss=0.939853, Validation Loss=1.077137\n",
      "Epoch 162 Training Loss=0.939660, Validation Loss=1.077345\n",
      "Epoch 163 Training Loss=0.939471, Validation Loss=1.077544\n",
      "Epoch 164 Training Loss=0.939286, Validation Loss=1.077735\n",
      "Epoch 165 Training Loss=0.939104, Validation Loss=1.077917\n",
      "Epoch 166 Training Loss=0.938925, Validation Loss=1.078090\n",
      "Epoch 167 Training Loss=0.938750, Validation Loss=1.078254\n",
      "Epoch 168 Training Loss=0.938579, Validation Loss=1.078408\n",
      "Epoch 169 Training Loss=0.938411, Validation Loss=1.078551\n",
      "Epoch 170 Training Loss=0.938246, Validation Loss=1.078683\n",
      "Epoch 171 Training Loss=0.938084, Validation Loss=1.078803\n",
      "Epoch 172 Training Loss=0.937925, Validation Loss=1.078910\n",
      "Epoch 173 Training Loss=0.937769, Validation Loss=1.079003\n",
      "Epoch 174 Training Loss=0.937616, Validation Loss=1.079079\n",
      "Epoch 175 Training Loss=0.937465, Validation Loss=1.079138\n",
      "Epoch 176 Training Loss=0.937315, Validation Loss=1.079175\n",
      "Epoch 177 Training Loss=0.937167, Validation Loss=1.079189\n",
      "Epoch 178 Training Loss=0.937018, Validation Loss=1.079176\n",
      "Epoch 179 Training Loss=0.936866, Validation Loss=1.079131\n",
      "Epoch 180 Training Loss=0.936710, Validation Loss=1.079050\n",
      "Epoch 181 Training Loss=0.936544, Validation Loss=1.078929\n",
      "Epoch 182 Training Loss=0.936363, Validation Loss=1.078763\n",
      "Epoch 183 Training Loss=0.936159, Validation Loss=1.078554\n",
      "Epoch 184 Training Loss=0.935921, Validation Loss=1.078310\n",
      "Epoch 185 Training Loss=0.935639, Validation Loss=1.078048\n",
      "Epoch 186 Training Loss=0.935306, Validation Loss=1.077803\n",
      "Epoch 187 Training Loss=0.934924, Validation Loss=1.077616\n",
      "Epoch 188 Training Loss=0.934508, Validation Loss=1.077527\n",
      "Epoch 189 Training Loss=0.934082, Validation Loss=1.077555\n",
      "Epoch 190 Training Loss=0.933669, Validation Loss=1.077697\n",
      "Epoch 191 Training Loss=0.933284, Validation Loss=1.077927\n",
      "Epoch 192 Training Loss=0.932930, Validation Loss=1.078211\n",
      "Epoch 193 Training Loss=0.932604, Validation Loss=1.078523\n",
      "Epoch 194 Training Loss=0.932300, Validation Loss=1.078843\n",
      "Epoch 195 Training Loss=0.932013, Validation Loss=1.079161\n",
      "Epoch 196 Training Loss=0.931740, Validation Loss=1.079472\n",
      "Epoch 197 Training Loss=0.931479, Validation Loss=1.079772\n",
      "Epoch 198 Training Loss=0.931227, Validation Loss=1.080063\n",
      "Epoch 199 Training Loss=0.930984, Validation Loss=1.080344\n",
      "Epoch 0 Training Loss=1.058003, Validation Loss=0.932617\n",
      "Epoch 1 Training Loss=1.084609, Validation Loss=0.968821\n",
      "Epoch 2 Training Loss=1.072922, Validation Loss=0.960598\n",
      "Epoch 3 Training Loss=1.065390, Validation Loss=0.960526\n",
      "Epoch 4 Training Loss=1.062562, Validation Loss=0.961956\n",
      "Epoch 5 Training Loss=1.059203, Validation Loss=0.962234\n",
      "Epoch 6 Training Loss=1.056690, Validation Loss=0.962766\n",
      "Epoch 7 Training Loss=1.054340, Validation Loss=0.963207\n",
      "Epoch 8 Training Loss=1.052142, Validation Loss=0.963704\n",
      "Epoch 9 Training Loss=1.050105, Validation Loss=0.964329\n",
      "Epoch 10 Training Loss=1.048163, Validation Loss=0.965081\n",
      "Epoch 11 Training Loss=1.046294, Validation Loss=0.965969\n",
      "Epoch 12 Training Loss=1.044479, Validation Loss=0.966998\n",
      "Epoch 13 Training Loss=1.042702, Validation Loss=0.968166\n",
      "Epoch 14 Training Loss=1.040953, Validation Loss=0.969466\n",
      "Epoch 15 Training Loss=1.039224, Validation Loss=0.970892\n",
      "Epoch 16 Training Loss=1.037513, Validation Loss=0.972432\n",
      "Epoch 17 Training Loss=1.035816, Validation Loss=0.974072\n",
      "Epoch 18 Training Loss=1.034135, Validation Loss=0.975796\n",
      "Epoch 19 Training Loss=1.032472, Validation Loss=0.977583\n",
      "Epoch 20 Training Loss=1.030829, Validation Loss=0.979413\n",
      "Epoch 21 Training Loss=1.029212, Validation Loss=0.981264\n",
      "Epoch 22 Training Loss=1.027623, Validation Loss=0.983115\n",
      "Epoch 23 Training Loss=1.026067, Validation Loss=0.984944\n",
      "Epoch 24 Training Loss=1.024545, Validation Loss=0.986736\n",
      "Epoch 25 Training Loss=1.023059, Validation Loss=0.988476\n",
      "Epoch 26 Training Loss=1.021612, Validation Loss=0.990152\n",
      "Epoch 27 Training Loss=1.020203, Validation Loss=0.991756\n",
      "Epoch 28 Training Loss=1.018833, Validation Loss=0.993282\n",
      "Epoch 29 Training Loss=1.017500, Validation Loss=0.994724\n",
      "Epoch 30 Training Loss=1.016204, Validation Loss=0.996079\n",
      "Epoch 31 Training Loss=1.014943, Validation Loss=0.997344\n",
      "Epoch 32 Training Loss=1.013714, Validation Loss=0.998517\n",
      "Epoch 33 Training Loss=1.012517, Validation Loss=0.999596\n",
      "Epoch 34 Training Loss=1.011347, Validation Loss=1.000580\n",
      "Epoch 35 Training Loss=1.010203, Validation Loss=1.001468\n",
      "Epoch 36 Training Loss=1.009081, Validation Loss=1.002261\n",
      "Epoch 37 Training Loss=1.007979, Validation Loss=1.002962\n",
      "Epoch 38 Training Loss=1.006894, Validation Loss=1.003574\n",
      "Epoch 39 Training Loss=1.005825, Validation Loss=1.004102\n",
      "Epoch 40 Training Loss=1.004769, Validation Loss=1.004551\n",
      "Epoch 41 Training Loss=1.003725, Validation Loss=1.004929\n",
      "Epoch 42 Training Loss=1.002691, Validation Loss=1.005244\n",
      "Epoch 43 Training Loss=1.001666, Validation Loss=1.005504\n",
      "Epoch 44 Training Loss=1.000650, Validation Loss=1.005719\n",
      "Epoch 45 Training Loss=0.999640, Validation Loss=1.005897\n",
      "Epoch 46 Training Loss=0.998635, Validation Loss=1.006048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training Loss=0.997635, Validation Loss=1.006181\n",
      "Epoch 48 Training Loss=0.996637, Validation Loss=1.006305\n",
      "Epoch 49 Training Loss=0.995641, Validation Loss=1.006426\n",
      "Epoch 50 Training Loss=0.994645, Validation Loss=1.006554\n",
      "Epoch 51 Training Loss=0.993647, Validation Loss=1.006693\n",
      "Epoch 52 Training Loss=0.992645, Validation Loss=1.006851\n",
      "Epoch 53 Training Loss=0.991639, Validation Loss=1.007033\n",
      "Epoch 54 Training Loss=0.990625, Validation Loss=1.007241\n",
      "Epoch 55 Training Loss=0.989603, Validation Loss=1.007482\n",
      "Epoch 56 Training Loss=0.988570, Validation Loss=1.007756\n",
      "Epoch 57 Training Loss=0.987526, Validation Loss=1.008068\n",
      "Epoch 58 Training Loss=0.986468, Validation Loss=1.008418\n",
      "Epoch 59 Training Loss=0.985394, Validation Loss=1.008808\n",
      "Epoch 60 Training Loss=0.984304, Validation Loss=1.009241\n",
      "Epoch 61 Training Loss=0.983196, Validation Loss=1.009716\n",
      "Epoch 62 Training Loss=0.982068, Validation Loss=1.010235\n",
      "Epoch 63 Training Loss=0.980920, Validation Loss=1.010800\n",
      "Epoch 64 Training Loss=0.979751, Validation Loss=1.011412\n",
      "Epoch 65 Training Loss=0.978560, Validation Loss=1.012072\n",
      "Epoch 66 Training Loss=0.977346, Validation Loss=1.012783\n",
      "Epoch 67 Training Loss=0.976109, Validation Loss=1.013547\n",
      "Epoch 68 Training Loss=0.974849, Validation Loss=1.014364\n",
      "Epoch 69 Training Loss=0.973564, Validation Loss=1.015237\n",
      "Epoch 70 Training Loss=0.972257, Validation Loss=1.016168\n",
      "Epoch 71 Training Loss=0.970926, Validation Loss=1.017156\n",
      "Epoch 72 Training Loss=0.969572, Validation Loss=1.018203\n",
      "Epoch 73 Training Loss=0.968196, Validation Loss=1.019308\n",
      "Epoch 74 Training Loss=0.966798, Validation Loss=1.020468\n",
      "Epoch 75 Training Loss=0.965381, Validation Loss=1.021683\n",
      "Epoch 76 Training Loss=0.963945, Validation Loss=1.022949\n",
      "Epoch 77 Training Loss=0.962492, Validation Loss=1.024262\n",
      "Epoch 78 Training Loss=0.961023, Validation Loss=1.025619\n",
      "Epoch 79 Training Loss=0.959541, Validation Loss=1.027016\n",
      "Epoch 80 Training Loss=0.958048, Validation Loss=1.028447\n",
      "Epoch 81 Training Loss=0.956545, Validation Loss=1.029909\n",
      "Epoch 82 Training Loss=0.955035, Validation Loss=1.031397\n",
      "Epoch 83 Training Loss=0.953519, Validation Loss=1.032909\n",
      "Epoch 84 Training Loss=0.952000, Validation Loss=1.034440\n",
      "Epoch 85 Training Loss=0.950479, Validation Loss=1.035988\n",
      "Epoch 86 Training Loss=0.948959, Validation Loss=1.037550\n",
      "Epoch 87 Training Loss=0.947440, Validation Loss=1.039123\n",
      "Epoch 88 Training Loss=0.945924, Validation Loss=1.040706\n",
      "Epoch 89 Training Loss=0.944413, Validation Loss=1.042296\n",
      "Epoch 90 Training Loss=0.942908, Validation Loss=1.043890\n",
      "Epoch 91 Training Loss=0.941410, Validation Loss=1.045488\n",
      "Epoch 92 Training Loss=0.939920, Validation Loss=1.047087\n",
      "Epoch 93 Training Loss=0.938439, Validation Loss=1.048686\n",
      "Epoch 94 Training Loss=0.936967, Validation Loss=1.050281\n",
      "Epoch 95 Training Loss=0.935504, Validation Loss=1.051872\n",
      "Epoch 96 Training Loss=0.934052, Validation Loss=1.053458\n",
      "Epoch 97 Training Loss=0.932609, Validation Loss=1.055036\n",
      "Epoch 98 Training Loss=0.931177, Validation Loss=1.056605\n",
      "Epoch 99 Training Loss=0.929755, Validation Loss=1.058166\n",
      "Epoch 100 Training Loss=0.928342, Validation Loss=1.059718\n",
      "Epoch 101 Training Loss=0.926939, Validation Loss=1.061260\n",
      "Epoch 102 Training Loss=0.925544, Validation Loss=1.062795\n",
      "Epoch 103 Training Loss=0.924159, Validation Loss=1.064323\n",
      "Epoch 104 Training Loss=0.922782, Validation Loss=1.065845\n",
      "Epoch 105 Training Loss=0.921413, Validation Loss=1.067363\n",
      "Epoch 106 Training Loss=0.920053, Validation Loss=1.068879\n",
      "Epoch 107 Training Loss=0.918701, Validation Loss=1.070393\n",
      "Epoch 108 Training Loss=0.917356, Validation Loss=1.071908\n",
      "Epoch 109 Training Loss=0.916019, Validation Loss=1.073423\n",
      "Epoch 110 Training Loss=0.914689, Validation Loss=1.074939\n",
      "Epoch 111 Training Loss=0.913366, Validation Loss=1.076457\n",
      "Epoch 112 Training Loss=0.912049, Validation Loss=1.077975\n",
      "Epoch 113 Training Loss=0.910738, Validation Loss=1.079495\n",
      "Epoch 114 Training Loss=0.909432, Validation Loss=1.081016\n",
      "Epoch 115 Training Loss=0.908130, Validation Loss=1.082538\n",
      "Epoch 116 Training Loss=0.906833, Validation Loss=1.084062\n",
      "Epoch 117 Training Loss=0.905538, Validation Loss=1.085587\n",
      "Epoch 118 Training Loss=0.904246, Validation Loss=1.087116\n",
      "Epoch 119 Training Loss=0.902955, Validation Loss=1.088649\n",
      "Epoch 120 Training Loss=0.901666, Validation Loss=1.090187\n",
      "Epoch 121 Training Loss=0.900377, Validation Loss=1.091733\n",
      "Epoch 122 Training Loss=0.899089, Validation Loss=1.093289\n",
      "Epoch 123 Training Loss=0.897800, Validation Loss=1.094856\n",
      "Epoch 124 Training Loss=0.896511, Validation Loss=1.096438\n",
      "Epoch 125 Training Loss=0.895222, Validation Loss=1.098037\n",
      "Epoch 126 Training Loss=0.893933, Validation Loss=1.099655\n",
      "Epoch 127 Training Loss=0.892645, Validation Loss=1.101296\n",
      "Epoch 128 Training Loss=0.891358, Validation Loss=1.102962\n",
      "Epoch 129 Training Loss=0.890074, Validation Loss=1.104656\n",
      "Epoch 130 Training Loss=0.888792, Validation Loss=1.106381\n",
      "Epoch 131 Training Loss=0.887514, Validation Loss=1.108141\n",
      "Epoch 132 Training Loss=0.886239, Validation Loss=1.109938\n",
      "Epoch 133 Training Loss=0.884969, Validation Loss=1.111775\n",
      "Epoch 134 Training Loss=0.883703, Validation Loss=1.113655\n",
      "Epoch 135 Training Loss=0.882442, Validation Loss=1.115580\n",
      "Epoch 136 Training Loss=0.881185, Validation Loss=1.117551\n",
      "Epoch 137 Training Loss=0.879931, Validation Loss=1.119573\n",
      "Epoch 138 Training Loss=0.878682, Validation Loss=1.121646\n",
      "Epoch 139 Training Loss=0.877437, Validation Loss=1.123772\n",
      "Epoch 140 Training Loss=0.876195, Validation Loss=1.125954\n",
      "Epoch 141 Training Loss=0.874958, Validation Loss=1.128193\n",
      "Epoch 142 Training Loss=0.873725, Validation Loss=1.130491\n",
      "Epoch 143 Training Loss=0.872497, Validation Loss=1.132851\n",
      "Epoch 144 Training Loss=0.871274, Validation Loss=1.135273\n",
      "Epoch 145 Training Loss=0.870058, Validation Loss=1.137760\n",
      "Epoch 146 Training Loss=0.868848, Validation Loss=1.140314\n",
      "Epoch 147 Training Loss=0.867645, Validation Loss=1.142935\n",
      "Epoch 148 Training Loss=0.866451, Validation Loss=1.145625\n",
      "Epoch 149 Training Loss=0.865266, Validation Loss=1.148384\n",
      "Epoch 150 Training Loss=0.864091, Validation Loss=1.151214\n",
      "Epoch 151 Training Loss=0.862926, Validation Loss=1.154113\n",
      "Epoch 152 Training Loss=0.861773, Validation Loss=1.157081\n",
      "Epoch 153 Training Loss=0.860633, Validation Loss=1.160115\n",
      "Epoch 154 Training Loss=0.859504, Validation Loss=1.163213\n",
      "Epoch 155 Training Loss=0.858390, Validation Loss=1.166373\n",
      "Epoch 156 Training Loss=0.857290, Validation Loss=1.169590\n",
      "Epoch 157 Training Loss=0.856204, Validation Loss=1.172860\n",
      "Epoch 158 Training Loss=0.855134, Validation Loss=1.176177\n",
      "Epoch 159 Training Loss=0.854079, Validation Loss=1.179536\n",
      "Epoch 160 Training Loss=0.853040, Validation Loss=1.182932\n",
      "Epoch 161 Training Loss=0.852017, Validation Loss=1.186358\n",
      "Epoch 162 Training Loss=0.851010, Validation Loss=1.189809\n",
      "Epoch 163 Training Loss=0.850019, Validation Loss=1.193278\n",
      "Epoch 164 Training Loss=0.849044, Validation Loss=1.196761\n",
      "Epoch 165 Training Loss=0.848085, Validation Loss=1.200251\n",
      "Epoch 166 Training Loss=0.847142, Validation Loss=1.203746\n",
      "Epoch 167 Training Loss=0.846214, Validation Loss=1.207239\n",
      "Epoch 168 Training Loss=0.845301, Validation Loss=1.210726\n",
      "Epoch 169 Training Loss=0.844403, Validation Loss=1.214206\n",
      "Epoch 170 Training Loss=0.843520, Validation Loss=1.217673\n",
      "Epoch 171 Training Loss=0.842650, Validation Loss=1.221125\n",
      "Epoch 172 Training Loss=0.841794, Validation Loss=1.224558\n",
      "Epoch 173 Training Loss=0.840951, Validation Loss=1.227971\n",
      "Epoch 174 Training Loss=0.840121, Validation Loss=1.231361\n",
      "Epoch 175 Training Loss=0.839304, Validation Loss=1.234725\n",
      "Epoch 176 Training Loss=0.838499, Validation Loss=1.238060\n",
      "Epoch 177 Training Loss=0.837706, Validation Loss=1.241363\n",
      "Epoch 178 Training Loss=0.836925, Validation Loss=1.244633\n",
      "Epoch 179 Training Loss=0.836156, Validation Loss=1.247867\n",
      "Epoch 180 Training Loss=0.835399, Validation Loss=1.251062\n",
      "Epoch 181 Training Loss=0.834653, Validation Loss=1.254215\n",
      "Epoch 182 Training Loss=0.833919, Validation Loss=1.257325\n",
      "Epoch 183 Training Loss=0.833197, Validation Loss=1.260388\n",
      "Epoch 184 Training Loss=0.832485, Validation Loss=1.263403\n",
      "Epoch 185 Training Loss=0.831785, Validation Loss=1.266367\n",
      "Epoch 186 Training Loss=0.831096, Validation Loss=1.269278\n",
      "Epoch 187 Training Loss=0.830418, Validation Loss=1.272134\n",
      "Epoch 188 Training Loss=0.829751, Validation Loss=1.274934\n",
      "Epoch 189 Training Loss=0.829094, Validation Loss=1.277676\n",
      "Epoch 190 Training Loss=0.828448, Validation Loss=1.280360\n",
      "Epoch 191 Training Loss=0.827812, Validation Loss=1.282983\n",
      "Epoch 192 Training Loss=0.827186, Validation Loss=1.285546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193 Training Loss=0.826570, Validation Loss=1.288048\n",
      "Epoch 194 Training Loss=0.825963, Validation Loss=1.290488\n",
      "Epoch 195 Training Loss=0.825366, Validation Loss=1.292865\n",
      "Epoch 196 Training Loss=0.824777, Validation Loss=1.295181\n",
      "Epoch 197 Training Loss=0.824197, Validation Loss=1.297434\n",
      "Epoch 198 Training Loss=0.823625, Validation Loss=1.299625\n",
      "Epoch 199 Training Loss=0.823061, Validation Loss=1.301754\n",
      "Epoch 0 Training Loss=1.112162, Validation Loss=0.967460\n",
      "Epoch 1 Training Loss=1.161997, Validation Loss=1.083073\n",
      "Epoch 2 Training Loss=1.215572, Validation Loss=1.124259\n",
      "Epoch 3 Training Loss=1.222907, Validation Loss=1.098907\n",
      "Epoch 4 Training Loss=1.209049, Validation Loss=1.016431\n",
      "Epoch 5 Training Loss=1.181260, Validation Loss=0.950781\n",
      "Epoch 6 Training Loss=1.142060, Validation Loss=0.947783\n",
      "Epoch 7 Training Loss=1.107645, Validation Loss=0.960434\n",
      "Epoch 8 Training Loss=1.088236, Validation Loss=0.961042\n",
      "Epoch 9 Training Loss=1.079868, Validation Loss=0.957849\n",
      "Epoch 10 Training Loss=1.074492, Validation Loss=0.957344\n",
      "Epoch 11 Training Loss=1.069181, Validation Loss=0.958967\n",
      "Epoch 12 Training Loss=1.064634, Validation Loss=0.961015\n",
      "Epoch 13 Training Loss=1.061070, Validation Loss=0.962872\n",
      "Epoch 14 Training Loss=1.058078, Validation Loss=0.964527\n",
      "Epoch 15 Training Loss=1.055458, Validation Loss=0.966071\n",
      "Epoch 16 Training Loss=1.053171, Validation Loss=0.967539\n",
      "Epoch 17 Training Loss=1.051173, Validation Loss=0.968948\n",
      "Epoch 18 Training Loss=1.049424, Validation Loss=0.970314\n",
      "Epoch 19 Training Loss=1.047900, Validation Loss=0.971650\n",
      "Epoch 20 Training Loss=1.046586, Validation Loss=0.972968\n",
      "Epoch 21 Training Loss=1.045468, Validation Loss=0.974274\n",
      "Epoch 22 Training Loss=1.044544, Validation Loss=0.975571\n",
      "Epoch 23 Training Loss=1.043811, Validation Loss=0.976853\n",
      "Epoch 24 Training Loss=1.043274, Validation Loss=0.978107\n",
      "Epoch 25 Training Loss=1.042937, Validation Loss=0.979310\n",
      "Epoch 26 Training Loss=1.042806, Validation Loss=0.980435\n",
      "Epoch 27 Training Loss=1.042887, Validation Loss=0.981457\n",
      "Epoch 28 Training Loss=1.043176, Validation Loss=0.982375\n",
      "Epoch 29 Training Loss=1.043660, Validation Loss=0.983247\n",
      "Epoch 30 Training Loss=1.044301, Validation Loss=0.984240\n",
      "Epoch 31 Training Loss=1.045031, Validation Loss=0.985679\n",
      "Epoch 32 Training Loss=1.045739, Validation Loss=0.988047\n",
      "Epoch 33 Training Loss=1.046269, Validation Loss=0.991866\n",
      "Epoch 34 Training Loss=1.046427, Validation Loss=0.997371\n",
      "Epoch 35 Training Loss=1.045994, Validation Loss=1.004059\n",
      "Epoch 36 Training Loss=1.044766, Validation Loss=1.010432\n",
      "Epoch 37 Training Loss=1.042630, Validation Loss=1.014545\n",
      "Epoch 38 Training Loss=1.039645, Validation Loss=1.015414\n",
      "Epoch 39 Training Loss=1.036082, Validation Loss=1.013921\n",
      "Epoch 40 Training Loss=1.032378, Validation Loss=1.011889\n",
      "Epoch 41 Training Loss=1.028986, Validation Loss=1.010472\n",
      "Epoch 42 Training Loss=1.026168, Validation Loss=1.009816\n",
      "Epoch 43 Training Loss=1.023927, Validation Loss=1.009666\n",
      "Epoch 44 Training Loss=1.022116, Validation Loss=1.009789\n",
      "Epoch 45 Training Loss=1.020582, Validation Loss=1.010058\n",
      "Epoch 46 Training Loss=1.019218, Validation Loss=1.010407\n",
      "Epoch 47 Training Loss=1.017971, Validation Loss=1.010806\n",
      "Epoch 48 Training Loss=1.016811, Validation Loss=1.011236\n",
      "Epoch 49 Training Loss=1.015722, Validation Loss=1.011687\n",
      "Epoch 50 Training Loss=1.014694, Validation Loss=1.012151\n",
      "Epoch 51 Training Loss=1.013716, Validation Loss=1.012622\n",
      "Epoch 52 Training Loss=1.012783, Validation Loss=1.013095\n",
      "Epoch 53 Training Loss=1.011887, Validation Loss=1.013568\n",
      "Epoch 54 Training Loss=1.011025, Validation Loss=1.014038\n",
      "Epoch 55 Training Loss=1.010191, Validation Loss=1.014502\n",
      "Epoch 56 Training Loss=1.009383, Validation Loss=1.014960\n",
      "Epoch 57 Training Loss=1.008597, Validation Loss=1.015411\n",
      "Epoch 58 Training Loss=1.007831, Validation Loss=1.015855\n",
      "Epoch 59 Training Loss=1.007082, Validation Loss=1.016292\n",
      "Epoch 60 Training Loss=1.006348, Validation Loss=1.016722\n",
      "Epoch 61 Training Loss=1.005626, Validation Loss=1.017146\n",
      "Epoch 62 Training Loss=1.004916, Validation Loss=1.017565\n",
      "Epoch 63 Training Loss=1.004215, Validation Loss=1.017980\n",
      "Epoch 64 Training Loss=1.003523, Validation Loss=1.018394\n",
      "Epoch 65 Training Loss=1.002837, Validation Loss=1.018808\n",
      "Epoch 66 Training Loss=1.002157, Validation Loss=1.019224\n",
      "Epoch 67 Training Loss=1.001482, Validation Loss=1.019645\n",
      "Epoch 68 Training Loss=1.000811, Validation Loss=1.020071\n",
      "Epoch 69 Training Loss=1.000145, Validation Loss=1.020505\n",
      "Epoch 70 Training Loss=0.999481, Validation Loss=1.020948\n",
      "Epoch 71 Training Loss=0.998821, Validation Loss=1.021402\n",
      "Epoch 72 Training Loss=0.998164, Validation Loss=1.021866\n",
      "Epoch 73 Training Loss=0.997510, Validation Loss=1.022343\n",
      "Epoch 74 Training Loss=0.996859, Validation Loss=1.022832\n",
      "Epoch 75 Training Loss=0.996211, Validation Loss=1.023332\n",
      "Epoch 76 Training Loss=0.995567, Validation Loss=1.023844\n",
      "Epoch 77 Training Loss=0.994926, Validation Loss=1.024367\n",
      "Epoch 78 Training Loss=0.994287, Validation Loss=1.024900\n",
      "Epoch 79 Training Loss=0.993652, Validation Loss=1.025445\n",
      "Epoch 80 Training Loss=0.993020, Validation Loss=1.025999\n",
      "Epoch 81 Training Loss=0.992391, Validation Loss=1.026563\n",
      "Epoch 82 Training Loss=0.991764, Validation Loss=1.027137\n",
      "Epoch 83 Training Loss=0.991140, Validation Loss=1.027721\n",
      "Epoch 84 Training Loss=0.990518, Validation Loss=1.028316\n",
      "Epoch 85 Training Loss=0.989898, Validation Loss=1.028921\n",
      "Epoch 86 Training Loss=0.989280, Validation Loss=1.029537\n",
      "Epoch 87 Training Loss=0.988664, Validation Loss=1.030166\n",
      "Epoch 88 Training Loss=0.988049, Validation Loss=1.030807\n",
      "Epoch 89 Training Loss=0.987436, Validation Loss=1.031461\n",
      "Epoch 90 Training Loss=0.986825, Validation Loss=1.032129\n",
      "Epoch 91 Training Loss=0.986215, Validation Loss=1.032811\n",
      "Epoch 92 Training Loss=0.985607, Validation Loss=1.033507\n",
      "Epoch 93 Training Loss=0.984999, Validation Loss=1.034218\n",
      "Epoch 94 Training Loss=0.984393, Validation Loss=1.034943\n",
      "Epoch 95 Training Loss=0.983788, Validation Loss=1.035681\n",
      "Epoch 96 Training Loss=0.983183, Validation Loss=1.036433\n",
      "Epoch 97 Training Loss=0.982578, Validation Loss=1.037197\n",
      "Epoch 98 Training Loss=0.981973, Validation Loss=1.037971\n",
      "Epoch 99 Training Loss=0.981365, Validation Loss=1.038755\n",
      "Epoch 100 Training Loss=0.980753, Validation Loss=1.039547\n",
      "Epoch 101 Training Loss=0.980136, Validation Loss=1.040345\n",
      "Epoch 102 Training Loss=0.979509, Validation Loss=1.041147\n",
      "Epoch 103 Training Loss=0.978869, Validation Loss=1.041952\n",
      "Epoch 104 Training Loss=0.978212, Validation Loss=1.042761\n",
      "Epoch 105 Training Loss=0.977533, Validation Loss=1.043573\n",
      "Epoch 106 Training Loss=0.976829, Validation Loss=1.044390\n",
      "Epoch 107 Training Loss=0.976099, Validation Loss=1.045214\n",
      "Epoch 108 Training Loss=0.975342, Validation Loss=1.046049\n",
      "Epoch 109 Training Loss=0.974565, Validation Loss=1.046896\n",
      "Epoch 110 Training Loss=0.973774, Validation Loss=1.047753\n",
      "Epoch 111 Training Loss=0.972978, Validation Loss=1.048617\n",
      "Epoch 112 Training Loss=0.972183, Validation Loss=1.049483\n",
      "Epoch 113 Training Loss=0.971392, Validation Loss=1.050343\n",
      "Epoch 114 Training Loss=0.970606, Validation Loss=1.051194\n",
      "Epoch 115 Training Loss=0.969825, Validation Loss=1.052036\n",
      "Epoch 116 Training Loss=0.969046, Validation Loss=1.052867\n",
      "Epoch 117 Training Loss=0.968267, Validation Loss=1.053692\n",
      "Epoch 118 Training Loss=0.967486, Validation Loss=1.054514\n",
      "Epoch 119 Training Loss=0.966703, Validation Loss=1.055336\n",
      "Epoch 120 Training Loss=0.965915, Validation Loss=1.056162\n",
      "Epoch 121 Training Loss=0.965123, Validation Loss=1.056995\n",
      "Epoch 122 Training Loss=0.964326, Validation Loss=1.057836\n",
      "Epoch 123 Training Loss=0.963525, Validation Loss=1.058686\n",
      "Epoch 124 Training Loss=0.962719, Validation Loss=1.059548\n",
      "Epoch 125 Training Loss=0.961909, Validation Loss=1.060420\n",
      "Epoch 126 Training Loss=0.961096, Validation Loss=1.061303\n",
      "Epoch 127 Training Loss=0.960281, Validation Loss=1.062198\n",
      "Epoch 128 Training Loss=0.959464, Validation Loss=1.063102\n",
      "Epoch 129 Training Loss=0.958647, Validation Loss=1.064015\n",
      "Epoch 130 Training Loss=0.957830, Validation Loss=1.064936\n",
      "Epoch 131 Training Loss=0.957015, Validation Loss=1.065863\n",
      "Epoch 132 Training Loss=0.956203, Validation Loss=1.066794\n",
      "Epoch 133 Training Loss=0.955395, Validation Loss=1.067729\n",
      "Epoch 134 Training Loss=0.954591, Validation Loss=1.068665\n",
      "Epoch 135 Training Loss=0.953793, Validation Loss=1.069600\n",
      "Epoch 136 Training Loss=0.953002, Validation Loss=1.070533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 Training Loss=0.952219, Validation Loss=1.071461\n",
      "Epoch 138 Training Loss=0.951444, Validation Loss=1.072383\n",
      "Epoch 139 Training Loss=0.950678, Validation Loss=1.073297\n",
      "Epoch 140 Training Loss=0.949922, Validation Loss=1.074201\n",
      "Epoch 141 Training Loss=0.949176, Validation Loss=1.075093\n",
      "Epoch 142 Training Loss=0.948440, Validation Loss=1.075971\n",
      "Epoch 143 Training Loss=0.947716, Validation Loss=1.076834\n",
      "Epoch 144 Training Loss=0.947002, Validation Loss=1.077681\n",
      "Epoch 145 Training Loss=0.946300, Validation Loss=1.078509\n",
      "Epoch 146 Training Loss=0.945609, Validation Loss=1.079318\n",
      "Epoch 147 Training Loss=0.944930, Validation Loss=1.080106\n",
      "Epoch 148 Training Loss=0.944262, Validation Loss=1.080874\n",
      "Epoch 149 Training Loss=0.943605, Validation Loss=1.081620\n",
      "Epoch 150 Training Loss=0.942960, Validation Loss=1.082344\n",
      "Epoch 151 Training Loss=0.942325, Validation Loss=1.083046\n",
      "Epoch 152 Training Loss=0.941702, Validation Loss=1.083726\n",
      "Epoch 153 Training Loss=0.941089, Validation Loss=1.084384\n",
      "Epoch 154 Training Loss=0.940488, Validation Loss=1.085021\n",
      "Epoch 155 Training Loss=0.939896, Validation Loss=1.085638\n",
      "Epoch 156 Training Loss=0.939315, Validation Loss=1.086234\n",
      "Epoch 157 Training Loss=0.938744, Validation Loss=1.086811\n",
      "Epoch 158 Training Loss=0.938183, Validation Loss=1.087369\n",
      "Epoch 159 Training Loss=0.937632, Validation Loss=1.087910\n",
      "Epoch 160 Training Loss=0.937090, Validation Loss=1.088434\n",
      "Epoch 161 Training Loss=0.936558, Validation Loss=1.088942\n",
      "Epoch 162 Training Loss=0.936034, Validation Loss=1.089436\n",
      "Epoch 163 Training Loss=0.935519, Validation Loss=1.089915\n",
      "Epoch 164 Training Loss=0.935013, Validation Loss=1.090382\n",
      "Epoch 165 Training Loss=0.934515, Validation Loss=1.090837\n",
      "Epoch 166 Training Loss=0.934025, Validation Loss=1.091280\n",
      "Epoch 167 Training Loss=0.933543, Validation Loss=1.091713\n",
      "Epoch 168 Training Loss=0.933068, Validation Loss=1.092136\n",
      "Epoch 169 Training Loss=0.932600, Validation Loss=1.092551\n",
      "Epoch 170 Training Loss=0.932139, Validation Loss=1.092957\n",
      "Epoch 171 Training Loss=0.931685, Validation Loss=1.093356\n",
      "Epoch 172 Training Loss=0.931237, Validation Loss=1.093747\n",
      "Epoch 173 Training Loss=0.930795, Validation Loss=1.094132\n",
      "Epoch 174 Training Loss=0.930359, Validation Loss=1.094511\n",
      "Epoch 175 Training Loss=0.929928, Validation Loss=1.094885\n",
      "Epoch 176 Training Loss=0.929502, Validation Loss=1.095254\n",
      "Epoch 177 Training Loss=0.929081, Validation Loss=1.095618\n",
      "Epoch 178 Training Loss=0.928665, Validation Loss=1.095979\n",
      "Epoch 179 Training Loss=0.928254, Validation Loss=1.096335\n",
      "Epoch 180 Training Loss=0.927846, Validation Loss=1.096689\n",
      "Epoch 181 Training Loss=0.927443, Validation Loss=1.097039\n",
      "Epoch 182 Training Loss=0.927043, Validation Loss=1.097388\n",
      "Epoch 183 Training Loss=0.926648, Validation Loss=1.097734\n",
      "Epoch 184 Training Loss=0.926255, Validation Loss=1.098078\n",
      "Epoch 185 Training Loss=0.925866, Validation Loss=1.098421\n",
      "Epoch 186 Training Loss=0.925480, Validation Loss=1.098763\n",
      "Epoch 187 Training Loss=0.925098, Validation Loss=1.099105\n",
      "Epoch 188 Training Loss=0.924718, Validation Loss=1.099446\n",
      "Epoch 189 Training Loss=0.924342, Validation Loss=1.099787\n",
      "Epoch 190 Training Loss=0.923968, Validation Loss=1.100128\n",
      "Epoch 191 Training Loss=0.923598, Validation Loss=1.100470\n",
      "Epoch 192 Training Loss=0.923230, Validation Loss=1.100812\n",
      "Epoch 193 Training Loss=0.922865, Validation Loss=1.101156\n",
      "Epoch 194 Training Loss=0.922502, Validation Loss=1.101500\n",
      "Epoch 195 Training Loss=0.922143, Validation Loss=1.101846\n",
      "Epoch 196 Training Loss=0.921786, Validation Loss=1.102194\n",
      "Epoch 197 Training Loss=0.921432, Validation Loss=1.102543\n",
      "Epoch 198 Training Loss=0.921080, Validation Loss=1.102894\n",
      "Epoch 199 Training Loss=0.920732, Validation Loss=1.103246\n",
      "Epoch 0 Training Loss=1.094252, Validation Loss=0.945947\n",
      "Epoch 1 Training Loss=1.147307, Validation Loss=1.019416\n",
      "Epoch 2 Training Loss=1.180434, Validation Loss=1.020835\n",
      "Epoch 3 Training Loss=1.167539, Validation Loss=1.026098\n",
      "Epoch 4 Training Loss=1.137664, Validation Loss=1.021014\n",
      "Epoch 5 Training Loss=1.118708, Validation Loss=1.009158\n",
      "Epoch 6 Training Loss=1.109830, Validation Loss=0.998849\n",
      "Epoch 7 Training Loss=1.104663, Validation Loss=0.990520\n",
      "Epoch 8 Training Loss=1.099333, Validation Loss=0.982481\n",
      "Epoch 9 Training Loss=1.092711, Validation Loss=0.975232\n",
      "Epoch 10 Training Loss=1.085341, Validation Loss=0.970400\n",
      "Epoch 11 Training Loss=1.078118, Validation Loss=0.968547\n",
      "Epoch 12 Training Loss=1.071794, Validation Loss=0.969013\n",
      "Epoch 13 Training Loss=1.066631, Validation Loss=0.970765\n",
      "Epoch 14 Training Loss=1.062474, Validation Loss=0.973070\n",
      "Epoch 15 Training Loss=1.059038, Validation Loss=0.975586\n",
      "Epoch 16 Training Loss=1.056088, Validation Loss=0.978188\n",
      "Epoch 17 Training Loss=1.053480, Validation Loss=0.980829\n",
      "Epoch 18 Training Loss=1.051125, Validation Loss=0.983484\n",
      "Epoch 19 Training Loss=1.048962, Validation Loss=0.986141\n",
      "Epoch 20 Training Loss=1.046949, Validation Loss=0.988791\n",
      "Epoch 21 Training Loss=1.045052, Validation Loss=0.991429\n",
      "Epoch 22 Training Loss=1.043247, Validation Loss=0.994052\n",
      "Epoch 23 Training Loss=1.041517, Validation Loss=0.996659\n",
      "Epoch 24 Training Loss=1.039847, Validation Loss=0.999248\n",
      "Epoch 25 Training Loss=1.038224, Validation Loss=1.001820\n",
      "Epoch 26 Training Loss=1.036642, Validation Loss=1.004372\n",
      "Epoch 27 Training Loss=1.035090, Validation Loss=1.006903\n",
      "Epoch 28 Training Loss=1.033564, Validation Loss=1.009413\n",
      "Epoch 29 Training Loss=1.032058, Validation Loss=1.011899\n",
      "Epoch 30 Training Loss=1.030566, Validation Loss=1.014361\n",
      "Epoch 31 Training Loss=1.029085, Validation Loss=1.016796\n",
      "Epoch 32 Training Loss=1.027609, Validation Loss=1.019204\n",
      "Epoch 33 Training Loss=1.026136, Validation Loss=1.021584\n",
      "Epoch 34 Training Loss=1.024662, Validation Loss=1.023937\n",
      "Epoch 35 Training Loss=1.023185, Validation Loss=1.026261\n",
      "Epoch 36 Training Loss=1.021700, Validation Loss=1.028559\n",
      "Epoch 37 Training Loss=1.020208, Validation Loss=1.030833\n",
      "Epoch 38 Training Loss=1.018704, Validation Loss=1.033083\n",
      "Epoch 39 Training Loss=1.017189, Validation Loss=1.035314\n",
      "Epoch 40 Training Loss=1.015660, Validation Loss=1.037527\n",
      "Epoch 41 Training Loss=1.014116, Validation Loss=1.039725\n",
      "Epoch 42 Training Loss=1.012558, Validation Loss=1.041911\n",
      "Epoch 43 Training Loss=1.010985, Validation Loss=1.044089\n",
      "Epoch 44 Training Loss=1.009396, Validation Loss=1.046258\n",
      "Epoch 45 Training Loss=1.007791, Validation Loss=1.048422\n",
      "Epoch 46 Training Loss=1.006171, Validation Loss=1.050582\n",
      "Epoch 47 Training Loss=1.004535, Validation Loss=1.052738\n",
      "Epoch 48 Training Loss=1.002884, Validation Loss=1.054890\n",
      "Epoch 49 Training Loss=1.001218, Validation Loss=1.057038\n",
      "Epoch 50 Training Loss=0.999538, Validation Loss=1.059182\n",
      "Epoch 51 Training Loss=0.997843, Validation Loss=1.061322\n",
      "Epoch 52 Training Loss=0.996136, Validation Loss=1.063457\n",
      "Epoch 53 Training Loss=0.994416, Validation Loss=1.065586\n",
      "Epoch 54 Training Loss=0.992685, Validation Loss=1.067711\n",
      "Epoch 55 Training Loss=0.990945, Validation Loss=1.069831\n",
      "Epoch 56 Training Loss=0.989198, Validation Loss=1.071945\n",
      "Epoch 57 Training Loss=0.987446, Validation Loss=1.074054\n",
      "Epoch 58 Training Loss=0.985691, Validation Loss=1.076158\n",
      "Epoch 59 Training Loss=0.983935, Validation Loss=1.078255\n",
      "Epoch 60 Training Loss=0.982182, Validation Loss=1.080343\n",
      "Epoch 61 Training Loss=0.980433, Validation Loss=1.082423\n",
      "Epoch 62 Training Loss=0.978690, Validation Loss=1.084491\n",
      "Epoch 63 Training Loss=0.976956, Validation Loss=1.086547\n",
      "Epoch 64 Training Loss=0.975232, Validation Loss=1.088588\n",
      "Epoch 65 Training Loss=0.973518, Validation Loss=1.090611\n",
      "Epoch 66 Training Loss=0.971816, Validation Loss=1.092615\n",
      "Epoch 67 Training Loss=0.970125, Validation Loss=1.094598\n",
      "Epoch 68 Training Loss=0.968445, Validation Loss=1.096557\n",
      "Epoch 69 Training Loss=0.966776, Validation Loss=1.098489\n",
      "Epoch 70 Training Loss=0.965116, Validation Loss=1.100393\n",
      "Epoch 71 Training Loss=0.963464, Validation Loss=1.102265\n",
      "Epoch 72 Training Loss=0.961819, Validation Loss=1.104106\n",
      "Epoch 73 Training Loss=0.960179, Validation Loss=1.105911\n",
      "Epoch 74 Training Loss=0.958541, Validation Loss=1.107680\n",
      "Epoch 75 Training Loss=0.956905, Validation Loss=1.109410\n",
      "Epoch 76 Training Loss=0.955269, Validation Loss=1.111102\n",
      "Epoch 77 Training Loss=0.953630, Validation Loss=1.112752\n",
      "Epoch 78 Training Loss=0.951987, Validation Loss=1.114362\n",
      "Epoch 79 Training Loss=0.950339, Validation Loss=1.115930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Training Loss=0.948684, Validation Loss=1.117455\n",
      "Epoch 81 Training Loss=0.947022, Validation Loss=1.118938\n",
      "Epoch 82 Training Loss=0.945351, Validation Loss=1.120378\n",
      "Epoch 83 Training Loss=0.943671, Validation Loss=1.121776\n",
      "Epoch 84 Training Loss=0.941982, Validation Loss=1.123132\n",
      "Epoch 85 Training Loss=0.940283, Validation Loss=1.124447\n",
      "Epoch 86 Training Loss=0.938574, Validation Loss=1.125722\n",
      "Epoch 87 Training Loss=0.936856, Validation Loss=1.126959\n",
      "Epoch 88 Training Loss=0.935128, Validation Loss=1.128158\n",
      "Epoch 89 Training Loss=0.933392, Validation Loss=1.129323\n",
      "Epoch 90 Training Loss=0.931647, Validation Loss=1.130454\n",
      "Epoch 91 Training Loss=0.929895, Validation Loss=1.131554\n",
      "Epoch 92 Training Loss=0.928136, Validation Loss=1.132626\n",
      "Epoch 93 Training Loss=0.926372, Validation Loss=1.133672\n",
      "Epoch 94 Training Loss=0.924602, Validation Loss=1.134695\n",
      "Epoch 95 Training Loss=0.922828, Validation Loss=1.135696\n",
      "Epoch 96 Training Loss=0.921051, Validation Loss=1.136679\n",
      "Epoch 97 Training Loss=0.919272, Validation Loss=1.137646\n",
      "Epoch 98 Training Loss=0.917494, Validation Loss=1.138598\n",
      "Epoch 99 Training Loss=0.915716, Validation Loss=1.139538\n",
      "Epoch 100 Training Loss=0.913940, Validation Loss=1.140465\n",
      "Epoch 101 Training Loss=0.912169, Validation Loss=1.141381\n",
      "Epoch 102 Training Loss=0.910404, Validation Loss=1.142285\n",
      "Epoch 103 Training Loss=0.908647, Validation Loss=1.143179\n",
      "Epoch 104 Training Loss=0.906898, Validation Loss=1.144060\n",
      "Epoch 105 Training Loss=0.905161, Validation Loss=1.144928\n",
      "Epoch 106 Training Loss=0.903436, Validation Loss=1.145783\n",
      "Epoch 107 Training Loss=0.901725, Validation Loss=1.146622\n",
      "Epoch 108 Training Loss=0.900029, Validation Loss=1.147444\n",
      "Epoch 109 Training Loss=0.898349, Validation Loss=1.148249\n",
      "Epoch 110 Training Loss=0.896686, Validation Loss=1.149034\n",
      "Epoch 111 Training Loss=0.895041, Validation Loss=1.149799\n",
      "Epoch 112 Training Loss=0.893413, Validation Loss=1.150542\n",
      "Epoch 113 Training Loss=0.891803, Validation Loss=1.151265\n",
      "Epoch 114 Training Loss=0.890211, Validation Loss=1.151966\n",
      "Epoch 115 Training Loss=0.888636, Validation Loss=1.152648\n",
      "Epoch 116 Training Loss=0.887077, Validation Loss=1.153312\n",
      "Epoch 117 Training Loss=0.885534, Validation Loss=1.153962\n",
      "Epoch 118 Training Loss=0.884006, Validation Loss=1.154602\n",
      "Epoch 119 Training Loss=0.882491, Validation Loss=1.155238\n",
      "Epoch 120 Training Loss=0.880987, Validation Loss=1.155878\n",
      "Epoch 121 Training Loss=0.879493, Validation Loss=1.156530\n",
      "Epoch 122 Training Loss=0.878007, Validation Loss=1.157204\n",
      "Epoch 123 Training Loss=0.876525, Validation Loss=1.157913\n",
      "Epoch 124 Training Loss=0.875044, Validation Loss=1.158669\n",
      "Epoch 125 Training Loss=0.873563, Validation Loss=1.159484\n",
      "Epoch 126 Training Loss=0.872077, Validation Loss=1.160370\n",
      "Epoch 127 Training Loss=0.870586, Validation Loss=1.161340\n",
      "Epoch 128 Training Loss=0.869090, Validation Loss=1.162402\n",
      "Epoch 129 Training Loss=0.867592, Validation Loss=1.163563\n",
      "Epoch 130 Training Loss=0.866101, Validation Loss=1.164827\n",
      "Epoch 131 Training Loss=0.864624, Validation Loss=1.166197\n",
      "Epoch 132 Training Loss=0.863171, Validation Loss=1.167672\n",
      "Epoch 133 Training Loss=0.861746, Validation Loss=1.169250\n",
      "Epoch 134 Training Loss=0.860349, Validation Loss=1.170928\n",
      "Epoch 135 Training Loss=0.858976, Validation Loss=1.172702\n",
      "Epoch 136 Training Loss=0.857621, Validation Loss=1.174568\n",
      "Epoch 137 Training Loss=0.856278, Validation Loss=1.176520\n",
      "Epoch 138 Training Loss=0.854940, Validation Loss=1.178551\n",
      "Epoch 139 Training Loss=0.853606, Validation Loss=1.180650\n",
      "Epoch 140 Training Loss=0.852274, Validation Loss=1.182806\n",
      "Epoch 141 Training Loss=0.850943, Validation Loss=1.185004\n",
      "Epoch 142 Training Loss=0.849616, Validation Loss=1.187225\n",
      "Epoch 143 Training Loss=0.848295, Validation Loss=1.189450\n",
      "Epoch 144 Training Loss=0.846984, Validation Loss=1.191659\n",
      "Epoch 145 Training Loss=0.845687, Validation Loss=1.193829\n",
      "Epoch 146 Training Loss=0.844410, Validation Loss=1.195937\n",
      "Epoch 147 Training Loss=0.843156, Validation Loss=1.197958\n",
      "Epoch 148 Training Loss=0.841932, Validation Loss=1.199870\n",
      "Epoch 149 Training Loss=0.840742, Validation Loss=1.201647\n",
      "Epoch 150 Training Loss=0.839588, Validation Loss=1.203270\n",
      "Epoch 151 Training Loss=0.838476, Validation Loss=1.204720\n",
      "Epoch 152 Training Loss=0.837405, Validation Loss=1.205980\n",
      "Epoch 153 Training Loss=0.836377, Validation Loss=1.207039\n",
      "Epoch 154 Training Loss=0.835391, Validation Loss=1.207888\n",
      "Epoch 155 Training Loss=0.834446, Validation Loss=1.208527\n",
      "Epoch 156 Training Loss=0.833540, Validation Loss=1.208955\n",
      "Epoch 157 Training Loss=0.832668, Validation Loss=1.209178\n",
      "Epoch 158 Training Loss=0.831829, Validation Loss=1.209207\n",
      "Epoch 159 Training Loss=0.831019, Validation Loss=1.209057\n",
      "Epoch 160 Training Loss=0.830234, Validation Loss=1.208746\n",
      "Epoch 161 Training Loss=0.829471, Validation Loss=1.208296\n",
      "Epoch 162 Training Loss=0.828727, Validation Loss=1.207734\n",
      "Epoch 163 Training Loss=0.827998, Validation Loss=1.207088\n",
      "Epoch 164 Training Loss=0.827283, Validation Loss=1.206391\n",
      "Epoch 165 Training Loss=0.826578, Validation Loss=1.205674\n",
      "Epoch 166 Training Loss=0.825880, Validation Loss=1.204975\n",
      "Epoch 167 Training Loss=0.825188, Validation Loss=1.204328\n",
      "Epoch 168 Training Loss=0.824498, Validation Loss=1.203769\n",
      "Epoch 169 Training Loss=0.823807, Validation Loss=1.203331\n",
      "Epoch 170 Training Loss=0.823112, Validation Loss=1.203050\n",
      "Epoch 171 Training Loss=0.822409, Validation Loss=1.202952\n",
      "Epoch 172 Training Loss=0.821696, Validation Loss=1.203067\n",
      "Epoch 173 Training Loss=0.820970, Validation Loss=1.203416\n",
      "Epoch 174 Training Loss=0.820228, Validation Loss=1.204017\n",
      "Epoch 175 Training Loss=0.819468, Validation Loss=1.204885\n",
      "Epoch 176 Training Loss=0.818690, Validation Loss=1.206027\n",
      "Epoch 177 Training Loss=0.817893, Validation Loss=1.207448\n",
      "Epoch 178 Training Loss=0.817078, Validation Loss=1.209147\n",
      "Epoch 179 Training Loss=0.816247, Validation Loss=1.211121\n",
      "Epoch 180 Training Loss=0.815403, Validation Loss=1.213362\n",
      "Epoch 181 Training Loss=0.814549, Validation Loss=1.215859\n",
      "Epoch 182 Training Loss=0.813689, Validation Loss=1.218600\n",
      "Epoch 183 Training Loss=0.812830, Validation Loss=1.221572\n",
      "Epoch 184 Training Loss=0.811978, Validation Loss=1.224759\n",
      "Epoch 185 Training Loss=0.811140, Validation Loss=1.228142\n",
      "Epoch 186 Training Loss=0.810322, Validation Loss=1.231706\n",
      "Epoch 187 Training Loss=0.809535, Validation Loss=1.235429\n",
      "Epoch 188 Training Loss=0.808784, Validation Loss=1.239293\n",
      "Epoch 189 Training Loss=0.808081, Validation Loss=1.243274\n",
      "Epoch 190 Training Loss=0.807434, Validation Loss=1.247351\n",
      "Epoch 191 Training Loss=0.806851, Validation Loss=1.251497\n",
      "Epoch 192 Training Loss=0.806343, Validation Loss=1.255687\n",
      "Epoch 193 Training Loss=0.805917, Validation Loss=1.259893\n",
      "Epoch 194 Training Loss=0.805584, Validation Loss=1.264084\n",
      "Epoch 195 Training Loss=0.805352, Validation Loss=1.268227\n",
      "Epoch 196 Training Loss=0.805231, Validation Loss=1.272286\n",
      "Epoch 197 Training Loss=0.805228, Validation Loss=1.276224\n",
      "Epoch 198 Training Loss=0.805350, Validation Loss=1.279999\n",
      "Epoch 199 Training Loss=0.805603, Validation Loss=1.283567\n"
     ]
    }
   ],
   "source": [
    "# Treino da rede neural\n",
    "\n",
    "def compute_num_batches(num_samples, batch_size):\n",
    "    return (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "models = []\n",
    "final_loss = []\n",
    "\n",
    "MSE_losses_train = []\n",
    "MSE_losses_val = []\n",
    "\n",
    "MRE_losses_train = []\n",
    "MRE_losses_val = []\n",
    "\n",
    "MAE_losses_train = []\n",
    "MAE_losses_val = []\n",
    "\n",
    "parameters = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for momentum in momentum_values:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for weight_decay in weight_decays:\n",
    "\n",
    "                current_MSE_train = []\n",
    "                current_MSE_val = []\n",
    "\n",
    "                current_MRE_train = []\n",
    "                current_MRE_val = []\n",
    "\n",
    "                current_MAE_train = []\n",
    "                current_MAE_val = []\n",
    "\n",
    "                # Definir o modelo MLP\n",
    "                model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "                # Definir a função de perda e o otimizador\n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay = weight_decay)\n",
    "                \n",
    "                parameters.append({\"hidden_size\" : hidden_size,\n",
    "                                   \"learning_rate\": learning_rate,\n",
    "                                   \"momentum\": momentum, \n",
    "                                   \"weight_decay\": weight_decay})\n",
    "\n",
    "                # Loop de treinamento\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()  # Definir o modelo para o modo de treinamento\n",
    "                    running_loss = 0.0\n",
    "                    running_mre = 0.0\n",
    "                    running_mae = 0.0\n",
    "\n",
    "                    num_batches = compute_num_batches(x_train.shape[0], batch_size)\n",
    "                    #with tqdm.trange(num_batches, unit=\"batch\", mininterval=0) as bar:\n",
    "                        #bar.set_description(f\"Epoch {epoch}\")\n",
    "                        #for batch in bar:\n",
    "                    for batch in range(num_batches):\n",
    "                            # Obter o lote atual\n",
    "                            start_idx = batch * batch_size\n",
    "                            end_idx = min((batch + 1) * batch_size, x_train.shape[0])\n",
    "\n",
    "                            inputs = x_train[start_idx:end_idx]\n",
    "                            targets = y_train[start_idx:end_idx]\n",
    "\n",
    "                            # Zerar os gradientes acumulados\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            # Forward pass\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, targets)\n",
    "                            mre = mean_absolute_percentage_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "                            mae = mean_absolute_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "\n",
    "                            # Backward pass e otimização\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                            # Atualizar a perda acumulada\n",
    "                            running_loss += loss.item() * inputs.size(0)\n",
    "                            running_mre +=  mre * inputs.size(0)\n",
    "                            running_mae +=  mae * inputs.size(0)\n",
    "                            #bar.set_postfix(\n",
    "                            #    loss=float(running_loss)\n",
    "                            #)\n",
    "\n",
    "                        #print(loss.item())\n",
    "\n",
    "                    # Calcular a perda média do epoch\n",
    "                    epoch_loss = running_loss / x_train.shape[0]\n",
    "                    epoch_mre = running_mre/ x_train.shape[0]\n",
    "                    epoch_mae = running_mae/ x_train.shape[0]\n",
    "\n",
    "                    # Avaliar o modelo no conjunto de validação\n",
    "                    model.eval()  # Definir o modelo para o modo de avaliação\n",
    "                    val_outputs = model(x_valid)\n",
    "\n",
    "                    val_loss = criterion(val_outputs, y_valid).item()\n",
    "                    val_mre = mean_absolute_percentage_error(y_valid.detach().numpy(), val_outputs.detach().numpy())\n",
    "                    val_mae = mean_absolute_error(y_valid.detach().numpy(), val_outputs.detach().numpy())\n",
    "\n",
    "                    # Imprimir as métricas do epoch\n",
    "                    #print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.6f}, Validation Loss: {val_loss:.6f}\")\n",
    "                    print(f\"Epoch {epoch} Training Loss={epoch_loss:.6f}, Validation Loss={val_loss:.6f}\")\n",
    "                    current_MSE_train.append(epoch_loss)\n",
    "                    current_MSE_val.append(val_loss)\n",
    "\n",
    "                    current_MRE_train.append(epoch_mre)\n",
    "                    current_MRE_val.append(val_mre)\n",
    "\n",
    "                    current_MAE_train.append(epoch_mae)\n",
    "                    current_MAE_val.append(val_mae)\n",
    "\n",
    "                models.append(model)\n",
    "                final_loss.append(val_loss)\n",
    "\n",
    "                MSE_losses_train.append(current_MSE_train)\n",
    "                MSE_losses_val.append(current_MSE_val)\n",
    "\n",
    "                MRE_losses_train.append(current_MRE_train)\n",
    "                MRE_losses_val.append(current_MRE_val)\n",
    "\n",
    "                MAE_losses_train.append(current_MAE_train)\n",
    "                MAE_losses_val.append(current_MAE_val)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e87cfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 32, 'learning_rate': 0.001, 'momentum': 0.5, 'weight_decay': 0.005}\n"
     ]
    }
   ],
   "source": [
    "menor_valor = min(final_loss)  # Encontra o menor valor na lista\n",
    "indice_menor = final_loss.index(menor_valor)\n",
    "\n",
    "best_model = models[indice_menor]\n",
    "\n",
    "best_MSE_train = MSE_losses_train[indice_menor]\n",
    "best_MSE_val = MSE_losses_val[indice_menor]\n",
    "            \n",
    "best_MRE_train = MRE_losses_train[indice_menor]\n",
    "best_MRE_val = MRE_losses_val[indice_menor]\n",
    "            \n",
    "best_MAE_train = MAE_losses_train[indice_menor]\n",
    "best_MAE_val = MAE_losses_val[indice_menor]\n",
    "\n",
    "print(parameters[indice_menor])\n",
    "parameters_ = parameters[indice_menor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc951f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss=1.190248, Test Loss=1.180375\n",
      "Epoch 1 Training Loss=1.123697, Test Loss=1.130634\n",
      "Epoch 2 Training Loss=1.082005, Test Loss=1.099119\n",
      "Epoch 3 Training Loss=1.055373, Test Loss=1.078604\n",
      "Epoch 4 Training Loss=1.037949, Test Loss=1.064863\n",
      "Epoch 5 Training Loss=1.026262, Test Loss=1.055373\n",
      "Epoch 6 Training Loss=1.018216, Test Loss=1.048606\n",
      "Epoch 7 Training Loss=1.012524, Test Loss=1.043621\n",
      "Epoch 8 Training Loss=1.008386, Test Loss=1.039832\n",
      "Epoch 9 Training Loss=1.005296, Test Loss=1.036868\n",
      "Epoch 10 Training Loss=1.002933, Test Loss=1.034492\n",
      "Epoch 11 Training Loss=1.001085, Test Loss=1.032546\n",
      "Epoch 12 Training Loss=0.999612, Test Loss=1.030925\n",
      "Epoch 13 Training Loss=0.998420, Test Loss=1.029555\n",
      "Epoch 14 Training Loss=0.997443, Test Loss=1.028388\n",
      "Epoch 15 Training Loss=0.996633, Test Loss=1.027382\n",
      "Epoch 16 Training Loss=0.995956, Test Loss=1.026512\n",
      "Epoch 17 Training Loss=0.995386, Test Loss=1.025754\n",
      "Epoch 18 Training Loss=0.994904, Test Loss=1.025092\n",
      "Epoch 19 Training Loss=0.994495, Test Loss=1.024510\n",
      "Epoch 20 Training Loss=0.994145, Test Loss=1.023997\n",
      "Epoch 21 Training Loss=0.993845, Test Loss=1.023544\n",
      "Epoch 22 Training Loss=0.993587, Test Loss=1.023142\n",
      "Epoch 23 Training Loss=0.993364, Test Loss=1.022785\n",
      "Epoch 24 Training Loss=0.993171, Test Loss=1.022466\n",
      "Epoch 25 Training Loss=0.993004, Test Loss=1.022181\n",
      "Epoch 26 Training Loss=0.992858, Test Loss=1.021925\n",
      "Epoch 27 Training Loss=0.992730, Test Loss=1.021694\n",
      "Epoch 28 Training Loss=0.992617, Test Loss=1.021486\n",
      "Epoch 29 Training Loss=0.992517, Test Loss=1.021297\n",
      "Epoch 30 Training Loss=0.992429, Test Loss=1.021126\n",
      "Epoch 31 Training Loss=0.992350, Test Loss=1.020970\n",
      "Epoch 32 Training Loss=0.992280, Test Loss=1.020826\n",
      "Epoch 33 Training Loss=0.992216, Test Loss=1.020695\n",
      "Epoch 34 Training Loss=0.992158, Test Loss=1.020574\n",
      "Epoch 35 Training Loss=0.992106, Test Loss=1.020462\n",
      "Epoch 36 Training Loss=0.992058, Test Loss=1.020359\n",
      "Epoch 37 Training Loss=0.992013, Test Loss=1.020262\n",
      "Epoch 38 Training Loss=0.991972, Test Loss=1.020173\n",
      "Epoch 39 Training Loss=0.991933, Test Loss=1.020089\n",
      "Epoch 40 Training Loss=0.991897, Test Loss=1.020010\n",
      "Epoch 41 Training Loss=0.991863, Test Loss=1.019936\n",
      "Epoch 42 Training Loss=0.991831, Test Loss=1.019866\n",
      "Epoch 43 Training Loss=0.991800, Test Loss=1.019800\n",
      "Epoch 44 Training Loss=0.991771, Test Loss=1.019737\n",
      "Epoch 45 Training Loss=0.991742, Test Loss=1.019678\n",
      "Epoch 46 Training Loss=0.991715, Test Loss=1.019621\n",
      "Epoch 47 Training Loss=0.991689, Test Loss=1.019567\n",
      "Epoch 48 Training Loss=0.991663, Test Loss=1.019515\n",
      "Epoch 49 Training Loss=0.991638, Test Loss=1.019466\n",
      "Epoch 50 Training Loss=0.991614, Test Loss=1.019418\n",
      "Epoch 51 Training Loss=0.991590, Test Loss=1.019373\n",
      "Epoch 52 Training Loss=0.991566, Test Loss=1.019328\n",
      "Epoch 53 Training Loss=0.991543, Test Loss=1.019286\n",
      "Epoch 54 Training Loss=0.991521, Test Loss=1.019245\n",
      "Epoch 55 Training Loss=0.991499, Test Loss=1.019205\n",
      "Epoch 56 Training Loss=0.991477, Test Loss=1.019167\n",
      "Epoch 57 Training Loss=0.991455, Test Loss=1.019130\n",
      "Epoch 58 Training Loss=0.991433, Test Loss=1.019093\n",
      "Epoch 59 Training Loss=0.991412, Test Loss=1.019058\n",
      "Epoch 60 Training Loss=0.991391, Test Loss=1.019024\n",
      "Epoch 61 Training Loss=0.991370, Test Loss=1.018990\n",
      "Epoch 62 Training Loss=0.991349, Test Loss=1.018957\n",
      "Epoch 63 Training Loss=0.991329, Test Loss=1.018925\n",
      "Epoch 64 Training Loss=0.991309, Test Loss=1.018894\n",
      "Epoch 65 Training Loss=0.991288, Test Loss=1.018863\n",
      "Epoch 66 Training Loss=0.991268, Test Loss=1.018833\n",
      "Epoch 67 Training Loss=0.991248, Test Loss=1.018804\n",
      "Epoch 68 Training Loss=0.991228, Test Loss=1.018775\n",
      "Epoch 69 Training Loss=0.991208, Test Loss=1.018747\n",
      "Epoch 70 Training Loss=0.991189, Test Loss=1.018719\n",
      "Epoch 71 Training Loss=0.991169, Test Loss=1.018691\n",
      "Epoch 72 Training Loss=0.991150, Test Loss=1.018664\n",
      "Epoch 73 Training Loss=0.991130, Test Loss=1.018638\n",
      "Epoch 74 Training Loss=0.991111, Test Loss=1.018612\n",
      "Epoch 75 Training Loss=0.991091, Test Loss=1.018586\n",
      "Epoch 76 Training Loss=0.991072, Test Loss=1.018560\n",
      "Epoch 77 Training Loss=0.991053, Test Loss=1.018535\n",
      "Epoch 78 Training Loss=0.991034, Test Loss=1.018510\n",
      "Epoch 79 Training Loss=0.991015, Test Loss=1.018486\n",
      "Epoch 80 Training Loss=0.990996, Test Loss=1.018462\n",
      "Epoch 81 Training Loss=0.990977, Test Loss=1.018438\n",
      "Epoch 82 Training Loss=0.990959, Test Loss=1.018414\n",
      "Epoch 83 Training Loss=0.990940, Test Loss=1.018391\n",
      "Epoch 84 Training Loss=0.990921, Test Loss=1.018367\n",
      "Epoch 85 Training Loss=0.990903, Test Loss=1.018344\n",
      "Epoch 86 Training Loss=0.990884, Test Loss=1.018322\n",
      "Epoch 87 Training Loss=0.990866, Test Loss=1.018299\n",
      "Epoch 88 Training Loss=0.990847, Test Loss=1.018277\n",
      "Epoch 89 Training Loss=0.990829, Test Loss=1.018255\n",
      "Epoch 90 Training Loss=0.990811, Test Loss=1.018233\n",
      "Epoch 91 Training Loss=0.990792, Test Loss=1.018211\n",
      "Epoch 92 Training Loss=0.990774, Test Loss=1.018189\n",
      "Epoch 93 Training Loss=0.990756, Test Loss=1.018168\n",
      "Epoch 94 Training Loss=0.990738, Test Loss=1.018146\n",
      "Epoch 95 Training Loss=0.990720, Test Loss=1.018125\n",
      "Epoch 96 Training Loss=0.990702, Test Loss=1.018104\n",
      "Epoch 97 Training Loss=0.990684, Test Loss=1.018083\n",
      "Epoch 98 Training Loss=0.990666, Test Loss=1.018063\n",
      "Epoch 99 Training Loss=0.990648, Test Loss=1.018042\n",
      "Epoch 100 Training Loss=0.990630, Test Loss=1.018021\n",
      "Epoch 101 Training Loss=0.990613, Test Loss=1.018001\n",
      "Epoch 102 Training Loss=0.990595, Test Loss=1.017981\n",
      "Epoch 103 Training Loss=0.990577, Test Loss=1.017961\n",
      "Epoch 104 Training Loss=0.990560, Test Loss=1.017941\n",
      "Epoch 105 Training Loss=0.990542, Test Loss=1.017921\n",
      "Epoch 106 Training Loss=0.990525, Test Loss=1.017901\n",
      "Epoch 107 Training Loss=0.990507, Test Loss=1.017882\n",
      "Epoch 108 Training Loss=0.990490, Test Loss=1.017862\n",
      "Epoch 109 Training Loss=0.990472, Test Loss=1.017843\n",
      "Epoch 110 Training Loss=0.990455, Test Loss=1.017823\n",
      "Epoch 111 Training Loss=0.990438, Test Loss=1.017804\n",
      "Epoch 112 Training Loss=0.990420, Test Loss=1.017785\n",
      "Epoch 113 Training Loss=0.990403, Test Loss=1.017765\n",
      "Epoch 114 Training Loss=0.990386, Test Loss=1.017746\n",
      "Epoch 115 Training Loss=0.990369, Test Loss=1.017727\n",
      "Epoch 116 Training Loss=0.990352, Test Loss=1.017709\n",
      "Epoch 117 Training Loss=0.990335, Test Loss=1.017690\n",
      "Epoch 118 Training Loss=0.990318, Test Loss=1.017671\n",
      "Epoch 119 Training Loss=0.990301, Test Loss=1.017652\n",
      "Epoch 120 Training Loss=0.990284, Test Loss=1.017634\n",
      "Epoch 121 Training Loss=0.990267, Test Loss=1.017615\n",
      "Epoch 122 Training Loss=0.990250, Test Loss=1.017597\n",
      "Epoch 123 Training Loss=0.990233, Test Loss=1.017578\n",
      "Epoch 124 Training Loss=0.990216, Test Loss=1.017560\n",
      "Epoch 125 Training Loss=0.990200, Test Loss=1.017542\n",
      "Epoch 126 Training Loss=0.990183, Test Loss=1.017524\n",
      "Epoch 127 Training Loss=0.990166, Test Loss=1.017506\n",
      "Epoch 128 Training Loss=0.990149, Test Loss=1.017487\n",
      "Epoch 129 Training Loss=0.990133, Test Loss=1.017470\n",
      "Epoch 130 Training Loss=0.990116, Test Loss=1.017452\n",
      "Epoch 131 Training Loss=0.990100, Test Loss=1.017434\n",
      "Epoch 132 Training Loss=0.990083, Test Loss=1.017416\n",
      "Epoch 133 Training Loss=0.990067, Test Loss=1.017398\n",
      "Epoch 134 Training Loss=0.990050, Test Loss=1.017380\n",
      "Epoch 135 Training Loss=0.990034, Test Loss=1.017363\n",
      "Epoch 136 Training Loss=0.990017, Test Loss=1.017345\n",
      "Epoch 137 Training Loss=0.990001, Test Loss=1.017327\n",
      "Epoch 138 Training Loss=0.989985, Test Loss=1.017310\n",
      "Epoch 139 Training Loss=0.989968, Test Loss=1.017292\n",
      "Epoch 140 Training Loss=0.989952, Test Loss=1.017275\n",
      "Epoch 141 Training Loss=0.989936, Test Loss=1.017258\n",
      "Epoch 142 Training Loss=0.989920, Test Loss=1.017240\n",
      "Epoch 143 Training Loss=0.989904, Test Loss=1.017223\n",
      "Epoch 144 Training Loss=0.989887, Test Loss=1.017206\n",
      "Epoch 145 Training Loss=0.989871, Test Loss=1.017189\n",
      "Epoch 146 Training Loss=0.989855, Test Loss=1.017171\n",
      "Epoch 147 Training Loss=0.989839, Test Loss=1.017154\n",
      "Epoch 148 Training Loss=0.989823, Test Loss=1.017137\n",
      "Epoch 149 Training Loss=0.989807, Test Loss=1.017120\n",
      "Epoch 150 Training Loss=0.989791, Test Loss=1.017103\n",
      "Epoch 151 Training Loss=0.989775, Test Loss=1.017086\n",
      "Epoch 152 Training Loss=0.989759, Test Loss=1.017069\n",
      "Epoch 153 Training Loss=0.989744, Test Loss=1.017052\n",
      "Epoch 154 Training Loss=0.989728, Test Loss=1.017035\n",
      "Epoch 155 Training Loss=0.989712, Test Loss=1.017019\n",
      "Epoch 156 Training Loss=0.989696, Test Loss=1.017002\n",
      "Epoch 157 Training Loss=0.989680, Test Loss=1.016985\n",
      "Epoch 158 Training Loss=0.989665, Test Loss=1.016968\n",
      "Epoch 159 Training Loss=0.989649, Test Loss=1.016952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 Training Loss=0.989633, Test Loss=1.016935\n",
      "Epoch 161 Training Loss=0.989618, Test Loss=1.016918\n",
      "Epoch 162 Training Loss=0.989602, Test Loss=1.016902\n",
      "Epoch 163 Training Loss=0.989586, Test Loss=1.016885\n",
      "Epoch 164 Training Loss=0.989571, Test Loss=1.016868\n",
      "Epoch 165 Training Loss=0.989555, Test Loss=1.016852\n",
      "Epoch 166 Training Loss=0.989540, Test Loss=1.016836\n",
      "Epoch 167 Training Loss=0.989524, Test Loss=1.016819\n",
      "Epoch 168 Training Loss=0.989509, Test Loss=1.016803\n",
      "Epoch 169 Training Loss=0.989493, Test Loss=1.016786\n",
      "Epoch 170 Training Loss=0.989478, Test Loss=1.016770\n",
      "Epoch 171 Training Loss=0.989462, Test Loss=1.016754\n",
      "Epoch 172 Training Loss=0.989447, Test Loss=1.016737\n",
      "Epoch 173 Training Loss=0.989432, Test Loss=1.016721\n",
      "Epoch 174 Training Loss=0.989416, Test Loss=1.016705\n",
      "Epoch 175 Training Loss=0.989401, Test Loss=1.016689\n",
      "Epoch 176 Training Loss=0.989386, Test Loss=1.016672\n",
      "Epoch 177 Training Loss=0.989371, Test Loss=1.016656\n",
      "Epoch 178 Training Loss=0.989355, Test Loss=1.016640\n",
      "Epoch 179 Training Loss=0.989340, Test Loss=1.016624\n",
      "Epoch 180 Training Loss=0.989325, Test Loss=1.016608\n",
      "Epoch 181 Training Loss=0.989310, Test Loss=1.016592\n",
      "Epoch 182 Training Loss=0.989295, Test Loss=1.016576\n",
      "Epoch 183 Training Loss=0.989279, Test Loss=1.016560\n",
      "Epoch 184 Training Loss=0.989264, Test Loss=1.016544\n",
      "Epoch 185 Training Loss=0.989249, Test Loss=1.016528\n",
      "Epoch 186 Training Loss=0.989234, Test Loss=1.016512\n",
      "Epoch 187 Training Loss=0.989219, Test Loss=1.016496\n",
      "Epoch 188 Training Loss=0.989204, Test Loss=1.016480\n",
      "Epoch 189 Training Loss=0.989189, Test Loss=1.016464\n",
      "Epoch 190 Training Loss=0.989174, Test Loss=1.016448\n",
      "Epoch 191 Training Loss=0.989159, Test Loss=1.016432\n",
      "Epoch 192 Training Loss=0.989144, Test Loss=1.016417\n",
      "Epoch 193 Training Loss=0.989129, Test Loss=1.016401\n",
      "Epoch 194 Training Loss=0.989114, Test Loss=1.016385\n",
      "Epoch 195 Training Loss=0.989099, Test Loss=1.016369\n",
      "Epoch 196 Training Loss=0.989085, Test Loss=1.016354\n",
      "Epoch 197 Training Loss=0.989070, Test Loss=1.016338\n",
      "Epoch 198 Training Loss=0.989055, Test Loss=1.016322\n",
      "Epoch 199 Training Loss=0.989040, Test Loss=1.016307\n"
     ]
    }
   ],
   "source": [
    "hidden_size = parameters_[\"hidden_size\"]\n",
    "lr = parameters_[\"learning_rate\"]\n",
    "momentum = parameters_[\"momentum\"]\n",
    "weight_decay = parameters_[\"weight_decay\"]\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "x_train = torch.cat((x_train, x_valid), dim=0)\n",
    "y_train = torch.cat((y_train, y_valid), dim=0)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "current_MSE_train = []\n",
    "current_MSE_test = []\n",
    "\n",
    "current_MRE_train = []\n",
    "current_MRE_test = []\n",
    "\n",
    "current_MAE_train = []\n",
    "current_MAE_test = []\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Definir o modelo para o modo de treinamento\n",
    "    running_loss = 0.0\n",
    "    running_mre = 0.0\n",
    "    running_mae = 0.0\n",
    "\n",
    "    num_batches = compute_num_batches(x_train.shape[0], batch_size)\n",
    "    #with tqdm.trange(num_batches, unit=\"batch\", mininterval=0) as bar:\n",
    "        #bar.set_description(f\"Epoch {epoch}\")\n",
    "    for batch in range(num_batches):\n",
    "            # Obter o lote atual\n",
    "            start_idx = batch * batch_size\n",
    "            end_idx = min((batch + 1) * batch_size, x_train.shape[0])\n",
    "\n",
    "            inputs = x_train[start_idx:end_idx]\n",
    "            targets = y_train[start_idx:end_idx]\n",
    "\n",
    "            # Zerar os gradientes acumulados\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            mre = mean_absolute_percentage_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "            mae = mean_absolute_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "\n",
    "            # Backward pass e otimização\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Atualizar a perda acumulada\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_mre += mre * inputs.size(0)\n",
    "            running_mae += mae * inputs.size(0)\n",
    "            #bar.set_postfix(loss=float(running_loss))\n",
    "\n",
    "    # Calcular a perda média do epoch\n",
    "    epoch_loss = running_loss / x_train.shape[0]\n",
    "    epoch_mre = running_mre / x_train.shape[0]\n",
    "    epoch_mae = running_mae / x_train.shape[0]\n",
    "\n",
    "    # Avaliar o modelo no conjunto de validação\n",
    "    model.eval()  # Definir o modelo para o modo de avaliação\n",
    "    test_outputs = model(x_test)\n",
    "\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    test_mre = mean_absolute_percentage_error(y_test.detach().numpy(), test_outputs.detach().numpy())\n",
    "    test_mae = mean_absolute_error(y_test.detach().numpy(), test_outputs.detach().numpy())\n",
    "\n",
    "    # Imprimir as métricas do epoch\n",
    "    print(f\"Epoch {epoch} Training Loss={epoch_loss:.6f}, Test Loss={test_loss:.6f}\")\n",
    "    current_MSE_train.append(epoch_loss)\n",
    "    current_MSE_test.append(test_loss)\n",
    "\n",
    "    current_MRE_train.append(epoch_mre)\n",
    "    current_MRE_test.append(test_mre)\n",
    "\n",
    "    current_MAE_train.append(epoch_mae)\n",
    "    current_MAE_test.append(test_mae)\n",
    "\n",
    "best_MSE_train = current_MSE_train\n",
    "best_MSE_test = current_MSE_test\n",
    "\n",
    "best_MRE_train = current_MRE_train\n",
    "best_MRE_test = current_MRE_test\n",
    "\n",
    "best_MAE_train = current_MAE_train\n",
    "best_MAE_test = current_MAE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf82cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(best_MSE_train) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(epochs, best_MSE_test, 'b', label='Test Cost')\n",
    "ax.plot(epochs, best_MSE_train, 'r', label='Train Cost')\n",
    "plt.title('Losses Cost per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Cost')\n",
    "plt.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d978f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(best_MAE_train) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(epochs, best_MAE_test, 'b', label='Test MAE')\n",
    "ax.plot(epochs, best_MAE_train, 'r', label='Train MAE')\n",
    "plt.title('MAE Cost per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE Cost')\n",
    "plt.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f00752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(best_MRE_train) + 1)\n",
    "\n",
    "best_MRE_test_100 = np.array(best_MRE_test)/100\n",
    "best_MRE_train_100 = np.array(best_MRE_train)/100\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(epochs, best_MRE_test_100, 'b', label='Test MRE')\n",
    "ax.plot(epochs, best_MRE_train_100, 'r', label='Train MRE')\n",
    "plt.title('MRE Cost per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MRE Cost')\n",
    "plt.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236a11ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro(MSE) do teste:  1.0163065195083618\n",
      "MRE do teste:  0.01207611083984375\n",
      "MAE do teste:  0.8307593\n"
     ]
    }
   ],
   "source": [
    "# utilizar o treino\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "test_outputs = model(x_test)\n",
    "test_loss = mse(test_outputs, y_test).item()\n",
    "test_mae = mean_absolute_error(y_test.detach().numpy(), test_outputs.detach().numpy())\n",
    "test_mape = mean_absolute_percentage_error(y_test.detach().numpy(), test_outputs.detach().numpy())\n",
    "\n",
    "print(\"Erro(MSE) do teste: \", test_loss)\n",
    "print(\"MRE do teste: \", test_mape/100)\n",
    "print(\"MAE do teste: \", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b2fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"ama_lista_04/vowel.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b49f9055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 10)\n",
      "(990, 11)\n"
     ]
    }
   ],
   "source": [
    "# Definir os hiperparâmetros\n",
    "input_size = 10  # Tamanho da camada de entrada (9 colunas de entrada - 1 coluna de saída)\n",
    "output_size = 11  # Tamanho da camada de saída (regressão)\n",
    "\n",
    "X = dataset[:, :10]\n",
    "y = dataset[:, [10]]\n",
    "\n",
    "normalizer = Zscore(dataset.shape[1])\n",
    "X = normalizer.scale(X)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y)\n",
    "y = ohe.transform(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x_train, x_test, x_valid = split_train_test_valid(X)\n",
    "\n",
    "y_train, y_test, y_valid = split_train_test_valid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d555a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train: Cross-entropy=2.461312254269918, Accuracy=0.078125\n",
      "Epoch 0 validation: Cross-entropy=2.4341678619384766, Accuracy=0.12121212482452393\n",
      "Epoch 1 train: Cross-entropy=2.4483883645799427, Accuracy=0.0763888888888889\n",
      "Epoch 1 validation: Cross-entropy=2.4264183044433594, Accuracy=0.12121212482452393\n",
      "Epoch 2 train: Cross-entropy=2.4379733403523765, Accuracy=0.078125\n",
      "Epoch 2 validation: Cross-entropy=2.4206771850585938, Accuracy=0.11616161465644836\n",
      "Epoch 3 train: Cross-entropy=2.4297403229607477, Accuracy=0.08159722222222222\n",
      "Epoch 3 validation: Cross-entropy=2.4164083003997803, Accuracy=0.1111111119389534\n",
      "Epoch 4 train: Cross-entropy=2.4231585131751165, Accuracy=0.08159722222222222\n",
      "Epoch 4 validation: Cross-entropy=2.4132373332977295, Accuracy=0.12121212482452393\n",
      "Epoch 5 train: Cross-entropy=2.417848163180881, Accuracy=0.0798611111111111\n",
      "Epoch 5 validation: Cross-entropy=2.4108946323394775, Accuracy=0.1111111119389534\n",
      "Epoch 6 train: Cross-entropy=2.41353087955051, Accuracy=0.0798611111111111\n",
      "Epoch 6 validation: Cross-entropy=2.409184217453003, Accuracy=0.1111111119389534\n",
      "Epoch 7 train: Cross-entropy=2.4099985228644476, Accuracy=0.07291666666666667\n",
      "Epoch 7 validation: Cross-entropy=2.4079599380493164, Accuracy=0.1111111119389534\n",
      "Epoch 8 train: Cross-entropy=2.4070923063490124, Accuracy=0.08854166666666667\n",
      "Epoch 8 validation: Cross-entropy=2.4071097373962402, Accuracy=0.10606060922145844\n",
      "Epoch 9 train: Cross-entropy=2.404689484172397, Accuracy=0.0798611111111111\n",
      "Epoch 9 validation: Cross-entropy=2.4065492153167725, Accuracy=0.10606060922145844\n",
      "Epoch 10 train: Cross-entropy=2.402693854437934, Accuracy=0.0920138888888889\n",
      "Epoch 10 validation: Cross-entropy=2.406212091445923, Accuracy=0.09595959633588791\n",
      "Epoch 11 train: Cross-entropy=2.401029692755805, Accuracy=0.0954861111111111\n",
      "Epoch 11 validation: Cross-entropy=2.4060471057891846, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.399636016951667, Accuracy=0.09027777777777778\n",
      "Epoch 12 validation: Cross-entropy=2.4060137271881104, Accuracy=0.09595959633588791\n",
      "Epoch 13 train: Cross-entropy=2.398464149898953, Accuracy=0.08680555555555555\n",
      "Epoch 13 validation: Cross-entropy=2.406080484390259, Accuracy=0.10101009905338287\n",
      "Epoch 14 train: Cross-entropy=2.397474553849962, Accuracy=0.08506944444444445\n",
      "Epoch 14 validation: Cross-entropy=2.406221628189087, Accuracy=0.09595959633588791\n",
      "Epoch 15 train: Cross-entropy=2.3966352144877114, Accuracy=0.0920138888888889\n",
      "Epoch 15 validation: Cross-entropy=2.4064180850982666, Accuracy=0.09090909361839294\n",
      "Epoch 16 train: Cross-entropy=2.3959199719958835, Accuracy=0.08854166666666667\n",
      "Epoch 16 validation: Cross-entropy=2.40665340423584, Accuracy=0.08585858345031738\n",
      "Epoch 17 train: Cross-entropy=2.3953073157204523, Accuracy=0.09027777777777778\n",
      "Epoch 17 validation: Cross-entropy=2.4069161415100098, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.3947796291775174, Accuracy=0.0920138888888889\n",
      "Epoch 18 validation: Cross-entropy=2.4071953296661377, Accuracy=0.09090909361839294\n",
      "Epoch 19 train: Cross-entropy=2.3943222628699408, Accuracy=0.08680555555555555\n",
      "Epoch 19 validation: Cross-entropy=2.407484531402588, Accuracy=0.10606060922145844\n",
      "Epoch 20 train: Cross-entropy=2.3939235077963934, Accuracy=0.08506944444444445\n",
      "Epoch 20 validation: Cross-entropy=2.4077770709991455, Accuracy=0.10101009905338287\n",
      "Epoch 21 train: Cross-entropy=2.39357324441274, Accuracy=0.08854166666666667\n",
      "Epoch 21 validation: Cross-entropy=2.4080686569213867, Accuracy=0.10101009905338287\n",
      "Epoch 22 train: Cross-entropy=2.3932633664872913, Accuracy=0.08854166666666667\n",
      "Epoch 22 validation: Cross-entropy=2.408356189727783, Accuracy=0.10101009905338287\n",
      "Epoch 23 train: Cross-entropy=2.3929870658450656, Accuracy=0.08854166666666667\n",
      "Epoch 23 validation: Cross-entropy=2.4086363315582275, Accuracy=0.10606060922145844\n",
      "Epoch 24 train: Cross-entropy=2.3927387793858848, Accuracy=0.09027777777777778\n",
      "Epoch 24 validation: Cross-entropy=2.408907890319824, Accuracy=0.10606060922145844\n",
      "Epoch 25 train: Cross-entropy=2.392513712247213, Accuracy=0.09027777777777778\n",
      "Epoch 25 validation: Cross-entropy=2.4091689586639404, Accuracy=0.10606060922145844\n",
      "Epoch 26 train: Cross-entropy=2.392308129204644, Accuracy=0.08854166666666667\n",
      "Epoch 26 validation: Cross-entropy=2.409419298171997, Accuracy=0.10606060922145844\n",
      "Epoch 27 train: Cross-entropy=2.392118798361884, Accuracy=0.08680555555555555\n",
      "Epoch 27 validation: Cross-entropy=2.409658432006836, Accuracy=0.10606060922145844\n",
      "Epoch 28 train: Cross-entropy=2.3919429381688437, Accuracy=0.08854166666666667\n",
      "Epoch 28 validation: Cross-entropy=2.4098854064941406, Accuracy=0.10606060922145844\n",
      "Epoch 29 train: Cross-entropy=2.3917784293492637, Accuracy=0.08680555555555555\n",
      "Epoch 29 validation: Cross-entropy=2.4101006984710693, Accuracy=0.10101009905338287\n",
      "Epoch 30 train: Cross-entropy=2.3916233910454645, Accuracy=0.08680555555555555\n",
      "Epoch 30 validation: Cross-entropy=2.410304546356201, Accuracy=0.10101009905338287\n",
      "Epoch 31 train: Cross-entropy=2.3914762205547757, Accuracy=0.08854166666666667\n",
      "Epoch 31 validation: Cross-entropy=2.4104971885681152, Accuracy=0.10101009905338287\n",
      "Epoch 32 train: Cross-entropy=2.3913358449935913, Accuracy=0.08854166666666667\n",
      "Epoch 32 validation: Cross-entropy=2.4106786251068115, Accuracy=0.10101009905338287\n",
      "Epoch 33 train: Cross-entropy=2.3912009795506797, Accuracy=0.08854166666666667\n",
      "Epoch 33 validation: Cross-entropy=2.4108493328094482, Accuracy=0.10606060922145844\n",
      "Epoch 34 train: Cross-entropy=2.3910708692338734, Accuracy=0.08854166666666667\n",
      "Epoch 34 validation: Cross-entropy=2.411010503768921, Accuracy=0.10606060922145844\n",
      "Epoch 35 train: Cross-entropy=2.3909447722964816, Accuracy=0.08854166666666667\n",
      "Epoch 35 validation: Cross-entropy=2.4111618995666504, Accuracy=0.10606060922145844\n",
      "Epoch 36 train: Cross-entropy=2.3908219469918146, Accuracy=0.08854166666666667\n",
      "Epoch 36 validation: Cross-entropy=2.411303997039795, Accuracy=0.1111111119389534\n",
      "Epoch 37 train: Cross-entropy=2.390702154901293, Accuracy=0.08854166666666667\n",
      "Epoch 37 validation: Cross-entropy=2.411437749862671, Accuracy=0.10606060922145844\n",
      "Epoch 38 train: Cross-entropy=2.390584694014655, Accuracy=0.08854166666666667\n",
      "Epoch 38 validation: Cross-entropy=2.4115633964538574, Accuracy=0.10606060922145844\n",
      "Epoch 39 train: Cross-entropy=2.3904694186316595, Accuracy=0.08854166666666667\n",
      "Epoch 39 validation: Cross-entropy=2.4116814136505127, Accuracy=0.10101009905338287\n",
      "Epoch 40 train: Cross-entropy=2.3903559181425305, Accuracy=0.08680555555555555\n",
      "Epoch 40 validation: Cross-entropy=2.411792039871216, Accuracy=0.10101009905338287\n",
      "Epoch 41 train: Cross-entropy=2.3902439143922596, Accuracy=0.08854166666666667\n",
      "Epoch 41 validation: Cross-entropy=2.4118964672088623, Accuracy=0.10101009905338287\n",
      "Epoch 42 train: Cross-entropy=2.390133327907986, Accuracy=0.09027777777777778\n",
      "Epoch 42 validation: Cross-entropy=2.411994457244873, Accuracy=0.09595959633588791\n",
      "Epoch 43 train: Cross-entropy=2.3900239335166082, Accuracy=0.09027777777777778\n",
      "Epoch 43 validation: Cross-entropy=2.4120869636535645, Accuracy=0.09595959633588791\n",
      "Epoch 44 train: Cross-entropy=2.3899155855178833, Accuracy=0.09027777777777778\n",
      "Epoch 44 validation: Cross-entropy=2.4121735095977783, Accuracy=0.09090909361839294\n",
      "Epoch 45 train: Cross-entropy=2.3898081249660916, Accuracy=0.09027777777777778\n",
      "Epoch 45 validation: Cross-entropy=2.4122555255889893, Accuracy=0.09090909361839294\n",
      "Epoch 46 train: Cross-entropy=2.389701498879327, Accuracy=0.08854166666666667\n",
      "Epoch 46 validation: Cross-entropy=2.4123332500457764, Accuracy=0.08585858345031738\n",
      "Epoch 47 train: Cross-entropy=2.3895956410302057, Accuracy=0.08854166666666667\n",
      "Epoch 47 validation: Cross-entropy=2.4124059677124023, Accuracy=0.08585858345031738\n",
      "Epoch 48 train: Cross-entropy=2.389490458700392, Accuracy=0.08854166666666667\n",
      "Epoch 48 validation: Cross-entropy=2.412475347518921, Accuracy=0.08585858345031738\n",
      "Epoch 49 train: Cross-entropy=2.3893858989079795, Accuracy=0.08854166666666667\n",
      "Epoch 49 validation: Cross-entropy=2.4125406742095947, Accuracy=0.08585858345031738\n",
      "Epoch 50 train: Cross-entropy=2.3892818689346313, Accuracy=0.08680555555555555\n",
      "Epoch 50 validation: Cross-entropy=2.412602424621582, Accuracy=0.08585858345031738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 train: Cross-entropy=2.389178368780348, Accuracy=0.08854166666666667\n",
      "Epoch 51 validation: Cross-entropy=2.412661552429199, Accuracy=0.08585858345031738\n",
      "Epoch 52 train: Cross-entropy=2.389075424936083, Accuracy=0.08854166666666667\n",
      "Epoch 52 validation: Cross-entropy=2.412717342376709, Accuracy=0.08585858345031738\n",
      "Epoch 53 train: Cross-entropy=2.3889728784561157, Accuracy=0.08680555555555555\n",
      "Epoch 53 validation: Cross-entropy=2.4127707481384277, Accuracy=0.08585858345031738\n",
      "Epoch 54 train: Cross-entropy=2.388870848549737, Accuracy=0.08854166666666667\n",
      "Epoch 54 validation: Cross-entropy=2.4128220081329346, Accuracy=0.09090909361839294\n",
      "Epoch 55 train: Cross-entropy=2.3887692160076566, Accuracy=0.09027777777777778\n",
      "Epoch 55 validation: Cross-entropy=2.412870407104492, Accuracy=0.09090909361839294\n",
      "Epoch 56 train: Cross-entropy=2.388668007320828, Accuracy=0.0920138888888889\n",
      "Epoch 56 validation: Cross-entropy=2.412916898727417, Accuracy=0.09090909361839294\n",
      "Epoch 57 train: Cross-entropy=2.3885671032799616, Accuracy=0.0920138888888889\n",
      "Epoch 57 validation: Cross-entropy=2.412961006164551, Accuracy=0.09090909361839294\n",
      "Epoch 58 train: Cross-entropy=2.3884666628307767, Accuracy=0.09722222222222222\n",
      "Epoch 58 validation: Cross-entropy=2.413003921508789, Accuracy=0.09090909361839294\n",
      "Epoch 59 train: Cross-entropy=2.388366593254937, Accuracy=0.09895833333333333\n",
      "Epoch 59 validation: Cross-entropy=2.4130451679229736, Accuracy=0.09090909361839294\n",
      "Epoch 60 train: Cross-entropy=2.3882668018341064, Accuracy=0.09895833333333333\n",
      "Epoch 60 validation: Cross-entropy=2.4130847454071045, Accuracy=0.08585858345031738\n",
      "Epoch 61 train: Cross-entropy=2.3881675137413874, Accuracy=0.09895833333333333\n",
      "Epoch 61 validation: Cross-entropy=2.4131228923797607, Accuracy=0.08585858345031738\n",
      "Epoch 62 train: Cross-entropy=2.388068437576294, Accuracy=0.09895833333333333\n",
      "Epoch 62 validation: Cross-entropy=2.4131598472595215, Accuracy=0.08585858345031738\n",
      "Epoch 63 train: Cross-entropy=2.3879697455300226, Accuracy=0.09895833333333333\n",
      "Epoch 63 validation: Cross-entropy=2.4131956100463867, Accuracy=0.08585858345031738\n",
      "Epoch 64 train: Cross-entropy=2.387871437602573, Accuracy=0.09895833333333333\n",
      "Epoch 64 validation: Cross-entropy=2.4132304191589355, Accuracy=0.08585858345031738\n",
      "Epoch 65 train: Cross-entropy=2.3877733945846558, Accuracy=0.09895833333333333\n",
      "Epoch 65 validation: Cross-entropy=2.413264036178589, Accuracy=0.08585858345031738\n",
      "Epoch 66 train: Cross-entropy=2.3876757091946073, Accuracy=0.10069444444444445\n",
      "Epoch 66 validation: Cross-entropy=2.413296699523926, Accuracy=0.08585858345031738\n",
      "Epoch 67 train: Cross-entropy=2.387578354941474, Accuracy=0.10416666666666667\n",
      "Epoch 67 validation: Cross-entropy=2.4133288860321045, Accuracy=0.08585858345031738\n",
      "Epoch 68 train: Cross-entropy=2.3874813848071628, Accuracy=0.10243055555555555\n",
      "Epoch 68 validation: Cross-entropy=2.4133598804473877, Accuracy=0.08585858345031738\n",
      "Epoch 69 train: Cross-entropy=2.3873845603730945, Accuracy=0.10416666666666667\n",
      "Epoch 69 validation: Cross-entropy=2.4133903980255127, Accuracy=0.08585858345031738\n",
      "Epoch 70 train: Cross-entropy=2.387288212776184, Accuracy=0.10416666666666667\n",
      "Epoch 70 validation: Cross-entropy=2.4134202003479004, Accuracy=0.08585858345031738\n",
      "Epoch 71 train: Cross-entropy=2.387192169825236, Accuracy=0.10243055555555555\n",
      "Epoch 71 validation: Cross-entropy=2.413450002670288, Accuracy=0.08585858345031738\n",
      "Epoch 72 train: Cross-entropy=2.387096325556437, Accuracy=0.10243055555555555\n",
      "Epoch 72 validation: Cross-entropy=2.4134786128997803, Accuracy=0.08585858345031738\n",
      "Epoch 73 train: Cross-entropy=2.38700090514289, Accuracy=0.10243055555555555\n",
      "Epoch 73 validation: Cross-entropy=2.4135069847106934, Accuracy=0.08585858345031738\n",
      "Epoch 74 train: Cross-entropy=2.386905789375305, Accuracy=0.10243055555555555\n",
      "Epoch 74 validation: Cross-entropy=2.4135348796844482, Accuracy=0.08585858345031738\n",
      "Epoch 75 train: Cross-entropy=2.386810885535346, Accuracy=0.10243055555555555\n",
      "Epoch 75 validation: Cross-entropy=2.413562297821045, Accuracy=0.08585858345031738\n",
      "Epoch 76 train: Cross-entropy=2.3867163260777793, Accuracy=0.10243055555555555\n",
      "Epoch 76 validation: Cross-entropy=2.4135892391204834, Accuracy=0.08585858345031738\n",
      "Epoch 77 train: Cross-entropy=2.386622111002604, Accuracy=0.10243055555555555\n",
      "Epoch 77 validation: Cross-entropy=2.4136159420013428, Accuracy=0.08585858345031738\n",
      "Epoch 78 train: Cross-entropy=2.386528147591485, Accuracy=0.10243055555555555\n",
      "Epoch 78 validation: Cross-entropy=2.413642406463623, Accuracy=0.08585858345031738\n",
      "Epoch 79 train: Cross-entropy=2.3864345682991877, Accuracy=0.10243055555555555\n",
      "Epoch 79 validation: Cross-entropy=2.413668632507324, Accuracy=0.08585858345031738\n",
      "Epoch 80 train: Cross-entropy=2.386341174443563, Accuracy=0.10243055555555555\n",
      "Epoch 80 validation: Cross-entropy=2.4136948585510254, Accuracy=0.08585858345031738\n",
      "Epoch 81 train: Cross-entropy=2.3862481911977134, Accuracy=0.10243055555555555\n",
      "Epoch 81 validation: Cross-entropy=2.4137203693389893, Accuracy=0.08585858345031738\n",
      "Epoch 82 train: Cross-entropy=2.386155446370443, Accuracy=0.10243055555555555\n",
      "Epoch 82 validation: Cross-entropy=2.4137461185455322, Accuracy=0.08585858345031738\n",
      "Epoch 83 train: Cross-entropy=2.3860629664527044, Accuracy=0.10416666666666667\n",
      "Epoch 83 validation: Cross-entropy=2.413770914077759, Accuracy=0.08585858345031738\n",
      "Epoch 84 train: Cross-entropy=2.385970777935452, Accuracy=0.10590277777777778\n",
      "Epoch 84 validation: Cross-entropy=2.4137964248657227, Accuracy=0.08585858345031738\n",
      "Epoch 85 train: Cross-entropy=2.3858789205551147, Accuracy=0.1076388888888889\n",
      "Epoch 85 validation: Cross-entropy=2.413821220397949, Accuracy=0.08585858345031738\n",
      "Epoch 86 train: Cross-entropy=2.3857873015933566, Accuracy=0.109375\n",
      "Epoch 86 validation: Cross-entropy=2.413846015930176, Accuracy=0.08585858345031738\n",
      "Epoch 87 train: Cross-entropy=2.385696040259467, Accuracy=0.109375\n",
      "Epoch 87 validation: Cross-entropy=2.4138708114624023, Accuracy=0.08585858345031738\n",
      "Epoch 88 train: Cross-entropy=2.38560512330797, Accuracy=0.1111111111111111\n",
      "Epoch 88 validation: Cross-entropy=2.413895845413208, Accuracy=0.08585858345031738\n",
      "Epoch 89 train: Cross-entropy=2.385514405038622, Accuracy=0.11284722222222222\n",
      "Epoch 89 validation: Cross-entropy=2.4139201641082764, Accuracy=0.08585858345031738\n",
      "Epoch 90 train: Cross-entropy=2.385423951678806, Accuracy=0.11284722222222222\n",
      "Epoch 90 validation: Cross-entropy=2.4139444828033447, Accuracy=0.08080808073282242\n",
      "Epoch 91 train: Cross-entropy=2.3853337499830456, Accuracy=0.11458333333333333\n",
      "Epoch 91 validation: Cross-entropy=2.413968801498413, Accuracy=0.08080808073282242\n",
      "Epoch 92 train: Cross-entropy=2.385243919160631, Accuracy=0.11284722222222222\n",
      "Epoch 92 validation: Cross-entropy=2.4139931201934814, Accuracy=0.08080808073282242\n",
      "Epoch 93 train: Cross-entropy=2.3851543400022717, Accuracy=0.11284722222222222\n",
      "Epoch 93 validation: Cross-entropy=2.414017915725708, Accuracy=0.08080808073282242\n",
      "Epoch 94 train: Cross-entropy=2.3850650125079684, Accuracy=0.11458333333333333\n",
      "Epoch 94 validation: Cross-entropy=2.414041519165039, Accuracy=0.08080808073282242\n",
      "Epoch 95 train: Cross-entropy=2.3849759499231973, Accuracy=0.11805555555555555\n",
      "Epoch 95 validation: Cross-entropy=2.4140658378601074, Accuracy=0.08080808073282242\n",
      "Epoch 96 train: Cross-entropy=2.384887218475342, Accuracy=0.11805555555555555\n",
      "Epoch 96 validation: Cross-entropy=2.414090156555176, Accuracy=0.08080808073282242\n",
      "Epoch 97 train: Cross-entropy=2.3847987386915417, Accuracy=0.11805555555555555\n",
      "Epoch 97 validation: Cross-entropy=2.414114236831665, Accuracy=0.08080808073282242\n",
      "Epoch 98 train: Cross-entropy=2.384710576799181, Accuracy=0.11805555555555555\n",
      "Epoch 98 validation: Cross-entropy=2.4141383171081543, Accuracy=0.08080808073282242\n",
      "Epoch 99 train: Cross-entropy=2.3846225606070623, Accuracy=0.11805555555555555\n",
      "Epoch 99 validation: Cross-entropy=2.4141623973846436, Accuracy=0.08080808073282242\n",
      "Epoch 100 train: Cross-entropy=2.3845349417792425, Accuracy=0.11979166666666667\n",
      "Epoch 100 validation: Cross-entropy=2.414186477661133, Accuracy=0.08080808073282242\n",
      "Epoch 101 train: Cross-entropy=2.384447601106432, Accuracy=0.12152777777777778\n",
      "Epoch 101 validation: Cross-entropy=2.414210557937622, Accuracy=0.08080808073282242\n",
      "Epoch 102 train: Cross-entropy=2.3843604988522, Accuracy=0.1232638888888889\n",
      "Epoch 102 validation: Cross-entropy=2.4142346382141113, Accuracy=0.08080808073282242\n",
      "Epoch 103 train: Cross-entropy=2.384273568789164, Accuracy=0.1232638888888889\n",
      "Epoch 103 validation: Cross-entropy=2.4142587184906006, Accuracy=0.07575757801532745\n",
      "Epoch 104 train: Cross-entropy=2.384187036090427, Accuracy=0.1232638888888889\n",
      "Epoch 104 validation: Cross-entropy=2.4142825603485107, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 train: Cross-entropy=2.3841006888283625, Accuracy=0.1232638888888889\n",
      "Epoch 105 validation: Cross-entropy=2.414306879043579, Accuracy=0.08080808073282242\n",
      "Epoch 106 train: Cross-entropy=2.384014699194166, Accuracy=0.12152777777777778\n",
      "Epoch 106 validation: Cross-entropy=2.4143309593200684, Accuracy=0.08080808073282242\n",
      "Epoch 107 train: Cross-entropy=2.3839289214875965, Accuracy=0.12152777777777778\n",
      "Epoch 107 validation: Cross-entropy=2.4143550395965576, Accuracy=0.08080808073282242\n",
      "Epoch 108 train: Cross-entropy=2.3838433424631753, Accuracy=0.12152777777777778\n",
      "Epoch 108 validation: Cross-entropy=2.414379119873047, Accuracy=0.08080808073282242\n",
      "Epoch 109 train: Cross-entropy=2.383758121066623, Accuracy=0.12152777777777778\n",
      "Epoch 109 validation: Cross-entropy=2.414403200149536, Accuracy=0.08080808073282242\n",
      "Epoch 110 train: Cross-entropy=2.383673111597697, Accuracy=0.1232638888888889\n",
      "Epoch 110 validation: Cross-entropy=2.4144275188446045, Accuracy=0.08080808073282242\n",
      "Epoch 111 train: Cross-entropy=2.38358834054735, Accuracy=0.1232638888888889\n",
      "Epoch 111 validation: Cross-entropy=2.4144515991210938, Accuracy=0.08080808073282242\n",
      "Epoch 112 train: Cross-entropy=2.3835039138793945, Accuracy=0.1232638888888889\n",
      "Epoch 112 validation: Cross-entropy=2.414475917816162, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.383419672648112, Accuracy=0.1232638888888889\n",
      "Epoch 113 validation: Cross-entropy=2.4144997596740723, Accuracy=0.08080808073282242\n",
      "Epoch 114 train: Cross-entropy=2.3833356698354087, Accuracy=0.125\n",
      "Epoch 114 validation: Cross-entropy=2.4145243167877197, Accuracy=0.08080808073282242\n",
      "Epoch 115 train: Cross-entropy=2.3832519319322376, Accuracy=0.125\n",
      "Epoch 115 validation: Cross-entropy=2.414548397064209, Accuracy=0.08080808073282242\n",
      "Epoch 116 train: Cross-entropy=2.383168511920505, Accuracy=0.1267361111111111\n",
      "Epoch 116 validation: Cross-entropy=2.4145727157592773, Accuracy=0.08080808073282242\n",
      "Epoch 117 train: Cross-entropy=2.3830852773454456, Accuracy=0.1267361111111111\n",
      "Epoch 117 validation: Cross-entropy=2.4145970344543457, Accuracy=0.08080808073282242\n",
      "Epoch 118 train: Cross-entropy=2.3830023209253945, Accuracy=0.125\n",
      "Epoch 118 validation: Cross-entropy=2.414621353149414, Accuracy=0.08080808073282242\n",
      "Epoch 119 train: Cross-entropy=2.3829196294148765, Accuracy=0.125\n",
      "Epoch 119 validation: Cross-entropy=2.4146456718444824, Accuracy=0.08080808073282242\n",
      "Epoch 120 train: Cross-entropy=2.3828371498319836, Accuracy=0.1267361111111111\n",
      "Epoch 120 validation: Cross-entropy=2.414669990539551, Accuracy=0.08080808073282242\n",
      "Epoch 121 train: Cross-entropy=2.3827549351586237, Accuracy=0.1267361111111111\n",
      "Epoch 121 validation: Cross-entropy=2.4146945476531982, Accuracy=0.08080808073282242\n",
      "Epoch 122 train: Cross-entropy=2.3826729324128895, Accuracy=0.1267361111111111\n",
      "Epoch 122 validation: Cross-entropy=2.4147188663482666, Accuracy=0.07575757801532745\n",
      "Epoch 123 train: Cross-entropy=2.382591234313117, Accuracy=0.1267361111111111\n",
      "Epoch 123 validation: Cross-entropy=2.414743423461914, Accuracy=0.07575757801532745\n",
      "Epoch 124 train: Cross-entropy=2.3825097481409707, Accuracy=0.1284722222222222\n",
      "Epoch 124 validation: Cross-entropy=2.4147679805755615, Accuracy=0.07575757801532745\n",
      "Epoch 125 train: Cross-entropy=2.382428619596693, Accuracy=0.13020833333333334\n",
      "Epoch 125 validation: Cross-entropy=2.41479229927063, Accuracy=0.07575757801532745\n",
      "Epoch 126 train: Cross-entropy=2.382347491052416, Accuracy=0.13020833333333334\n",
      "Epoch 126 validation: Cross-entropy=2.4148168563842773, Accuracy=0.07575757801532745\n",
      "Epoch 127 train: Cross-entropy=2.38226678636339, Accuracy=0.13020833333333334\n",
      "Epoch 127 validation: Cross-entropy=2.414841413497925, Accuracy=0.07575757801532745\n",
      "Epoch 128 train: Cross-entropy=2.38218625386556, Accuracy=0.13020833333333334\n",
      "Epoch 128 validation: Cross-entropy=2.4148662090301514, Accuracy=0.07575757801532745\n",
      "Epoch 129 train: Cross-entropy=2.382105999522739, Accuracy=0.13020833333333334\n",
      "Epoch 129 validation: Cross-entropy=2.414891004562378, Accuracy=0.07575757801532745\n",
      "Epoch 130 train: Cross-entropy=2.3820259968439736, Accuracy=0.13020833333333334\n",
      "Epoch 130 validation: Cross-entropy=2.414915084838867, Accuracy=0.07575757801532745\n",
      "Epoch 131 train: Cross-entropy=2.3819461398654513, Accuracy=0.1284722222222222\n",
      "Epoch 131 validation: Cross-entropy=2.414940118789673, Accuracy=0.08080808073282242\n",
      "Epoch 132 train: Cross-entropy=2.3818665875328913, Accuracy=0.1284722222222222\n",
      "Epoch 132 validation: Cross-entropy=2.4149646759033203, Accuracy=0.08080808073282242\n",
      "Epoch 133 train: Cross-entropy=2.3817872603734336, Accuracy=0.1267361111111111\n",
      "Epoch 133 validation: Cross-entropy=2.414989471435547, Accuracy=0.08080808073282242\n",
      "Epoch 134 train: Cross-entropy=2.3817081583870783, Accuracy=0.13020833333333334\n",
      "Epoch 134 validation: Cross-entropy=2.4150140285491943, Accuracy=0.08080808073282242\n",
      "Epoch 135 train: Cross-entropy=2.381629321310255, Accuracy=0.13020833333333334\n",
      "Epoch 135 validation: Cross-entropy=2.4150390625, Accuracy=0.08080808073282242\n",
      "Epoch 136 train: Cross-entropy=2.3815506431791515, Accuracy=0.13020833333333334\n",
      "Epoch 136 validation: Cross-entropy=2.4150638580322266, Accuracy=0.08080808073282242\n",
      "Epoch 137 train: Cross-entropy=2.3814722961849637, Accuracy=0.1284722222222222\n",
      "Epoch 137 validation: Cross-entropy=2.415088653564453, Accuracy=0.08080808073282242\n",
      "Epoch 138 train: Cross-entropy=2.3813941611184015, Accuracy=0.13020833333333334\n",
      "Epoch 138 validation: Cross-entropy=2.4151134490966797, Accuracy=0.08080808073282242\n",
      "Epoch 139 train: Cross-entropy=2.381316145261129, Accuracy=0.13020833333333334\n",
      "Epoch 139 validation: Cross-entropy=2.4151382446289062, Accuracy=0.08080808073282242\n",
      "Epoch 140 train: Cross-entropy=2.3812384472952948, Accuracy=0.13194444444444445\n",
      "Epoch 140 validation: Cross-entropy=2.415163278579712, Accuracy=0.08080808073282242\n",
      "Epoch 141 train: Cross-entropy=2.381161000993517, Accuracy=0.13194444444444445\n",
      "Epoch 141 validation: Cross-entropy=2.4151883125305176, Accuracy=0.08080808073282242\n",
      "Epoch 142 train: Cross-entropy=2.3810837401284113, Accuracy=0.13194444444444445\n",
      "Epoch 142 validation: Cross-entropy=2.4152133464813232, Accuracy=0.08080808073282242\n",
      "Epoch 143 train: Cross-entropy=2.381006677945455, Accuracy=0.13194444444444445\n",
      "Epoch 143 validation: Cross-entropy=2.415238618850708, Accuracy=0.08080808073282242\n",
      "Epoch 144 train: Cross-entropy=2.380929880672031, Accuracy=0.13020833333333334\n",
      "Epoch 144 validation: Cross-entropy=2.4152634143829346, Accuracy=0.08080808073282242\n",
      "Epoch 145 train: Cross-entropy=2.380853361553616, Accuracy=0.13194444444444445\n",
      "Epoch 145 validation: Cross-entropy=2.4152884483337402, Accuracy=0.08080808073282242\n",
      "Epoch 146 train: Cross-entropy=2.3807769881354437, Accuracy=0.13194444444444445\n",
      "Epoch 146 validation: Cross-entropy=2.415313720703125, Accuracy=0.08080808073282242\n",
      "Epoch 147 train: Cross-entropy=2.380700800153944, Accuracy=0.13194444444444445\n",
      "Epoch 147 validation: Cross-entropy=2.4153387546539307, Accuracy=0.08080808073282242\n",
      "Epoch 148 train: Cross-entropy=2.380624916818407, Accuracy=0.13194444444444445\n",
      "Epoch 148 validation: Cross-entropy=2.4153637886047363, Accuracy=0.08080808073282242\n",
      "Epoch 149 train: Cross-entropy=2.380549192428589, Accuracy=0.13194444444444445\n",
      "Epoch 149 validation: Cross-entropy=2.4153892993927, Accuracy=0.08080808073282242\n",
      "Epoch 150 train: Cross-entropy=2.3804737594392567, Accuracy=0.13368055555555555\n",
      "Epoch 150 validation: Cross-entropy=2.4154140949249268, Accuracy=0.08080808073282242\n",
      "Epoch 151 train: Cross-entropy=2.380398432413737, Accuracy=0.13194444444444445\n",
      "Epoch 151 validation: Cross-entropy=2.4154396057128906, Accuracy=0.08080808073282242\n",
      "Epoch 152 train: Cross-entropy=2.3803234100341797, Accuracy=0.13368055555555555\n",
      "Epoch 152 validation: Cross-entropy=2.4154646396636963, Accuracy=0.08080808073282242\n",
      "Epoch 153 train: Cross-entropy=2.3802485598458185, Accuracy=0.13368055555555555\n",
      "Epoch 153 validation: Cross-entropy=2.41549015045166, Accuracy=0.08080808073282242\n",
      "Epoch 154 train: Cross-entropy=2.3801739348305597, Accuracy=0.13368055555555555\n",
      "Epoch 154 validation: Cross-entropy=2.415515422821045, Accuracy=0.08080808073282242\n",
      "Epoch 155 train: Cross-entropy=2.3800995614793568, Accuracy=0.13368055555555555\n",
      "Epoch 155 validation: Cross-entropy=2.4155406951904297, Accuracy=0.08080808073282242\n",
      "Epoch 156 train: Cross-entropy=2.380025373564826, Accuracy=0.13368055555555555\n",
      "Epoch 156 validation: Cross-entropy=2.4155659675598145, Accuracy=0.08080808073282242\n",
      "Epoch 157 train: Cross-entropy=2.379951424068875, Accuracy=0.13368055555555555\n",
      "Epoch 157 validation: Cross-entropy=2.4155914783477783, Accuracy=0.08080808073282242\n",
      "Epoch 158 train: Cross-entropy=2.3798776070276895, Accuracy=0.13368055555555555\n",
      "Epoch 158 validation: Cross-entropy=2.415616750717163, Accuracy=0.08080808073282242\n",
      "Epoch 159 train: Cross-entropy=2.379804107877943, Accuracy=0.13368055555555555\n",
      "Epoch 159 validation: Cross-entropy=2.415642261505127, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160 train: Cross-entropy=2.3797307544284396, Accuracy=0.13368055555555555\n",
      "Epoch 160 validation: Cross-entropy=2.415667772293091, Accuracy=0.08080808073282242\n",
      "Epoch 161 train: Cross-entropy=2.379657586415609, Accuracy=0.13368055555555555\n",
      "Epoch 161 validation: Cross-entropy=2.4156930446624756, Accuracy=0.08080808073282242\n",
      "Epoch 162 train: Cross-entropy=2.3795845905939736, Accuracy=0.13368055555555555\n",
      "Epoch 162 validation: Cross-entropy=2.4157185554504395, Accuracy=0.08080808073282242\n",
      "Epoch 163 train: Cross-entropy=2.379511925909254, Accuracy=0.13368055555555555\n",
      "Epoch 163 validation: Cross-entropy=2.4157443046569824, Accuracy=0.08080808073282242\n",
      "Epoch 164 train: Cross-entropy=2.3794393804338245, Accuracy=0.13368055555555555\n",
      "Epoch 164 validation: Cross-entropy=2.415769577026367, Accuracy=0.08080808073282242\n",
      "Epoch 165 train: Cross-entropy=2.3793670336405435, Accuracy=0.13368055555555555\n",
      "Epoch 165 validation: Cross-entropy=2.415794849395752, Accuracy=0.08080808073282242\n",
      "Epoch 166 train: Cross-entropy=2.3792949385113187, Accuracy=0.13368055555555555\n",
      "Epoch 166 validation: Cross-entropy=2.415820837020874, Accuracy=0.08080808073282242\n",
      "Epoch 167 train: Cross-entropy=2.3792231215371027, Accuracy=0.13541666666666666\n",
      "Epoch 167 validation: Cross-entropy=2.415846347808838, Accuracy=0.08080808073282242\n",
      "Epoch 168 train: Cross-entropy=2.37915137079027, Accuracy=0.13368055555555555\n",
      "Epoch 168 validation: Cross-entropy=2.4158718585968018, Accuracy=0.08080808073282242\n",
      "Epoch 169 train: Cross-entropy=2.3790798452165394, Accuracy=0.13368055555555555\n",
      "Epoch 169 validation: Cross-entropy=2.4158973693847656, Accuracy=0.08080808073282242\n",
      "Epoch 170 train: Cross-entropy=2.379008558061388, Accuracy=0.13368055555555555\n",
      "Epoch 170 validation: Cross-entropy=2.4159231185913086, Accuracy=0.08080808073282242\n",
      "Epoch 171 train: Cross-entropy=2.3789374430974326, Accuracy=0.13368055555555555\n",
      "Epoch 171 validation: Cross-entropy=2.4159486293792725, Accuracy=0.08080808073282242\n",
      "Epoch 172 train: Cross-entropy=2.3788666195339627, Accuracy=0.13541666666666666\n",
      "Epoch 172 validation: Cross-entropy=2.4159743785858154, Accuracy=0.08080808073282242\n",
      "Epoch 173 train: Cross-entropy=2.3787958357069225, Accuracy=0.13541666666666666\n",
      "Epoch 173 validation: Cross-entropy=2.4160001277923584, Accuracy=0.08080808073282242\n",
      "Epoch 174 train: Cross-entropy=2.3787253167894153, Accuracy=0.13541666666666666\n",
      "Epoch 174 validation: Cross-entropy=2.4160258769989014, Accuracy=0.08080808073282242\n",
      "Epoch 175 train: Cross-entropy=2.37865510251787, Accuracy=0.13541666666666666\n",
      "Epoch 175 validation: Cross-entropy=2.4160513877868652, Accuracy=0.08080808073282242\n",
      "Epoch 176 train: Cross-entropy=2.378584901491801, Accuracy=0.13541666666666666\n",
      "Epoch 176 validation: Cross-entropy=2.4160773754119873, Accuracy=0.08080808073282242\n",
      "Epoch 177 train: Cross-entropy=2.378515044848124, Accuracy=0.13368055555555555\n",
      "Epoch 177 validation: Cross-entropy=2.416102886199951, Accuracy=0.08080808073282242\n",
      "Epoch 178 train: Cross-entropy=2.3784453206592135, Accuracy=0.13368055555555555\n",
      "Epoch 178 validation: Cross-entropy=2.4161288738250732, Accuracy=0.08080808073282242\n",
      "Epoch 179 train: Cross-entropy=2.3783757819069757, Accuracy=0.13368055555555555\n",
      "Epoch 179 validation: Cross-entropy=2.4161548614501953, Accuracy=0.08080808073282242\n",
      "Epoch 180 train: Cross-entropy=2.3783064815733166, Accuracy=0.13368055555555555\n",
      "Epoch 180 validation: Cross-entropy=2.4161806106567383, Accuracy=0.08080808073282242\n",
      "Epoch 181 train: Cross-entropy=2.3782372739579944, Accuracy=0.13194444444444445\n",
      "Epoch 181 validation: Cross-entropy=2.4162063598632812, Accuracy=0.08080808073282242\n",
      "Epoch 182 train: Cross-entropy=2.378168331252204, Accuracy=0.13368055555555555\n",
      "Epoch 182 validation: Cross-entropy=2.416232109069824, Accuracy=0.08080808073282242\n",
      "Epoch 183 train: Cross-entropy=2.3780995077557034, Accuracy=0.13368055555555555\n",
      "Epoch 183 validation: Cross-entropy=2.416257858276367, Accuracy=0.08080808073282242\n",
      "Epoch 184 train: Cross-entropy=2.3780309624142117, Accuracy=0.13368055555555555\n",
      "Epoch 184 validation: Cross-entropy=2.4162838459014893, Accuracy=0.08080808073282242\n",
      "Epoch 185 train: Cross-entropy=2.3779626025093927, Accuracy=0.13541666666666666\n",
      "Epoch 185 validation: Cross-entropy=2.4163095951080322, Accuracy=0.08080808073282242\n",
      "Epoch 186 train: Cross-entropy=2.3778944280412464, Accuracy=0.13541666666666666\n",
      "Epoch 186 validation: Cross-entropy=2.4163355827331543, Accuracy=0.08080808073282242\n",
      "Epoch 187 train: Cross-entropy=2.3778264125188193, Accuracy=0.13541666666666666\n",
      "Epoch 187 validation: Cross-entropy=2.4163615703582764, Accuracy=0.08080808073282242\n",
      "Epoch 188 train: Cross-entropy=2.377758595678541, Accuracy=0.13541666666666666\n",
      "Epoch 188 validation: Cross-entropy=2.4163873195648193, Accuracy=0.08080808073282242\n",
      "Epoch 189 train: Cross-entropy=2.377690937783983, Accuracy=0.13368055555555555\n",
      "Epoch 189 validation: Cross-entropy=2.4164133071899414, Accuracy=0.08080808073282242\n",
      "Epoch 190 train: Cross-entropy=2.3776234653260975, Accuracy=0.13368055555555555\n",
      "Epoch 190 validation: Cross-entropy=2.4164395332336426, Accuracy=0.08080808073282242\n",
      "Epoch 191 train: Cross-entropy=2.3775561915503607, Accuracy=0.13368055555555555\n",
      "Epoch 191 validation: Cross-entropy=2.4164652824401855, Accuracy=0.08080808073282242\n",
      "Epoch 192 train: Cross-entropy=2.37748916943868, Accuracy=0.13194444444444445\n",
      "Epoch 192 validation: Cross-entropy=2.4164912700653076, Accuracy=0.08080808073282242\n",
      "Epoch 193 train: Cross-entropy=2.377422253290812, Accuracy=0.13194444444444445\n",
      "Epoch 193 validation: Cross-entropy=2.4165172576904297, Accuracy=0.08080808073282242\n",
      "Epoch 194 train: Cross-entropy=2.3773555093341403, Accuracy=0.13368055555555555\n",
      "Epoch 194 validation: Cross-entropy=2.4165432453155518, Accuracy=0.08080808073282242\n",
      "Epoch 195 train: Cross-entropy=2.377288964059618, Accuracy=0.13368055555555555\n",
      "Epoch 195 validation: Cross-entropy=2.416569232940674, Accuracy=0.08080808073282242\n",
      "Epoch 196 train: Cross-entropy=2.3772226174672446, Accuracy=0.13368055555555555\n",
      "Epoch 196 validation: Cross-entropy=2.416595458984375, Accuracy=0.08080808073282242\n",
      "Epoch 197 train: Cross-entropy=2.377156390084161, Accuracy=0.13368055555555555\n",
      "Epoch 197 validation: Cross-entropy=2.416621446609497, Accuracy=0.08080808073282242\n",
      "Epoch 198 train: Cross-entropy=2.377090427610609, Accuracy=0.13194444444444445\n",
      "Epoch 198 validation: Cross-entropy=2.4166476726531982, Accuracy=0.08080808073282242\n",
      "Epoch 199 train: Cross-entropy=2.377024677064684, Accuracy=0.13194444444444445\n",
      "Epoch 199 validation: Cross-entropy=2.4166736602783203, Accuracy=0.08080808073282242\n",
      "Epoch 0 train: Cross-entropy=2.4360869328180947, Accuracy=0.08159722222222222\n",
      "Epoch 0 validation: Cross-entropy=2.46431827545166, Accuracy=0.06565656512975693\n",
      "Epoch 1 train: Cross-entropy=2.425810972849528, Accuracy=0.09027777777777778\n",
      "Epoch 1 validation: Cross-entropy=2.4552252292633057, Accuracy=0.07070706784725189\n",
      "Epoch 2 train: Cross-entropy=2.4181894858678183, Accuracy=0.0920138888888889\n",
      "Epoch 2 validation: Cross-entropy=2.448418617248535, Accuracy=0.05050504952669144\n",
      "Epoch 3 train: Cross-entropy=2.4126424524519177, Accuracy=0.09722222222222222\n",
      "Epoch 3 validation: Cross-entropy=2.4432661533355713, Accuracy=0.07575757801532745\n",
      "Epoch 4 train: Cross-entropy=2.408567229906718, Accuracy=0.0954861111111111\n",
      "Epoch 4 validation: Cross-entropy=2.439328193664551, Accuracy=0.07575757801532745\n",
      "Epoch 5 train: Cross-entropy=2.4055473274654813, Accuracy=0.10069444444444445\n",
      "Epoch 5 validation: Cross-entropy=2.436293601989746, Accuracy=0.08585858345031738\n",
      "Epoch 6 train: Cross-entropy=2.4032897816763983, Accuracy=0.0954861111111111\n",
      "Epoch 6 validation: Cross-entropy=2.4339399337768555, Accuracy=0.08080808073282242\n",
      "Epoch 7 train: Cross-entropy=2.4015858703189426, Accuracy=0.08333333333333333\n",
      "Epoch 7 validation: Cross-entropy=2.4321024417877197, Accuracy=0.08080808073282242\n",
      "Epoch 8 train: Cross-entropy=2.400285177760654, Accuracy=0.078125\n",
      "Epoch 8 validation: Cross-entropy=2.4306602478027344, Accuracy=0.08080808073282242\n",
      "Epoch 9 train: Cross-entropy=2.3992787069744534, Accuracy=0.078125\n",
      "Epoch 9 validation: Cross-entropy=2.4295222759246826, Accuracy=0.08080808073282242\n",
      "Epoch 10 train: Cross-entropy=2.39848702483707, Accuracy=0.078125\n",
      "Epoch 10 validation: Cross-entropy=2.428619146347046, Accuracy=0.08080808073282242\n",
      "Epoch 11 train: Cross-entropy=2.397852076424493, Accuracy=0.078125\n",
      "Epoch 11 validation: Cross-entropy=2.4278998374938965, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.397331608666314, Accuracy=0.078125\n",
      "Epoch 12 validation: Cross-entropy=2.427323341369629, Accuracy=0.07070706784725189\n",
      "Epoch 13 train: Cross-entropy=2.3968944946924844, Accuracy=0.0798611111111111\n",
      "Epoch 13 validation: Cross-entropy=2.426859140396118, Accuracy=0.07070706784725189\n",
      "Epoch 14 train: Cross-entropy=2.3965181244744196, Accuracy=0.08333333333333333\n",
      "Epoch 14 validation: Cross-entropy=2.4264841079711914, Accuracy=0.07070706784725189\n",
      "Epoch 15 train: Cross-entropy=2.3961860736211142, Accuracy=0.08333333333333333\n",
      "Epoch 15 validation: Cross-entropy=2.4261791706085205, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 train: Cross-entropy=2.395886196030511, Accuracy=0.08333333333333333\n",
      "Epoch 16 validation: Cross-entropy=2.4259305000305176, Accuracy=0.07575757801532745\n",
      "Epoch 17 train: Cross-entropy=2.395609829160902, Accuracy=0.08680555555555555\n",
      "Epoch 17 validation: Cross-entropy=2.425726890563965, Accuracy=0.07575757801532745\n",
      "Epoch 18 train: Cross-entropy=2.3953506416744657, Accuracy=0.0920138888888889\n",
      "Epoch 18 validation: Cross-entropy=2.4255595207214355, Accuracy=0.07070706784725189\n",
      "Epoch 19 train: Cross-entropy=2.395103997654385, Accuracy=0.0920138888888889\n",
      "Epoch 19 validation: Cross-entropy=2.4254209995269775, Accuracy=0.07575757801532745\n",
      "Epoch 20 train: Cross-entropy=2.3948667181862726, Accuracy=0.0954861111111111\n",
      "Epoch 20 validation: Cross-entropy=2.425306558609009, Accuracy=0.07575757801532745\n",
      "Epoch 21 train: Cross-entropy=2.3946363263660007, Accuracy=0.09722222222222222\n",
      "Epoch 21 validation: Cross-entropy=2.425211191177368, Accuracy=0.07575757801532745\n",
      "Epoch 22 train: Cross-entropy=2.3944111135270862, Accuracy=0.09722222222222222\n",
      "Epoch 22 validation: Cross-entropy=2.4251317977905273, Accuracy=0.07575757801532745\n",
      "Epoch 23 train: Cross-entropy=2.3941899008221097, Accuracy=0.09895833333333333\n",
      "Epoch 23 validation: Cross-entropy=2.425065279006958, Accuracy=0.07575757801532745\n",
      "Epoch 24 train: Cross-entropy=2.393971800804138, Accuracy=0.10069444444444445\n",
      "Epoch 24 validation: Cross-entropy=2.4250094890594482, Accuracy=0.07575757801532745\n",
      "Epoch 25 train: Cross-entropy=2.3937560982174344, Accuracy=0.10069444444444445\n",
      "Epoch 25 validation: Cross-entropy=2.4249627590179443, Accuracy=0.07575757801532745\n",
      "Epoch 26 train: Cross-entropy=2.3935424619250827, Accuracy=0.10069444444444445\n",
      "Epoch 26 validation: Cross-entropy=2.4249234199523926, Accuracy=0.07575757801532745\n",
      "Epoch 27 train: Cross-entropy=2.393330560790168, Accuracy=0.10069444444444445\n",
      "Epoch 27 validation: Cross-entropy=2.4248905181884766, Accuracy=0.07575757801532745\n",
      "Epoch 28 train: Cross-entropy=2.393120209376017, Accuracy=0.10069444444444445\n",
      "Epoch 28 validation: Cross-entropy=2.4248623847961426, Accuracy=0.07575757801532745\n",
      "Epoch 29 train: Cross-entropy=2.392911050054762, Accuracy=0.10243055555555555\n",
      "Epoch 29 validation: Cross-entropy=2.4248392581939697, Accuracy=0.07575757801532745\n",
      "Epoch 30 train: Cross-entropy=2.3927032550175986, Accuracy=0.10416666666666667\n",
      "Epoch 30 validation: Cross-entropy=2.4248194694519043, Accuracy=0.07575757801532745\n",
      "Epoch 31 train: Cross-entropy=2.392496519618564, Accuracy=0.10243055555555555\n",
      "Epoch 31 validation: Cross-entropy=2.4248032569885254, Accuracy=0.07575757801532745\n",
      "Epoch 32 train: Cross-entropy=2.3922909233305187, Accuracy=0.10243055555555555\n",
      "Epoch 32 validation: Cross-entropy=2.4247889518737793, Accuracy=0.07575757801532745\n",
      "Epoch 33 train: Cross-entropy=2.3920863734351263, Accuracy=0.10243055555555555\n",
      "Epoch 33 validation: Cross-entropy=2.4247775077819824, Accuracy=0.07575757801532745\n",
      "Epoch 34 train: Cross-entropy=2.3918828699323864, Accuracy=0.10243055555555555\n",
      "Epoch 34 validation: Cross-entropy=2.4247677326202393, Accuracy=0.07575757801532745\n",
      "Epoch 35 train: Cross-entropy=2.39168029361301, Accuracy=0.10243055555555555\n",
      "Epoch 35 validation: Cross-entropy=2.424760103225708, Accuracy=0.07575757801532745\n",
      "Epoch 36 train: Cross-entropy=2.391478829913669, Accuracy=0.10243055555555555\n",
      "Epoch 36 validation: Cross-entropy=2.4247539043426514, Accuracy=0.07575757801532745\n",
      "Epoch 37 train: Cross-entropy=2.3912782271703086, Accuracy=0.10243055555555555\n",
      "Epoch 37 validation: Cross-entropy=2.4247488975524902, Accuracy=0.07575757801532745\n",
      "Epoch 38 train: Cross-entropy=2.3910786045922174, Accuracy=0.10416666666666667\n",
      "Epoch 38 validation: Cross-entropy=2.4247450828552246, Accuracy=0.07575757801532745\n",
      "Epoch 39 train: Cross-entropy=2.3908801078796387, Accuracy=0.10416666666666667\n",
      "Epoch 39 validation: Cross-entropy=2.4247422218322754, Accuracy=0.07575757801532745\n",
      "Epoch 40 train: Cross-entropy=2.3906823529137506, Accuracy=0.10590277777777778\n",
      "Epoch 40 validation: Cross-entropy=2.4247405529022217, Accuracy=0.07575757801532745\n",
      "Epoch 41 train: Cross-entropy=2.3904856708314686, Accuracy=0.10590277777777778\n",
      "Epoch 41 validation: Cross-entropy=2.4247395992279053, Accuracy=0.07575757801532745\n",
      "Epoch 42 train: Cross-entropy=2.390289862950643, Accuracy=0.1076388888888889\n",
      "Epoch 42 validation: Cross-entropy=2.4247395992279053, Accuracy=0.07575757801532745\n",
      "Epoch 43 train: Cross-entropy=2.3900951411989, Accuracy=0.109375\n",
      "Epoch 43 validation: Cross-entropy=2.4247398376464844, Accuracy=0.07575757801532745\n",
      "Epoch 44 train: Cross-entropy=2.389901227421231, Accuracy=0.109375\n",
      "Epoch 44 validation: Cross-entropy=2.424741268157959, Accuracy=0.07575757801532745\n",
      "Epoch 45 train: Cross-entropy=2.389708333545261, Accuracy=0.11284722222222222\n",
      "Epoch 45 validation: Cross-entropy=2.4247426986694336, Accuracy=0.07575757801532745\n",
      "Epoch 46 train: Cross-entropy=2.389516274134318, Accuracy=0.1111111111111111\n",
      "Epoch 46 validation: Cross-entropy=2.4247450828552246, Accuracy=0.08080808073282242\n",
      "Epoch 47 train: Cross-entropy=2.389325221379598, Accuracy=0.11284722222222222\n",
      "Epoch 47 validation: Cross-entropy=2.424748182296753, Accuracy=0.08080808073282242\n",
      "Epoch 48 train: Cross-entropy=2.389134989844428, Accuracy=0.11284722222222222\n",
      "Epoch 48 validation: Cross-entropy=2.4247517585754395, Accuracy=0.08080808073282242\n",
      "Epoch 49 train: Cross-entropy=2.3889457252290516, Accuracy=0.11284722222222222\n",
      "Epoch 49 validation: Cross-entropy=2.424755573272705, Accuracy=0.08080808073282242\n",
      "Epoch 50 train: Cross-entropy=2.3887573745515613, Accuracy=0.11284722222222222\n",
      "Epoch 50 validation: Cross-entropy=2.424759864807129, Accuracy=0.08080808073282242\n",
      "Epoch 51 train: Cross-entropy=2.3885698980755277, Accuracy=0.11284722222222222\n",
      "Epoch 51 validation: Cross-entropy=2.424764633178711, Accuracy=0.08080808073282242\n",
      "Epoch 52 train: Cross-entropy=2.3883833752738104, Accuracy=0.11631944444444445\n",
      "Epoch 52 validation: Cross-entropy=2.424769639968872, Accuracy=0.07575757801532745\n",
      "Epoch 53 train: Cross-entropy=2.38819776640998, Accuracy=0.11458333333333333\n",
      "Epoch 53 validation: Cross-entropy=2.4247753620147705, Accuracy=0.07575757801532745\n",
      "Epoch 54 train: Cross-entropy=2.38801289929284, Accuracy=0.11458333333333333\n",
      "Epoch 54 validation: Cross-entropy=2.424781322479248, Accuracy=0.07575757801532745\n",
      "Epoch 55 train: Cross-entropy=2.3878290520773993, Accuracy=0.11284722222222222\n",
      "Epoch 55 validation: Cross-entropy=2.424787998199463, Accuracy=0.07575757801532745\n",
      "Epoch 56 train: Cross-entropy=2.3876459863450794, Accuracy=0.11284722222222222\n",
      "Epoch 56 validation: Cross-entropy=2.4247944355010986, Accuracy=0.07575757801532745\n",
      "Epoch 57 train: Cross-entropy=2.3874638875325522, Accuracy=0.11284722222222222\n",
      "Epoch 57 validation: Cross-entropy=2.424801826477051, Accuracy=0.07575757801532745\n",
      "Epoch 58 train: Cross-entropy=2.3872825569576688, Accuracy=0.11284722222222222\n",
      "Epoch 58 validation: Cross-entropy=2.424809217453003, Accuracy=0.07575757801532745\n",
      "Epoch 59 train: Cross-entropy=2.3871021800571017, Accuracy=0.1111111111111111\n",
      "Epoch 59 validation: Cross-entropy=2.4248170852661133, Accuracy=0.07575757801532745\n",
      "Epoch 60 train: Cross-entropy=2.386922558148702, Accuracy=0.1111111111111111\n",
      "Epoch 60 validation: Cross-entropy=2.424825429916382, Accuracy=0.07575757801532745\n",
      "Epoch 61 train: Cross-entropy=2.3867437971962824, Accuracy=0.1111111111111111\n",
      "Epoch 61 validation: Cross-entropy=2.4248337745666504, Accuracy=0.07575757801532745\n",
      "Epoch 62 train: Cross-entropy=2.3865658971998425, Accuracy=0.1111111111111111\n",
      "Epoch 62 validation: Cross-entropy=2.424842596054077, Accuracy=0.07575757801532745\n",
      "Epoch 63 train: Cross-entropy=2.38638883166843, Accuracy=0.11284722222222222\n",
      "Epoch 63 validation: Cross-entropy=2.424851894378662, Accuracy=0.07575757801532745\n",
      "Epoch 64 train: Cross-entropy=2.386212640338474, Accuracy=0.1111111111111111\n",
      "Epoch 64 validation: Cross-entropy=2.424861192703247, Accuracy=0.07575757801532745\n",
      "Epoch 65 train: Cross-entropy=2.386037270228068, Accuracy=0.11458333333333333\n",
      "Epoch 65 validation: Cross-entropy=2.4248712062835693, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.3858626418643527, Accuracy=0.11805555555555555\n",
      "Epoch 66 validation: Cross-entropy=2.4248812198638916, Accuracy=0.07070706784725189\n",
      "Epoch 67 train: Cross-entropy=2.385688821474711, Accuracy=0.11805555555555555\n",
      "Epoch 67 validation: Cross-entropy=2.424891710281372, Accuracy=0.07070706784725189\n",
      "Epoch 68 train: Cross-entropy=2.385515915022956, Accuracy=0.11805555555555555\n",
      "Epoch 68 validation: Cross-entropy=2.4249024391174316, Accuracy=0.07070706784725189\n",
      "Epoch 69 train: Cross-entropy=2.385343763563368, Accuracy=0.11805555555555555\n",
      "Epoch 69 validation: Cross-entropy=2.4249136447906494, Accuracy=0.07070706784725189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 train: Cross-entropy=2.385172406832377, Accuracy=0.11631944444444445\n",
      "Epoch 70 validation: Cross-entropy=2.424924850463867, Accuracy=0.06565656512975693\n",
      "Epoch 71 train: Cross-entropy=2.38500185807546, Accuracy=0.11631944444444445\n",
      "Epoch 71 validation: Cross-entropy=2.424936532974243, Accuracy=0.06565656512975693\n",
      "Epoch 72 train: Cross-entropy=2.38483202457428, Accuracy=0.11805555555555555\n",
      "Epoch 72 validation: Cross-entropy=2.4249486923217773, Accuracy=0.06565656512975693\n",
      "Epoch 73 train: Cross-entropy=2.384663118256463, Accuracy=0.11805555555555555\n",
      "Epoch 73 validation: Cross-entropy=2.4249606132507324, Accuracy=0.06565656512975693\n",
      "Epoch 74 train: Cross-entropy=2.3844948212305703, Accuracy=0.11805555555555555\n",
      "Epoch 74 validation: Cross-entropy=2.424973249435425, Accuracy=0.06565656512975693\n",
      "Epoch 75 train: Cross-entropy=2.384327385160658, Accuracy=0.11805555555555555\n",
      "Epoch 75 validation: Cross-entropy=2.424985885620117, Accuracy=0.06565656512975693\n",
      "Epoch 76 train: Cross-entropy=2.384160690837436, Accuracy=0.11458333333333333\n",
      "Epoch 76 validation: Cross-entropy=2.4249989986419678, Accuracy=0.06565656512975693\n",
      "Epoch 77 train: Cross-entropy=2.383994870715671, Accuracy=0.11284722222222222\n",
      "Epoch 77 validation: Cross-entropy=2.4250121116638184, Accuracy=0.06565656512975693\n",
      "Epoch 78 train: Cross-entropy=2.38382977909512, Accuracy=0.11458333333333333\n",
      "Epoch 78 validation: Cross-entropy=2.4250259399414062, Accuracy=0.06060606241226196\n",
      "Epoch 79 train: Cross-entropy=2.383665362993876, Accuracy=0.11458333333333333\n",
      "Epoch 79 validation: Cross-entropy=2.4250400066375732, Accuracy=0.06060606241226196\n",
      "Epoch 80 train: Cross-entropy=2.3835016091664634, Accuracy=0.11284722222222222\n",
      "Epoch 80 validation: Cross-entropy=2.425053834915161, Accuracy=0.06060606241226196\n",
      "Epoch 81 train: Cross-entropy=2.383338689804077, Accuracy=0.11284722222222222\n",
      "Epoch 81 validation: Cross-entropy=2.4250683784484863, Accuracy=0.06060606241226196\n",
      "Epoch 82 train: Cross-entropy=2.3831765254338584, Accuracy=0.11284722222222222\n",
      "Epoch 82 validation: Cross-entropy=2.4250831604003906, Accuracy=0.06060606241226196\n",
      "Epoch 83 train: Cross-entropy=2.3830151557922363, Accuracy=0.11458333333333333\n",
      "Epoch 83 validation: Cross-entropy=2.425097703933716, Accuracy=0.0555555559694767\n",
      "Epoch 84 train: Cross-entropy=2.3828545014063516, Accuracy=0.11631944444444445\n",
      "Epoch 84 validation: Cross-entropy=2.4251129627227783, Accuracy=0.0555555559694767\n",
      "Epoch 85 train: Cross-entropy=2.3826944828033447, Accuracy=0.11631944444444445\n",
      "Epoch 85 validation: Cross-entropy=2.42512845993042, Accuracy=0.05050504952669144\n",
      "Epoch 86 train: Cross-entropy=2.3825352324379816, Accuracy=0.11631944444444445\n",
      "Epoch 86 validation: Cross-entropy=2.4251441955566406, Accuracy=0.05050504952669144\n",
      "Epoch 87 train: Cross-entropy=2.382376684082879, Accuracy=0.11631944444444445\n",
      "Epoch 87 validation: Cross-entropy=2.4251596927642822, Accuracy=0.05050504952669144\n",
      "Epoch 88 train: Cross-entropy=2.3822187847561307, Accuracy=0.11979166666666667\n",
      "Epoch 88 validation: Cross-entropy=2.4251763820648193, Accuracy=0.05050504952669144\n",
      "Epoch 89 train: Cross-entropy=2.382061719894409, Accuracy=0.11805555555555555\n",
      "Epoch 89 validation: Cross-entropy=2.4251925945281982, Accuracy=0.05050504952669144\n",
      "Epoch 90 train: Cross-entropy=2.3819053305519953, Accuracy=0.11805555555555555\n",
      "Epoch 90 validation: Cross-entropy=2.4252090454101562, Accuracy=0.05050504952669144\n",
      "Epoch 91 train: Cross-entropy=2.381749603483412, Accuracy=0.11805555555555555\n",
      "Epoch 91 validation: Cross-entropy=2.4252259731292725, Accuracy=0.05050504952669144\n",
      "Epoch 92 train: Cross-entropy=2.381594565179613, Accuracy=0.11979166666666667\n",
      "Epoch 92 validation: Cross-entropy=2.4252431392669678, Accuracy=0.05050504952669144\n",
      "Epoch 93 train: Cross-entropy=2.381440215640598, Accuracy=0.11805555555555555\n",
      "Epoch 93 validation: Cross-entropy=2.425260305404663, Accuracy=0.05050504952669144\n",
      "Epoch 94 train: Cross-entropy=2.3812865813573203, Accuracy=0.11805555555555555\n",
      "Epoch 94 validation: Cross-entropy=2.4252779483795166, Accuracy=0.05050504952669144\n",
      "Epoch 95 train: Cross-entropy=2.38113362259335, Accuracy=0.11631944444444445\n",
      "Epoch 95 validation: Cross-entropy=2.425295829772949, Accuracy=0.05050504952669144\n",
      "Epoch 96 train: Cross-entropy=2.3809813128577337, Accuracy=0.11805555555555555\n",
      "Epoch 96 validation: Cross-entropy=2.425313711166382, Accuracy=0.05050504952669144\n",
      "Epoch 97 train: Cross-entropy=2.380829678641425, Accuracy=0.11805555555555555\n",
      "Epoch 97 validation: Cross-entropy=2.4253320693969727, Accuracy=0.05050504952669144\n",
      "Epoch 98 train: Cross-entropy=2.3806786669625177, Accuracy=0.11805555555555555\n",
      "Epoch 98 validation: Cross-entropy=2.4253504276275635, Accuracy=0.05050504952669144\n",
      "Epoch 99 train: Cross-entropy=2.3805284102757773, Accuracy=0.11979166666666667\n",
      "Epoch 99 validation: Cross-entropy=2.4253690242767334, Accuracy=0.05050504952669144\n",
      "Epoch 100 train: Cross-entropy=2.3803788158628674, Accuracy=0.12152777777777778\n",
      "Epoch 100 validation: Cross-entropy=2.4253883361816406, Accuracy=0.05050504952669144\n",
      "Epoch 101 train: Cross-entropy=2.3802298837237887, Accuracy=0.125\n",
      "Epoch 101 validation: Cross-entropy=2.4254069328308105, Accuracy=0.05050504952669144\n",
      "Epoch 102 train: Cross-entropy=2.380081534385681, Accuracy=0.125\n",
      "Epoch 102 validation: Cross-entropy=2.4254262447357178, Accuracy=0.05050504952669144\n",
      "Epoch 103 train: Cross-entropy=2.3799338340759277, Accuracy=0.1267361111111111\n",
      "Epoch 103 validation: Cross-entropy=2.425445795059204, Accuracy=0.05050504952669144\n",
      "Epoch 104 train: Cross-entropy=2.379786743058099, Accuracy=0.1284722222222222\n",
      "Epoch 104 validation: Cross-entropy=2.4254653453826904, Accuracy=0.05050504952669144\n",
      "Epoch 105 train: Cross-entropy=2.379640367296007, Accuracy=0.1284722222222222\n",
      "Epoch 105 validation: Cross-entropy=2.425485372543335, Accuracy=0.05050504952669144\n",
      "Epoch 106 train: Cross-entropy=2.3794945743348865, Accuracy=0.13020833333333334\n",
      "Epoch 106 validation: Cross-entropy=2.4255053997039795, Accuracy=0.05050504952669144\n",
      "Epoch 107 train: Cross-entropy=2.3793494436475964, Accuracy=0.13020833333333334\n",
      "Epoch 107 validation: Cross-entropy=2.4255259037017822, Accuracy=0.05050504952669144\n",
      "Epoch 108 train: Cross-entropy=2.379204922252231, Accuracy=0.13020833333333334\n",
      "Epoch 108 validation: Cross-entropy=2.425546407699585, Accuracy=0.05050504952669144\n",
      "Epoch 109 train: Cross-entropy=2.3790610366397433, Accuracy=0.13020833333333334\n",
      "Epoch 109 validation: Cross-entropy=2.4255669116973877, Accuracy=0.05050504952669144\n",
      "Epoch 110 train: Cross-entropy=2.378917853037516, Accuracy=0.13020833333333334\n",
      "Epoch 110 validation: Cross-entropy=2.4255876541137695, Accuracy=0.05050504952669144\n",
      "Epoch 111 train: Cross-entropy=2.3787751065360174, Accuracy=0.13194444444444445\n",
      "Epoch 111 validation: Cross-entropy=2.4256088733673096, Accuracy=0.05050504952669144\n",
      "Epoch 112 train: Cross-entropy=2.3786331680085926, Accuracy=0.13368055555555555\n",
      "Epoch 112 validation: Cross-entropy=2.4256300926208496, Accuracy=0.05050504952669144\n",
      "Epoch 113 train: Cross-entropy=2.378491746054755, Accuracy=0.13368055555555555\n",
      "Epoch 113 validation: Cross-entropy=2.4256515502929688, Accuracy=0.05050504952669144\n",
      "Epoch 114 train: Cross-entropy=2.378350853919983, Accuracy=0.13368055555555555\n",
      "Epoch 114 validation: Cross-entropy=2.425673007965088, Accuracy=0.05050504952669144\n",
      "Epoch 115 train: Cross-entropy=2.378210663795471, Accuracy=0.13194444444444445\n",
      "Epoch 115 validation: Cross-entropy=2.4256949424743652, Accuracy=0.05050504952669144\n",
      "Epoch 116 train: Cross-entropy=2.378071043226454, Accuracy=0.13194444444444445\n",
      "Epoch 116 validation: Cross-entropy=2.4257168769836426, Accuracy=0.05050504952669144\n",
      "Epoch 117 train: Cross-entropy=2.377931978967455, Accuracy=0.13194444444444445\n",
      "Epoch 117 validation: Cross-entropy=2.425739049911499, Accuracy=0.05050504952669144\n",
      "Epoch 118 train: Cross-entropy=2.3777935769822864, Accuracy=0.13194444444444445\n",
      "Epoch 118 validation: Cross-entropy=2.4257614612579346, Accuracy=0.04545454680919647\n",
      "Epoch 119 train: Cross-entropy=2.3776557445526123, Accuracy=0.13194444444444445\n",
      "Epoch 119 validation: Cross-entropy=2.425783634185791, Accuracy=0.04545454680919647\n",
      "Epoch 120 train: Cross-entropy=2.3775184684329562, Accuracy=0.13541666666666666\n",
      "Epoch 120 validation: Cross-entropy=2.4258062839508057, Accuracy=0.04545454680919647\n",
      "Epoch 121 train: Cross-entropy=2.377381748623318, Accuracy=0.13541666666666666\n",
      "Epoch 121 validation: Cross-entropy=2.4258294105529785, Accuracy=0.04545454680919647\n",
      "Epoch 122 train: Cross-entropy=2.3772456778420343, Accuracy=0.13541666666666666\n",
      "Epoch 122 validation: Cross-entropy=2.4258522987365723, Accuracy=0.04545454680919647\n",
      "Epoch 123 train: Cross-entropy=2.3771101236343384, Accuracy=0.1388888888888889\n",
      "Epoch 123 validation: Cross-entropy=2.425875186920166, Accuracy=0.04545454680919647\n",
      "Epoch 124 train: Cross-entropy=2.3769751522276135, Accuracy=0.1388888888888889\n",
      "Epoch 124 validation: Cross-entropy=2.425898790359497, Accuracy=0.04545454680919647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 train: Cross-entropy=2.376840737130907, Accuracy=0.1371527777777778\n",
      "Epoch 125 validation: Cross-entropy=2.425922155380249, Accuracy=0.04545454680919647\n",
      "Epoch 126 train: Cross-entropy=2.376706931326124, Accuracy=0.1371527777777778\n",
      "Epoch 126 validation: Cross-entropy=2.42594575881958, Accuracy=0.04545454680919647\n",
      "Epoch 127 train: Cross-entropy=2.3765736156039767, Accuracy=0.1371527777777778\n",
      "Epoch 127 validation: Cross-entropy=2.4259696006774902, Accuracy=0.04545454680919647\n",
      "Epoch 128 train: Cross-entropy=2.37644092241923, Accuracy=0.1371527777777778\n",
      "Epoch 128 validation: Cross-entropy=2.4259936809539795, Accuracy=0.04545454680919647\n",
      "Epoch 129 train: Cross-entropy=2.3763087458080716, Accuracy=0.13541666666666666\n",
      "Epoch 129 validation: Cross-entropy=2.4260177612304688, Accuracy=0.04545454680919647\n",
      "Epoch 130 train: Cross-entropy=2.376177112261454, Accuracy=0.13541666666666666\n",
      "Epoch 130 validation: Cross-entropy=2.426041841506958, Accuracy=0.04545454680919647\n",
      "Epoch 131 train: Cross-entropy=2.3760460217793784, Accuracy=0.13541666666666666\n",
      "Epoch 131 validation: Cross-entropy=2.4260663986206055, Accuracy=0.04545454680919647\n",
      "Epoch 132 train: Cross-entropy=2.3759155140982733, Accuracy=0.13541666666666666\n",
      "Epoch 132 validation: Cross-entropy=2.426090717315674, Accuracy=0.04545454680919647\n",
      "Epoch 133 train: Cross-entropy=2.3757855892181396, Accuracy=0.13541666666666666\n",
      "Epoch 133 validation: Cross-entropy=2.4261155128479004, Accuracy=0.04545454680919647\n",
      "Epoch 134 train: Cross-entropy=2.3756560617023044, Accuracy=0.13541666666666666\n",
      "Epoch 134 validation: Cross-entropy=2.426140308380127, Accuracy=0.04545454680919647\n",
      "Epoch 135 train: Cross-entropy=2.3755271832148233, Accuracy=0.13541666666666666\n",
      "Epoch 135 validation: Cross-entropy=2.4261651039123535, Accuracy=0.05050504952669144\n",
      "Epoch 136 train: Cross-entropy=2.3753987418280706, Accuracy=0.13541666666666666\n",
      "Epoch 136 validation: Cross-entropy=2.4261903762817383, Accuracy=0.05050504952669144\n",
      "Epoch 137 train: Cross-entropy=2.375270883242289, Accuracy=0.13368055555555555\n",
      "Epoch 137 validation: Cross-entropy=2.426215648651123, Accuracy=0.05050504952669144\n",
      "Epoch 138 train: Cross-entropy=2.3751435809665256, Accuracy=0.1371527777777778\n",
      "Epoch 138 validation: Cross-entropy=2.426241159439087, Accuracy=0.05050504952669144\n",
      "Epoch 139 train: Cross-entropy=2.3750167157914905, Accuracy=0.1371527777777778\n",
      "Epoch 139 validation: Cross-entropy=2.426266670227051, Accuracy=0.05050504952669144\n",
      "Epoch 140 train: Cross-entropy=2.374890446662903, Accuracy=0.13541666666666666\n",
      "Epoch 140 validation: Cross-entropy=2.4262924194335938, Accuracy=0.05050504952669144\n",
      "Epoch 141 train: Cross-entropy=2.3747646808624268, Accuracy=0.13541666666666666\n",
      "Epoch 141 validation: Cross-entropy=2.4263181686401367, Accuracy=0.05050504952669144\n",
      "Epoch 142 train: Cross-entropy=2.3746393389172025, Accuracy=0.13368055555555555\n",
      "Epoch 142 validation: Cross-entropy=2.4263439178466797, Accuracy=0.04545454680919647\n",
      "Epoch 143 train: Cross-entropy=2.374514579772949, Accuracy=0.13368055555555555\n",
      "Epoch 143 validation: Cross-entropy=2.4263699054718018, Accuracy=0.04545454680919647\n",
      "Epoch 144 train: Cross-entropy=2.3743903901841907, Accuracy=0.13368055555555555\n",
      "Epoch 144 validation: Cross-entropy=2.426396131515503, Accuracy=0.04545454680919647\n",
      "Epoch 145 train: Cross-entropy=2.37426659795973, Accuracy=0.13541666666666666\n",
      "Epoch 145 validation: Cross-entropy=2.426422357559204, Accuracy=0.04545454680919647\n",
      "Epoch 146 train: Cross-entropy=2.3741433090633817, Accuracy=0.13541666666666666\n",
      "Epoch 146 validation: Cross-entropy=2.4264488220214844, Accuracy=0.04545454680919647\n",
      "Epoch 147 train: Cross-entropy=2.374020602968004, Accuracy=0.13368055555555555\n",
      "Epoch 147 validation: Cross-entropy=2.426475763320923, Accuracy=0.04545454680919647\n",
      "Epoch 148 train: Cross-entropy=2.3738983074824014, Accuracy=0.13368055555555555\n",
      "Epoch 148 validation: Cross-entropy=2.426502227783203, Accuracy=0.04545454680919647\n",
      "Epoch 149 train: Cross-entropy=2.3737766080432467, Accuracy=0.13194444444444445\n",
      "Epoch 149 validation: Cross-entropy=2.4265291690826416, Accuracy=0.04545454680919647\n",
      "Epoch 150 train: Cross-entropy=2.373655252986484, Accuracy=0.13194444444444445\n",
      "Epoch 150 validation: Cross-entropy=2.426555871963501, Accuracy=0.04545454680919647\n",
      "Epoch 151 train: Cross-entropy=2.373534467485216, Accuracy=0.13194444444444445\n",
      "Epoch 151 validation: Cross-entropy=2.4265830516815186, Accuracy=0.05050504952669144\n",
      "Epoch 152 train: Cross-entropy=2.373414158821106, Accuracy=0.13194444444444445\n",
      "Epoch 152 validation: Cross-entropy=2.426610231399536, Accuracy=0.05050504952669144\n",
      "Epoch 153 train: Cross-entropy=2.3732943402396307, Accuracy=0.13194444444444445\n",
      "Epoch 153 validation: Cross-entropy=2.4266371726989746, Accuracy=0.05050504952669144\n",
      "Epoch 154 train: Cross-entropy=2.3731749852498374, Accuracy=0.13194444444444445\n",
      "Epoch 154 validation: Cross-entropy=2.4266648292541504, Accuracy=0.05050504952669144\n",
      "Epoch 155 train: Cross-entropy=2.373056107097202, Accuracy=0.13194444444444445\n",
      "Epoch 155 validation: Cross-entropy=2.426692008972168, Accuracy=0.05050504952669144\n",
      "Epoch 156 train: Cross-entropy=2.3729376792907715, Accuracy=0.13020833333333334\n",
      "Epoch 156 validation: Cross-entropy=2.4267196655273438, Accuracy=0.05050504952669144\n",
      "Epoch 157 train: Cross-entropy=2.372819768057929, Accuracy=0.13194444444444445\n",
      "Epoch 157 validation: Cross-entropy=2.4267475605010986, Accuracy=0.05050504952669144\n",
      "Epoch 158 train: Cross-entropy=2.3727022541893854, Accuracy=0.13194444444444445\n",
      "Epoch 158 validation: Cross-entropy=2.4267752170562744, Accuracy=0.05050504952669144\n",
      "Epoch 159 train: Cross-entropy=2.3725852568944297, Accuracy=0.13194444444444445\n",
      "Epoch 159 validation: Cross-entropy=2.4268031120300293, Accuracy=0.05050504952669144\n",
      "Epoch 160 train: Cross-entropy=2.372468696700202, Accuracy=0.13194444444444445\n",
      "Epoch 160 validation: Cross-entropy=2.4268312454223633, Accuracy=0.05050504952669144\n",
      "Epoch 161 train: Cross-entropy=2.3723526530795627, Accuracy=0.13368055555555555\n",
      "Epoch 161 validation: Cross-entropy=2.4268593788146973, Accuracy=0.05050504952669144\n",
      "Epoch 162 train: Cross-entropy=2.372237033314175, Accuracy=0.13368055555555555\n",
      "Epoch 162 validation: Cross-entropy=2.4268875122070312, Accuracy=0.04545454680919647\n",
      "Epoch 163 train: Cross-entropy=2.3721217711766562, Accuracy=0.13541666666666666\n",
      "Epoch 163 validation: Cross-entropy=2.4269158840179443, Accuracy=0.04545454680919647\n",
      "Epoch 164 train: Cross-entropy=2.3720070785946317, Accuracy=0.13541666666666666\n",
      "Epoch 164 validation: Cross-entropy=2.4269444942474365, Accuracy=0.05050504952669144\n",
      "Epoch 165 train: Cross-entropy=2.371892876095242, Accuracy=0.13541666666666666\n",
      "Epoch 165 validation: Cross-entropy=2.4269728660583496, Accuracy=0.05050504952669144\n",
      "Epoch 166 train: Cross-entropy=2.3717789914872913, Accuracy=0.1388888888888889\n",
      "Epoch 166 validation: Cross-entropy=2.4270012378692627, Accuracy=0.05050504952669144\n",
      "Epoch 167 train: Cross-entropy=2.371665596961975, Accuracy=0.1423611111111111\n",
      "Epoch 167 validation: Cross-entropy=2.427030324935913, Accuracy=0.05050504952669144\n",
      "Epoch 168 train: Cross-entropy=2.371552666028341, Accuracy=0.1440972222222222\n",
      "Epoch 168 validation: Cross-entropy=2.4270589351654053, Accuracy=0.05050504952669144\n",
      "Epoch 169 train: Cross-entropy=2.3714401721954346, Accuracy=0.1440972222222222\n",
      "Epoch 169 validation: Cross-entropy=2.4270875453948975, Accuracy=0.05050504952669144\n",
      "Epoch 170 train: Cross-entropy=2.371328035990397, Accuracy=0.1440972222222222\n",
      "Epoch 170 validation: Cross-entropy=2.427116870880127, Accuracy=0.05050504952669144\n",
      "Epoch 171 train: Cross-entropy=2.3712164560953775, Accuracy=0.14583333333333334\n",
      "Epoch 171 validation: Cross-entropy=2.4271459579467773, Accuracy=0.05050504952669144\n",
      "Epoch 172 train: Cross-entropy=2.3711052735646567, Accuracy=0.14583333333333334\n",
      "Epoch 172 validation: Cross-entropy=2.427175283432007, Accuracy=0.05050504952669144\n",
      "Epoch 173 train: Cross-entropy=2.370994488398234, Accuracy=0.14583333333333334\n",
      "Epoch 173 validation: Cross-entropy=2.4272043704986572, Accuracy=0.05050504952669144\n",
      "Epoch 174 train: Cross-entropy=2.370884166823493, Accuracy=0.14583333333333334\n",
      "Epoch 174 validation: Cross-entropy=2.427233934402466, Accuracy=0.05050504952669144\n",
      "Epoch 175 train: Cross-entropy=2.370774189631144, Accuracy=0.14756944444444445\n",
      "Epoch 175 validation: Cross-entropy=2.4272632598876953, Accuracy=0.05050504952669144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176 train: Cross-entropy=2.3706646627850003, Accuracy=0.14583333333333334\n",
      "Epoch 176 validation: Cross-entropy=2.427292585372925, Accuracy=0.05050504952669144\n",
      "Epoch 177 train: Cross-entropy=2.3705556790033975, Accuracy=0.1440972222222222\n",
      "Epoch 177 validation: Cross-entropy=2.4273223876953125, Accuracy=0.05050504952669144\n",
      "Epoch 178 train: Cross-entropy=2.3704469866222806, Accuracy=0.1440972222222222\n",
      "Epoch 178 validation: Cross-entropy=2.427351713180542, Accuracy=0.05050504952669144\n",
      "Epoch 179 train: Cross-entropy=2.370338691605462, Accuracy=0.1440972222222222\n",
      "Epoch 179 validation: Cross-entropy=2.427381753921509, Accuracy=0.05050504952669144\n",
      "Epoch 180 train: Cross-entropy=2.3702308999167547, Accuracy=0.14583333333333334\n",
      "Epoch 180 validation: Cross-entropy=2.4274117946624756, Accuracy=0.05050504952669144\n",
      "Epoch 181 train: Cross-entropy=2.3701234791013928, Accuracy=0.14583333333333334\n",
      "Epoch 181 validation: Cross-entropy=2.4274415969848633, Accuracy=0.05050504952669144\n",
      "Epoch 182 train: Cross-entropy=2.370016429159376, Accuracy=0.1440972222222222\n",
      "Epoch 182 validation: Cross-entropy=2.42747163772583, Accuracy=0.05050504952669144\n",
      "Epoch 183 train: Cross-entropy=2.369909882545471, Accuracy=0.14583333333333334\n",
      "Epoch 183 validation: Cross-entropy=2.427501678466797, Accuracy=0.05050504952669144\n",
      "Epoch 184 train: Cross-entropy=2.369803640577528, Accuracy=0.14583333333333334\n",
      "Epoch 184 validation: Cross-entropy=2.4275319576263428, Accuracy=0.05050504952669144\n",
      "Epoch 185 train: Cross-entropy=2.36969784895579, Accuracy=0.14583333333333334\n",
      "Epoch 185 validation: Cross-entropy=2.4275619983673096, Accuracy=0.05050504952669144\n",
      "Epoch 186 train: Cross-entropy=2.369592454698351, Accuracy=0.14583333333333334\n",
      "Epoch 186 validation: Cross-entropy=2.4275922775268555, Accuracy=0.05050504952669144\n",
      "Epoch 187 train: Cross-entropy=2.369487444559733, Accuracy=0.14930555555555555\n",
      "Epoch 187 validation: Cross-entropy=2.4276225566864014, Accuracy=0.05050504952669144\n",
      "Epoch 188 train: Cross-entropy=2.369382792048984, Accuracy=0.14930555555555555\n",
      "Epoch 188 validation: Cross-entropy=2.4276533126831055, Accuracy=0.05050504952669144\n",
      "Epoch 189 train: Cross-entropy=2.369278656111823, Accuracy=0.14930555555555555\n",
      "Epoch 189 validation: Cross-entropy=2.4276835918426514, Accuracy=0.05050504952669144\n",
      "Epoch 190 train: Cross-entropy=2.369174771838718, Accuracy=0.14930555555555555\n",
      "Epoch 190 validation: Cross-entropy=2.4277143478393555, Accuracy=0.05050504952669144\n",
      "Epoch 191 train: Cross-entropy=2.369071364402771, Accuracy=0.14583333333333334\n",
      "Epoch 191 validation: Cross-entropy=2.4277451038360596, Accuracy=0.05050504952669144\n",
      "Epoch 192 train: Cross-entropy=2.368968367576599, Accuracy=0.1440972222222222\n",
      "Epoch 192 validation: Cross-entropy=2.4277756214141846, Accuracy=0.05050504952669144\n",
      "Epoch 193 train: Cross-entropy=2.3688656621509128, Accuracy=0.14583333333333334\n",
      "Epoch 193 validation: Cross-entropy=2.4278066158294678, Accuracy=0.05050504952669144\n",
      "Epoch 194 train: Cross-entropy=2.3687634070714316, Accuracy=0.14756944444444445\n",
      "Epoch 194 validation: Cross-entropy=2.4278371334075928, Accuracy=0.04545454680919647\n",
      "Epoch 195 train: Cross-entropy=2.368661403656006, Accuracy=0.14583333333333334\n",
      "Epoch 195 validation: Cross-entropy=2.427868127822876, Accuracy=0.04545454680919647\n",
      "Epoch 196 train: Cross-entropy=2.3685599168141684, Accuracy=0.14583333333333334\n",
      "Epoch 196 validation: Cross-entropy=2.427899122238159, Accuracy=0.04545454680919647\n",
      "Epoch 197 train: Cross-entropy=2.368458800845676, Accuracy=0.14583333333333334\n",
      "Epoch 197 validation: Cross-entropy=2.4279303550720215, Accuracy=0.04545454680919647\n",
      "Epoch 198 train: Cross-entropy=2.3683580689960055, Accuracy=0.14583333333333334\n",
      "Epoch 198 validation: Cross-entropy=2.4279613494873047, Accuracy=0.04545454680919647\n",
      "Epoch 199 train: Cross-entropy=2.3682576417922974, Accuracy=0.14583333333333334\n",
      "Epoch 199 validation: Cross-entropy=2.427992343902588, Accuracy=0.04545454680919647\n",
      "Epoch 0 train: Cross-entropy=2.4356821642981634, Accuracy=0.08506944444444445\n",
      "Epoch 0 validation: Cross-entropy=2.45100474357605, Accuracy=0.06060606241226196\n",
      "Epoch 1 train: Cross-entropy=2.4195441934797497, Accuracy=0.08159722222222222\n",
      "Epoch 1 validation: Cross-entropy=2.4376466274261475, Accuracy=0.06060606241226196\n",
      "Epoch 2 train: Cross-entropy=2.4106115102767944, Accuracy=0.08854166666666667\n",
      "Epoch 2 validation: Cross-entropy=2.4301183223724365, Accuracy=0.06565656512975693\n",
      "Epoch 3 train: Cross-entropy=2.4058161444134183, Accuracy=0.0920138888888889\n",
      "Epoch 3 validation: Cross-entropy=2.425807237625122, Accuracy=0.0555555559694767\n",
      "Epoch 4 train: Cross-entropy=2.403182453579373, Accuracy=0.09027777777777778\n",
      "Epoch 4 validation: Cross-entropy=2.423267126083374, Accuracy=0.06060606241226196\n",
      "Epoch 5 train: Cross-entropy=2.40165294541253, Accuracy=0.0920138888888889\n",
      "Epoch 5 validation: Cross-entropy=2.421715021133423, Accuracy=0.06565656512975693\n",
      "Epoch 6 train: Cross-entropy=2.4006790187623768, Accuracy=0.09375\n",
      "Epoch 6 validation: Cross-entropy=2.420731782913208, Accuracy=0.06565656512975693\n",
      "Epoch 7 train: Cross-entropy=2.3999827835294933, Accuracy=0.09722222222222222\n",
      "Epoch 7 validation: Cross-entropy=2.420088052749634, Accuracy=0.06060606241226196\n",
      "Epoch 8 train: Cross-entropy=2.3994255595737033, Accuracy=0.09722222222222222\n",
      "Epoch 8 validation: Cross-entropy=2.419656991958618, Accuracy=0.07070706784725189\n",
      "Epoch 9 train: Cross-entropy=2.398938629362318, Accuracy=0.09722222222222222\n",
      "Epoch 9 validation: Cross-entropy=2.4193649291992188, Accuracy=0.07575757801532745\n",
      "Epoch 10 train: Cross-entropy=2.398488336139255, Accuracy=0.10069444444444445\n",
      "Epoch 10 validation: Cross-entropy=2.419166088104248, Accuracy=0.07070706784725189\n",
      "Epoch 11 train: Cross-entropy=2.3980579243765936, Accuracy=0.10243055555555555\n",
      "Epoch 11 validation: Cross-entropy=2.419032335281372, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.3976391553878784, Accuracy=0.1076388888888889\n",
      "Epoch 12 validation: Cross-entropy=2.4189443588256836, Accuracy=0.07070706784725189\n",
      "Epoch 13 train: Cross-entropy=2.397227962811788, Accuracy=0.1076388888888889\n",
      "Epoch 13 validation: Cross-entropy=2.4188895225524902, Accuracy=0.07070706784725189\n",
      "Epoch 14 train: Cross-entropy=2.396822214126587, Accuracy=0.1076388888888889\n",
      "Epoch 14 validation: Cross-entropy=2.4188590049743652, Accuracy=0.07070706784725189\n",
      "Epoch 15 train: Cross-entropy=2.396421061621772, Accuracy=0.10416666666666667\n",
      "Epoch 15 validation: Cross-entropy=2.4188461303710938, Accuracy=0.07070706784725189\n",
      "Epoch 16 train: Cross-entropy=2.3960236178504095, Accuracy=0.1076388888888889\n",
      "Epoch 16 validation: Cross-entropy=2.418846607208252, Accuracy=0.07070706784725189\n",
      "Epoch 17 train: Cross-entropy=2.3956298960579767, Accuracy=0.10590277777777778\n",
      "Epoch 17 validation: Cross-entropy=2.4188570976257324, Accuracy=0.06565656512975693\n",
      "Epoch 18 train: Cross-entropy=2.3952395651075573, Accuracy=0.1076388888888889\n",
      "Epoch 18 validation: Cross-entropy=2.418874979019165, Accuracy=0.06565656512975693\n",
      "Epoch 19 train: Cross-entropy=2.394852466053433, Accuracy=0.10590277777777778\n",
      "Epoch 19 validation: Cross-entropy=2.418898820877075, Accuracy=0.06060606241226196\n",
      "Epoch 20 train: Cross-entropy=2.3944686916139393, Accuracy=0.10590277777777778\n",
      "Epoch 20 validation: Cross-entropy=2.4189271926879883, Accuracy=0.06060606241226196\n",
      "Epoch 21 train: Cross-entropy=2.3940880033704968, Accuracy=0.10416666666666667\n",
      "Epoch 21 validation: Cross-entropy=2.418959140777588, Accuracy=0.06060606241226196\n",
      "Epoch 22 train: Cross-entropy=2.393710480795966, Accuracy=0.1076388888888889\n",
      "Epoch 22 validation: Cross-entropy=2.418994426727295, Accuracy=0.06060606241226196\n",
      "Epoch 23 train: Cross-entropy=2.3933359649446277, Accuracy=0.10590277777777778\n",
      "Epoch 23 validation: Cross-entropy=2.419031858444214, Accuracy=0.06060606241226196\n",
      "Epoch 24 train: Cross-entropy=2.3929646147622003, Accuracy=0.10416666666666667\n",
      "Epoch 24 validation: Cross-entropy=2.419071674346924, Accuracy=0.06060606241226196\n",
      "Epoch 25 train: Cross-entropy=2.3925961123572455, Accuracy=0.10590277777777778\n",
      "Epoch 25 validation: Cross-entropy=2.4191136360168457, Accuracy=0.06060606241226196\n",
      "Epoch 26 train: Cross-entropy=2.392230643166436, Accuracy=0.109375\n",
      "Epoch 26 validation: Cross-entropy=2.419156789779663, Accuracy=0.06060606241226196\n",
      "Epoch 27 train: Cross-entropy=2.3918681144714355, Accuracy=0.109375\n",
      "Epoch 27 validation: Cross-entropy=2.419201612472534, Accuracy=0.06060606241226196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 train: Cross-entropy=2.391508420308431, Accuracy=0.109375\n",
      "Epoch 28 validation: Cross-entropy=2.419248104095459, Accuracy=0.06060606241226196\n",
      "Epoch 29 train: Cross-entropy=2.3911516666412354, Accuracy=0.1076388888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4192955493927, Accuracy=0.06060606241226196\n",
      "Epoch 30 train: Cross-entropy=2.3907976812786527, Accuracy=0.10590277777777778\n",
      "Epoch 30 validation: Cross-entropy=2.419344425201416, Accuracy=0.06060606241226196\n",
      "Epoch 31 train: Cross-entropy=2.390446503957113, Accuracy=0.1076388888888889\n",
      "Epoch 31 validation: Cross-entropy=2.4193947315216064, Accuracy=0.06060606241226196\n",
      "Epoch 32 train: Cross-entropy=2.390098041958279, Accuracy=0.109375\n",
      "Epoch 32 validation: Cross-entropy=2.4194459915161133, Accuracy=0.06565656512975693\n",
      "Epoch 33 train: Cross-entropy=2.3897523482640586, Accuracy=0.109375\n",
      "Epoch 33 validation: Cross-entropy=2.4194982051849365, Accuracy=0.06060606241226196\n",
      "Epoch 34 train: Cross-entropy=2.3894093566470676, Accuracy=0.109375\n",
      "Epoch 34 validation: Cross-entropy=2.4195516109466553, Accuracy=0.06060606241226196\n",
      "Epoch 35 train: Cross-entropy=2.3890691068437366, Accuracy=0.1111111111111111\n",
      "Epoch 35 validation: Cross-entropy=2.4196062088012695, Accuracy=0.06060606241226196\n",
      "Epoch 36 train: Cross-entropy=2.3887313736809626, Accuracy=0.11284722222222222\n",
      "Epoch 36 validation: Cross-entropy=2.419661521911621, Accuracy=0.06060606241226196\n",
      "Epoch 37 train: Cross-entropy=2.3883963028589883, Accuracy=0.11458333333333333\n",
      "Epoch 37 validation: Cross-entropy=2.419718027114868, Accuracy=0.06565656512975693\n",
      "Epoch 38 train: Cross-entropy=2.3880638943778143, Accuracy=0.11805555555555555\n",
      "Epoch 38 validation: Cross-entropy=2.4197757244110107, Accuracy=0.06565656512975693\n",
      "Epoch 39 train: Cross-entropy=2.387733962800768, Accuracy=0.11805555555555555\n",
      "Epoch 39 validation: Cross-entropy=2.4198341369628906, Accuracy=0.06565656512975693\n",
      "Epoch 40 train: Cross-entropy=2.387406481636895, Accuracy=0.11979166666666667\n",
      "Epoch 40 validation: Cross-entropy=2.419893264770508, Accuracy=0.06565656512975693\n",
      "Epoch 41 train: Cross-entropy=2.387081782023112, Accuracy=0.11979166666666667\n",
      "Epoch 41 validation: Cross-entropy=2.4199535846710205, Accuracy=0.06565656512975693\n",
      "Epoch 42 train: Cross-entropy=2.3867592679129706, Accuracy=0.12152777777777778\n",
      "Epoch 42 validation: Cross-entropy=2.4200148582458496, Accuracy=0.06565656512975693\n",
      "Epoch 43 train: Cross-entropy=2.3864393499162464, Accuracy=0.1232638888888889\n",
      "Epoch 43 validation: Cross-entropy=2.420076847076416, Accuracy=0.06565656512975693\n",
      "Epoch 44 train: Cross-entropy=2.3861218690872192, Accuracy=0.1232638888888889\n",
      "Epoch 44 validation: Cross-entropy=2.420139789581299, Accuracy=0.06565656512975693\n",
      "Epoch 45 train: Cross-entropy=2.3858067327075534, Accuracy=0.12152777777777778\n",
      "Epoch 45 validation: Cross-entropy=2.42020320892334, Accuracy=0.06565656512975693\n",
      "Epoch 46 train: Cross-entropy=2.3854939805136786, Accuracy=0.12152777777777778\n",
      "Epoch 46 validation: Cross-entropy=2.4202678203582764, Accuracy=0.06565656512975693\n",
      "Epoch 47 train: Cross-entropy=2.385183652242025, Accuracy=0.1232638888888889\n",
      "Epoch 47 validation: Cross-entropy=2.42033314704895, Accuracy=0.06565656512975693\n",
      "Epoch 48 train: Cross-entropy=2.3848754829830594, Accuracy=0.1232638888888889\n",
      "Epoch 48 validation: Cross-entropy=2.4203994274139404, Accuracy=0.06565656512975693\n",
      "Epoch 49 train: Cross-entropy=2.3845697376463146, Accuracy=0.125\n",
      "Epoch 49 validation: Cross-entropy=2.420466661453247, Accuracy=0.06565656512975693\n",
      "Epoch 50 train: Cross-entropy=2.3842662307951183, Accuracy=0.1232638888888889\n",
      "Epoch 50 validation: Cross-entropy=2.420534133911133, Accuracy=0.06565656512975693\n",
      "Epoch 51 train: Cross-entropy=2.3839650021659002, Accuracy=0.125\n",
      "Epoch 51 validation: Cross-entropy=2.420602560043335, Accuracy=0.06565656512975693\n",
      "Epoch 52 train: Cross-entropy=2.383665985531277, Accuracy=0.1284722222222222\n",
      "Epoch 52 validation: Cross-entropy=2.4206717014312744, Accuracy=0.06565656512975693\n",
      "Epoch 53 train: Cross-entropy=2.3833691941367254, Accuracy=0.1284722222222222\n",
      "Epoch 53 validation: Cross-entropy=2.420741558074951, Accuracy=0.06565656512975693\n",
      "Epoch 54 train: Cross-entropy=2.383074508772956, Accuracy=0.1284722222222222\n",
      "Epoch 54 validation: Cross-entropy=2.4208121299743652, Accuracy=0.06565656512975693\n",
      "Epoch 55 train: Cross-entropy=2.3827821413675943, Accuracy=0.1284722222222222\n",
      "Epoch 55 validation: Cross-entropy=2.4208834171295166, Accuracy=0.06565656512975693\n",
      "Epoch 56 train: Cross-entropy=2.382491774029202, Accuracy=0.13020833333333334\n",
      "Epoch 56 validation: Cross-entropy=2.4209554195404053, Accuracy=0.06565656512975693\n",
      "Epoch 57 train: Cross-entropy=2.382203631930881, Accuracy=0.13020833333333334\n",
      "Epoch 57 validation: Cross-entropy=2.421027898788452, Accuracy=0.06565656512975693\n",
      "Epoch 58 train: Cross-entropy=2.3819174898995294, Accuracy=0.13020833333333334\n",
      "Epoch 58 validation: Cross-entropy=2.4211013317108154, Accuracy=0.06565656512975693\n",
      "Epoch 59 train: Cross-entropy=2.38163341416253, Accuracy=0.13020833333333334\n",
      "Epoch 59 validation: Cross-entropy=2.421175479888916, Accuracy=0.06565656512975693\n",
      "Epoch 60 train: Cross-entropy=2.381351431210836, Accuracy=0.13368055555555555\n",
      "Epoch 60 validation: Cross-entropy=2.4212498664855957, Accuracy=0.06565656512975693\n",
      "Epoch 61 train: Cross-entropy=2.3810714880625405, Accuracy=0.13368055555555555\n",
      "Epoch 61 validation: Cross-entropy=2.4213249683380127, Accuracy=0.06565656512975693\n",
      "Epoch 62 train: Cross-entropy=2.3807935449812145, Accuracy=0.13020833333333334\n",
      "Epoch 62 validation: Cross-entropy=2.421400308609009, Accuracy=0.06565656512975693\n",
      "Epoch 63 train: Cross-entropy=2.3805175357394748, Accuracy=0.13020833333333334\n",
      "Epoch 63 validation: Cross-entropy=2.4214768409729004, Accuracy=0.06565656512975693\n",
      "Epoch 64 train: Cross-entropy=2.3802436192830405, Accuracy=0.13194444444444445\n",
      "Epoch 64 validation: Cross-entropy=2.421553611755371, Accuracy=0.06565656512975693\n",
      "Epoch 65 train: Cross-entropy=2.3799715836842856, Accuracy=0.13368055555555555\n",
      "Epoch 65 validation: Cross-entropy=2.421631097793579, Accuracy=0.07070706784725189\n",
      "Epoch 66 train: Cross-entropy=2.3797013494703503, Accuracy=0.13368055555555555\n",
      "Epoch 66 validation: Cross-entropy=2.421708822250366, Accuracy=0.07575757801532745\n",
      "Epoch 67 train: Cross-entropy=2.379433208041721, Accuracy=0.13368055555555555\n",
      "Epoch 67 validation: Cross-entropy=2.421787738800049, Accuracy=0.07575757801532745\n",
      "Epoch 68 train: Cross-entropy=2.379166907734341, Accuracy=0.13368055555555555\n",
      "Epoch 68 validation: Cross-entropy=2.4218664169311523, Accuracy=0.07575757801532745\n",
      "Epoch 69 train: Cross-entropy=2.378902475039164, Accuracy=0.13541666666666666\n",
      "Epoch 69 validation: Cross-entropy=2.4219462871551514, Accuracy=0.07575757801532745\n",
      "Epoch 70 train: Cross-entropy=2.378639883465237, Accuracy=0.1371527777777778\n",
      "Epoch 70 validation: Cross-entropy=2.4220261573791504, Accuracy=0.07575757801532745\n",
      "Epoch 71 train: Cross-entropy=2.378379080030653, Accuracy=0.1371527777777778\n",
      "Epoch 71 validation: Cross-entropy=2.4221065044403076, Accuracy=0.07575757801532745\n",
      "Epoch 72 train: Cross-entropy=2.378120117717319, Accuracy=0.1371527777777778\n",
      "Epoch 72 validation: Cross-entropy=2.422187566757202, Accuracy=0.07575757801532745\n",
      "Epoch 73 train: Cross-entropy=2.377862983279758, Accuracy=0.1371527777777778\n",
      "Epoch 73 validation: Cross-entropy=2.422268867492676, Accuracy=0.07575757801532745\n",
      "Epoch 74 train: Cross-entropy=2.377607650227017, Accuracy=0.1371527777777778\n",
      "Epoch 74 validation: Cross-entropy=2.4223508834838867, Accuracy=0.07575757801532745\n",
      "Epoch 75 train: Cross-entropy=2.3773540920681424, Accuracy=0.13194444444444445\n",
      "Epoch 75 validation: Cross-entropy=2.4224328994750977, Accuracy=0.07575757801532745\n",
      "Epoch 76 train: Cross-entropy=2.3771022028393216, Accuracy=0.13194444444444445\n",
      "Epoch 76 validation: Cross-entropy=2.422515869140625, Accuracy=0.07575757801532745\n",
      "Epoch 77 train: Cross-entropy=2.376852035522461, Accuracy=0.13368055555555555\n",
      "Epoch 77 validation: Cross-entropy=2.4225990772247314, Accuracy=0.07575757801532745\n",
      "Epoch 78 train: Cross-entropy=2.3766037358178034, Accuracy=0.13368055555555555\n",
      "Epoch 78 validation: Cross-entropy=2.422682523727417, Accuracy=0.07575757801532745\n",
      "Epoch 79 train: Cross-entropy=2.37635698583391, Accuracy=0.13368055555555555\n",
      "Epoch 79 validation: Cross-entropy=2.4227664470672607, Accuracy=0.07575757801532745\n",
      "Epoch 80 train: Cross-entropy=2.3761119842529297, Accuracy=0.13368055555555555\n",
      "Epoch 80 validation: Cross-entropy=2.4228508472442627, Accuracy=0.07575757801532745\n",
      "Epoch 81 train: Cross-entropy=2.3758685191472373, Accuracy=0.13194444444444445\n",
      "Epoch 81 validation: Cross-entropy=2.422935724258423, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 train: Cross-entropy=2.3756267891989813, Accuracy=0.13194444444444445\n",
      "Epoch 82 validation: Cross-entropy=2.423020839691162, Accuracy=0.07575757801532745\n",
      "Epoch 83 train: Cross-entropy=2.375386701689826, Accuracy=0.13194444444444445\n",
      "Epoch 83 validation: Cross-entropy=2.4231061935424805, Accuracy=0.07575757801532745\n",
      "Epoch 84 train: Cross-entropy=2.3751481771469116, Accuracy=0.13368055555555555\n",
      "Epoch 84 validation: Cross-entropy=2.423192262649536, Accuracy=0.07575757801532745\n",
      "Epoch 85 train: Cross-entropy=2.3749112685521445, Accuracy=0.13368055555555555\n",
      "Epoch 85 validation: Cross-entropy=2.423278570175171, Accuracy=0.07575757801532745\n",
      "Epoch 86 train: Cross-entropy=2.3746759759055243, Accuracy=0.13368055555555555\n",
      "Epoch 86 validation: Cross-entropy=2.4233648777008057, Accuracy=0.07575757801532745\n",
      "Epoch 87 train: Cross-entropy=2.3744422329796686, Accuracy=0.13541666666666666\n",
      "Epoch 87 validation: Cross-entropy=2.4234514236450195, Accuracy=0.07070706784725189\n",
      "Epoch 88 train: Cross-entropy=2.3742100530200534, Accuracy=0.13541666666666666\n",
      "Epoch 88 validation: Cross-entropy=2.4235386848449707, Accuracy=0.07070706784725189\n",
      "Epoch 89 train: Cross-entropy=2.3739793565538196, Accuracy=0.13541666666666666\n",
      "Epoch 89 validation: Cross-entropy=2.42362642288208, Accuracy=0.07070706784725189\n",
      "Epoch 90 train: Cross-entropy=2.3737502760357327, Accuracy=0.13541666666666666\n",
      "Epoch 90 validation: Cross-entropy=2.4237141609191895, Accuracy=0.07070706784725189\n",
      "Epoch 91 train: Cross-entropy=2.3735226260291205, Accuracy=0.1371527777777778\n",
      "Epoch 91 validation: Cross-entropy=2.423801898956299, Accuracy=0.07070706784725189\n",
      "Epoch 92 train: Cross-entropy=2.373296446270413, Accuracy=0.1371527777777778\n",
      "Epoch 92 validation: Cross-entropy=2.4238905906677246, Accuracy=0.07575757801532745\n",
      "Epoch 93 train: Cross-entropy=2.373071829477946, Accuracy=0.13541666666666666\n",
      "Epoch 93 validation: Cross-entropy=2.423978805541992, Accuracy=0.07575757801532745\n",
      "Epoch 94 train: Cross-entropy=2.372848629951477, Accuracy=0.13541666666666666\n",
      "Epoch 94 validation: Cross-entropy=2.424067974090576, Accuracy=0.07575757801532745\n",
      "Epoch 95 train: Cross-entropy=2.372626874181959, Accuracy=0.13541666666666666\n",
      "Epoch 95 validation: Cross-entropy=2.42415714263916, Accuracy=0.08080808073282242\n",
      "Epoch 96 train: Cross-entropy=2.3724065754148693, Accuracy=0.13541666666666666\n",
      "Epoch 96 validation: Cross-entropy=2.4242465496063232, Accuracy=0.08080808073282242\n",
      "Epoch 97 train: Cross-entropy=2.3721877336502075, Accuracy=0.13541666666666666\n",
      "Epoch 97 validation: Cross-entropy=2.4243361949920654, Accuracy=0.08080808073282242\n",
      "Epoch 98 train: Cross-entropy=2.371970216433207, Accuracy=0.13541666666666666\n",
      "Epoch 98 validation: Cross-entropy=2.4244260787963867, Accuracy=0.08080808073282242\n",
      "Epoch 99 train: Cross-entropy=2.371754116482205, Accuracy=0.13541666666666666\n",
      "Epoch 99 validation: Cross-entropy=2.424516201019287, Accuracy=0.08080808073282242\n",
      "Epoch 100 train: Cross-entropy=2.3715394735336304, Accuracy=0.13541666666666666\n",
      "Epoch 100 validation: Cross-entropy=2.4246065616607666, Accuracy=0.08080808073282242\n",
      "Epoch 101 train: Cross-entropy=2.3713261683781943, Accuracy=0.13541666666666666\n",
      "Epoch 101 validation: Cross-entropy=2.424697160720825, Accuracy=0.08080808073282242\n",
      "Epoch 102 train: Cross-entropy=2.3711141215430365, Accuracy=0.13541666666666666\n",
      "Epoch 102 validation: Cross-entropy=2.424787998199463, Accuracy=0.08080808073282242\n",
      "Epoch 103 train: Cross-entropy=2.3709035317103067, Accuracy=0.13541666666666666\n",
      "Epoch 103 validation: Cross-entropy=2.4248788356781006, Accuracy=0.08080808073282242\n",
      "Epoch 104 train: Cross-entropy=2.3706942399342856, Accuracy=0.13541666666666666\n",
      "Epoch 104 validation: Cross-entropy=2.4249701499938965, Accuracy=0.07575757801532745\n",
      "Epoch 105 train: Cross-entropy=2.3704863124423556, Accuracy=0.13541666666666666\n",
      "Epoch 105 validation: Cross-entropy=2.4250614643096924, Accuracy=0.07575757801532745\n",
      "Epoch 106 train: Cross-entropy=2.370279735989041, Accuracy=0.13541666666666666\n",
      "Epoch 106 validation: Cross-entropy=2.4251530170440674, Accuracy=0.07575757801532745\n",
      "Epoch 107 train: Cross-entropy=2.3700742854012384, Accuracy=0.13541666666666666\n",
      "Epoch 107 validation: Cross-entropy=2.4252448081970215, Accuracy=0.07575757801532745\n",
      "Epoch 108 train: Cross-entropy=2.369870238833957, Accuracy=0.13541666666666666\n",
      "Epoch 108 validation: Cross-entropy=2.4253368377685547, Accuracy=0.07575757801532745\n",
      "Epoch 109 train: Cross-entropy=2.3696674638324313, Accuracy=0.13541666666666666\n",
      "Epoch 109 validation: Cross-entropy=2.425428867340088, Accuracy=0.07575757801532745\n",
      "Epoch 110 train: Cross-entropy=2.3694658411873712, Accuracy=0.13541666666666666\n",
      "Epoch 110 validation: Cross-entropy=2.425520896911621, Accuracy=0.07575757801532745\n",
      "Epoch 111 train: Cross-entropy=2.369265596071879, Accuracy=0.13541666666666666\n",
      "Epoch 111 validation: Cross-entropy=2.4256131649017334, Accuracy=0.07575757801532745\n",
      "Epoch 112 train: Cross-entropy=2.3690665562947593, Accuracy=0.13368055555555555\n",
      "Epoch 112 validation: Cross-entropy=2.425705909729004, Accuracy=0.07575757801532745\n",
      "Epoch 113 train: Cross-entropy=2.3688687483469644, Accuracy=0.13368055555555555\n",
      "Epoch 113 validation: Cross-entropy=2.4257984161376953, Accuracy=0.07575757801532745\n",
      "Epoch 114 train: Cross-entropy=2.3686720662646823, Accuracy=0.13541666666666666\n",
      "Epoch 114 validation: Cross-entropy=2.425891399383545, Accuracy=0.07575757801532745\n",
      "Epoch 115 train: Cross-entropy=2.368476708730062, Accuracy=0.13541666666666666\n",
      "Epoch 115 validation: Cross-entropy=2.4259843826293945, Accuracy=0.07575757801532745\n",
      "Epoch 116 train: Cross-entropy=2.3682825167973838, Accuracy=0.13541666666666666\n",
      "Epoch 116 validation: Cross-entropy=2.426077127456665, Accuracy=0.07575757801532745\n",
      "Epoch 117 train: Cross-entropy=2.3680894242392645, Accuracy=0.1371527777777778\n",
      "Epoch 117 validation: Cross-entropy=2.4261703491210938, Accuracy=0.07575757801532745\n",
      "Epoch 118 train: Cross-entropy=2.3678975900014243, Accuracy=0.1371527777777778\n",
      "Epoch 118 validation: Cross-entropy=2.4262635707855225, Accuracy=0.07575757801532745\n",
      "Epoch 119 train: Cross-entropy=2.367706961101956, Accuracy=0.13368055555555555\n",
      "Epoch 119 validation: Cross-entropy=2.4263570308685303, Accuracy=0.07575757801532745\n",
      "Epoch 120 train: Cross-entropy=2.3675174845589533, Accuracy=0.13194444444444445\n",
      "Epoch 120 validation: Cross-entropy=2.426450729370117, Accuracy=0.07575757801532745\n",
      "Epoch 121 train: Cross-entropy=2.36732898818122, Accuracy=0.13194444444444445\n",
      "Epoch 121 validation: Cross-entropy=2.426544189453125, Accuracy=0.07575757801532745\n",
      "Epoch 122 train: Cross-entropy=2.367141776614719, Accuracy=0.13368055555555555\n",
      "Epoch 122 validation: Cross-entropy=2.426637887954712, Accuracy=0.07575757801532745\n",
      "Epoch 123 train: Cross-entropy=2.3669556114408703, Accuracy=0.13194444444444445\n",
      "Epoch 123 validation: Cross-entropy=2.426731586456299, Accuracy=0.07070706784725189\n",
      "Epoch 124 train: Cross-entropy=2.3667705721325345, Accuracy=0.13368055555555555\n",
      "Epoch 124 validation: Cross-entropy=2.426825523376465, Accuracy=0.07070706784725189\n",
      "Epoch 125 train: Cross-entropy=2.366586605707804, Accuracy=0.13194444444444445\n",
      "Epoch 125 validation: Cross-entropy=2.4269192218780518, Accuracy=0.07575757801532745\n",
      "Epoch 126 train: Cross-entropy=2.366403818130493, Accuracy=0.13541666666666666\n",
      "Epoch 126 validation: Cross-entropy=2.427013397216797, Accuracy=0.07575757801532745\n",
      "Epoch 127 train: Cross-entropy=2.366221970982022, Accuracy=0.1371527777777778\n",
      "Epoch 127 validation: Cross-entropy=2.427107334136963, Accuracy=0.07575757801532745\n",
      "Epoch 128 train: Cross-entropy=2.366041342417399, Accuracy=0.1371527777777778\n",
      "Epoch 128 validation: Cross-entropy=2.427201747894287, Accuracy=0.07575757801532745\n",
      "Epoch 129 train: Cross-entropy=2.365861733754476, Accuracy=0.1371527777777778\n",
      "Epoch 129 validation: Cross-entropy=2.4272959232330322, Accuracy=0.07575757801532745\n",
      "Epoch 130 train: Cross-entropy=2.3656831449932523, Accuracy=0.1371527777777778\n",
      "Epoch 130 validation: Cross-entropy=2.4273900985717773, Accuracy=0.07575757801532745\n",
      "Epoch 131 train: Cross-entropy=2.365505655606588, Accuracy=0.13541666666666666\n",
      "Epoch 131 validation: Cross-entropy=2.4274847507476807, Accuracy=0.08080808073282242\n",
      "Epoch 132 train: Cross-entropy=2.365329146385193, Accuracy=0.1371527777777778\n",
      "Epoch 132 validation: Cross-entropy=2.427578926086426, Accuracy=0.08080808073282242\n",
      "Epoch 133 train: Cross-entropy=2.365153710047404, Accuracy=0.1371527777777778\n",
      "Epoch 133 validation: Cross-entropy=2.427673101425171, Accuracy=0.07575757801532745\n",
      "Epoch 134 train: Cross-entropy=2.3649792273839316, Accuracy=0.140625\n",
      "Epoch 134 validation: Cross-entropy=2.427767753601074, Accuracy=0.07575757801532745\n",
      "Epoch 135 train: Cross-entropy=2.3648058705859714, Accuracy=0.140625\n",
      "Epoch 135 validation: Cross-entropy=2.4278624057769775, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 train: Cross-entropy=2.3646333614985147, Accuracy=0.1388888888888889\n",
      "Epoch 136 validation: Cross-entropy=2.4279565811157227, Accuracy=0.07575757801532745\n",
      "Epoch 137 train: Cross-entropy=2.364461965031094, Accuracy=0.1388888888888889\n",
      "Epoch 137 validation: Cross-entropy=2.428051233291626, Accuracy=0.07575757801532745\n",
      "Epoch 138 train: Cross-entropy=2.3642914825015597, Accuracy=0.1388888888888889\n",
      "Epoch 138 validation: Cross-entropy=2.4281458854675293, Accuracy=0.07575757801532745\n",
      "Epoch 139 train: Cross-entropy=2.3641220066282482, Accuracy=0.1388888888888889\n",
      "Epoch 139 validation: Cross-entropy=2.4282402992248535, Accuracy=0.07575757801532745\n",
      "Epoch 140 train: Cross-entropy=2.3639534579383, Accuracy=0.1388888888888889\n",
      "Epoch 140 validation: Cross-entropy=2.428334951400757, Accuracy=0.07575757801532745\n",
      "Epoch 141 train: Cross-entropy=2.363785889413622, Accuracy=0.1388888888888889\n",
      "Epoch 141 validation: Cross-entropy=2.42842960357666, Accuracy=0.07575757801532745\n",
      "Epoch 142 train: Cross-entropy=2.363619327545166, Accuracy=0.1388888888888889\n",
      "Epoch 142 validation: Cross-entropy=2.4285242557525635, Accuracy=0.07575757801532745\n",
      "Epoch 143 train: Cross-entropy=2.363453653123644, Accuracy=0.1388888888888889\n",
      "Epoch 143 validation: Cross-entropy=2.4286186695098877, Accuracy=0.07575757801532745\n",
      "Epoch 144 train: Cross-entropy=2.363288892640008, Accuracy=0.1388888888888889\n",
      "Epoch 144 validation: Cross-entropy=2.428713321685791, Accuracy=0.07070706784725189\n",
      "Epoch 145 train: Cross-entropy=2.363125138812595, Accuracy=0.140625\n",
      "Epoch 145 validation: Cross-entropy=2.4288079738616943, Accuracy=0.07070706784725189\n",
      "Epoch 146 train: Cross-entropy=2.3629622326956854, Accuracy=0.140625\n",
      "Epoch 146 validation: Cross-entropy=2.4289028644561768, Accuracy=0.07070706784725189\n",
      "Epoch 147 train: Cross-entropy=2.362800293498569, Accuracy=0.140625\n",
      "Epoch 147 validation: Cross-entropy=2.428997278213501, Accuracy=0.07070706784725189\n",
      "Epoch 148 train: Cross-entropy=2.362639202011956, Accuracy=0.140625\n",
      "Epoch 148 validation: Cross-entropy=2.4290919303894043, Accuracy=0.07070706784725189\n",
      "Epoch 149 train: Cross-entropy=2.362479011217753, Accuracy=0.140625\n",
      "Epoch 149 validation: Cross-entropy=2.4291865825653076, Accuracy=0.07070706784725189\n",
      "Epoch 150 train: Cross-entropy=2.36231976085239, Accuracy=0.140625\n",
      "Epoch 150 validation: Cross-entropy=2.429280996322632, Accuracy=0.07070706784725189\n",
      "Epoch 151 train: Cross-entropy=2.3621612787246704, Accuracy=0.1423611111111111\n",
      "Epoch 151 validation: Cross-entropy=2.429375648498535, Accuracy=0.07070706784725189\n",
      "Epoch 152 train: Cross-entropy=2.362003790007697, Accuracy=0.1423611111111111\n",
      "Epoch 152 validation: Cross-entropy=2.4294700622558594, Accuracy=0.07070706784725189\n",
      "Epoch 153 train: Cross-entropy=2.3618470827738443, Accuracy=0.1423611111111111\n",
      "Epoch 153 validation: Cross-entropy=2.4295647144317627, Accuracy=0.07070706784725189\n",
      "Epoch 154 train: Cross-entropy=2.361691262986925, Accuracy=0.1423611111111111\n",
      "Epoch 154 validation: Cross-entropy=2.429659128189087, Accuracy=0.07070706784725189\n",
      "Epoch 155 train: Cross-entropy=2.361536330646939, Accuracy=0.1423611111111111\n",
      "Epoch 155 validation: Cross-entropy=2.429753541946411, Accuracy=0.07070706784725189\n",
      "Epoch 156 train: Cross-entropy=2.3613822195265026, Accuracy=0.1423611111111111\n",
      "Epoch 156 validation: Cross-entropy=2.4298477172851562, Accuracy=0.07070706784725189\n",
      "Epoch 157 train: Cross-entropy=2.3612289428710938, Accuracy=0.1423611111111111\n",
      "Epoch 157 validation: Cross-entropy=2.4299423694610596, Accuracy=0.07070706784725189\n",
      "Epoch 158 train: Cross-entropy=2.3610765006807117, Accuracy=0.1423611111111111\n",
      "Epoch 158 validation: Cross-entropy=2.4300365447998047, Accuracy=0.07070706784725189\n",
      "Epoch 159 train: Cross-entropy=2.3609249194463096, Accuracy=0.1423611111111111\n",
      "Epoch 159 validation: Cross-entropy=2.43013072013855, Accuracy=0.07070706784725189\n",
      "Epoch 160 train: Cross-entropy=2.360774132940504, Accuracy=0.1423611111111111\n",
      "Epoch 160 validation: Cross-entropy=2.430224895477295, Accuracy=0.07070706784725189\n",
      "Epoch 161 train: Cross-entropy=2.360624114672343, Accuracy=0.1423611111111111\n",
      "Epoch 161 validation: Cross-entropy=2.43031907081604, Accuracy=0.07070706784725189\n",
      "Epoch 162 train: Cross-entropy=2.3604749176237316, Accuracy=0.1423611111111111\n",
      "Epoch 162 validation: Cross-entropy=2.4304134845733643, Accuracy=0.07070706784725189\n",
      "Epoch 163 train: Cross-entropy=2.3603265550401478, Accuracy=0.1423611111111111\n",
      "Epoch 163 validation: Cross-entropy=2.430507183074951, Accuracy=0.07070706784725189\n",
      "Epoch 164 train: Cross-entropy=2.360178960694207, Accuracy=0.1423611111111111\n",
      "Epoch 164 validation: Cross-entropy=2.430601119995117, Accuracy=0.07070706784725189\n",
      "Epoch 165 train: Cross-entropy=2.3600321213404336, Accuracy=0.1423611111111111\n",
      "Epoch 165 validation: Cross-entropy=2.4306955337524414, Accuracy=0.07070706784725189\n",
      "Epoch 166 train: Cross-entropy=2.359886129697164, Accuracy=0.1423611111111111\n",
      "Epoch 166 validation: Cross-entropy=2.4307894706726074, Accuracy=0.07070706784725189\n",
      "Epoch 167 train: Cross-entropy=2.359740826818678, Accuracy=0.1423611111111111\n",
      "Epoch 167 validation: Cross-entropy=2.4308831691741943, Accuracy=0.07070706784725189\n",
      "Epoch 168 train: Cross-entropy=2.359596358405219, Accuracy=0.1423611111111111\n",
      "Epoch 168 validation: Cross-entropy=2.4309768676757812, Accuracy=0.07070706784725189\n",
      "Epoch 169 train: Cross-entropy=2.359452631738451, Accuracy=0.1423611111111111\n",
      "Epoch 169 validation: Cross-entropy=2.431070566177368, Accuracy=0.07070706784725189\n",
      "Epoch 170 train: Cross-entropy=2.359309686554803, Accuracy=0.1423611111111111\n",
      "Epoch 170 validation: Cross-entropy=2.431164264678955, Accuracy=0.07070706784725189\n",
      "Epoch 171 train: Cross-entropy=2.359167456626892, Accuracy=0.1440972222222222\n",
      "Epoch 171 validation: Cross-entropy=2.431257724761963, Accuracy=0.07070706784725189\n",
      "Epoch 172 train: Cross-entropy=2.3590259552001953, Accuracy=0.14583333333333334\n",
      "Epoch 172 validation: Cross-entropy=2.4313511848449707, Accuracy=0.07070706784725189\n",
      "Epoch 173 train: Cross-entropy=2.3588851822747126, Accuracy=0.14583333333333334\n",
      "Epoch 173 validation: Cross-entropy=2.4314446449279785, Accuracy=0.07070706784725189\n",
      "Epoch 174 train: Cross-entropy=2.3587452438142567, Accuracy=0.14583333333333334\n",
      "Epoch 174 validation: Cross-entropy=2.431537628173828, Accuracy=0.07070706784725189\n",
      "Epoch 175 train: Cross-entropy=2.358605835172865, Accuracy=0.14583333333333334\n",
      "Epoch 175 validation: Cross-entropy=2.431630849838257, Accuracy=0.07070706784725189\n",
      "Epoch 176 train: Cross-entropy=2.35846738020579, Accuracy=0.14756944444444445\n",
      "Epoch 176 validation: Cross-entropy=2.4317240715026855, Accuracy=0.07070706784725189\n",
      "Epoch 177 train: Cross-entropy=2.35832949479421, Accuracy=0.14756944444444445\n",
      "Epoch 177 validation: Cross-entropy=2.4318172931671143, Accuracy=0.07070706784725189\n",
      "Epoch 178 train: Cross-entropy=2.3581923643747964, Accuracy=0.14756944444444445\n",
      "Epoch 178 validation: Cross-entropy=2.431910276412964, Accuracy=0.07070706784725189\n",
      "Epoch 179 train: Cross-entropy=2.358055909474691, Accuracy=0.14930555555555555\n",
      "Epoch 179 validation: Cross-entropy=2.4320030212402344, Accuracy=0.07575757801532745\n",
      "Epoch 180 train: Cross-entropy=2.357920143339369, Accuracy=0.14930555555555555\n",
      "Epoch 180 validation: Cross-entropy=2.432095766067505, Accuracy=0.07575757801532745\n",
      "Epoch 181 train: Cross-entropy=2.357785039477878, Accuracy=0.14930555555555555\n",
      "Epoch 181 validation: Cross-entropy=2.4321887493133545, Accuracy=0.07575757801532745\n",
      "Epoch 182 train: Cross-entropy=2.357650717099508, Accuracy=0.14930555555555555\n",
      "Epoch 182 validation: Cross-entropy=2.432281255722046, Accuracy=0.07575757801532745\n",
      "Epoch 183 train: Cross-entropy=2.357517030504015, Accuracy=0.14930555555555555\n",
      "Epoch 183 validation: Cross-entropy=2.4323737621307373, Accuracy=0.07575757801532745\n",
      "Epoch 184 train: Cross-entropy=2.3573840459187827, Accuracy=0.15104166666666666\n",
      "Epoch 184 validation: Cross-entropy=2.4324660301208496, Accuracy=0.07575757801532745\n",
      "Epoch 185 train: Cross-entropy=2.357251670625475, Accuracy=0.14930555555555555\n",
      "Epoch 185 validation: Cross-entropy=2.432558536529541, Accuracy=0.07575757801532745\n",
      "Epoch 186 train: Cross-entropy=2.3571200238333807, Accuracy=0.14930555555555555\n",
      "Epoch 186 validation: Cross-entropy=2.4326508045196533, Accuracy=0.07575757801532745\n",
      "Epoch 187 train: Cross-entropy=2.356989039315118, Accuracy=0.14930555555555555\n",
      "Epoch 187 validation: Cross-entropy=2.4327425956726074, Accuracy=0.07575757801532745\n",
      "Epoch 188 train: Cross-entropy=2.356858637597826, Accuracy=0.14930555555555555\n",
      "Epoch 188 validation: Cross-entropy=2.4328346252441406, Accuracy=0.07575757801532745\n",
      "Epoch 189 train: Cross-entropy=2.3567289776272244, Accuracy=0.14930555555555555\n",
      "Epoch 189 validation: Cross-entropy=2.4329264163970947, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 train: Cross-entropy=2.3565998474756875, Accuracy=0.14930555555555555\n",
      "Epoch 190 validation: Cross-entropy=2.433018445968628, Accuracy=0.07575757801532745\n",
      "Epoch 191 train: Cross-entropy=2.3564714855617948, Accuracy=0.14930555555555555\n",
      "Epoch 191 validation: Cross-entropy=2.433109998703003, Accuracy=0.07575757801532745\n",
      "Epoch 192 train: Cross-entropy=2.3563436799579196, Accuracy=0.1527777777777778\n",
      "Epoch 192 validation: Cross-entropy=2.433201551437378, Accuracy=0.07575757801532745\n",
      "Epoch 193 train: Cross-entropy=2.3562165366278753, Accuracy=0.15104166666666666\n",
      "Epoch 193 validation: Cross-entropy=2.433293104171753, Accuracy=0.07575757801532745\n",
      "Epoch 194 train: Cross-entropy=2.3560899760988026, Accuracy=0.1527777777777778\n",
      "Epoch 194 validation: Cross-entropy=2.433384418487549, Accuracy=0.07575757801532745\n",
      "Epoch 195 train: Cross-entropy=2.35596411757999, Accuracy=0.1527777777777778\n",
      "Epoch 195 validation: Cross-entropy=2.433475971221924, Accuracy=0.07575757801532745\n",
      "Epoch 196 train: Cross-entropy=2.3558388418621488, Accuracy=0.1527777777777778\n",
      "Epoch 196 validation: Cross-entropy=2.4335668087005615, Accuracy=0.07575757801532745\n",
      "Epoch 197 train: Cross-entropy=2.3557141489452786, Accuracy=0.1527777777777778\n",
      "Epoch 197 validation: Cross-entropy=2.433657646179199, Accuracy=0.08080808073282242\n",
      "Epoch 198 train: Cross-entropy=2.355590065320333, Accuracy=0.1527777777777778\n",
      "Epoch 198 validation: Cross-entropy=2.433748722076416, Accuracy=0.08080808073282242\n",
      "Epoch 199 train: Cross-entropy=2.355466617478265, Accuracy=0.1527777777777778\n",
      "Epoch 199 validation: Cross-entropy=2.4338393211364746, Accuracy=0.08080808073282242\n",
      "Epoch 0 train: Cross-entropy=2.4181645578808255, Accuracy=0.07291666666666667\n",
      "Epoch 0 validation: Cross-entropy=2.4104180335998535, Accuracy=0.09090909361839294\n",
      "Epoch 1 train: Cross-entropy=2.4033173984951444, Accuracy=0.08333333333333333\n",
      "Epoch 1 validation: Cross-entropy=2.4086122512817383, Accuracy=0.06565656512975693\n",
      "Epoch 2 train: Cross-entropy=2.4003463321261935, Accuracy=0.09375\n",
      "Epoch 2 validation: Cross-entropy=2.4091176986694336, Accuracy=0.07070706784725189\n",
      "Epoch 3 train: Cross-entropy=2.399086448881361, Accuracy=0.0954861111111111\n",
      "Epoch 3 validation: Cross-entropy=2.409642457962036, Accuracy=0.07070706784725189\n",
      "Epoch 4 train: Cross-entropy=2.397986584239536, Accuracy=0.10069444444444445\n",
      "Epoch 4 validation: Cross-entropy=2.4100120067596436, Accuracy=0.07070706784725189\n",
      "Epoch 5 train: Cross-entropy=2.396910230318705, Accuracy=0.10416666666666667\n",
      "Epoch 5 validation: Cross-entropy=2.410290479660034, Accuracy=0.07575757801532745\n",
      "Epoch 6 train: Cross-entropy=2.3958595858679876, Accuracy=0.10590277777777778\n",
      "Epoch 6 validation: Cross-entropy=2.410529613494873, Accuracy=0.07575757801532745\n",
      "Epoch 7 train: Cross-entropy=2.3948395119773016, Accuracy=0.1111111111111111\n",
      "Epoch 7 validation: Cross-entropy=2.4107553958892822, Accuracy=0.07575757801532745\n",
      "Epoch 8 train: Cross-entropy=2.393851253721449, Accuracy=0.11458333333333333\n",
      "Epoch 8 validation: Cross-entropy=2.410980224609375, Accuracy=0.07070706784725189\n",
      "Epoch 9 train: Cross-entropy=2.392894016371833, Accuracy=0.11284722222222222\n",
      "Epoch 9 validation: Cross-entropy=2.411207437515259, Accuracy=0.07070706784725189\n",
      "Epoch 10 train: Cross-entropy=2.3919668594996133, Accuracy=0.11805555555555555\n",
      "Epoch 10 validation: Cross-entropy=2.4114394187927246, Accuracy=0.07070706784725189\n",
      "Epoch 11 train: Cross-entropy=2.3910682996114097, Accuracy=0.11805555555555555\n",
      "Epoch 11 validation: Cross-entropy=2.4116764068603516, Accuracy=0.07070706784725189\n",
      "Epoch 12 train: Cross-entropy=2.390197330050998, Accuracy=0.12152777777777778\n",
      "Epoch 12 validation: Cross-entropy=2.4119181632995605, Accuracy=0.07070706784725189\n",
      "Epoch 13 train: Cross-entropy=2.3893523481157093, Accuracy=0.12152777777777778\n",
      "Epoch 13 validation: Cross-entropy=2.412163734436035, Accuracy=0.07070706784725189\n",
      "Epoch 14 train: Cross-entropy=2.3885325855678983, Accuracy=0.1232638888888889\n",
      "Epoch 14 validation: Cross-entropy=2.4124133586883545, Accuracy=0.07070706784725189\n",
      "Epoch 15 train: Cross-entropy=2.387736717859904, Accuracy=0.1232638888888889\n",
      "Epoch 15 validation: Cross-entropy=2.4126663208007812, Accuracy=0.07070706784725189\n",
      "Epoch 16 train: Cross-entropy=2.3869639105266995, Accuracy=0.12152777777777778\n",
      "Epoch 16 validation: Cross-entropy=2.4129221439361572, Accuracy=0.06565656512975693\n",
      "Epoch 17 train: Cross-entropy=2.3862130641937256, Accuracy=0.12152777777777778\n",
      "Epoch 17 validation: Cross-entropy=2.413180351257324, Accuracy=0.06565656512975693\n",
      "Epoch 18 train: Cross-entropy=2.3854832119411893, Accuracy=0.12152777777777778\n",
      "Epoch 18 validation: Cross-entropy=2.4134409427642822, Accuracy=0.06565656512975693\n",
      "Epoch 19 train: Cross-entropy=2.3847736914952598, Accuracy=0.12152777777777778\n",
      "Epoch 19 validation: Cross-entropy=2.413703441619873, Accuracy=0.07070706784725189\n",
      "Epoch 20 train: Cross-entropy=2.38408354918162, Accuracy=0.11631944444444445\n",
      "Epoch 20 validation: Cross-entropy=2.4139671325683594, Accuracy=0.07070706784725189\n",
      "Epoch 21 train: Cross-entropy=2.3834120432535806, Accuracy=0.11805555555555555\n",
      "Epoch 21 validation: Cross-entropy=2.414232015609741, Accuracy=0.06565656512975693\n",
      "Epoch 22 train: Cross-entropy=2.3827583657370672, Accuracy=0.11631944444444445\n",
      "Epoch 22 validation: Cross-entropy=2.4144983291625977, Accuracy=0.06565656512975693\n",
      "Epoch 23 train: Cross-entropy=2.3821218146218195, Accuracy=0.11631944444444445\n",
      "Epoch 23 validation: Cross-entropy=2.4147651195526123, Accuracy=0.06565656512975693\n",
      "Epoch 24 train: Cross-entropy=2.381501793861389, Accuracy=0.11805555555555555\n",
      "Epoch 24 validation: Cross-entropy=2.415031909942627, Accuracy=0.06565656512975693\n",
      "Epoch 25 train: Cross-entropy=2.380897694163852, Accuracy=0.11979166666666667\n",
      "Epoch 25 validation: Cross-entropy=2.4152991771698, Accuracy=0.06565656512975693\n",
      "Epoch 26 train: Cross-entropy=2.380308826764425, Accuracy=0.11805555555555555\n",
      "Epoch 26 validation: Cross-entropy=2.4155666828155518, Accuracy=0.07070706784725189\n",
      "Epoch 27 train: Cross-entropy=2.379734661844042, Accuracy=0.11979166666666667\n",
      "Epoch 27 validation: Cross-entropy=2.4158341884613037, Accuracy=0.07070706784725189\n",
      "Epoch 28 train: Cross-entropy=2.3791746430926852, Accuracy=0.12152777777777778\n",
      "Epoch 28 validation: Cross-entropy=2.4161012172698975, Accuracy=0.06565656512975693\n",
      "Epoch 29 train: Cross-entropy=2.3786282936731973, Accuracy=0.1267361111111111\n",
      "Epoch 29 validation: Cross-entropy=2.416367530822754, Accuracy=0.06565656512975693\n",
      "Epoch 30 train: Cross-entropy=2.3780950572755604, Accuracy=0.1284722222222222\n",
      "Epoch 30 validation: Cross-entropy=2.416633129119873, Accuracy=0.06565656512975693\n",
      "Epoch 31 train: Cross-entropy=2.3775744438171387, Accuracy=0.1284722222222222\n",
      "Epoch 31 validation: Cross-entropy=2.416898488998413, Accuracy=0.06565656512975693\n",
      "Epoch 32 train: Cross-entropy=2.377066148651971, Accuracy=0.13368055555555555\n",
      "Epoch 32 validation: Cross-entropy=2.4171624183654785, Accuracy=0.06565656512975693\n",
      "Epoch 33 train: Cross-entropy=2.376569496260749, Accuracy=0.1371527777777778\n",
      "Epoch 33 validation: Cross-entropy=2.4174258708953857, Accuracy=0.06565656512975693\n",
      "Epoch 34 train: Cross-entropy=2.3760842614703708, Accuracy=0.13368055555555555\n",
      "Epoch 34 validation: Cross-entropy=2.4176876544952393, Accuracy=0.06565656512975693\n",
      "Epoch 35 train: Cross-entropy=2.375610113143921, Accuracy=0.13194444444444445\n",
      "Epoch 35 validation: Cross-entropy=2.4179487228393555, Accuracy=0.06565656512975693\n",
      "Epoch 36 train: Cross-entropy=2.375146468480428, Accuracy=0.13194444444444445\n",
      "Epoch 36 validation: Cross-entropy=2.418208360671997, Accuracy=0.06565656512975693\n",
      "Epoch 37 train: Cross-entropy=2.374693128797743, Accuracy=0.13020833333333334\n",
      "Epoch 37 validation: Cross-entropy=2.418466329574585, Accuracy=0.06565656512975693\n",
      "Epoch 38 train: Cross-entropy=2.3742495907677545, Accuracy=0.13020833333333334\n",
      "Epoch 38 validation: Cross-entropy=2.4187231063842773, Accuracy=0.06565656512975693\n",
      "Epoch 39 train: Cross-entropy=2.3738157086902194, Accuracy=0.1284722222222222\n",
      "Epoch 39 validation: Cross-entropy=2.418978214263916, Accuracy=0.07070706784725189\n",
      "Epoch 40 train: Cross-entropy=2.373391032218933, Accuracy=0.1284722222222222\n",
      "Epoch 40 validation: Cross-entropy=2.41923189163208, Accuracy=0.07070706784725189\n",
      "Epoch 41 train: Cross-entropy=2.3729753626717462, Accuracy=0.1284722222222222\n",
      "Epoch 41 validation: Cross-entropy=2.4194839000701904, Accuracy=0.06565656512975693\n",
      "Epoch 42 train: Cross-entropy=2.3725683291753135, Accuracy=0.1284722222222222\n",
      "Epoch 42 validation: Cross-entropy=2.419734239578247, Accuracy=0.06565656512975693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 train: Cross-entropy=2.372169706556532, Accuracy=0.1267361111111111\n",
      "Epoch 43 validation: Cross-entropy=2.419982671737671, Accuracy=0.06565656512975693\n",
      "Epoch 44 train: Cross-entropy=2.3717792563968234, Accuracy=0.1267361111111111\n",
      "Epoch 44 validation: Cross-entropy=2.420229434967041, Accuracy=0.06565656512975693\n",
      "Epoch 45 train: Cross-entropy=2.371396541595459, Accuracy=0.13020833333333334\n",
      "Epoch 45 validation: Cross-entropy=2.4204742908477783, Accuracy=0.07070706784725189\n",
      "Epoch 46 train: Cross-entropy=2.3710215091705322, Accuracy=0.1284722222222222\n",
      "Epoch 46 validation: Cross-entropy=2.420717477798462, Accuracy=0.07575757801532745\n",
      "Epoch 47 train: Cross-entropy=2.3706539471944175, Accuracy=0.1284722222222222\n",
      "Epoch 47 validation: Cross-entropy=2.4209587574005127, Accuracy=0.08080808073282242\n",
      "Epoch 48 train: Cross-entropy=2.3702934980392456, Accuracy=0.1267361111111111\n",
      "Epoch 48 validation: Cross-entropy=2.4211981296539307, Accuracy=0.08080808073282242\n",
      "Epoch 49 train: Cross-entropy=2.3699399762683444, Accuracy=0.1284722222222222\n",
      "Epoch 49 validation: Cross-entropy=2.4214353561401367, Accuracy=0.08080808073282242\n",
      "Epoch 50 train: Cross-entropy=2.369593169954088, Accuracy=0.13020833333333334\n",
      "Epoch 50 validation: Cross-entropy=2.42167067527771, Accuracy=0.08080808073282242\n",
      "Epoch 51 train: Cross-entropy=2.3692529996236167, Accuracy=0.1284722222222222\n",
      "Epoch 51 validation: Cross-entropy=2.4219040870666504, Accuracy=0.08080808073282242\n",
      "Epoch 52 train: Cross-entropy=2.3689191473854914, Accuracy=0.1284722222222222\n",
      "Epoch 52 validation: Cross-entropy=2.422135829925537, Accuracy=0.08080808073282242\n",
      "Epoch 53 train: Cross-entropy=2.3685914410485163, Accuracy=0.1284722222222222\n",
      "Epoch 53 validation: Cross-entropy=2.422365188598633, Accuracy=0.08080808073282242\n",
      "Epoch 54 train: Cross-entropy=2.3682696554395886, Accuracy=0.13020833333333334\n",
      "Epoch 54 validation: Cross-entropy=2.4225926399230957, Accuracy=0.08080808073282242\n",
      "Epoch 55 train: Cross-entropy=2.367953817049662, Accuracy=0.13194444444444445\n",
      "Epoch 55 validation: Cross-entropy=2.422818183898926, Accuracy=0.08585858345031738\n",
      "Epoch 56 train: Cross-entropy=2.367643528514438, Accuracy=0.13020833333333334\n",
      "Epoch 56 validation: Cross-entropy=2.423041820526123, Accuracy=0.08585858345031738\n",
      "Epoch 57 train: Cross-entropy=2.36733877658844, Accuracy=0.13020833333333334\n",
      "Epoch 57 validation: Cross-entropy=2.4232633113861084, Accuracy=0.08585858345031738\n",
      "Epoch 58 train: Cross-entropy=2.3670393890804715, Accuracy=0.1284722222222222\n",
      "Epoch 58 validation: Cross-entropy=2.423482894897461, Accuracy=0.08585858345031738\n",
      "Epoch 59 train: Cross-entropy=2.3667450878355236, Accuracy=0.13194444444444445\n",
      "Epoch 59 validation: Cross-entropy=2.4237003326416016, Accuracy=0.08585858345031738\n",
      "Epoch 60 train: Cross-entropy=2.36645589934455, Accuracy=0.13194444444444445\n",
      "Epoch 60 validation: Cross-entropy=2.4239156246185303, Accuracy=0.08585858345031738\n",
      "Epoch 61 train: Cross-entropy=2.366171638170878, Accuracy=0.13194444444444445\n",
      "Epoch 61 validation: Cross-entropy=2.4241292476654053, Accuracy=0.08585858345031738\n",
      "Epoch 62 train: Cross-entropy=2.3658920658959284, Accuracy=0.1371527777777778\n",
      "Epoch 62 validation: Cross-entropy=2.4243407249450684, Accuracy=0.08585858345031738\n",
      "Epoch 63 train: Cross-entropy=2.3656172222561307, Accuracy=0.1371527777777778\n",
      "Epoch 63 validation: Cross-entropy=2.4245502948760986, Accuracy=0.09090909361839294\n",
      "Epoch 64 train: Cross-entropy=2.3653468555874295, Accuracy=0.140625\n",
      "Epoch 64 validation: Cross-entropy=2.424757957458496, Accuracy=0.09090909361839294\n",
      "Epoch 65 train: Cross-entropy=2.3650809393988714, Accuracy=0.140625\n",
      "Epoch 65 validation: Cross-entropy=2.4249632358551025, Accuracy=0.09595959633588791\n",
      "Epoch 66 train: Cross-entropy=2.3648193544811673, Accuracy=0.1423611111111111\n",
      "Epoch 66 validation: Cross-entropy=2.4251668453216553, Accuracy=0.09090909361839294\n",
      "Epoch 67 train: Cross-entropy=2.364561835924784, Accuracy=0.1440972222222222\n",
      "Epoch 67 validation: Cross-entropy=2.425368547439575, Accuracy=0.08585858345031738\n",
      "Epoch 68 train: Cross-entropy=2.364308410220676, Accuracy=0.14583333333333334\n",
      "Epoch 68 validation: Cross-entropy=2.4255683422088623, Accuracy=0.08585858345031738\n",
      "Epoch 69 train: Cross-entropy=2.364058905177646, Accuracy=0.14583333333333334\n",
      "Epoch 69 validation: Cross-entropy=2.4257664680480957, Accuracy=0.08585858345031738\n",
      "Epoch 70 train: Cross-entropy=2.363813466495938, Accuracy=0.14583333333333334\n",
      "Epoch 70 validation: Cross-entropy=2.425961971282959, Accuracy=0.09090909361839294\n",
      "Epoch 71 train: Cross-entropy=2.363571564356486, Accuracy=0.14583333333333334\n",
      "Epoch 71 validation: Cross-entropy=2.4261560440063477, Accuracy=0.09090909361839294\n",
      "Epoch 72 train: Cross-entropy=2.3633334901597767, Accuracy=0.14930555555555555\n",
      "Epoch 72 validation: Cross-entropy=2.4263482093811035, Accuracy=0.09090909361839294\n",
      "Epoch 73 train: Cross-entropy=2.3630989260143704, Accuracy=0.14756944444444445\n",
      "Epoch 73 validation: Cross-entropy=2.4265382289886475, Accuracy=0.09090909361839294\n",
      "Epoch 74 train: Cross-entropy=2.3628678586747913, Accuracy=0.14930555555555555\n",
      "Epoch 74 validation: Cross-entropy=2.4267265796661377, Accuracy=0.09090909361839294\n",
      "Epoch 75 train: Cross-entropy=2.362640235159132, Accuracy=0.14930555555555555\n",
      "Epoch 75 validation: Cross-entropy=2.4269134998321533, Accuracy=0.09090909361839294\n",
      "Epoch 76 train: Cross-entropy=2.3624159230126276, Accuracy=0.14756944444444445\n",
      "Epoch 76 validation: Cross-entropy=2.427098035812378, Accuracy=0.09090909361839294\n",
      "Epoch 77 train: Cross-entropy=2.362194789780511, Accuracy=0.14756944444444445\n",
      "Epoch 77 validation: Cross-entropy=2.427281141281128, Accuracy=0.09090909361839294\n",
      "Epoch 78 train: Cross-entropy=2.361976941426595, Accuracy=0.14930555555555555\n",
      "Epoch 78 validation: Cross-entropy=2.427462100982666, Accuracy=0.09090909361839294\n",
      "Epoch 79 train: Cross-entropy=2.3617620733049183, Accuracy=0.14930555555555555\n",
      "Epoch 79 validation: Cross-entropy=2.4276413917541504, Accuracy=0.08585858345031738\n",
      "Epoch 80 train: Cross-entropy=2.3615503443611994, Accuracy=0.14930555555555555\n",
      "Epoch 80 validation: Cross-entropy=2.42781925201416, Accuracy=0.08585858345031738\n",
      "Epoch 81 train: Cross-entropy=2.3613414764404297, Accuracy=0.14930555555555555\n",
      "Epoch 81 validation: Cross-entropy=2.427994966506958, Accuracy=0.08585858345031738\n",
      "Epoch 82 train: Cross-entropy=2.3611355225245156, Accuracy=0.14930555555555555\n",
      "Epoch 82 validation: Cross-entropy=2.428169012069702, Accuracy=0.08585858345031738\n",
      "Epoch 83 train: Cross-entropy=2.360932363404168, Accuracy=0.14930555555555555\n",
      "Epoch 83 validation: Cross-entropy=2.4283413887023926, Accuracy=0.08585858345031738\n",
      "Epoch 84 train: Cross-entropy=2.3607319990793862, Accuracy=0.15104166666666666\n",
      "Epoch 84 validation: Cross-entropy=2.4285123348236084, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.3605342970954046, Accuracy=0.15104166666666666\n",
      "Epoch 85 validation: Cross-entropy=2.4286813735961914, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.360339257452223, Accuracy=0.1527777777777778\n",
      "Epoch 86 validation: Cross-entropy=2.4288489818573, Accuracy=0.08080808073282242\n",
      "Epoch 87 train: Cross-entropy=2.360146721204122, Accuracy=0.1527777777777778\n",
      "Epoch 87 validation: Cross-entropy=2.4290149211883545, Accuracy=0.08080808073282242\n",
      "Epoch 88 train: Cross-entropy=2.359956728087531, Accuracy=0.1527777777777778\n",
      "Epoch 88 validation: Cross-entropy=2.4291789531707764, Accuracy=0.08585858345031738\n",
      "Epoch 89 train: Cross-entropy=2.3597692118750677, Accuracy=0.1527777777777778\n",
      "Epoch 89 validation: Cross-entropy=2.4293415546417236, Accuracy=0.08585858345031738\n",
      "Epoch 90 train: Cross-entropy=2.359584093093872, Accuracy=0.15104166666666666\n",
      "Epoch 90 validation: Cross-entropy=2.4295029640197754, Accuracy=0.08585858345031738\n",
      "Epoch 91 train: Cross-entropy=2.359401305516561, Accuracy=0.15104166666666666\n",
      "Epoch 91 validation: Cross-entropy=2.4296624660491943, Accuracy=0.08585858345031738\n",
      "Epoch 92 train: Cross-entropy=2.3592208094067044, Accuracy=0.15104166666666666\n",
      "Epoch 92 validation: Cross-entropy=2.4298200607299805, Accuracy=0.08585858345031738\n",
      "Epoch 93 train: Cross-entropy=2.3590426047643027, Accuracy=0.1527777777777778\n",
      "Epoch 93 validation: Cross-entropy=2.42997670173645, Accuracy=0.08585858345031738\n",
      "Epoch 94 train: Cross-entropy=2.358866559134589, Accuracy=0.1527777777777778\n",
      "Epoch 94 validation: Cross-entropy=2.430131673812866, Accuracy=0.08585858345031738\n",
      "Epoch 95 train: Cross-entropy=2.358692659272088, Accuracy=0.1527777777777778\n",
      "Epoch 95 validation: Cross-entropy=2.4302852153778076, Accuracy=0.08585858345031738\n",
      "Epoch 96 train: Cross-entropy=2.358520931667752, Accuracy=0.15104166666666666\n",
      "Epoch 96 validation: Cross-entropy=2.4304370880126953, Accuracy=0.08585858345031738\n",
      "Epoch 97 train: Cross-entropy=2.3583512438668146, Accuracy=0.15104166666666666\n",
      "Epoch 97 validation: Cross-entropy=2.4305880069732666, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 train: Cross-entropy=2.3581835826238, Accuracy=0.14930555555555555\n",
      "Epoch 98 validation: Cross-entropy=2.430737018585205, Accuracy=0.08080808073282242\n",
      "Epoch 99 train: Cross-entropy=2.3580179479387073, Accuracy=0.14930555555555555\n",
      "Epoch 99 validation: Cross-entropy=2.430884599685669, Accuracy=0.08080808073282242\n",
      "Epoch 100 train: Cross-entropy=2.3578541543748646, Accuracy=0.15104166666666666\n",
      "Epoch 100 validation: Cross-entropy=2.4310309886932373, Accuracy=0.08080808073282242\n",
      "Epoch 101 train: Cross-entropy=2.357692321141561, Accuracy=0.1527777777777778\n",
      "Epoch 101 validation: Cross-entropy=2.43117618560791, Accuracy=0.08080808073282242\n",
      "Epoch 102 train: Cross-entropy=2.357532342274984, Accuracy=0.1527777777777778\n",
      "Epoch 102 validation: Cross-entropy=2.43131947517395, Accuracy=0.08080808073282242\n",
      "Epoch 103 train: Cross-entropy=2.357374178038703, Accuracy=0.1527777777777778\n",
      "Epoch 103 validation: Cross-entropy=2.431461811065674, Accuracy=0.07575757801532745\n",
      "Epoch 104 train: Cross-entropy=2.357217881414625, Accuracy=0.1545138888888889\n",
      "Epoch 104 validation: Cross-entropy=2.431602954864502, Accuracy=0.07575757801532745\n",
      "Epoch 105 train: Cross-entropy=2.357063227229648, Accuracy=0.15104166666666666\n",
      "Epoch 105 validation: Cross-entropy=2.4317424297332764, Accuracy=0.07070706784725189\n",
      "Epoch 106 train: Cross-entropy=2.356910321447584, Accuracy=0.15104166666666666\n",
      "Epoch 106 validation: Cross-entropy=2.4318809509277344, Accuracy=0.07070706784725189\n",
      "Epoch 107 train: Cross-entropy=2.3567591640684338, Accuracy=0.15104166666666666\n",
      "Epoch 107 validation: Cross-entropy=2.432018280029297, Accuracy=0.07070706784725189\n",
      "Epoch 108 train: Cross-entropy=2.3566096093919544, Accuracy=0.15104166666666666\n",
      "Epoch 108 validation: Cross-entropy=2.4321539402008057, Accuracy=0.07070706784725189\n",
      "Epoch 109 train: Cross-entropy=2.3564617104000516, Accuracy=0.14930555555555555\n",
      "Epoch 109 validation: Cross-entropy=2.432288646697998, Accuracy=0.07070706784725189\n",
      "Epoch 110 train: Cross-entropy=2.3563153876198664, Accuracy=0.15104166666666666\n",
      "Epoch 110 validation: Cross-entropy=2.432422161102295, Accuracy=0.06565656512975693\n",
      "Epoch 111 train: Cross-entropy=2.3561706013149686, Accuracy=0.15104166666666666\n",
      "Epoch 111 validation: Cross-entropy=2.432554244995117, Accuracy=0.06565656512975693\n",
      "Epoch 112 train: Cross-entropy=2.356027364730835, Accuracy=0.15104166666666666\n",
      "Epoch 112 validation: Cross-entropy=2.432685375213623, Accuracy=0.06565656512975693\n",
      "Epoch 113 train: Cross-entropy=2.3558856116400824, Accuracy=0.15104166666666666\n",
      "Epoch 113 validation: Cross-entropy=2.4328153133392334, Accuracy=0.06565656512975693\n",
      "Epoch 114 train: Cross-entropy=2.3557453287972345, Accuracy=0.15104166666666666\n",
      "Epoch 114 validation: Cross-entropy=2.4329440593719482, Accuracy=0.06565656512975693\n",
      "Epoch 115 train: Cross-entropy=2.3556065559387207, Accuracy=0.14930555555555555\n",
      "Epoch 115 validation: Cross-entropy=2.4330716133117676, Accuracy=0.06565656512975693\n",
      "Epoch 116 train: Cross-entropy=2.355469240082635, Accuracy=0.14930555555555555\n",
      "Epoch 116 validation: Cross-entropy=2.4331979751586914, Accuracy=0.06565656512975693\n",
      "Epoch 117 train: Cross-entropy=2.3553332222832575, Accuracy=0.15104166666666666\n",
      "Epoch 117 validation: Cross-entropy=2.433323383331299, Accuracy=0.06565656512975693\n",
      "Epoch 118 train: Cross-entropy=2.3551985820134482, Accuracy=0.1527777777777778\n",
      "Epoch 118 validation: Cross-entropy=2.4334475994110107, Accuracy=0.06565656512975693\n",
      "Epoch 119 train: Cross-entropy=2.3550652927822537, Accuracy=0.1527777777777778\n",
      "Epoch 119 validation: Cross-entropy=2.433570623397827, Accuracy=0.06565656512975693\n",
      "Epoch 120 train: Cross-entropy=2.354933394326104, Accuracy=0.15104166666666666\n",
      "Epoch 120 validation: Cross-entropy=2.4336929321289062, Accuracy=0.06565656512975693\n",
      "Epoch 121 train: Cross-entropy=2.354802754190233, Accuracy=0.15104166666666666\n",
      "Epoch 121 validation: Cross-entropy=2.43381404876709, Accuracy=0.06565656512975693\n",
      "Epoch 122 train: Cross-entropy=2.354673292901781, Accuracy=0.1527777777777778\n",
      "Epoch 122 validation: Cross-entropy=2.433933973312378, Accuracy=0.06565656512975693\n",
      "Epoch 123 train: Cross-entropy=2.354545142915514, Accuracy=0.1545138888888889\n",
      "Epoch 123 validation: Cross-entropy=2.4340529441833496, Accuracy=0.06565656512975693\n",
      "Epoch 124 train: Cross-entropy=2.3544182777404785, Accuracy=0.1545138888888889\n",
      "Epoch 124 validation: Cross-entropy=2.434171199798584, Accuracy=0.06565656512975693\n",
      "Epoch 125 train: Cross-entropy=2.3542926179038153, Accuracy=0.1545138888888889\n",
      "Epoch 125 validation: Cross-entropy=2.434288263320923, Accuracy=0.07575757801532745\n",
      "Epoch 126 train: Cross-entropy=2.354168110423618, Accuracy=0.1545138888888889\n",
      "Epoch 126 validation: Cross-entropy=2.4344043731689453, Accuracy=0.07575757801532745\n",
      "Epoch 127 train: Cross-entropy=2.354044795036316, Accuracy=0.1545138888888889\n",
      "Epoch 127 validation: Cross-entropy=2.4345195293426514, Accuracy=0.07575757801532745\n",
      "Epoch 128 train: Cross-entropy=2.3539225922690497, Accuracy=0.1545138888888889\n",
      "Epoch 128 validation: Cross-entropy=2.434633493423462, Accuracy=0.07575757801532745\n",
      "Epoch 129 train: Cross-entropy=2.353801555103726, Accuracy=0.1545138888888889\n",
      "Epoch 129 validation: Cross-entropy=2.434746742248535, Accuracy=0.07575757801532745\n",
      "Epoch 130 train: Cross-entropy=2.3536815775765314, Accuracy=0.1545138888888889\n",
      "Epoch 130 validation: Cross-entropy=2.434858798980713, Accuracy=0.07575757801532745\n",
      "Epoch 131 train: Cross-entropy=2.353562686178419, Accuracy=0.1545138888888889\n",
      "Epoch 131 validation: Cross-entropy=2.4349701404571533, Accuracy=0.07575757801532745\n",
      "Epoch 132 train: Cross-entropy=2.3534450001186795, Accuracy=0.1545138888888889\n",
      "Epoch 132 validation: Cross-entropy=2.4350807666778564, Accuracy=0.07575757801532745\n",
      "Epoch 133 train: Cross-entropy=2.353328227996826, Accuracy=0.15625\n",
      "Epoch 133 validation: Cross-entropy=2.435190200805664, Accuracy=0.07575757801532745\n",
      "Epoch 134 train: Cross-entropy=2.353212555249532, Accuracy=0.15625\n",
      "Epoch 134 validation: Cross-entropy=2.4352991580963135, Accuracy=0.07575757801532745\n",
      "Epoch 135 train: Cross-entropy=2.3530979288948908, Accuracy=0.15625\n",
      "Epoch 135 validation: Cross-entropy=2.4354069232940674, Accuracy=0.07575757801532745\n",
      "Epoch 136 train: Cross-entropy=2.352984242969089, Accuracy=0.15625\n",
      "Epoch 136 validation: Cross-entropy=2.435513734817505, Accuracy=0.07575757801532745\n",
      "Epoch 137 train: Cross-entropy=2.3528716299268932, Accuracy=0.15625\n",
      "Epoch 137 validation: Cross-entropy=2.435619831085205, Accuracy=0.07575757801532745\n",
      "Epoch 138 train: Cross-entropy=2.3527599573135376, Accuracy=0.1579861111111111\n",
      "Epoch 138 validation: Cross-entropy=2.435725450515747, Accuracy=0.07575757801532745\n",
      "Epoch 139 train: Cross-entropy=2.352649172147115, Accuracy=0.1579861111111111\n",
      "Epoch 139 validation: Cross-entropy=2.4358298778533936, Accuracy=0.07575757801532745\n",
      "Epoch 140 train: Cross-entropy=2.3525394333733454, Accuracy=0.1579861111111111\n",
      "Epoch 140 validation: Cross-entropy=2.4359335899353027, Accuracy=0.07575757801532745\n",
      "Epoch 141 train: Cross-entropy=2.352430635028415, Accuracy=0.1579861111111111\n",
      "Epoch 141 validation: Cross-entropy=2.4360365867614746, Accuracy=0.07575757801532745\n",
      "Epoch 142 train: Cross-entropy=2.3523226181666055, Accuracy=0.1579861111111111\n",
      "Epoch 142 validation: Cross-entropy=2.43613862991333, Accuracy=0.07575757801532745\n",
      "Epoch 143 train: Cross-entropy=2.3522155947155423, Accuracy=0.1579861111111111\n",
      "Epoch 143 validation: Cross-entropy=2.4362399578094482, Accuracy=0.07575757801532745\n",
      "Epoch 144 train: Cross-entropy=2.3521093924840293, Accuracy=0.1579861111111111\n",
      "Epoch 144 validation: Cross-entropy=2.4363410472869873, Accuracy=0.07575757801532745\n",
      "Epoch 145 train: Cross-entropy=2.3520042101542153, Accuracy=0.1579861111111111\n",
      "Epoch 145 validation: Cross-entropy=2.4364407062530518, Accuracy=0.07575757801532745\n",
      "Epoch 146 train: Cross-entropy=2.351899743080139, Accuracy=0.1579861111111111\n",
      "Epoch 146 validation: Cross-entropy=2.436539649963379, Accuracy=0.07575757801532745\n",
      "Epoch 147 train: Cross-entropy=2.3517961502075195, Accuracy=0.15625\n",
      "Epoch 147 validation: Cross-entropy=2.436638116836548, Accuracy=0.07575757801532745\n",
      "Epoch 148 train: Cross-entropy=2.35169341829088, Accuracy=0.15625\n",
      "Epoch 148 validation: Cross-entropy=2.4367356300354004, Accuracy=0.07575757801532745\n",
      "Epoch 149 train: Cross-entropy=2.3515915208392673, Accuracy=0.1579861111111111\n",
      "Epoch 149 validation: Cross-entropy=2.4368326663970947, Accuracy=0.07575757801532745\n",
      "Epoch 150 train: Cross-entropy=2.351490471098158, Accuracy=0.1597222222222222\n",
      "Epoch 150 validation: Cross-entropy=2.4369289875030518, Accuracy=0.07575757801532745\n",
      "Epoch 151 train: Cross-entropy=2.351390096876356, Accuracy=0.1597222222222222\n",
      "Epoch 151 validation: Cross-entropy=2.4370245933532715, Accuracy=0.07575757801532745\n",
      "Epoch 152 train: Cross-entropy=2.3512906630833945, Accuracy=0.1597222222222222\n",
      "Epoch 152 validation: Cross-entropy=2.437119245529175, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 train: Cross-entropy=2.351191931300693, Accuracy=0.1597222222222222\n",
      "Epoch 153 validation: Cross-entropy=2.437213897705078, Accuracy=0.07575757801532745\n",
      "Epoch 154 train: Cross-entropy=2.3510939412646823, Accuracy=0.1579861111111111\n",
      "Epoch 154 validation: Cross-entropy=2.437307357788086, Accuracy=0.07575757801532745\n",
      "Epoch 155 train: Cross-entropy=2.3509967724482217, Accuracy=0.1579861111111111\n",
      "Epoch 155 validation: Cross-entropy=2.4374003410339355, Accuracy=0.07575757801532745\n",
      "Epoch 156 train: Cross-entropy=2.3509002791510687, Accuracy=0.1579861111111111\n",
      "Epoch 156 validation: Cross-entropy=2.4374923706054688, Accuracy=0.07575757801532745\n",
      "Epoch 157 train: Cross-entropy=2.350804567337036, Accuracy=0.1579861111111111\n",
      "Epoch 157 validation: Cross-entropy=2.4375839233398438, Accuracy=0.07575757801532745\n",
      "Epoch 158 train: Cross-entropy=2.350709570778741, Accuracy=0.1597222222222222\n",
      "Epoch 158 validation: Cross-entropy=2.4376749992370605, Accuracy=0.07575757801532745\n",
      "Epoch 159 train: Cross-entropy=2.350615302721659, Accuracy=0.16145833333333334\n",
      "Epoch 159 validation: Cross-entropy=2.4377658367156982, Accuracy=0.07575757801532745\n",
      "Epoch 160 train: Cross-entropy=2.3505217101838856, Accuracy=0.16145833333333334\n",
      "Epoch 160 validation: Cross-entropy=2.4378554821014404, Accuracy=0.07575757801532745\n",
      "Epoch 161 train: Cross-entropy=2.3504287931654186, Accuracy=0.16145833333333334\n",
      "Epoch 161 validation: Cross-entropy=2.4379444122314453, Accuracy=0.07575757801532745\n",
      "Epoch 162 train: Cross-entropy=2.3503365914026895, Accuracy=0.16145833333333334\n",
      "Epoch 162 validation: Cross-entropy=2.438033103942871, Accuracy=0.07575757801532745\n",
      "Epoch 163 train: Cross-entropy=2.3502450386683145, Accuracy=0.16145833333333334\n",
      "Epoch 163 validation: Cross-entropy=2.4381210803985596, Accuracy=0.07575757801532745\n",
      "Epoch 164 train: Cross-entropy=2.3501542939080133, Accuracy=0.16145833333333334\n",
      "Epoch 164 validation: Cross-entropy=2.4382083415985107, Accuracy=0.07575757801532745\n",
      "Epoch 165 train: Cross-entropy=2.350063999493917, Accuracy=0.1597222222222222\n",
      "Epoch 165 validation: Cross-entropy=2.438295364379883, Accuracy=0.07575757801532745\n",
      "Epoch 166 train: Cross-entropy=2.3499744865629406, Accuracy=0.1597222222222222\n",
      "Epoch 166 validation: Cross-entropy=2.4383816719055176, Accuracy=0.07575757801532745\n",
      "Epoch 167 train: Cross-entropy=2.349885582923889, Accuracy=0.1597222222222222\n",
      "Epoch 167 validation: Cross-entropy=2.438467264175415, Accuracy=0.07575757801532745\n",
      "Epoch 168 train: Cross-entropy=2.349797328313192, Accuracy=0.1597222222222222\n",
      "Epoch 168 validation: Cross-entropy=2.4385526180267334, Accuracy=0.07575757801532745\n",
      "Epoch 169 train: Cross-entropy=2.349709630012512, Accuracy=0.1597222222222222\n",
      "Epoch 169 validation: Cross-entropy=2.4386372566223145, Accuracy=0.07575757801532745\n",
      "Epoch 170 train: Cross-entropy=2.34962260723114, Accuracy=0.1597222222222222\n",
      "Epoch 170 validation: Cross-entropy=2.4387214183807373, Accuracy=0.07575757801532745\n",
      "Epoch 171 train: Cross-entropy=2.3495361937416925, Accuracy=0.1597222222222222\n",
      "Epoch 171 validation: Cross-entropy=2.438805103302002, Accuracy=0.07575757801532745\n",
      "Epoch 172 train: Cross-entropy=2.349450429280599, Accuracy=0.1579861111111111\n",
      "Epoch 172 validation: Cross-entropy=2.4388883113861084, Accuracy=0.07575757801532745\n",
      "Epoch 173 train: Cross-entropy=2.3493652078840466, Accuracy=0.15625\n",
      "Epoch 173 validation: Cross-entropy=2.4389705657958984, Accuracy=0.07575757801532745\n",
      "Epoch 174 train: Cross-entropy=2.3492806222703724, Accuracy=0.15625\n",
      "Epoch 174 validation: Cross-entropy=2.4390525817871094, Accuracy=0.08080808073282242\n",
      "Epoch 175 train: Cross-entropy=2.3491965929667153, Accuracy=0.15625\n",
      "Epoch 175 validation: Cross-entropy=2.439134359359741, Accuracy=0.08080808073282242\n",
      "Epoch 176 train: Cross-entropy=2.3491130934821234, Accuracy=0.15625\n",
      "Epoch 176 validation: Cross-entropy=2.4392151832580566, Accuracy=0.08080808073282242\n",
      "Epoch 177 train: Cross-entropy=2.349030163553026, Accuracy=0.15625\n",
      "Epoch 177 validation: Cross-entropy=2.439296007156372, Accuracy=0.08585858345031738\n",
      "Epoch 178 train: Cross-entropy=2.3489478561613293, Accuracy=0.15625\n",
      "Epoch 178 validation: Cross-entropy=2.439375638961792, Accuracy=0.08585858345031738\n",
      "Epoch 179 train: Cross-entropy=2.3488660785886974, Accuracy=0.15625\n",
      "Epoch 179 validation: Cross-entropy=2.439455270767212, Accuracy=0.08585858345031738\n",
      "Epoch 180 train: Cross-entropy=2.348784844080607, Accuracy=0.15625\n",
      "Epoch 180 validation: Cross-entropy=2.4395344257354736, Accuracy=0.08585858345031738\n",
      "Epoch 181 train: Cross-entropy=2.348704139391581, Accuracy=0.15625\n",
      "Epoch 181 validation: Cross-entropy=2.4396133422851562, Accuracy=0.08585858345031738\n",
      "Epoch 182 train: Cross-entropy=2.34862396452162, Accuracy=0.15625\n",
      "Epoch 182 validation: Cross-entropy=2.4396915435791016, Accuracy=0.08585858345031738\n",
      "Epoch 183 train: Cross-entropy=2.3485442797342935, Accuracy=0.15625\n",
      "Epoch 183 validation: Cross-entropy=2.4397692680358887, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.348465257220798, Accuracy=0.15625\n",
      "Epoch 184 validation: Cross-entropy=2.4398465156555176, Accuracy=0.09090909361839294\n",
      "Epoch 185 train: Cross-entropy=2.3483866585625544, Accuracy=0.15625\n",
      "Epoch 185 validation: Cross-entropy=2.4399235248565674, Accuracy=0.09090909361839294\n",
      "Epoch 186 train: Cross-entropy=2.3483086029688516, Accuracy=0.15625\n",
      "Epoch 186 validation: Cross-entropy=2.43999981880188, Accuracy=0.09090909361839294\n",
      "Epoch 187 train: Cross-entropy=2.3482310109668307, Accuracy=0.15625\n",
      "Epoch 187 validation: Cross-entropy=2.4400758743286133, Accuracy=0.09090909361839294\n",
      "Epoch 188 train: Cross-entropy=2.348153935538398, Accuracy=0.15625\n",
      "Epoch 188 validation: Cross-entropy=2.4401516914367676, Accuracy=0.09090909361839294\n",
      "Epoch 189 train: Cross-entropy=2.348077376683553, Accuracy=0.15625\n",
      "Epoch 189 validation: Cross-entropy=2.4402267932891846, Accuracy=0.09090909361839294\n",
      "Epoch 190 train: Cross-entropy=2.348001334402296, Accuracy=0.15625\n",
      "Epoch 190 validation: Cross-entropy=2.4403014183044434, Accuracy=0.09090909361839294\n",
      "Epoch 191 train: Cross-entropy=2.3479256762398615, Accuracy=0.15625\n",
      "Epoch 191 validation: Cross-entropy=2.440376043319702, Accuracy=0.09090909361839294\n",
      "Epoch 192 train: Cross-entropy=2.3478505611419678, Accuracy=0.15625\n",
      "Epoch 192 validation: Cross-entropy=2.4404497146606445, Accuracy=0.09090909361839294\n",
      "Epoch 193 train: Cross-entropy=2.347775856653849, Accuracy=0.15625\n",
      "Epoch 193 validation: Cross-entropy=2.440523386001587, Accuracy=0.09090909361839294\n",
      "Epoch 194 train: Cross-entropy=2.347701734966702, Accuracy=0.15625\n",
      "Epoch 194 validation: Cross-entropy=2.440596580505371, Accuracy=0.09090909361839294\n",
      "Epoch 195 train: Cross-entropy=2.347628010643853, Accuracy=0.15625\n",
      "Epoch 195 validation: Cross-entropy=2.440669298171997, Accuracy=0.09090909361839294\n",
      "Epoch 196 train: Cross-entropy=2.3475547631581626, Accuracy=0.15625\n",
      "Epoch 196 validation: Cross-entropy=2.440741777420044, Accuracy=0.09090909361839294\n",
      "Epoch 197 train: Cross-entropy=2.347482019000583, Accuracy=0.15625\n",
      "Epoch 197 validation: Cross-entropy=2.4408140182495117, Accuracy=0.09090909361839294\n",
      "Epoch 198 train: Cross-entropy=2.3474096059799194, Accuracy=0.15625\n",
      "Epoch 198 validation: Cross-entropy=2.440885305404663, Accuracy=0.09090909361839294\n",
      "Epoch 199 train: Cross-entropy=2.347337736023797, Accuracy=0.1545138888888889\n",
      "Epoch 199 validation: Cross-entropy=2.4409565925598145, Accuracy=0.09090909361839294\n",
      "Epoch 0 train: Cross-entropy=2.4255928728315563, Accuracy=0.0954861111111111\n",
      "Epoch 0 validation: Cross-entropy=2.4132440090179443, Accuracy=0.08585858345031738\n",
      "Epoch 1 train: Cross-entropy=2.40585896703932, Accuracy=0.08680555555555555\n",
      "Epoch 1 validation: Cross-entropy=2.416581869125366, Accuracy=0.08585858345031738\n",
      "Epoch 2 train: Cross-entropy=2.4037623008092246, Accuracy=0.08159722222222222\n",
      "Epoch 2 validation: Cross-entropy=2.4167556762695312, Accuracy=0.07575757801532745\n",
      "Epoch 3 train: Cross-entropy=2.401626017358568, Accuracy=0.08506944444444445\n",
      "Epoch 3 validation: Cross-entropy=2.4168477058410645, Accuracy=0.07575757801532745\n",
      "Epoch 4 train: Cross-entropy=2.3995916843414307, Accuracy=0.08333333333333333\n",
      "Epoch 4 validation: Cross-entropy=2.4169774055480957, Accuracy=0.07575757801532745\n",
      "Epoch 5 train: Cross-entropy=2.3976570897632175, Accuracy=0.08854166666666667\n",
      "Epoch 5 validation: Cross-entropy=2.4171440601348877, Accuracy=0.06565656512975693\n",
      "Epoch 6 train: Cross-entropy=2.3958153989579944, Accuracy=0.0954861111111111\n",
      "Epoch 6 validation: Cross-entropy=2.417343854904175, Accuracy=0.06565656512975693\n",
      "Epoch 7 train: Cross-entropy=2.394060320324368, Accuracy=0.09722222222222222\n",
      "Epoch 7 validation: Cross-entropy=2.4175734519958496, Accuracy=0.07070706784725189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: Cross-entropy=2.3923864629533558, Accuracy=0.10416666666666667\n",
      "Epoch 8 validation: Cross-entropy=2.4178295135498047, Accuracy=0.06565656512975693\n",
      "Epoch 9 train: Cross-entropy=2.390788621372647, Accuracy=0.10416666666666667\n",
      "Epoch 9 validation: Cross-entropy=2.4181087017059326, Accuracy=0.07575757801532745\n",
      "Epoch 10 train: Cross-entropy=2.389262146419949, Accuracy=0.10590277777777778\n",
      "Epoch 10 validation: Cross-entropy=2.4184086322784424, Accuracy=0.08080808073282242\n",
      "Epoch 11 train: Cross-entropy=2.387802587615119, Accuracy=0.109375\n",
      "Epoch 11 validation: Cross-entropy=2.418726682662964, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.3864060242970786, Accuracy=0.1111111111111111\n",
      "Epoch 12 validation: Cross-entropy=2.419060468673706, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.385068562295702, Accuracy=0.11458333333333333\n",
      "Epoch 13 validation: Cross-entropy=2.419408082962036, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.3837868902418347, Accuracy=0.11979166666666667\n",
      "Epoch 14 validation: Cross-entropy=2.4197678565979004, Accuracy=0.07070706784725189\n",
      "Epoch 15 train: Cross-entropy=2.38255767027537, Accuracy=0.1232638888888889\n",
      "Epoch 15 validation: Cross-entropy=2.420137882232666, Accuracy=0.07070706784725189\n",
      "Epoch 16 train: Cross-entropy=2.3813779751459756, Accuracy=0.1284722222222222\n",
      "Epoch 16 validation: Cross-entropy=2.4205167293548584, Accuracy=0.07070706784725189\n",
      "Epoch 17 train: Cross-entropy=2.3802449968126087, Accuracy=0.1284722222222222\n",
      "Epoch 17 validation: Cross-entropy=2.420903444290161, Accuracy=0.07070706784725189\n",
      "Epoch 18 train: Cross-entropy=2.3791561788982816, Accuracy=0.13020833333333334\n",
      "Epoch 18 validation: Cross-entropy=2.4212958812713623, Accuracy=0.06565656512975693\n",
      "Epoch 19 train: Cross-entropy=2.3781090709898205, Accuracy=0.13020833333333334\n",
      "Epoch 19 validation: Cross-entropy=2.4216935634613037, Accuracy=0.07070706784725189\n",
      "Epoch 20 train: Cross-entropy=2.3771014875835843, Accuracy=0.13541666666666666\n",
      "Epoch 20 validation: Cross-entropy=2.42209529876709, Accuracy=0.07070706784725189\n",
      "Epoch 21 train: Cross-entropy=2.376131256421407, Accuracy=0.1388888888888889\n",
      "Epoch 21 validation: Cross-entropy=2.422499895095825, Accuracy=0.07070706784725189\n",
      "Epoch 22 train: Cross-entropy=2.37519641717275, Accuracy=0.1371527777777778\n",
      "Epoch 22 validation: Cross-entropy=2.4229068756103516, Accuracy=0.0555555559694767\n",
      "Epoch 23 train: Cross-entropy=2.3742952081892224, Accuracy=0.1388888888888889\n",
      "Epoch 23 validation: Cross-entropy=2.4233152866363525, Accuracy=0.05050504952669144\n",
      "Epoch 24 train: Cross-entropy=2.3734258943133884, Accuracy=0.1423611111111111\n",
      "Epoch 24 validation: Cross-entropy=2.4237241744995117, Accuracy=0.05050504952669144\n",
      "Epoch 25 train: Cross-entropy=2.3725867536332874, Accuracy=0.1423611111111111\n",
      "Epoch 25 validation: Cross-entropy=2.42413330078125, Accuracy=0.05050504952669144\n",
      "Epoch 26 train: Cross-entropy=2.3717764218648276, Accuracy=0.1423611111111111\n",
      "Epoch 26 validation: Cross-entropy=2.42454195022583, Accuracy=0.05050504952669144\n",
      "Epoch 27 train: Cross-entropy=2.3709934287601047, Accuracy=0.1388888888888889\n",
      "Epoch 27 validation: Cross-entropy=2.424949884414673, Accuracy=0.05050504952669144\n",
      "Epoch 28 train: Cross-entropy=2.370236463016934, Accuracy=0.1388888888888889\n",
      "Epoch 28 validation: Cross-entropy=2.425356149673462, Accuracy=0.05050504952669144\n",
      "Epoch 29 train: Cross-entropy=2.3695043192969427, Accuracy=0.1388888888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4257607460021973, Accuracy=0.0555555559694767\n",
      "Epoch 30 train: Cross-entropy=2.3687956598069935, Accuracy=0.1423611111111111\n",
      "Epoch 30 validation: Cross-entropy=2.4261629581451416, Accuracy=0.0555555559694767\n",
      "Epoch 31 train: Cross-entropy=2.3681096103456287, Accuracy=0.1423611111111111\n",
      "Epoch 31 validation: Cross-entropy=2.4265623092651367, Accuracy=0.0555555559694767\n",
      "Epoch 32 train: Cross-entropy=2.3674449920654297, Accuracy=0.1423611111111111\n",
      "Epoch 32 validation: Cross-entropy=2.4269587993621826, Accuracy=0.0555555559694767\n",
      "Epoch 33 train: Cross-entropy=2.366800864537557, Accuracy=0.1440972222222222\n",
      "Epoch 33 validation: Cross-entropy=2.4273526668548584, Accuracy=0.06060606241226196\n",
      "Epoch 34 train: Cross-entropy=2.3661763270696006, Accuracy=0.1440972222222222\n",
      "Epoch 34 validation: Cross-entropy=2.4277427196502686, Accuracy=0.06060606241226196\n",
      "Epoch 35 train: Cross-entropy=2.365570545196533, Accuracy=0.14583333333333334\n",
      "Epoch 35 validation: Cross-entropy=2.4281296730041504, Accuracy=0.06060606241226196\n",
      "Epoch 36 train: Cross-entropy=2.3649825519985623, Accuracy=0.14756944444444445\n",
      "Epoch 36 validation: Cross-entropy=2.4285123348236084, Accuracy=0.06565656512975693\n",
      "Epoch 37 train: Cross-entropy=2.3644117646747165, Accuracy=0.14756944444444445\n",
      "Epoch 37 validation: Cross-entropy=2.428891181945801, Accuracy=0.06565656512975693\n",
      "Epoch 38 train: Cross-entropy=2.3638573620054455, Accuracy=0.14930555555555555\n",
      "Epoch 38 validation: Cross-entropy=2.4292662143707275, Accuracy=0.06565656512975693\n",
      "Epoch 39 train: Cross-entropy=2.3633186287350125, Accuracy=0.14756944444444445\n",
      "Epoch 39 validation: Cross-entropy=2.4296367168426514, Accuracy=0.06565656512975693\n",
      "Epoch 40 train: Cross-entropy=2.3627949820624456, Accuracy=0.14756944444444445\n",
      "Epoch 40 validation: Cross-entropy=2.4300031661987305, Accuracy=0.06565656512975693\n",
      "Epoch 41 train: Cross-entropy=2.362285772959391, Accuracy=0.14756944444444445\n",
      "Epoch 41 validation: Cross-entropy=2.4303650856018066, Accuracy=0.06565656512975693\n",
      "Epoch 42 train: Cross-entropy=2.3617903788884482, Accuracy=0.14930555555555555\n",
      "Epoch 42 validation: Cross-entropy=2.430722713470459, Accuracy=0.06060606241226196\n",
      "Epoch 43 train: Cross-entropy=2.361308309766981, Accuracy=0.14930555555555555\n",
      "Epoch 43 validation: Cross-entropy=2.4310755729675293, Accuracy=0.06060606241226196\n",
      "Epoch 44 train: Cross-entropy=2.3608390622668796, Accuracy=0.14583333333333334\n",
      "Epoch 44 validation: Cross-entropy=2.431424140930176, Accuracy=0.06060606241226196\n",
      "Epoch 45 train: Cross-entropy=2.3603820403416953, Accuracy=0.1423611111111111\n",
      "Epoch 45 validation: Cross-entropy=2.4317681789398193, Accuracy=0.06565656512975693\n",
      "Epoch 46 train: Cross-entropy=2.3599368466271295, Accuracy=0.140625\n",
      "Epoch 46 validation: Cross-entropy=2.4321072101593018, Accuracy=0.06565656512975693\n",
      "Epoch 47 train: Cross-entropy=2.3595030440224543, Accuracy=0.140625\n",
      "Epoch 47 validation: Cross-entropy=2.4324419498443604, Accuracy=0.06565656512975693\n",
      "Epoch 48 train: Cross-entropy=2.3590801424450345, Accuracy=0.1388888888888889\n",
      "Epoch 48 validation: Cross-entropy=2.432772159576416, Accuracy=0.06565656512975693\n",
      "Epoch 49 train: Cross-entropy=2.3586678240034313, Accuracy=0.1388888888888889\n",
      "Epoch 49 validation: Cross-entropy=2.4330973625183105, Accuracy=0.06565656512975693\n",
      "Epoch 50 train: Cross-entropy=2.358265585369534, Accuracy=0.1388888888888889\n",
      "Epoch 50 validation: Cross-entropy=2.4334182739257812, Accuracy=0.06565656512975693\n",
      "Epoch 51 train: Cross-entropy=2.357873214615716, Accuracy=0.140625\n",
      "Epoch 51 validation: Cross-entropy=2.433734178543091, Accuracy=0.07070706784725189\n",
      "Epoch 52 train: Cross-entropy=2.3574902216593423, Accuracy=0.140625\n",
      "Epoch 52 validation: Cross-entropy=2.4340460300445557, Accuracy=0.07070706784725189\n",
      "Epoch 53 train: Cross-entropy=2.357116315099928, Accuracy=0.140625\n",
      "Epoch 53 validation: Cross-entropy=2.4343528747558594, Accuracy=0.07070706784725189\n",
      "Epoch 54 train: Cross-entropy=2.356751216782464, Accuracy=0.1388888888888889\n",
      "Epoch 54 validation: Cross-entropy=2.43465518951416, Accuracy=0.07070706784725189\n",
      "Epoch 55 train: Cross-entropy=2.356394648551941, Accuracy=0.1388888888888889\n",
      "Epoch 55 validation: Cross-entropy=2.434953212738037, Accuracy=0.07070706784725189\n",
      "Epoch 56 train: Cross-entropy=2.356046199798584, Accuracy=0.1371527777777778\n",
      "Epoch 56 validation: Cross-entropy=2.435246229171753, Accuracy=0.07070706784725189\n",
      "Epoch 57 train: Cross-entropy=2.3557057248221502, Accuracy=0.1371527777777778\n",
      "Epoch 57 validation: Cross-entropy=2.435535430908203, Accuracy=0.07575757801532745\n",
      "Epoch 58 train: Cross-entropy=2.3553728792402477, Accuracy=0.1371527777777778\n",
      "Epoch 58 validation: Cross-entropy=2.4358201026916504, Accuracy=0.07575757801532745\n",
      "Epoch 59 train: Cross-entropy=2.355047517352634, Accuracy=0.1388888888888889\n",
      "Epoch 59 validation: Cross-entropy=2.4361002445220947, Accuracy=0.07575757801532745\n",
      "Epoch 60 train: Cross-entropy=2.3547292947769165, Accuracy=0.1388888888888889\n",
      "Epoch 60 validation: Cross-entropy=2.4363763332366943, Accuracy=0.07575757801532745\n",
      "Epoch 61 train: Cross-entropy=2.354418012830946, Accuracy=0.140625\n",
      "Epoch 61 validation: Cross-entropy=2.436647891998291, Accuracy=0.07575757801532745\n",
      "Epoch 62 train: Cross-entropy=2.3541134860780506, Accuracy=0.1423611111111111\n",
      "Epoch 62 validation: Cross-entropy=2.436915159225464, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 train: Cross-entropy=2.35381543636322, Accuracy=0.14583333333333334\n",
      "Epoch 63 validation: Cross-entropy=2.43717885017395, Accuracy=0.07575757801532745\n",
      "Epoch 64 train: Cross-entropy=2.3535236385133533, Accuracy=0.1440972222222222\n",
      "Epoch 64 validation: Cross-entropy=2.4374377727508545, Accuracy=0.07575757801532745\n",
      "Epoch 65 train: Cross-entropy=2.3532380527920194, Accuracy=0.1423611111111111\n",
      "Epoch 65 validation: Cross-entropy=2.437692880630493, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.35295840104421, Accuracy=0.1423611111111111\n",
      "Epoch 66 validation: Cross-entropy=2.437944173812866, Accuracy=0.07575757801532745\n",
      "Epoch 67 train: Cross-entropy=2.3526845243242054, Accuracy=0.1423611111111111\n",
      "Epoch 67 validation: Cross-entropy=2.4381914138793945, Accuracy=0.07575757801532745\n",
      "Epoch 68 train: Cross-entropy=2.3524161842134266, Accuracy=0.1423611111111111\n",
      "Epoch 68 validation: Cross-entropy=2.438434600830078, Accuracy=0.07575757801532745\n",
      "Epoch 69 train: Cross-entropy=2.3521533144844904, Accuracy=0.1440972222222222\n",
      "Epoch 69 validation: Cross-entropy=2.438673973083496, Accuracy=0.07070706784725189\n",
      "Epoch 70 train: Cross-entropy=2.3518957561916776, Accuracy=0.14583333333333334\n",
      "Epoch 70 validation: Cross-entropy=2.4389097690582275, Accuracy=0.07070706784725189\n",
      "Epoch 71 train: Cross-entropy=2.3516432444254556, Accuracy=0.14583333333333334\n",
      "Epoch 71 validation: Cross-entropy=2.4391415119171143, Accuracy=0.07070706784725189\n",
      "Epoch 72 train: Cross-entropy=2.351395779185825, Accuracy=0.14583333333333334\n",
      "Epoch 72 validation: Cross-entropy=2.4393699169158936, Accuracy=0.07070706784725189\n",
      "Epoch 73 train: Cross-entropy=2.351153108808729, Accuracy=0.14583333333333334\n",
      "Epoch 73 validation: Cross-entropy=2.4395945072174072, Accuracy=0.07575757801532745\n",
      "Epoch 74 train: Cross-entropy=2.350915167066786, Accuracy=0.14583333333333334\n",
      "Epoch 74 validation: Cross-entropy=2.4398157596588135, Accuracy=0.07575757801532745\n",
      "Epoch 75 train: Cross-entropy=2.3506817950142755, Accuracy=0.14756944444444445\n",
      "Epoch 75 validation: Cross-entropy=2.440033197402954, Accuracy=0.07575757801532745\n",
      "Epoch 76 train: Cross-entropy=2.350452833705478, Accuracy=0.14756944444444445\n",
      "Epoch 76 validation: Cross-entropy=2.4402475357055664, Accuracy=0.07575757801532745\n",
      "Epoch 77 train: Cross-entropy=2.350228375858731, Accuracy=0.14756944444444445\n",
      "Epoch 77 validation: Cross-entropy=2.4404587745666504, Accuracy=0.07575757801532745\n",
      "Epoch 78 train: Cross-entropy=2.350007997618781, Accuracy=0.14756944444444445\n",
      "Epoch 78 validation: Cross-entropy=2.4406659603118896, Accuracy=0.07575757801532745\n",
      "Epoch 79 train: Cross-entropy=2.349791791703966, Accuracy=0.14756944444444445\n",
      "Epoch 79 validation: Cross-entropy=2.4408702850341797, Accuracy=0.07575757801532745\n",
      "Epoch 80 train: Cross-entropy=2.349579519695706, Accuracy=0.14756944444444445\n",
      "Epoch 80 validation: Cross-entropy=2.4410712718963623, Accuracy=0.07575757801532745\n",
      "Epoch 81 train: Cross-entropy=2.3493712345759072, Accuracy=0.14756944444444445\n",
      "Epoch 81 validation: Cross-entropy=2.4412691593170166, Accuracy=0.07575757801532745\n",
      "Epoch 82 train: Cross-entropy=2.3491667244169445, Accuracy=0.14930555555555555\n",
      "Epoch 82 validation: Cross-entropy=2.4414639472961426, Accuracy=0.07575757801532745\n",
      "Epoch 83 train: Cross-entropy=2.3489659229914346, Accuracy=0.14930555555555555\n",
      "Epoch 83 validation: Cross-entropy=2.441655397415161, Accuracy=0.07575757801532745\n",
      "Epoch 84 train: Cross-entropy=2.348768843544854, Accuracy=0.14930555555555555\n",
      "Epoch 84 validation: Cross-entropy=2.4418442249298096, Accuracy=0.07575757801532745\n",
      "Epoch 85 train: Cross-entropy=2.348575128449334, Accuracy=0.14583333333333334\n",
      "Epoch 85 validation: Cross-entropy=2.4420299530029297, Accuracy=0.07575757801532745\n",
      "Epoch 86 train: Cross-entropy=2.3483849366505942, Accuracy=0.14583333333333334\n",
      "Epoch 86 validation: Cross-entropy=2.4422128200531006, Accuracy=0.07575757801532745\n",
      "Epoch 87 train: Cross-entropy=2.3481980827119617, Accuracy=0.14583333333333334\n",
      "Epoch 87 validation: Cross-entropy=2.4423930644989014, Accuracy=0.07575757801532745\n",
      "Epoch 88 train: Cross-entropy=2.3480144606696234, Accuracy=0.14583333333333334\n",
      "Epoch 88 validation: Cross-entropy=2.4425697326660156, Accuracy=0.07575757801532745\n",
      "Epoch 89 train: Cross-entropy=2.3478341235054865, Accuracy=0.14756944444444445\n",
      "Epoch 89 validation: Cross-entropy=2.442744016647339, Accuracy=0.07575757801532745\n",
      "Epoch 90 train: Cross-entropy=2.3476569520102606, Accuracy=0.14756944444444445\n",
      "Epoch 90 validation: Cross-entropy=2.442915678024292, Accuracy=0.07575757801532745\n",
      "Epoch 91 train: Cross-entropy=2.347482747501797, Accuracy=0.14583333333333334\n",
      "Epoch 91 validation: Cross-entropy=2.443084716796875, Accuracy=0.07575757801532745\n",
      "Epoch 92 train: Cross-entropy=2.347311509980096, Accuracy=0.1440972222222222\n",
      "Epoch 92 validation: Cross-entropy=2.443251132965088, Accuracy=0.08080808073282242\n",
      "Epoch 93 train: Cross-entropy=2.34714322619968, Accuracy=0.14583333333333334\n",
      "Epoch 93 validation: Cross-entropy=2.4434149265289307, Accuracy=0.08080808073282242\n",
      "Epoch 94 train: Cross-entropy=2.3469777637057834, Accuracy=0.14583333333333334\n",
      "Epoch 94 validation: Cross-entropy=2.4435760974884033, Accuracy=0.08080808073282242\n",
      "Epoch 95 train: Cross-entropy=2.346815162234836, Accuracy=0.1440972222222222\n",
      "Epoch 95 validation: Cross-entropy=2.443734884262085, Accuracy=0.08080808073282242\n",
      "Epoch 96 train: Cross-entropy=2.346655183368259, Accuracy=0.1440972222222222\n",
      "Epoch 96 validation: Cross-entropy=2.4438912868499756, Accuracy=0.08080808073282242\n",
      "Epoch 97 train: Cross-entropy=2.3464979463153415, Accuracy=0.1440972222222222\n",
      "Epoch 97 validation: Cross-entropy=2.444045066833496, Accuracy=0.08585858345031738\n",
      "Epoch 98 train: Cross-entropy=2.3463432523939343, Accuracy=0.14583333333333334\n",
      "Epoch 98 validation: Cross-entropy=2.444196939468384, Accuracy=0.08585858345031738\n",
      "Epoch 99 train: Cross-entropy=2.346191167831421, Accuracy=0.14583333333333334\n",
      "Epoch 99 validation: Cross-entropy=2.444345712661743, Accuracy=0.08585858345031738\n",
      "Epoch 100 train: Cross-entropy=2.3460415071911283, Accuracy=0.14583333333333334\n",
      "Epoch 100 validation: Cross-entropy=2.444492816925049, Accuracy=0.08585858345031738\n",
      "Epoch 101 train: Cross-entropy=2.345894310209486, Accuracy=0.14583333333333334\n",
      "Epoch 101 validation: Cross-entropy=2.4446375370025635, Accuracy=0.08585858345031738\n",
      "Epoch 102 train: Cross-entropy=2.3457495503955417, Accuracy=0.14756944444444445\n",
      "Epoch 102 validation: Cross-entropy=2.4447803497314453, Accuracy=0.08585858345031738\n",
      "Epoch 103 train: Cross-entropy=2.3456071747673883, Accuracy=0.14930555555555555\n",
      "Epoch 103 validation: Cross-entropy=2.444920539855957, Accuracy=0.08585858345031738\n",
      "Epoch 104 train: Cross-entropy=2.3454669713974, Accuracy=0.14930555555555555\n",
      "Epoch 104 validation: Cross-entropy=2.445059061050415, Accuracy=0.08585858345031738\n",
      "Epoch 105 train: Cross-entropy=2.3453290462493896, Accuracy=0.15104166666666666\n",
      "Epoch 105 validation: Cross-entropy=2.445194959640503, Accuracy=0.08585858345031738\n",
      "Epoch 106 train: Cross-entropy=2.345193306605021, Accuracy=0.15104166666666666\n",
      "Epoch 106 validation: Cross-entropy=2.445329189300537, Accuracy=0.08585858345031738\n",
      "Epoch 107 train: Cross-entropy=2.3450596862369113, Accuracy=0.15104166666666666\n",
      "Epoch 107 validation: Cross-entropy=2.4454610347747803, Accuracy=0.08585858345031738\n",
      "Epoch 108 train: Cross-entropy=2.3449282911088734, Accuracy=0.15104166666666666\n",
      "Epoch 108 validation: Cross-entropy=2.445591449737549, Accuracy=0.08585858345031738\n",
      "Epoch 109 train: Cross-entropy=2.344798829820421, Accuracy=0.1527777777777778\n",
      "Epoch 109 validation: Cross-entropy=2.4457194805145264, Accuracy=0.08585858345031738\n",
      "Epoch 110 train: Cross-entropy=2.3446715010537043, Accuracy=0.1527777777777778\n",
      "Epoch 110 validation: Cross-entropy=2.44584584236145, Accuracy=0.08585858345031738\n",
      "Epoch 111 train: Cross-entropy=2.3445460398991904, Accuracy=0.1527777777777778\n",
      "Epoch 111 validation: Cross-entropy=2.445970296859741, Accuracy=0.08585858345031738\n",
      "Epoch 112 train: Cross-entropy=2.3444225788116455, Accuracy=0.15104166666666666\n",
      "Epoch 112 validation: Cross-entropy=2.4460928440093994, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.3443009985817804, Accuracy=0.15104166666666666\n",
      "Epoch 113 validation: Cross-entropy=2.446213483810425, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 train: Cross-entropy=2.3441814051734076, Accuracy=0.15104166666666666\n",
      "Epoch 114 validation: Cross-entropy=2.4463324546813965, Accuracy=0.08080808073282242\n",
      "Epoch 115 train: Cross-entropy=2.3440635336769953, Accuracy=0.14930555555555555\n",
      "Epoch 115 validation: Cross-entropy=2.4464497566223145, Accuracy=0.08080808073282242\n",
      "Epoch 116 train: Cross-entropy=2.3439474635654025, Accuracy=0.14930555555555555\n",
      "Epoch 116 validation: Cross-entropy=2.4465651512145996, Accuracy=0.08080808073282242\n",
      "Epoch 117 train: Cross-entropy=2.343833181593153, Accuracy=0.14930555555555555\n",
      "Epoch 117 validation: Cross-entropy=2.4466793537139893, Accuracy=0.08585858345031738\n",
      "Epoch 118 train: Cross-entropy=2.3437205950419107, Accuracy=0.14930555555555555\n",
      "Epoch 118 validation: Cross-entropy=2.446791172027588, Accuracy=0.08585858345031738\n",
      "Epoch 119 train: Cross-entropy=2.3436097701390586, Accuracy=0.14930555555555555\n",
      "Epoch 119 validation: Cross-entropy=2.446901798248291, Accuracy=0.08585858345031738\n",
      "Epoch 120 train: Cross-entropy=2.3435005346934, Accuracy=0.14930555555555555\n",
      "Epoch 120 validation: Cross-entropy=2.4470107555389404, Accuracy=0.08585858345031738\n",
      "Epoch 121 train: Cross-entropy=2.343392981423272, Accuracy=0.14930555555555555\n",
      "Epoch 121 validation: Cross-entropy=2.447118043899536, Accuracy=0.08585858345031738\n",
      "Epoch 122 train: Cross-entropy=2.3432870308558145, Accuracy=0.14756944444444445\n",
      "Epoch 122 validation: Cross-entropy=2.447223663330078, Accuracy=0.08585858345031738\n",
      "Epoch 123 train: Cross-entropy=2.3431827094819813, Accuracy=0.14756944444444445\n",
      "Epoch 123 validation: Cross-entropy=2.4473278522491455, Accuracy=0.08585858345031738\n",
      "Epoch 124 train: Cross-entropy=2.343079858356052, Accuracy=0.14756944444444445\n",
      "Epoch 124 validation: Cross-entropy=2.4474310874938965, Accuracy=0.08585858345031738\n",
      "Epoch 125 train: Cross-entropy=2.342978556950887, Accuracy=0.14756944444444445\n",
      "Epoch 125 validation: Cross-entropy=2.4475321769714355, Accuracy=0.09090909361839294\n",
      "Epoch 126 train: Cross-entropy=2.3428786993026733, Accuracy=0.14930555555555555\n",
      "Epoch 126 validation: Cross-entropy=2.447632074356079, Accuracy=0.09090909361839294\n",
      "Epoch 127 train: Cross-entropy=2.3427803119023642, Accuracy=0.14930555555555555\n",
      "Epoch 127 validation: Cross-entropy=2.447730541229248, Accuracy=0.09090909361839294\n",
      "Epoch 128 train: Cross-entropy=2.342683434486389, Accuracy=0.15104166666666666\n",
      "Epoch 128 validation: Cross-entropy=2.4478275775909424, Accuracy=0.09090909361839294\n",
      "Epoch 129 train: Cross-entropy=2.3425879743364124, Accuracy=0.15104166666666666\n",
      "Epoch 129 validation: Cross-entropy=2.447923183441162, Accuracy=0.09090909361839294\n",
      "Epoch 130 train: Cross-entropy=2.342493838734097, Accuracy=0.15104166666666666\n",
      "Epoch 130 validation: Cross-entropy=2.4480173587799072, Accuracy=0.09090909361839294\n",
      "Epoch 131 train: Cross-entropy=2.342401107152303, Accuracy=0.15104166666666666\n",
      "Epoch 131 validation: Cross-entropy=2.448110342025757, Accuracy=0.09090909361839294\n",
      "Epoch 132 train: Cross-entropy=2.342309739854601, Accuracy=0.15104166666666666\n",
      "Epoch 132 validation: Cross-entropy=2.448202133178711, Accuracy=0.09090909361839294\n",
      "Epoch 133 train: Cross-entropy=2.342219604386224, Accuracy=0.15104166666666666\n",
      "Epoch 133 validation: Cross-entropy=2.4482924938201904, Accuracy=0.09090909361839294\n",
      "Epoch 134 train: Cross-entropy=2.342130806710985, Accuracy=0.15104166666666666\n",
      "Epoch 134 validation: Cross-entropy=2.4483814239501953, Accuracy=0.09090909361839294\n",
      "Epoch 135 train: Cross-entropy=2.342043307092455, Accuracy=0.15104166666666666\n",
      "Epoch 135 validation: Cross-entropy=2.448469400405884, Accuracy=0.09090909361839294\n",
      "Epoch 136 train: Cross-entropy=2.3419570525487265, Accuracy=0.15104166666666666\n",
      "Epoch 136 validation: Cross-entropy=2.4485559463500977, Accuracy=0.09090909361839294\n",
      "Epoch 137 train: Cross-entropy=2.3418719636069403, Accuracy=0.15104166666666666\n",
      "Epoch 137 validation: Cross-entropy=2.448641300201416, Accuracy=0.09090909361839294\n",
      "Epoch 138 train: Cross-entropy=2.3417881859673395, Accuracy=0.15104166666666666\n",
      "Epoch 138 validation: Cross-entropy=2.448725700378418, Accuracy=0.09090909361839294\n",
      "Epoch 139 train: Cross-entropy=2.341705494456821, Accuracy=0.15104166666666666\n",
      "Epoch 139 validation: Cross-entropy=2.4488086700439453, Accuracy=0.09090909361839294\n",
      "Epoch 140 train: Cross-entropy=2.341624034775628, Accuracy=0.15104166666666666\n",
      "Epoch 140 validation: Cross-entropy=2.4488906860351562, Accuracy=0.09090909361839294\n",
      "Epoch 141 train: Cross-entropy=2.3415437406963773, Accuracy=0.15104166666666666\n",
      "Epoch 141 validation: Cross-entropy=2.4489715099334717, Accuracy=0.09090909361839294\n",
      "Epoch 142 train: Cross-entropy=2.3414645062552557, Accuracy=0.15104166666666666\n",
      "Epoch 142 validation: Cross-entropy=2.4490513801574707, Accuracy=0.09090909361839294\n",
      "Epoch 143 train: Cross-entropy=2.34138646390703, Accuracy=0.15104166666666666\n",
      "Epoch 143 validation: Cross-entropy=2.449130058288574, Accuracy=0.08585858345031738\n",
      "Epoch 144 train: Cross-entropy=2.3413094679514566, Accuracy=0.14930555555555555\n",
      "Epoch 144 validation: Cross-entropy=2.449207305908203, Accuracy=0.08585858345031738\n",
      "Epoch 145 train: Cross-entropy=2.3412335448794894, Accuracy=0.14930555555555555\n",
      "Epoch 145 validation: Cross-entropy=2.4492838382720947, Accuracy=0.08585858345031738\n",
      "Epoch 146 train: Cross-entropy=2.341158707936605, Accuracy=0.14930555555555555\n",
      "Epoch 146 validation: Cross-entropy=2.44935941696167, Accuracy=0.08585858345031738\n",
      "Epoch 147 train: Cross-entropy=2.3410849571228027, Accuracy=0.14930555555555555\n",
      "Epoch 147 validation: Cross-entropy=2.4494338035583496, Accuracy=0.08585858345031738\n",
      "Epoch 148 train: Cross-entropy=2.3410121070014105, Accuracy=0.14930555555555555\n",
      "Epoch 148 validation: Cross-entropy=2.449507236480713, Accuracy=0.08585858345031738\n",
      "Epoch 149 train: Cross-entropy=2.340940382745531, Accuracy=0.14930555555555555\n",
      "Epoch 149 validation: Cross-entropy=2.4495797157287598, Accuracy=0.09090909361839294\n",
      "Epoch 150 train: Cross-entropy=2.3408696386549206, Accuracy=0.14930555555555555\n",
      "Epoch 150 validation: Cross-entropy=2.4496512413024902, Accuracy=0.09090909361839294\n",
      "Epoch 151 train: Cross-entropy=2.340799887975057, Accuracy=0.14930555555555555\n",
      "Epoch 151 validation: Cross-entropy=2.449721574783325, Accuracy=0.09090909361839294\n",
      "Epoch 152 train: Cross-entropy=2.340730998251173, Accuracy=0.14930555555555555\n",
      "Epoch 152 validation: Cross-entropy=2.449791431427002, Accuracy=0.09090909361839294\n",
      "Epoch 153 train: Cross-entropy=2.340663062201606, Accuracy=0.15104166666666666\n",
      "Epoch 153 validation: Cross-entropy=2.449860095977783, Accuracy=0.09090909361839294\n",
      "Epoch 154 train: Cross-entropy=2.340596172544691, Accuracy=0.15104166666666666\n",
      "Epoch 154 validation: Cross-entropy=2.449927806854248, Accuracy=0.09090909361839294\n",
      "Epoch 155 train: Cross-entropy=2.3405301438437567, Accuracy=0.15104166666666666\n",
      "Epoch 155 validation: Cross-entropy=2.4499945640563965, Accuracy=0.09090909361839294\n",
      "Epoch 156 train: Cross-entropy=2.3404649760988026, Accuracy=0.15104166666666666\n",
      "Epoch 156 validation: Cross-entropy=2.4500606060028076, Accuracy=0.09090909361839294\n",
      "Epoch 157 train: Cross-entropy=2.3404007222917347, Accuracy=0.15104166666666666\n",
      "Epoch 157 validation: Cross-entropy=2.4501256942749023, Accuracy=0.09090909361839294\n",
      "Epoch 158 train: Cross-entropy=2.34033731619517, Accuracy=0.15104166666666666\n",
      "Epoch 158 validation: Cross-entropy=2.4501898288726807, Accuracy=0.09090909361839294\n",
      "Epoch 159 train: Cross-entropy=2.3402748770183988, Accuracy=0.15104166666666666\n",
      "Epoch 159 validation: Cross-entropy=2.4502532482147217, Accuracy=0.09090909361839294\n",
      "Epoch 160 train: Cross-entropy=2.3402132060792713, Accuracy=0.15104166666666666\n",
      "Epoch 160 validation: Cross-entropy=2.4503157138824463, Accuracy=0.09090909361839294\n",
      "Epoch 161 train: Cross-entropy=2.3401523696051703, Accuracy=0.15104166666666666\n",
      "Epoch 161 validation: Cross-entropy=2.4503777027130127, Accuracy=0.09090909361839294\n",
      "Epoch 162 train: Cross-entropy=2.3400923808415732, Accuracy=0.15104166666666666\n",
      "Epoch 162 validation: Cross-entropy=2.4504384994506836, Accuracy=0.09090909361839294\n",
      "Epoch 163 train: Cross-entropy=2.340033173561096, Accuracy=0.15104166666666666\n",
      "Epoch 163 validation: Cross-entropy=2.4504988193511963, Accuracy=0.09090909361839294\n",
      "Epoch 164 train: Cross-entropy=2.339974800745646, Accuracy=0.15104166666666666\n",
      "Epoch 164 validation: Cross-entropy=2.4505581855773926, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 train: Cross-entropy=2.339917262395223, Accuracy=0.15104166666666666\n",
      "Epoch 165 validation: Cross-entropy=2.4506165981292725, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.339860452546014, Accuracy=0.15104166666666666\n",
      "Epoch 166 validation: Cross-entropy=2.450674533843994, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.339804344707065, Accuracy=0.1527777777777778\n",
      "Epoch 167 validation: Cross-entropy=2.4507319927215576, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.339749058087667, Accuracy=0.1527777777777778\n",
      "Epoch 168 validation: Cross-entropy=2.4507880210876465, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.3396944602330527, Accuracy=0.1527777777777778\n",
      "Epoch 169 validation: Cross-entropy=2.4508440494537354, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.3396406835979886, Accuracy=0.1527777777777778\n",
      "Epoch 170 validation: Cross-entropy=2.4508988857269287, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.3395875692367554, Accuracy=0.1527777777777778\n",
      "Epoch 171 validation: Cross-entropy=2.4509530067443848, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.339535209867689, Accuracy=0.1527777777777778\n",
      "Epoch 172 validation: Cross-entropy=2.4510066509246826, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.339483446545071, Accuracy=0.1527777777777778\n",
      "Epoch 173 validation: Cross-entropy=2.451059579849243, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.33943243821462, Accuracy=0.1527777777777778\n",
      "Epoch 174 validation: Cross-entropy=2.4511120319366455, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.3393821318944297, Accuracy=0.1527777777777778\n",
      "Epoch 175 validation: Cross-entropy=2.4511635303497314, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.3393325010935464, Accuracy=0.1527777777777778\n",
      "Epoch 176 validation: Cross-entropy=2.4512147903442383, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.339283506075541, Accuracy=0.1527777777777778\n",
      "Epoch 177 validation: Cross-entropy=2.4512648582458496, Accuracy=0.08585858345031738\n",
      "Epoch 178 train: Cross-entropy=2.33923512034946, Accuracy=0.1527777777777778\n",
      "Epoch 178 validation: Cross-entropy=2.4513144493103027, Accuracy=0.08585858345031738\n",
      "Epoch 179 train: Cross-entropy=2.33918739689721, Accuracy=0.1527777777777778\n",
      "Epoch 179 validation: Cross-entropy=2.4513635635375977, Accuracy=0.08585858345031738\n",
      "Epoch 180 train: Cross-entropy=2.3391403754552207, Accuracy=0.1527777777777778\n",
      "Epoch 180 validation: Cross-entropy=2.4514119625091553, Accuracy=0.08585858345031738\n",
      "Epoch 181 train: Cross-entropy=2.339093910323249, Accuracy=0.1527777777777778\n",
      "Epoch 181 validation: Cross-entropy=2.4514598846435547, Accuracy=0.08585858345031738\n",
      "Epoch 182 train: Cross-entropy=2.3390480942196317, Accuracy=0.1527777777777778\n",
      "Epoch 182 validation: Cross-entropy=2.451507568359375, Accuracy=0.08585858345031738\n",
      "Epoch 183 train: Cross-entropy=2.3390028609169855, Accuracy=0.1527777777777778\n",
      "Epoch 183 validation: Cross-entropy=2.4515540599823, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.33895825015174, Accuracy=0.1527777777777778\n",
      "Epoch 184 validation: Cross-entropy=2.4516000747680664, Accuracy=0.08585858345031738\n",
      "Epoch 185 train: Cross-entropy=2.338914248678419, Accuracy=0.15104166666666666\n",
      "Epoch 185 validation: Cross-entropy=2.451645851135254, Accuracy=0.08585858345031738\n",
      "Epoch 186 train: Cross-entropy=2.3388706843058267, Accuracy=0.15104166666666666\n",
      "Epoch 186 validation: Cross-entropy=2.451690673828125, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.3388278484344482, Accuracy=0.15104166666666666\n",
      "Epoch 187 validation: Cross-entropy=2.451735019683838, Accuracy=0.09090909361839294\n",
      "Epoch 188 train: Cross-entropy=2.3387854761547513, Accuracy=0.14930555555555555\n",
      "Epoch 188 validation: Cross-entropy=2.4517791271209717, Accuracy=0.09090909361839294\n",
      "Epoch 189 train: Cross-entropy=2.3387437661488852, Accuracy=0.14930555555555555\n",
      "Epoch 189 validation: Cross-entropy=2.451822280883789, Accuracy=0.09090909361839294\n",
      "Epoch 190 train: Cross-entropy=2.3387024667527943, Accuracy=0.14930555555555555\n",
      "Epoch 190 validation: Cross-entropy=2.4518651962280273, Accuracy=0.09090909361839294\n",
      "Epoch 191 train: Cross-entropy=2.338661895857917, Accuracy=0.14930555555555555\n",
      "Epoch 191 validation: Cross-entropy=2.4519076347351074, Accuracy=0.09090909361839294\n",
      "Epoch 192 train: Cross-entropy=2.3386217090818615, Accuracy=0.14930555555555555\n",
      "Epoch 192 validation: Cross-entropy=2.4519498348236084, Accuracy=0.09090909361839294\n",
      "Epoch 193 train: Cross-entropy=2.3385821183522544, Accuracy=0.14930555555555555\n",
      "Epoch 193 validation: Cross-entropy=2.451991319656372, Accuracy=0.09090909361839294\n",
      "Epoch 194 train: Cross-entropy=2.3385430177052817, Accuracy=0.14930555555555555\n",
      "Epoch 194 validation: Cross-entropy=2.4520318508148193, Accuracy=0.09090909361839294\n",
      "Epoch 195 train: Cross-entropy=2.33850449985928, Accuracy=0.14930555555555555\n",
      "Epoch 195 validation: Cross-entropy=2.4520723819732666, Accuracy=0.09090909361839294\n",
      "Epoch 196 train: Cross-entropy=2.338466419114007, Accuracy=0.14930555555555555\n",
      "Epoch 196 validation: Cross-entropy=2.4521124362945557, Accuracy=0.09090909361839294\n",
      "Epoch 197 train: Cross-entropy=2.338428841696845, Accuracy=0.15104166666666666\n",
      "Epoch 197 validation: Cross-entropy=2.4521517753601074, Accuracy=0.09090909361839294\n",
      "Epoch 198 train: Cross-entropy=2.338391820589701, Accuracy=0.15104166666666666\n",
      "Epoch 198 validation: Cross-entropy=2.45219087600708, Accuracy=0.09090909361839294\n",
      "Epoch 199 train: Cross-entropy=2.338355210092333, Accuracy=0.15104166666666666\n",
      "Epoch 199 validation: Cross-entropy=2.4522292613983154, Accuracy=0.09090909361839294\n",
      "Epoch 0 train: Cross-entropy=2.424315916167365, Accuracy=0.09375\n",
      "Epoch 0 validation: Cross-entropy=2.4072682857513428, Accuracy=0.09595959633588791\n",
      "Epoch 1 train: Cross-entropy=2.416733185450236, Accuracy=0.07291666666666667\n",
      "Epoch 1 validation: Cross-entropy=2.4082400798797607, Accuracy=0.10606060922145844\n",
      "Epoch 2 train: Cross-entropy=2.412209219402737, Accuracy=0.07465277777777778\n",
      "Epoch 2 validation: Cross-entropy=2.4085428714752197, Accuracy=0.09595959633588791\n",
      "Epoch 3 train: Cross-entropy=2.4085792038175793, Accuracy=0.08159722222222222\n",
      "Epoch 3 validation: Cross-entropy=2.40901255607605, Accuracy=0.1111111119389534\n",
      "Epoch 4 train: Cross-entropy=2.405211779806349, Accuracy=0.08333333333333333\n",
      "Epoch 4 validation: Cross-entropy=2.409578800201416, Accuracy=0.10606060922145844\n",
      "Epoch 5 train: Cross-entropy=2.402102642589145, Accuracy=0.0798611111111111\n",
      "Epoch 5 validation: Cross-entropy=2.4102261066436768, Accuracy=0.09090909361839294\n",
      "Epoch 6 train: Cross-entropy=2.3992237647374473, Accuracy=0.08506944444444445\n",
      "Epoch 6 validation: Cross-entropy=2.4109394550323486, Accuracy=0.09595959633588791\n",
      "Epoch 7 train: Cross-entropy=2.3965516752666898, Accuracy=0.09027777777777778\n",
      "Epoch 7 validation: Cross-entropy=2.41170597076416, Accuracy=0.09595959633588791\n",
      "Epoch 8 train: Cross-entropy=2.394065817197164, Accuracy=0.0920138888888889\n",
      "Epoch 8 validation: Cross-entropy=2.4125144481658936, Accuracy=0.08585858345031738\n",
      "Epoch 9 train: Cross-entropy=2.391747620370653, Accuracy=0.10069444444444445\n",
      "Epoch 9 validation: Cross-entropy=2.413356065750122, Accuracy=0.09090909361839294\n",
      "Epoch 10 train: Cross-entropy=2.3895812696880765, Accuracy=0.10069444444444445\n",
      "Epoch 10 validation: Cross-entropy=2.414222240447998, Accuracy=0.09090909361839294\n",
      "Epoch 11 train: Cross-entropy=2.387552499771118, Accuracy=0.10416666666666667\n",
      "Epoch 11 validation: Cross-entropy=2.415106773376465, Accuracy=0.09595959633588791\n",
      "Epoch 12 train: Cross-entropy=2.3856487539079456, Accuracy=0.1076388888888889\n",
      "Epoch 12 validation: Cross-entropy=2.416003704071045, Accuracy=0.09595959633588791\n",
      "Epoch 13 train: Cross-entropy=2.383858707216051, Accuracy=0.1076388888888889\n",
      "Epoch 13 validation: Cross-entropy=2.4169082641601562, Accuracy=0.09595959633588791\n",
      "Epoch 14 train: Cross-entropy=2.3821726772520275, Accuracy=0.1111111111111111\n",
      "Epoch 14 validation: Cross-entropy=2.417815923690796, Accuracy=0.09595959633588791\n",
      "Epoch 15 train: Cross-entropy=2.3805816968282065, Accuracy=0.11458333333333333\n",
      "Epoch 15 validation: Cross-entropy=2.4187235832214355, Accuracy=0.10101009905338287\n",
      "Epoch 16 train: Cross-entropy=2.3790778054131403, Accuracy=0.11458333333333333\n",
      "Epoch 16 validation: Cross-entropy=2.4196279048919678, Accuracy=0.10101009905338287\n",
      "Epoch 17 train: Cross-entropy=2.3776541815863714, Accuracy=0.11805555555555555\n",
      "Epoch 17 validation: Cross-entropy=2.4205269813537598, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 train: Cross-entropy=2.376304202609592, Accuracy=0.11979166666666667\n",
      "Epoch 18 validation: Cross-entropy=2.4214181900024414, Accuracy=0.09595959633588791\n",
      "Epoch 19 train: Cross-entropy=2.3750222788916693, Accuracy=0.11979166666666667\n",
      "Epoch 19 validation: Cross-entropy=2.422300100326538, Accuracy=0.09595959633588791\n",
      "Epoch 20 train: Cross-entropy=2.3738033639060125, Accuracy=0.12152777777777778\n",
      "Epoch 20 validation: Cross-entropy=2.423171281814575, Accuracy=0.09595959633588791\n",
      "Epoch 21 train: Cross-entropy=2.3726426892810397, Accuracy=0.125\n",
      "Epoch 21 validation: Cross-entropy=2.424030303955078, Accuracy=0.09595959633588791\n",
      "Epoch 22 train: Cross-entropy=2.371536228391859, Accuracy=0.125\n",
      "Epoch 22 validation: Cross-entropy=2.4248762130737305, Accuracy=0.09595959633588791\n",
      "Epoch 23 train: Cross-entropy=2.370480087068346, Accuracy=0.125\n",
      "Epoch 23 validation: Cross-entropy=2.425708532333374, Accuracy=0.09090909361839294\n",
      "Epoch 24 train: Cross-entropy=2.3694708347320557, Accuracy=0.1232638888888889\n",
      "Epoch 24 validation: Cross-entropy=2.4265267848968506, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.3685053984324136, Accuracy=0.1232638888888889\n",
      "Epoch 25 validation: Cross-entropy=2.4273297786712646, Accuracy=0.09090909361839294\n",
      "Epoch 26 train: Cross-entropy=2.367581009864807, Accuracy=0.1232638888888889\n",
      "Epoch 26 validation: Cross-entropy=2.4281177520751953, Accuracy=0.09090909361839294\n",
      "Epoch 27 train: Cross-entropy=2.366694860988193, Accuracy=0.125\n",
      "Epoch 27 validation: Cross-entropy=2.4288902282714844, Accuracy=0.08585858345031738\n",
      "Epoch 28 train: Cross-entropy=2.365844633844164, Accuracy=0.1284722222222222\n",
      "Epoch 28 validation: Cross-entropy=2.429647445678711, Accuracy=0.09595959633588791\n",
      "Epoch 29 train: Cross-entropy=2.3650283018747964, Accuracy=0.13020833333333334\n",
      "Epoch 29 validation: Cross-entropy=2.430388927459717, Accuracy=0.09595959633588791\n",
      "Epoch 30 train: Cross-entropy=2.36424363984002, Accuracy=0.13020833333333334\n",
      "Epoch 30 validation: Cross-entropy=2.431114673614502, Accuracy=0.10101009905338287\n",
      "Epoch 31 train: Cross-entropy=2.363489031791687, Accuracy=0.13194444444444445\n",
      "Epoch 31 validation: Cross-entropy=2.4318249225616455, Accuracy=0.10101009905338287\n",
      "Epoch 32 train: Cross-entropy=2.362762729326884, Accuracy=0.13194444444444445\n",
      "Epoch 32 validation: Cross-entropy=2.4325194358825684, Accuracy=0.10101009905338287\n",
      "Epoch 33 train: Cross-entropy=2.362062997288174, Accuracy=0.1388888888888889\n",
      "Epoch 33 validation: Cross-entropy=2.433198928833008, Accuracy=0.10606060922145844\n",
      "Epoch 34 train: Cross-entropy=2.3613886303371854, Accuracy=0.1388888888888889\n",
      "Epoch 34 validation: Cross-entropy=2.4338629245758057, Accuracy=0.1111111119389534\n",
      "Epoch 35 train: Cross-entropy=2.360738158226013, Accuracy=0.13541666666666666\n",
      "Epoch 35 validation: Cross-entropy=2.43451189994812, Accuracy=0.1111111119389534\n",
      "Epoch 36 train: Cross-entropy=2.360110282897949, Accuracy=0.13541666666666666\n",
      "Epoch 36 validation: Cross-entropy=2.4351463317871094, Accuracy=0.1111111119389534\n",
      "Epoch 37 train: Cross-entropy=2.3595039976967707, Accuracy=0.1388888888888889\n",
      "Epoch 37 validation: Cross-entropy=2.4357659816741943, Accuracy=0.1111111119389534\n",
      "Epoch 38 train: Cross-entropy=2.358918163511488, Accuracy=0.1388888888888889\n",
      "Epoch 38 validation: Cross-entropy=2.436371088027954, Accuracy=0.1111111119389534\n",
      "Epoch 39 train: Cross-entropy=2.358351813422309, Accuracy=0.1371527777777778\n",
      "Epoch 39 validation: Cross-entropy=2.436962127685547, Accuracy=0.1111111119389534\n",
      "Epoch 40 train: Cross-entropy=2.3578039407730103, Accuracy=0.1388888888888889\n",
      "Epoch 40 validation: Cross-entropy=2.437539577484131, Accuracy=0.1111111119389534\n",
      "Epoch 41 train: Cross-entropy=2.357273750834995, Accuracy=0.140625\n",
      "Epoch 41 validation: Cross-entropy=2.438103199005127, Accuracy=0.1111111119389534\n",
      "Epoch 42 train: Cross-entropy=2.356760435634189, Accuracy=0.1423611111111111\n",
      "Epoch 42 validation: Cross-entropy=2.4386537075042725, Accuracy=0.1111111119389534\n",
      "Epoch 43 train: Cross-entropy=2.3562632401784263, Accuracy=0.1423611111111111\n",
      "Epoch 43 validation: Cross-entropy=2.439190626144409, Accuracy=0.1111111119389534\n",
      "Epoch 44 train: Cross-entropy=2.355781396230062, Accuracy=0.140625\n",
      "Epoch 44 validation: Cross-entropy=2.4397153854370117, Accuracy=0.11616161465644836\n",
      "Epoch 45 train: Cross-entropy=2.3553143209881253, Accuracy=0.140625\n",
      "Epoch 45 validation: Cross-entropy=2.4402272701263428, Accuracy=0.11616161465644836\n",
      "Epoch 46 train: Cross-entropy=2.354861193233066, Accuracy=0.140625\n",
      "Epoch 46 validation: Cross-entropy=2.4407272338867188, Accuracy=0.1111111119389534\n",
      "Epoch 47 train: Cross-entropy=2.3544216420915394, Accuracy=0.1388888888888889\n",
      "Epoch 47 validation: Cross-entropy=2.4412150382995605, Accuracy=0.1111111119389534\n",
      "Epoch 48 train: Cross-entropy=2.35399501853519, Accuracy=0.1388888888888889\n",
      "Epoch 48 validation: Cross-entropy=2.4416911602020264, Accuracy=0.1111111119389534\n",
      "Epoch 49 train: Cross-entropy=2.3535808589723377, Accuracy=0.140625\n",
      "Epoch 49 validation: Cross-entropy=2.4421558380126953, Accuracy=0.1111111119389534\n",
      "Epoch 50 train: Cross-entropy=2.353178474638197, Accuracy=0.1423611111111111\n",
      "Epoch 50 validation: Cross-entropy=2.4426093101501465, Accuracy=0.1111111119389534\n",
      "Epoch 51 train: Cross-entropy=2.3527876933415732, Accuracy=0.1423611111111111\n",
      "Epoch 51 validation: Cross-entropy=2.443052053451538, Accuracy=0.1111111119389534\n",
      "Epoch 52 train: Cross-entropy=2.3524078130722046, Accuracy=0.140625\n",
      "Epoch 52 validation: Cross-entropy=2.443484306335449, Accuracy=0.1111111119389534\n",
      "Epoch 53 train: Cross-entropy=2.352038582166036, Accuracy=0.1423611111111111\n",
      "Epoch 53 validation: Cross-entropy=2.443905830383301, Accuracy=0.1111111119389534\n",
      "Epoch 54 train: Cross-entropy=2.3516795105404324, Accuracy=0.140625\n",
      "Epoch 54 validation: Cross-entropy=2.44431734085083, Accuracy=0.1111111119389534\n",
      "Epoch 55 train: Cross-entropy=2.3513302538130016, Accuracy=0.140625\n",
      "Epoch 55 validation: Cross-entropy=2.444718837738037, Accuracy=0.1111111119389534\n",
      "Epoch 56 train: Cross-entropy=2.3509904278649225, Accuracy=0.140625\n",
      "Epoch 56 validation: Cross-entropy=2.4451112747192383, Accuracy=0.1111111119389534\n",
      "Epoch 57 train: Cross-entropy=2.3506597677866616, Accuracy=0.140625\n",
      "Epoch 57 validation: Cross-entropy=2.445493698120117, Accuracy=0.1111111119389534\n",
      "Epoch 58 train: Cross-entropy=2.3503378099865384, Accuracy=0.1388888888888889\n",
      "Epoch 58 validation: Cross-entropy=2.445866823196411, Accuracy=0.11616161465644836\n",
      "Epoch 59 train: Cross-entropy=2.350024382273356, Accuracy=0.1388888888888889\n",
      "Epoch 59 validation: Cross-entropy=2.4462311267852783, Accuracy=0.11616161465644836\n",
      "Epoch 60 train: Cross-entropy=2.349719180001153, Accuracy=0.140625\n",
      "Epoch 60 validation: Cross-entropy=2.446586847305298, Accuracy=0.11616161465644836\n",
      "Epoch 61 train: Cross-entropy=2.3494217925601535, Accuracy=0.140625\n",
      "Epoch 61 validation: Cross-entropy=2.446934223175049, Accuracy=0.11616161465644836\n",
      "Epoch 62 train: Cross-entropy=2.349132113986545, Accuracy=0.140625\n",
      "Epoch 62 validation: Cross-entropy=2.447272777557373, Accuracy=0.11616161465644836\n",
      "Epoch 63 train: Cross-entropy=2.348849786652459, Accuracy=0.140625\n",
      "Epoch 63 validation: Cross-entropy=2.447603464126587, Accuracy=0.11616161465644836\n",
      "Epoch 64 train: Cross-entropy=2.3485747045940824, Accuracy=0.1388888888888889\n",
      "Epoch 64 validation: Cross-entropy=2.4479260444641113, Accuracy=0.11616161465644836\n",
      "Epoch 65 train: Cross-entropy=2.3483064572016397, Accuracy=0.140625\n",
      "Epoch 65 validation: Cross-entropy=2.4482407569885254, Accuracy=0.11616161465644836\n",
      "Epoch 66 train: Cross-entropy=2.3480448855294123, Accuracy=0.1388888888888889\n",
      "Epoch 66 validation: Cross-entropy=2.4485485553741455, Accuracy=0.11616161465644836\n",
      "Epoch 67 train: Cross-entropy=2.347789857122633, Accuracy=0.1388888888888889\n",
      "Epoch 67 validation: Cross-entropy=2.448848247528076, Accuracy=0.1111111119389534\n",
      "Epoch 68 train: Cross-entropy=2.3475410540898642, Accuracy=0.1388888888888889\n",
      "Epoch 68 validation: Cross-entropy=2.449141263961792, Accuracy=0.1111111119389534\n",
      "Epoch 69 train: Cross-entropy=2.347298343976339, Accuracy=0.1388888888888889\n",
      "Epoch 69 validation: Cross-entropy=2.4494268894195557, Accuracy=0.1111111119389534\n",
      "Epoch 70 train: Cross-entropy=2.347061528099908, Accuracy=0.1388888888888889\n",
      "Epoch 70 validation: Cross-entropy=2.4497058391571045, Accuracy=0.1111111119389534\n",
      "Epoch 71 train: Cross-entropy=2.346830513742235, Accuracy=0.1388888888888889\n",
      "Epoch 71 validation: Cross-entropy=2.4499778747558594, Accuracy=0.11616161465644836\n",
      "Epoch 72 train: Cross-entropy=2.3466049830118814, Accuracy=0.1388888888888889\n",
      "Epoch 72 validation: Cross-entropy=2.4502437114715576, Accuracy=0.11616161465644836\n",
      "Epoch 73 train: Cross-entropy=2.346384803454081, Accuracy=0.1388888888888889\n",
      "Epoch 73 validation: Cross-entropy=2.450502872467041, Accuracy=0.11616161465644836\n",
      "Epoch 74 train: Cross-entropy=2.3461699220869274, Accuracy=0.140625\n",
      "Epoch 74 validation: Cross-entropy=2.4507558345794678, Accuracy=0.11616161465644836\n",
      "Epoch 75 train: Cross-entropy=2.3459600740008884, Accuracy=0.1423611111111111\n",
      "Epoch 75 validation: Cross-entropy=2.451002836227417, Accuracy=0.1111111119389534\n",
      "Epoch 76 train: Cross-entropy=2.345755179723104, Accuracy=0.1423611111111111\n",
      "Epoch 76 validation: Cross-entropy=2.4512441158294678, Accuracy=0.1111111119389534\n",
      "Epoch 77 train: Cross-entropy=2.3455550405714245, Accuracy=0.1423611111111111\n",
      "Epoch 77 validation: Cross-entropy=2.451479196548462, Accuracy=0.1111111119389534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 train: Cross-entropy=2.3453596035639444, Accuracy=0.1423611111111111\n",
      "Epoch 78 validation: Cross-entropy=2.4517085552215576, Accuracy=0.1111111119389534\n",
      "Epoch 79 train: Cross-entropy=2.3451686832639904, Accuracy=0.1423611111111111\n",
      "Epoch 79 validation: Cross-entropy=2.451932668685913, Accuracy=0.1111111119389534\n",
      "Epoch 80 train: Cross-entropy=2.3449821869532266, Accuracy=0.1423611111111111\n",
      "Epoch 80 validation: Cross-entropy=2.452151298522949, Accuracy=0.1111111119389534\n",
      "Epoch 81 train: Cross-entropy=2.3447999821768866, Accuracy=0.1423611111111111\n",
      "Epoch 81 validation: Cross-entropy=2.452364444732666, Accuracy=0.1111111119389534\n",
      "Epoch 82 train: Cross-entropy=2.3446218967437744, Accuracy=0.1423611111111111\n",
      "Epoch 82 validation: Cross-entropy=2.4525725841522217, Accuracy=0.1111111119389534\n",
      "Epoch 83 train: Cross-entropy=2.3444478379355536, Accuracy=0.1440972222222222\n",
      "Epoch 83 validation: Cross-entropy=2.452775716781616, Accuracy=0.1111111119389534\n",
      "Epoch 84 train: Cross-entropy=2.344277752770318, Accuracy=0.1440972222222222\n",
      "Epoch 84 validation: Cross-entropy=2.4529738426208496, Accuracy=0.1111111119389534\n",
      "Epoch 85 train: Cross-entropy=2.344111522038778, Accuracy=0.1440972222222222\n",
      "Epoch 85 validation: Cross-entropy=2.45316743850708, Accuracy=0.1111111119389534\n",
      "Epoch 86 train: Cross-entropy=2.34394903977712, Accuracy=0.14583333333333334\n",
      "Epoch 86 validation: Cross-entropy=2.4533557891845703, Accuracy=0.1111111119389534\n",
      "Epoch 87 train: Cross-entropy=2.3437901867760553, Accuracy=0.14583333333333334\n",
      "Epoch 87 validation: Cross-entropy=2.453540325164795, Accuracy=0.1111111119389534\n",
      "Epoch 88 train: Cross-entropy=2.34363493654463, Accuracy=0.14583333333333334\n",
      "Epoch 88 validation: Cross-entropy=2.4537198543548584, Accuracy=0.1111111119389534\n",
      "Epoch 89 train: Cross-entropy=2.3434831168916492, Accuracy=0.14756944444444445\n",
      "Epoch 89 validation: Cross-entropy=2.453894853591919, Accuracy=0.10606060922145844\n",
      "Epoch 90 train: Cross-entropy=2.343334674835205, Accuracy=0.14930555555555555\n",
      "Epoch 90 validation: Cross-entropy=2.4540657997131348, Accuracy=0.10606060922145844\n",
      "Epoch 91 train: Cross-entropy=2.3431894779205322, Accuracy=0.14930555555555555\n",
      "Epoch 91 validation: Cross-entropy=2.4542324542999268, Accuracy=0.10606060922145844\n",
      "Epoch 92 train: Cross-entropy=2.3430474996566772, Accuracy=0.14930555555555555\n",
      "Epoch 92 validation: Cross-entropy=2.454395294189453, Accuracy=0.10606060922145844\n",
      "Epoch 93 train: Cross-entropy=2.3429086870617337, Accuracy=0.14930555555555555\n",
      "Epoch 93 validation: Cross-entropy=2.4545538425445557, Accuracy=0.10606060922145844\n",
      "Epoch 94 train: Cross-entropy=2.3427729871537952, Accuracy=0.14930555555555555\n",
      "Epoch 94 validation: Cross-entropy=2.4547085762023926, Accuracy=0.10606060922145844\n",
      "Epoch 95 train: Cross-entropy=2.3426401615142822, Accuracy=0.14930555555555555\n",
      "Epoch 95 validation: Cross-entropy=2.4548592567443848, Accuracy=0.10606060922145844\n",
      "Epoch 96 train: Cross-entropy=2.342510316107008, Accuracy=0.14756944444444445\n",
      "Epoch 96 validation: Cross-entropy=2.4550063610076904, Accuracy=0.10606060922145844\n",
      "Epoch 97 train: Cross-entropy=2.342383278740777, Accuracy=0.14756944444444445\n",
      "Epoch 97 validation: Cross-entropy=2.4551498889923096, Accuracy=0.10606060922145844\n",
      "Epoch 98 train: Cross-entropy=2.3422589831882052, Accuracy=0.14930555555555555\n",
      "Epoch 98 validation: Cross-entropy=2.455289602279663, Accuracy=0.10606060922145844\n",
      "Epoch 99 train: Cross-entropy=2.3421374559402466, Accuracy=0.14930555555555555\n",
      "Epoch 99 validation: Cross-entropy=2.4554262161254883, Accuracy=0.10606060922145844\n",
      "Epoch 100 train: Cross-entropy=2.3420184983147516, Accuracy=0.14930555555555555\n",
      "Epoch 100 validation: Cross-entropy=2.455559015274048, Accuracy=0.10606060922145844\n",
      "Epoch 101 train: Cross-entropy=2.341902176539103, Accuracy=0.14930555555555555\n",
      "Epoch 101 validation: Cross-entropy=2.455688238143921, Accuracy=0.10606060922145844\n",
      "Epoch 102 train: Cross-entropy=2.341788371404012, Accuracy=0.1527777777777778\n",
      "Epoch 102 validation: Cross-entropy=2.4558145999908447, Accuracy=0.10606060922145844\n",
      "Epoch 103 train: Cross-entropy=2.341677016682095, Accuracy=0.1527777777777778\n",
      "Epoch 103 validation: Cross-entropy=2.4559378623962402, Accuracy=0.10606060922145844\n",
      "Epoch 104 train: Cross-entropy=2.3415680858823986, Accuracy=0.1545138888888889\n",
      "Epoch 104 validation: Cross-entropy=2.4560577869415283, Accuracy=0.10606060922145844\n",
      "Epoch 105 train: Cross-entropy=2.341461459795634, Accuracy=0.15625\n",
      "Epoch 105 validation: Cross-entropy=2.456174373626709, Accuracy=0.10606060922145844\n",
      "Epoch 106 train: Cross-entropy=2.341357191403707, Accuracy=0.15625\n",
      "Epoch 106 validation: Cross-entropy=2.4562883377075195, Accuracy=0.10606060922145844\n",
      "Epoch 107 train: Cross-entropy=2.341255201233758, Accuracy=0.15625\n",
      "Epoch 107 validation: Cross-entropy=2.4563992023468018, Accuracy=0.10606060922145844\n",
      "Epoch 108 train: Cross-entropy=2.341155383321974, Accuracy=0.1545138888888889\n",
      "Epoch 108 validation: Cross-entropy=2.4565072059631348, Accuracy=0.10606060922145844\n",
      "Epoch 109 train: Cross-entropy=2.341057777404785, Accuracy=0.1545138888888889\n",
      "Epoch 109 validation: Cross-entropy=2.4566123485565186, Accuracy=0.10606060922145844\n",
      "Epoch 110 train: Cross-entropy=2.3409621583090887, Accuracy=0.1545138888888889\n",
      "Epoch 110 validation: Cross-entropy=2.456714630126953, Accuracy=0.10606060922145844\n",
      "Epoch 111 train: Cross-entropy=2.340868671735128, Accuracy=0.15625\n",
      "Epoch 111 validation: Cross-entropy=2.4568142890930176, Accuracy=0.10606060922145844\n",
      "Epoch 112 train: Cross-entropy=2.3407772382100425, Accuracy=0.15625\n",
      "Epoch 112 validation: Cross-entropy=2.456911087036133, Accuracy=0.10606060922145844\n",
      "Epoch 113 train: Cross-entropy=2.340687738524543, Accuracy=0.15625\n",
      "Epoch 113 validation: Cross-entropy=2.457005500793457, Accuracy=0.10606060922145844\n",
      "Epoch 114 train: Cross-entropy=2.3406001329421997, Accuracy=0.15625\n",
      "Epoch 114 validation: Cross-entropy=2.4570975303649902, Accuracy=0.10101009905338287\n",
      "Epoch 115 train: Cross-entropy=2.340514474444919, Accuracy=0.15625\n",
      "Epoch 115 validation: Cross-entropy=2.4571871757507324, Accuracy=0.10101009905338287\n",
      "Epoch 116 train: Cross-entropy=2.3404306968053183, Accuracy=0.15625\n",
      "Epoch 116 validation: Cross-entropy=2.4572741985321045, Accuracy=0.10101009905338287\n",
      "Epoch 117 train: Cross-entropy=2.340348733796014, Accuracy=0.1545138888888889\n",
      "Epoch 117 validation: Cross-entropy=2.4573585987091064, Accuracy=0.10101009905338287\n",
      "Epoch 118 train: Cross-entropy=2.3402684794531927, Accuracy=0.1545138888888889\n",
      "Epoch 118 validation: Cross-entropy=2.4574408531188965, Accuracy=0.10101009905338287\n",
      "Epoch 119 train: Cross-entropy=2.3401900927225747, Accuracy=0.1545138888888889\n",
      "Epoch 119 validation: Cross-entropy=2.4575207233428955, Accuracy=0.10101009905338287\n",
      "Epoch 120 train: Cross-entropy=2.3401132027308145, Accuracy=0.1545138888888889\n",
      "Epoch 120 validation: Cross-entropy=2.4575982093811035, Accuracy=0.10101009905338287\n",
      "Epoch 121 train: Cross-entropy=2.340038153860304, Accuracy=0.1545138888888889\n",
      "Epoch 121 validation: Cross-entropy=2.457674026489258, Accuracy=0.10101009905338287\n",
      "Epoch 122 train: Cross-entropy=2.3399647606743708, Accuracy=0.1545138888888889\n",
      "Epoch 122 validation: Cross-entropy=2.457747220993042, Accuracy=0.10101009905338287\n",
      "Epoch 123 train: Cross-entropy=2.3398928112453885, Accuracy=0.1545138888888889\n",
      "Epoch 123 validation: Cross-entropy=2.4578185081481934, Accuracy=0.10101009905338287\n",
      "Epoch 124 train: Cross-entropy=2.3398225572374134, Accuracy=0.1527777777777778\n",
      "Epoch 124 validation: Cross-entropy=2.457887649536133, Accuracy=0.10101009905338287\n",
      "Epoch 125 train: Cross-entropy=2.3397538397047253, Accuracy=0.1545138888888889\n",
      "Epoch 125 validation: Cross-entropy=2.4579548835754395, Accuracy=0.10101009905338287\n",
      "Epoch 126 train: Cross-entropy=2.339686552683512, Accuracy=0.1545138888888889\n",
      "Epoch 126 validation: Cross-entropy=2.458019733428955, Accuracy=0.10101009905338287\n",
      "Epoch 127 train: Cross-entropy=2.3396208816104465, Accuracy=0.1545138888888889\n",
      "Epoch 127 validation: Cross-entropy=2.458083152770996, Accuracy=0.10101009905338287\n",
      "Epoch 128 train: Cross-entropy=2.3395565350850425, Accuracy=0.1545138888888889\n",
      "Epoch 128 validation: Cross-entropy=2.4581446647644043, Accuracy=0.10101009905338287\n",
      "Epoch 129 train: Cross-entropy=2.339493645562066, Accuracy=0.1545138888888889\n",
      "Epoch 129 validation: Cross-entropy=2.4582042694091797, Accuracy=0.10101009905338287\n",
      "Epoch 130 train: Cross-entropy=2.3394321468141346, Accuracy=0.1545138888888889\n",
      "Epoch 130 validation: Cross-entropy=2.458261728286743, Accuracy=0.10101009905338287\n",
      "Epoch 131 train: Cross-entropy=2.3393720388412476, Accuracy=0.1545138888888889\n",
      "Epoch 131 validation: Cross-entropy=2.458317995071411, Accuracy=0.10101009905338287\n",
      "Epoch 132 train: Cross-entropy=2.339313334888882, Accuracy=0.1545138888888889\n",
      "Epoch 132 validation: Cross-entropy=2.458371639251709, Accuracy=0.10101009905338287\n",
      "Epoch 133 train: Cross-entropy=2.3392558495203652, Accuracy=0.1545138888888889\n",
      "Epoch 133 validation: Cross-entropy=2.4584240913391113, Accuracy=0.10101009905338287\n",
      "Epoch 134 train: Cross-entropy=2.3391997549268932, Accuracy=0.1545138888888889\n",
      "Epoch 134 validation: Cross-entropy=2.458475112915039, Accuracy=0.10101009905338287\n",
      "Epoch 135 train: Cross-entropy=2.339144812689887, Accuracy=0.1545138888888889\n",
      "Epoch 135 validation: Cross-entropy=2.458523988723755, Accuracy=0.10101009905338287\n",
      "Epoch 136 train: Cross-entropy=2.3390912082460193, Accuracy=0.1545138888888889\n",
      "Epoch 136 validation: Cross-entropy=2.458571434020996, Accuracy=0.10101009905338287\n",
      "Epoch 137 train: Cross-entropy=2.339038756158617, Accuracy=0.1545138888888889\n",
      "Epoch 137 validation: Cross-entropy=2.4586172103881836, Accuracy=0.10101009905338287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 train: Cross-entropy=2.3389875888824463, Accuracy=0.1545138888888889\n",
      "Epoch 138 validation: Cross-entropy=2.4586615562438965, Accuracy=0.10101009905338287\n",
      "Epoch 139 train: Cross-entropy=2.3389375739627414, Accuracy=0.15625\n",
      "Epoch 139 validation: Cross-entropy=2.4587042331695557, Accuracy=0.10101009905338287\n",
      "Epoch 140 train: Cross-entropy=2.338888645172119, Accuracy=0.15625\n",
      "Epoch 140 validation: Cross-entropy=2.4587457180023193, Accuracy=0.10101009905338287\n",
      "Epoch 141 train: Cross-entropy=2.3388409349653454, Accuracy=0.15625\n",
      "Epoch 141 validation: Cross-entropy=2.45878529548645, Accuracy=0.10101009905338287\n",
      "Epoch 142 train: Cross-entropy=2.3387943108876548, Accuracy=0.15625\n",
      "Epoch 142 validation: Cross-entropy=2.4588236808776855, Accuracy=0.10101009905338287\n",
      "Epoch 143 train: Cross-entropy=2.3387487729390464, Accuracy=0.15625\n",
      "Epoch 143 validation: Cross-entropy=2.4588608741760254, Accuracy=0.10101009905338287\n",
      "Epoch 144 train: Cross-entropy=2.338704334364997, Accuracy=0.15625\n",
      "Epoch 144 validation: Cross-entropy=2.4588966369628906, Accuracy=0.10101009905338287\n",
      "Epoch 145 train: Cross-entropy=2.3386609024471707, Accuracy=0.15625\n",
      "Epoch 145 validation: Cross-entropy=2.458930730819702, Accuracy=0.09595959633588791\n",
      "Epoch 146 train: Cross-entropy=2.3386185434129505, Accuracy=0.15625\n",
      "Epoch 146 validation: Cross-entropy=2.4589638710021973, Accuracy=0.09595959633588791\n",
      "Epoch 147 train: Cross-entropy=2.3385772042804294, Accuracy=0.15625\n",
      "Epoch 147 validation: Cross-entropy=2.4589955806732178, Accuracy=0.09595959633588791\n",
      "Epoch 148 train: Cross-entropy=2.338536885049608, Accuracy=0.15625\n",
      "Epoch 148 validation: Cross-entropy=2.4590260982513428, Accuracy=0.09595959633588791\n",
      "Epoch 149 train: Cross-entropy=2.338497440020243, Accuracy=0.15625\n",
      "Epoch 149 validation: Cross-entropy=2.459054946899414, Accuracy=0.09595959633588791\n",
      "Epoch 150 train: Cross-entropy=2.3384590678744845, Accuracy=0.15625\n",
      "Epoch 150 validation: Cross-entropy=2.459083080291748, Accuracy=0.09595959633588791\n",
      "Epoch 151 train: Cross-entropy=2.338421622912089, Accuracy=0.15625\n",
      "Epoch 151 validation: Cross-entropy=2.4591097831726074, Accuracy=0.09595959633588791\n",
      "Epoch 152 train: Cross-entropy=2.338385078642103, Accuracy=0.15625\n",
      "Epoch 152 validation: Cross-entropy=2.4591352939605713, Accuracy=0.09595959633588791\n",
      "Epoch 153 train: Cross-entropy=2.3383494350645275, Accuracy=0.15625\n",
      "Epoch 153 validation: Cross-entropy=2.4591598510742188, Accuracy=0.09595959633588791\n",
      "Epoch 154 train: Cross-entropy=2.3383147451612682, Accuracy=0.1545138888888889\n",
      "Epoch 154 validation: Cross-entropy=2.4591829776763916, Accuracy=0.09595959633588791\n",
      "Epoch 155 train: Cross-entropy=2.3382809427049427, Accuracy=0.1545138888888889\n",
      "Epoch 155 validation: Cross-entropy=2.459205150604248, Accuracy=0.09595959633588791\n",
      "Epoch 156 train: Cross-entropy=2.338247961468167, Accuracy=0.1545138888888889\n",
      "Epoch 156 validation: Cross-entropy=2.459226369857788, Accuracy=0.09595959633588791\n",
      "Epoch 157 train: Cross-entropy=2.3382158411873712, Accuracy=0.1545138888888889\n",
      "Epoch 157 validation: Cross-entropy=2.4592461585998535, Accuracy=0.09595959633588791\n",
      "Epoch 158 train: Cross-entropy=2.338184608353509, Accuracy=0.1545138888888889\n",
      "Epoch 158 validation: Cross-entropy=2.4592652320861816, Accuracy=0.09595959633588791\n",
      "Epoch 159 train: Cross-entropy=2.3381541437572904, Accuracy=0.1545138888888889\n",
      "Epoch 159 validation: Cross-entropy=2.4592831134796143, Accuracy=0.09595959633588791\n",
      "Epoch 160 train: Cross-entropy=2.338124500380622, Accuracy=0.1545138888888889\n",
      "Epoch 160 validation: Cross-entropy=2.4593002796173096, Accuracy=0.09595959633588791\n",
      "Epoch 161 train: Cross-entropy=2.3380956914689808, Accuracy=0.1545138888888889\n",
      "Epoch 161 validation: Cross-entropy=2.4593160152435303, Accuracy=0.09595959633588791\n",
      "Epoch 162 train: Cross-entropy=2.3380676640404596, Accuracy=0.1545138888888889\n",
      "Epoch 162 validation: Cross-entropy=2.4593312740325928, Accuracy=0.09595959633588791\n",
      "Epoch 163 train: Cross-entropy=2.3380403916041055, Accuracy=0.1527777777777778\n",
      "Epoch 163 validation: Cross-entropy=2.4593453407287598, Accuracy=0.09595959633588791\n",
      "Epoch 164 train: Cross-entropy=2.3380138211780124, Accuracy=0.1527777777777778\n",
      "Epoch 164 validation: Cross-entropy=2.4593586921691895, Accuracy=0.09595959633588791\n",
      "Epoch 165 train: Cross-entropy=2.337988111707899, Accuracy=0.1527777777777778\n",
      "Epoch 165 validation: Cross-entropy=2.4593710899353027, Accuracy=0.09595959633588791\n",
      "Epoch 166 train: Cross-entropy=2.337963024775187, Accuracy=0.1527777777777778\n",
      "Epoch 166 validation: Cross-entropy=2.4593822956085205, Accuracy=0.09595959633588791\n",
      "Epoch 167 train: Cross-entropy=2.3379386398527355, Accuracy=0.1527777777777778\n",
      "Epoch 167 validation: Cross-entropy=2.459392547607422, Accuracy=0.09595959633588791\n",
      "Epoch 168 train: Cross-entropy=2.3379150761498346, Accuracy=0.1527777777777778\n",
      "Epoch 168 validation: Cross-entropy=2.459402561187744, Accuracy=0.09595959633588791\n",
      "Epoch 169 train: Cross-entropy=2.3378921614752874, Accuracy=0.1527777777777778\n",
      "Epoch 169 validation: Cross-entropy=2.459411382675171, Accuracy=0.09595959633588791\n",
      "Epoch 170 train: Cross-entropy=2.3378699090745716, Accuracy=0.1527777777777778\n",
      "Epoch 170 validation: Cross-entropy=2.4594192504882812, Accuracy=0.09595959633588791\n",
      "Epoch 171 train: Cross-entropy=2.3378483719295926, Accuracy=0.1527777777777778\n",
      "Epoch 171 validation: Cross-entropy=2.4594264030456543, Accuracy=0.09595959633588791\n",
      "Epoch 172 train: Cross-entropy=2.337827444076538, Accuracy=0.1545138888888889\n",
      "Epoch 172 validation: Cross-entropy=2.4594333171844482, Accuracy=0.09595959633588791\n",
      "Epoch 173 train: Cross-entropy=2.337807231479221, Accuracy=0.1545138888888889\n",
      "Epoch 173 validation: Cross-entropy=2.4594388008117676, Accuracy=0.09595959633588791\n",
      "Epoch 174 train: Cross-entropy=2.337787561946445, Accuracy=0.1545138888888889\n",
      "Epoch 174 validation: Cross-entropy=2.4594435691833496, Accuracy=0.09595959633588791\n",
      "Epoch 175 train: Cross-entropy=2.337768660651313, Accuracy=0.1545138888888889\n",
      "Epoch 175 validation: Cross-entropy=2.4594478607177734, Accuracy=0.09595959633588791\n",
      "Epoch 176 train: Cross-entropy=2.3377503156661987, Accuracy=0.1545138888888889\n",
      "Epoch 176 validation: Cross-entropy=2.4594509601593018, Accuracy=0.09595959633588791\n",
      "Epoch 177 train: Cross-entropy=2.337732540236579, Accuracy=0.1545138888888889\n",
      "Epoch 177 validation: Cross-entropy=2.45945405960083, Accuracy=0.09595959633588791\n",
      "Epoch 178 train: Cross-entropy=2.33771542708079, Accuracy=0.1545138888888889\n",
      "Epoch 178 validation: Cross-entropy=2.459455966949463, Accuracy=0.09595959633588791\n",
      "Epoch 179 train: Cross-entropy=2.337698817253113, Accuracy=0.1545138888888889\n",
      "Epoch 179 validation: Cross-entropy=2.4594571590423584, Accuracy=0.09595959633588791\n",
      "Epoch 180 train: Cross-entropy=2.3376828961902194, Accuracy=0.1545138888888889\n",
      "Epoch 180 validation: Cross-entropy=2.459458351135254, Accuracy=0.09595959633588791\n",
      "Epoch 181 train: Cross-entropy=2.3376675181918674, Accuracy=0.1545138888888889\n",
      "Epoch 181 validation: Cross-entropy=2.459458351135254, Accuracy=0.09595959633588791\n",
      "Epoch 182 train: Cross-entropy=2.3376526170306735, Accuracy=0.1545138888888889\n",
      "Epoch 182 validation: Cross-entropy=2.4594578742980957, Accuracy=0.09595959633588791\n",
      "Epoch 183 train: Cross-entropy=2.337638325161404, Accuracy=0.1545138888888889\n",
      "Epoch 183 validation: Cross-entropy=2.4594566822052, Accuracy=0.09595959633588791\n",
      "Epoch 184 train: Cross-entropy=2.3376246425840588, Accuracy=0.1545138888888889\n",
      "Epoch 184 validation: Cross-entropy=2.4594550132751465, Accuracy=0.09595959633588791\n",
      "Epoch 185 train: Cross-entropy=2.337611450089349, Accuracy=0.1527777777777778\n",
      "Epoch 185 validation: Cross-entropy=2.4594523906707764, Accuracy=0.09595959633588791\n",
      "Epoch 186 train: Cross-entropy=2.3375987741682263, Accuracy=0.1527777777777778\n",
      "Epoch 186 validation: Cross-entropy=2.459449291229248, Accuracy=0.09595959633588791\n",
      "Epoch 187 train: Cross-entropy=2.3375866413116455, Accuracy=0.1527777777777778\n",
      "Epoch 187 validation: Cross-entropy=2.4594459533691406, Accuracy=0.09595959633588791\n",
      "Epoch 188 train: Cross-entropy=2.3375750250286527, Accuracy=0.1527777777777778\n",
      "Epoch 188 validation: Cross-entropy=2.4594414234161377, Accuracy=0.09595959633588791\n",
      "Epoch 189 train: Cross-entropy=2.337563845846388, Accuracy=0.1527777777777778\n",
      "Epoch 189 validation: Cross-entropy=2.4594368934631348, Accuracy=0.09595959633588791\n",
      "Epoch 190 train: Cross-entropy=2.3375531832377114, Accuracy=0.1527777777777778\n",
      "Epoch 190 validation: Cross-entropy=2.4594318866729736, Accuracy=0.09595959633588791\n",
      "Epoch 191 train: Cross-entropy=2.3375430901845298, Accuracy=0.1527777777777778\n",
      "Epoch 191 validation: Cross-entropy=2.459425926208496, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 train: Cross-entropy=2.337533394495646, Accuracy=0.1527777777777778\n",
      "Epoch 192 validation: Cross-entropy=2.4594197273254395, Accuracy=0.09595959633588791\n",
      "Epoch 193 train: Cross-entropy=2.3375242153803506, Accuracy=0.1527777777777778\n",
      "Epoch 193 validation: Cross-entropy=2.4594130516052246, Accuracy=0.09595959633588791\n",
      "Epoch 194 train: Cross-entropy=2.3375154203838773, Accuracy=0.1527777777777778\n",
      "Epoch 194 validation: Cross-entropy=2.4594056606292725, Accuracy=0.09595959633588791\n",
      "Epoch 195 train: Cross-entropy=2.337507208188375, Accuracy=0.1527777777777778\n",
      "Epoch 195 validation: Cross-entropy=2.459398031234741, Accuracy=0.09595959633588791\n",
      "Epoch 196 train: Cross-entropy=2.337499353620741, Accuracy=0.1527777777777778\n",
      "Epoch 196 validation: Cross-entropy=2.4593896865844727, Accuracy=0.09595959633588791\n",
      "Epoch 197 train: Cross-entropy=2.3374919758902655, Accuracy=0.1527777777777778\n",
      "Epoch 197 validation: Cross-entropy=2.459381341934204, Accuracy=0.09595959633588791\n",
      "Epoch 198 train: Cross-entropy=2.3374850749969482, Accuracy=0.1527777777777778\n",
      "Epoch 198 validation: Cross-entropy=2.4593722820281982, Accuracy=0.09595959633588791\n",
      "Epoch 199 train: Cross-entropy=2.3374785582224527, Accuracy=0.1527777777777778\n",
      "Epoch 199 validation: Cross-entropy=2.459362268447876, Accuracy=0.09595959633588791\n",
      "Epoch 0 train: Cross-entropy=2.411156098047892, Accuracy=0.10590277777777778\n",
      "Epoch 0 validation: Cross-entropy=2.4258809089660645, Accuracy=0.07070706784725189\n",
      "Epoch 1 train: Cross-entropy=2.4063806268903942, Accuracy=0.11458333333333333\n",
      "Epoch 1 validation: Cross-entropy=2.422600269317627, Accuracy=0.06060606241226196\n",
      "Epoch 2 train: Cross-entropy=2.4026367399427624, Accuracy=0.125\n",
      "Epoch 2 validation: Cross-entropy=2.4203062057495117, Accuracy=0.08585858345031738\n",
      "Epoch 3 train: Cross-entropy=2.3998537725872464, Accuracy=0.11805555555555555\n",
      "Epoch 3 validation: Cross-entropy=2.418729305267334, Accuracy=0.08585858345031738\n",
      "Epoch 4 train: Cross-entropy=2.3977671464284263, Accuracy=0.1284722222222222\n",
      "Epoch 4 validation: Cross-entropy=2.417660713195801, Accuracy=0.09090909361839294\n",
      "Epoch 5 train: Cross-entropy=2.3961867094039917, Accuracy=0.1232638888888889\n",
      "Epoch 5 validation: Cross-entropy=2.4169530868530273, Accuracy=0.08080808073282242\n",
      "Epoch 6 train: Cross-entropy=2.3949761523140802, Accuracy=0.11631944444444445\n",
      "Epoch 6 validation: Cross-entropy=2.416501045227051, Accuracy=0.08080808073282242\n",
      "Epoch 7 train: Cross-entropy=2.394037445386251, Accuracy=0.11458333333333333\n",
      "Epoch 7 validation: Cross-entropy=2.4162309169769287, Accuracy=0.05050504952669144\n",
      "Epoch 8 train: Cross-entropy=2.3932993014653525, Accuracy=0.1076388888888889\n",
      "Epoch 8 validation: Cross-entropy=2.416088104248047, Accuracy=0.05050504952669144\n",
      "Epoch 9 train: Cross-entropy=2.3927095201280384, Accuracy=0.10416666666666667\n",
      "Epoch 9 validation: Cross-entropy=2.416034698486328, Accuracy=0.04545454680919647\n",
      "Epoch 10 train: Cross-entropy=2.3922298749287925, Accuracy=0.09375\n",
      "Epoch 10 validation: Cross-entropy=2.416041851043701, Accuracy=0.04040404036641121\n",
      "Epoch 11 train: Cross-entropy=2.391832153002421, Accuracy=0.09722222222222222\n",
      "Epoch 11 validation: Cross-entropy=2.416090488433838, Accuracy=0.04040404036641121\n",
      "Epoch 12 train: Cross-entropy=2.3914955059687295, Accuracy=0.09375\n",
      "Epoch 12 validation: Cross-entropy=2.416165828704834, Accuracy=0.06060606241226196\n",
      "Epoch 13 train: Cross-entropy=2.391204555829366, Accuracy=0.0954861111111111\n",
      "Epoch 13 validation: Cross-entropy=2.416257619857788, Accuracy=0.07070706784725189\n",
      "Epoch 14 train: Cross-entropy=2.390947699546814, Accuracy=0.09722222222222222\n",
      "Epoch 14 validation: Cross-entropy=2.4163589477539062, Accuracy=0.07070706784725189\n",
      "Epoch 15 train: Cross-entropy=2.3907165129979453, Accuracy=0.09722222222222222\n",
      "Epoch 15 validation: Cross-entropy=2.4164645671844482, Accuracy=0.07070706784725189\n",
      "Epoch 16 train: Cross-entropy=2.3905046118630304, Accuracy=0.0920138888888889\n",
      "Epoch 16 validation: Cross-entropy=2.4165709018707275, Accuracy=0.07070706784725189\n",
      "Epoch 17 train: Cross-entropy=2.390307386716207, Accuracy=0.09895833333333333\n",
      "Epoch 17 validation: Cross-entropy=2.416675567626953, Accuracy=0.08080808073282242\n",
      "Epoch 18 train: Cross-entropy=2.390121062596639, Accuracy=0.09895833333333333\n",
      "Epoch 18 validation: Cross-entropy=2.4167773723602295, Accuracy=0.08080808073282242\n",
      "Epoch 19 train: Cross-entropy=2.389943109618293, Accuracy=0.10243055555555555\n",
      "Epoch 19 validation: Cross-entropy=2.416875123977661, Accuracy=0.08080808073282242\n",
      "Epoch 20 train: Cross-entropy=2.3897716999053955, Accuracy=0.10416666666666667\n",
      "Epoch 20 validation: Cross-entropy=2.41696834564209, Accuracy=0.07575757801532745\n",
      "Epoch 21 train: Cross-entropy=2.3896051910188465, Accuracy=0.10416666666666667\n",
      "Epoch 21 validation: Cross-entropy=2.4170563220977783, Accuracy=0.07070706784725189\n",
      "Epoch 22 train: Cross-entropy=2.389442563056946, Accuracy=0.10243055555555555\n",
      "Epoch 22 validation: Cross-entropy=2.417140007019043, Accuracy=0.07070706784725189\n",
      "Epoch 23 train: Cross-entropy=2.3892829020818076, Accuracy=0.10069444444444445\n",
      "Epoch 23 validation: Cross-entropy=2.4172191619873047, Accuracy=0.07070706784725189\n",
      "Epoch 24 train: Cross-entropy=2.389125837220086, Accuracy=0.10069444444444445\n",
      "Epoch 24 validation: Cross-entropy=2.4172935485839844, Accuracy=0.07070706784725189\n",
      "Epoch 25 train: Cross-entropy=2.3889706664615207, Accuracy=0.10069444444444445\n",
      "Epoch 25 validation: Cross-entropy=2.4173638820648193, Accuracy=0.07070706784725189\n",
      "Epoch 26 train: Cross-entropy=2.3888170851601496, Accuracy=0.09895833333333333\n",
      "Epoch 26 validation: Cross-entropy=2.4174301624298096, Accuracy=0.06565656512975693\n",
      "Epoch 27 train: Cross-entropy=2.3886649211247764, Accuracy=0.0954861111111111\n",
      "Epoch 27 validation: Cross-entropy=2.4174931049346924, Accuracy=0.06565656512975693\n",
      "Epoch 28 train: Cross-entropy=2.388513962427775, Accuracy=0.0954861111111111\n",
      "Epoch 28 validation: Cross-entropy=2.4175527095794678, Accuracy=0.06565656512975693\n",
      "Epoch 29 train: Cross-entropy=2.388364063368903, Accuracy=0.09375\n",
      "Epoch 29 validation: Cross-entropy=2.417609214782715, Accuracy=0.07070706784725189\n",
      "Epoch 30 train: Cross-entropy=2.388215104738871, Accuracy=0.09027777777777778\n",
      "Epoch 30 validation: Cross-entropy=2.417663097381592, Accuracy=0.07070706784725189\n",
      "Epoch 31 train: Cross-entropy=2.3880670070648193, Accuracy=0.09027777777777778\n",
      "Epoch 31 validation: Cross-entropy=2.417714834213257, Accuracy=0.07070706784725189\n",
      "Epoch 32 train: Cross-entropy=2.3879196776284113, Accuracy=0.09027777777777778\n",
      "Epoch 32 validation: Cross-entropy=2.4177639484405518, Accuracy=0.07070706784725189\n",
      "Epoch 33 train: Cross-entropy=2.3877731694115534, Accuracy=0.0920138888888889\n",
      "Epoch 33 validation: Cross-entropy=2.417811632156372, Accuracy=0.07070706784725189\n",
      "Epoch 34 train: Cross-entropy=2.3876273499594793, Accuracy=0.09375\n",
      "Epoch 34 validation: Cross-entropy=2.4178569316864014, Accuracy=0.07070706784725189\n",
      "Epoch 35 train: Cross-entropy=2.3874822192721896, Accuracy=0.09375\n",
      "Epoch 35 validation: Cross-entropy=2.4179012775421143, Accuracy=0.07070706784725189\n",
      "Epoch 36 train: Cross-entropy=2.387337803840637, Accuracy=0.09375\n",
      "Epoch 36 validation: Cross-entropy=2.4179441928863525, Accuracy=0.07070706784725189\n",
      "Epoch 37 train: Cross-entropy=2.387194037437439, Accuracy=0.09375\n",
      "Epoch 37 validation: Cross-entropy=2.417985439300537, Accuracy=0.07070706784725189\n",
      "Epoch 38 train: Cross-entropy=2.387050893571642, Accuracy=0.09375\n",
      "Epoch 38 validation: Cross-entropy=2.4180262088775635, Accuracy=0.07070706784725189\n",
      "Epoch 39 train: Cross-entropy=2.3869084384706287, Accuracy=0.09375\n",
      "Epoch 39 validation: Cross-entropy=2.4180655479431152, Accuracy=0.07070706784725189\n",
      "Epoch 40 train: Cross-entropy=2.3867665926615396, Accuracy=0.0954861111111111\n",
      "Epoch 40 validation: Cross-entropy=2.4181041717529297, Accuracy=0.07070706784725189\n",
      "Epoch 41 train: Cross-entropy=2.386625369389852, Accuracy=0.09722222222222222\n",
      "Epoch 41 validation: Cross-entropy=2.418142318725586, Accuracy=0.07070706784725189\n",
      "Epoch 42 train: Cross-entropy=2.3864848216374717, Accuracy=0.10069444444444445\n",
      "Epoch 42 validation: Cross-entropy=2.418179512023926, Accuracy=0.07070706784725189\n",
      "Epoch 43 train: Cross-entropy=2.3863448831770153, Accuracy=0.10069444444444445\n",
      "Epoch 43 validation: Cross-entropy=2.4182167053222656, Accuracy=0.07070706784725189\n",
      "Epoch 44 train: Cross-entropy=2.3862055672539606, Accuracy=0.10069444444444445\n",
      "Epoch 44 validation: Cross-entropy=2.418252944946289, Accuracy=0.07070706784725189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 train: Cross-entropy=2.38606686062283, Accuracy=0.10069444444444445\n",
      "Epoch 45 validation: Cross-entropy=2.4182889461517334, Accuracy=0.07070706784725189\n",
      "Epoch 46 train: Cross-entropy=2.3859286970562406, Accuracy=0.10243055555555555\n",
      "Epoch 46 validation: Cross-entropy=2.4183244705200195, Accuracy=0.07070706784725189\n",
      "Epoch 47 train: Cross-entropy=2.385791235499912, Accuracy=0.10243055555555555\n",
      "Epoch 47 validation: Cross-entropy=2.4183599948883057, Accuracy=0.07070706784725189\n",
      "Epoch 48 train: Cross-entropy=2.3856543170081244, Accuracy=0.10069444444444445\n",
      "Epoch 48 validation: Cross-entropy=2.4183948040008545, Accuracy=0.07070706784725189\n",
      "Epoch 49 train: Cross-entropy=2.3855179680718317, Accuracy=0.10243055555555555\n",
      "Epoch 49 validation: Cross-entropy=2.4184298515319824, Accuracy=0.07070706784725189\n",
      "Epoch 50 train: Cross-entropy=2.3853822814093695, Accuracy=0.10416666666666667\n",
      "Epoch 50 validation: Cross-entropy=2.4184646606445312, Accuracy=0.07070706784725189\n",
      "Epoch 51 train: Cross-entropy=2.3852471510569253, Accuracy=0.10416666666666667\n",
      "Epoch 51 validation: Cross-entropy=2.418499231338501, Accuracy=0.06565656512975693\n",
      "Epoch 52 train: Cross-entropy=2.3851125637690225, Accuracy=0.10243055555555555\n",
      "Epoch 52 validation: Cross-entropy=2.4185335636138916, Accuracy=0.06565656512975693\n",
      "Epoch 53 train: Cross-entropy=2.3849787182278104, Accuracy=0.10243055555555555\n",
      "Epoch 53 validation: Cross-entropy=2.4185678958892822, Accuracy=0.06565656512975693\n",
      "Epoch 54 train: Cross-entropy=2.384845323032803, Accuracy=0.10243055555555555\n",
      "Epoch 54 validation: Cross-entropy=2.418602228164673, Accuracy=0.06565656512975693\n",
      "Epoch 55 train: Cross-entropy=2.3847125238842435, Accuracy=0.10243055555555555\n",
      "Epoch 55 validation: Cross-entropy=2.4186367988586426, Accuracy=0.06565656512975693\n",
      "Epoch 56 train: Cross-entropy=2.3845803207821317, Accuracy=0.10243055555555555\n",
      "Epoch 56 validation: Cross-entropy=2.418670654296875, Accuracy=0.06565656512975693\n",
      "Epoch 57 train: Cross-entropy=2.384448700480991, Accuracy=0.10243055555555555\n",
      "Epoch 57 validation: Cross-entropy=2.4187052249908447, Accuracy=0.07575757801532745\n",
      "Epoch 58 train: Cross-entropy=2.384317570262485, Accuracy=0.10590277777777778\n",
      "Epoch 58 validation: Cross-entropy=2.4187393188476562, Accuracy=0.07575757801532745\n",
      "Epoch 59 train: Cross-entropy=2.38418702284495, Accuracy=0.10590277777777778\n",
      "Epoch 59 validation: Cross-entropy=2.4187734127044678, Accuracy=0.07575757801532745\n",
      "Epoch 60 train: Cross-entropy=2.38405712445577, Accuracy=0.10590277777777778\n",
      "Epoch 60 validation: Cross-entropy=2.4188077449798584, Accuracy=0.07575757801532745\n",
      "Epoch 61 train: Cross-entropy=2.3839277029037476, Accuracy=0.10590277777777778\n",
      "Epoch 61 validation: Cross-entropy=2.418842077255249, Accuracy=0.07070706784725189\n",
      "Epoch 62 train: Cross-entropy=2.383798877398173, Accuracy=0.1076388888888889\n",
      "Epoch 62 validation: Cross-entropy=2.4188761711120605, Accuracy=0.07070706784725189\n",
      "Epoch 63 train: Cross-entropy=2.38367051548428, Accuracy=0.10590277777777778\n",
      "Epoch 63 validation: Cross-entropy=2.4189107418060303, Accuracy=0.07070706784725189\n",
      "Epoch 64 train: Cross-entropy=2.3835428290896945, Accuracy=0.10590277777777778\n",
      "Epoch 64 validation: Cross-entropy=2.418945074081421, Accuracy=0.06565656512975693\n",
      "Epoch 65 train: Cross-entropy=2.383415619532267, Accuracy=0.10590277777777778\n",
      "Epoch 65 validation: Cross-entropy=2.4189796447753906, Accuracy=0.06060606241226196\n",
      "Epoch 66 train: Cross-entropy=2.3832889133029513, Accuracy=0.10590277777777778\n",
      "Epoch 66 validation: Cross-entropy=2.4190139770507812, Accuracy=0.06060606241226196\n",
      "Epoch 67 train: Cross-entropy=2.383162750138177, Accuracy=0.10590277777777778\n",
      "Epoch 67 validation: Cross-entropy=2.41904878616333, Accuracy=0.06060606241226196\n",
      "Epoch 68 train: Cross-entropy=2.38303718301985, Accuracy=0.1076388888888889\n",
      "Epoch 68 validation: Cross-entropy=2.4190831184387207, Accuracy=0.06060606241226196\n",
      "Epoch 69 train: Cross-entropy=2.3829120794932046, Accuracy=0.10590277777777778\n",
      "Epoch 69 validation: Cross-entropy=2.4191179275512695, Accuracy=0.06060606241226196\n",
      "Epoch 70 train: Cross-entropy=2.3827875322765775, Accuracy=0.10416666666666667\n",
      "Epoch 70 validation: Cross-entropy=2.4191527366638184, Accuracy=0.06060606241226196\n",
      "Epoch 71 train: Cross-entropy=2.382663514879015, Accuracy=0.10416666666666667\n",
      "Epoch 71 validation: Cross-entropy=2.419187545776367, Accuracy=0.06060606241226196\n",
      "Epoch 72 train: Cross-entropy=2.382539987564087, Accuracy=0.10590277777777778\n",
      "Epoch 72 validation: Cross-entropy=2.419222831726074, Accuracy=0.06060606241226196\n",
      "Epoch 73 train: Cross-entropy=2.3824170033137, Accuracy=0.10590277777777778\n",
      "Epoch 73 validation: Cross-entropy=2.419257402420044, Accuracy=0.06060606241226196\n",
      "Epoch 74 train: Cross-entropy=2.3822945488823786, Accuracy=0.10590277777777778\n",
      "Epoch 74 validation: Cross-entropy=2.419292449951172, Accuracy=0.06060606241226196\n",
      "Epoch 75 train: Cross-entropy=2.382172531551785, Accuracy=0.10590277777777778\n",
      "Epoch 75 validation: Cross-entropy=2.419327974319458, Accuracy=0.06060606241226196\n",
      "Epoch 76 train: Cross-entropy=2.3820510970221624, Accuracy=0.1076388888888889\n",
      "Epoch 76 validation: Cross-entropy=2.419363021850586, Accuracy=0.06060606241226196\n",
      "Epoch 77 train: Cross-entropy=2.3819301790661283, Accuracy=0.1076388888888889\n",
      "Epoch 77 validation: Cross-entropy=2.419398069381714, Accuracy=0.06060606241226196\n",
      "Epoch 78 train: Cross-entropy=2.381809671719869, Accuracy=0.109375\n",
      "Epoch 78 validation: Cross-entropy=2.419433832168579, Accuracy=0.06060606241226196\n",
      "Epoch 79 train: Cross-entropy=2.3816896941926746, Accuracy=0.109375\n",
      "Epoch 79 validation: Cross-entropy=2.419469118118286, Accuracy=0.06060606241226196\n",
      "Epoch 80 train: Cross-entropy=2.3815702729754977, Accuracy=0.109375\n",
      "Epoch 80 validation: Cross-entropy=2.419504404067993, Accuracy=0.06060606241226196\n",
      "Epoch 81 train: Cross-entropy=2.381451275613573, Accuracy=0.109375\n",
      "Epoch 81 validation: Cross-entropy=2.4195401668548584, Accuracy=0.06060606241226196\n",
      "Epoch 82 train: Cross-entropy=2.381332768334283, Accuracy=0.109375\n",
      "Epoch 82 validation: Cross-entropy=2.4195759296417236, Accuracy=0.06060606241226196\n",
      "Epoch 83 train: Cross-entropy=2.381214737892151, Accuracy=0.109375\n",
      "Epoch 83 validation: Cross-entropy=2.4196114540100098, Accuracy=0.06060606241226196\n",
      "Epoch 84 train: Cross-entropy=2.381097197532654, Accuracy=0.109375\n",
      "Epoch 84 validation: Cross-entropy=2.419647216796875, Accuracy=0.06060606241226196\n",
      "Epoch 85 train: Cross-entropy=2.380980213483175, Accuracy=0.1111111111111111\n",
      "Epoch 85 validation: Cross-entropy=2.4196829795837402, Accuracy=0.06060606241226196\n",
      "Epoch 86 train: Cross-entropy=2.3808635473251343, Accuracy=0.11284722222222222\n",
      "Epoch 86 validation: Cross-entropy=2.4197189807891846, Accuracy=0.06060606241226196\n",
      "Epoch 87 train: Cross-entropy=2.380747503704495, Accuracy=0.11458333333333333\n",
      "Epoch 87 validation: Cross-entropy=2.419754981994629, Accuracy=0.06060606241226196\n",
      "Epoch 88 train: Cross-entropy=2.3806318839391074, Accuracy=0.11458333333333333\n",
      "Epoch 88 validation: Cross-entropy=2.4197909832000732, Accuracy=0.06060606241226196\n",
      "Epoch 89 train: Cross-entropy=2.3805166482925415, Accuracy=0.11458333333333333\n",
      "Epoch 89 validation: Cross-entropy=2.4198269844055176, Accuracy=0.06060606241226196\n",
      "Epoch 90 train: Cross-entropy=2.380402035183377, Accuracy=0.11458333333333333\n",
      "Epoch 90 validation: Cross-entropy=2.419863224029541, Accuracy=0.06060606241226196\n",
      "Epoch 91 train: Cross-entropy=2.3802877399656506, Accuracy=0.11458333333333333\n",
      "Epoch 91 validation: Cross-entropy=2.4198994636535645, Accuracy=0.06060606241226196\n",
      "Epoch 92 train: Cross-entropy=2.3801739480760364, Accuracy=0.11458333333333333\n",
      "Epoch 92 validation: Cross-entropy=2.419935941696167, Accuracy=0.06060606241226196\n",
      "Epoch 93 train: Cross-entropy=2.3800606197781033, Accuracy=0.11458333333333333\n",
      "Epoch 93 validation: Cross-entropy=2.4199721813201904, Accuracy=0.06060606241226196\n",
      "Epoch 94 train: Cross-entropy=2.3799478080537586, Accuracy=0.11458333333333333\n",
      "Epoch 94 validation: Cross-entropy=2.420008659362793, Accuracy=0.06060606241226196\n",
      "Epoch 95 train: Cross-entropy=2.3798353804482355, Accuracy=0.11458333333333333\n",
      "Epoch 95 validation: Cross-entropy=2.4200451374053955, Accuracy=0.06060606241226196\n",
      "Epoch 96 train: Cross-entropy=2.3797233634524875, Accuracy=0.11458333333333333\n",
      "Epoch 96 validation: Cross-entropy=2.420081615447998, Accuracy=0.06060606241226196\n",
      "Epoch 97 train: Cross-entropy=2.379611929257711, Accuracy=0.11458333333333333\n",
      "Epoch 97 validation: Cross-entropy=2.4201183319091797, Accuracy=0.06060606241226196\n",
      "Epoch 98 train: Cross-entropy=2.3795007599724665, Accuracy=0.11458333333333333\n",
      "Epoch 98 validation: Cross-entropy=2.4201550483703613, Accuracy=0.06565656512975693\n",
      "Epoch 99 train: Cross-entropy=2.37939006752438, Accuracy=0.11458333333333333\n",
      "Epoch 99 validation: Cross-entropy=2.420191764831543, Accuracy=0.06565656512975693\n",
      "Epoch 100 train: Cross-entropy=2.3792799048953586, Accuracy=0.11458333333333333\n",
      "Epoch 100 validation: Cross-entropy=2.4202284812927246, Accuracy=0.06565656512975693\n",
      "Epoch 101 train: Cross-entropy=2.3791701131396823, Accuracy=0.11631944444444445\n",
      "Epoch 101 validation: Cross-entropy=2.420264959335327, Accuracy=0.06565656512975693\n",
      "Epoch 102 train: Cross-entropy=2.3790607982211642, Accuracy=0.11631944444444445\n",
      "Epoch 102 validation: Cross-entropy=2.420301914215088, Accuracy=0.06565656512975693\n",
      "Epoch 103 train: Cross-entropy=2.3789519204033747, Accuracy=0.11631944444444445\n",
      "Epoch 103 validation: Cross-entropy=2.420339345932007, Accuracy=0.06565656512975693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 train: Cross-entropy=2.3788433737225003, Accuracy=0.11631944444444445\n",
      "Epoch 104 validation: Cross-entropy=2.4203760623931885, Accuracy=0.06565656512975693\n",
      "Epoch 105 train: Cross-entropy=2.3787353303697376, Accuracy=0.11631944444444445\n",
      "Epoch 105 validation: Cross-entropy=2.420413017272949, Accuracy=0.06565656512975693\n",
      "Epoch 106 train: Cross-entropy=2.3786276711357965, Accuracy=0.11631944444444445\n",
      "Epoch 106 validation: Cross-entropy=2.42044997215271, Accuracy=0.06565656512975693\n",
      "Epoch 107 train: Cross-entropy=2.378520449002584, Accuracy=0.11631944444444445\n",
      "Epoch 107 validation: Cross-entropy=2.42048716545105, Accuracy=0.06565656512975693\n",
      "Epoch 108 train: Cross-entropy=2.3784135977427163, Accuracy=0.11631944444444445\n",
      "Epoch 108 validation: Cross-entropy=2.4205243587493896, Accuracy=0.06565656512975693\n",
      "Epoch 109 train: Cross-entropy=2.378307236565484, Accuracy=0.11631944444444445\n",
      "Epoch 109 validation: Cross-entropy=2.4205615520477295, Accuracy=0.06565656512975693\n",
      "Epoch 110 train: Cross-entropy=2.37820123301612, Accuracy=0.11805555555555555\n",
      "Epoch 110 validation: Cross-entropy=2.4205987453460693, Accuracy=0.06565656512975693\n",
      "Epoch 111 train: Cross-entropy=2.378095587094625, Accuracy=0.11979166666666667\n",
      "Epoch 111 validation: Cross-entropy=2.4206361770629883, Accuracy=0.06565656512975693\n",
      "Epoch 112 train: Cross-entropy=2.3779904577467175, Accuracy=0.11979166666666667\n",
      "Epoch 112 validation: Cross-entropy=2.420673370361328, Accuracy=0.06565656512975693\n",
      "Epoch 113 train: Cross-entropy=2.3778857125176325, Accuracy=0.11979166666666667\n",
      "Epoch 113 validation: Cross-entropy=2.420710802078247, Accuracy=0.06565656512975693\n",
      "Epoch 114 train: Cross-entropy=2.3777813381618924, Accuracy=0.11979166666666667\n",
      "Epoch 114 validation: Cross-entropy=2.420748710632324, Accuracy=0.06565656512975693\n",
      "Epoch 115 train: Cross-entropy=2.377677400906881, Accuracy=0.11979166666666667\n",
      "Epoch 115 validation: Cross-entropy=2.420785665512085, Accuracy=0.06565656512975693\n",
      "Epoch 116 train: Cross-entropy=2.377573808034261, Accuracy=0.12152777777777778\n",
      "Epoch 116 validation: Cross-entropy=2.420823335647583, Accuracy=0.06565656512975693\n",
      "Epoch 117 train: Cross-entropy=2.3774706655078464, Accuracy=0.12152777777777778\n",
      "Epoch 117 validation: Cross-entropy=2.420860767364502, Accuracy=0.06565656512975693\n",
      "Epoch 118 train: Cross-entropy=2.3773678806093006, Accuracy=0.12152777777777778\n",
      "Epoch 118 validation: Cross-entropy=2.4208984375, Accuracy=0.06565656512975693\n",
      "Epoch 119 train: Cross-entropy=2.3772654400931463, Accuracy=0.12152777777777778\n",
      "Epoch 119 validation: Cross-entropy=2.420936107635498, Accuracy=0.06565656512975693\n",
      "Epoch 120 train: Cross-entropy=2.377163396941291, Accuracy=0.12152777777777778\n",
      "Epoch 120 validation: Cross-entropy=2.420973539352417, Accuracy=0.06565656512975693\n",
      "Epoch 121 train: Cross-entropy=2.377061857117547, Accuracy=0.12152777777777778\n",
      "Epoch 121 validation: Cross-entropy=2.4210116863250732, Accuracy=0.06565656512975693\n",
      "Epoch 122 train: Cross-entropy=2.376960621939765, Accuracy=0.12152777777777778\n",
      "Epoch 122 validation: Cross-entropy=2.421049118041992, Accuracy=0.06565656512975693\n",
      "Epoch 123 train: Cross-entropy=2.3768597841262817, Accuracy=0.11979166666666667\n",
      "Epoch 123 validation: Cross-entropy=2.4210870265960693, Accuracy=0.06565656512975693\n",
      "Epoch 124 train: Cross-entropy=2.3767592509587607, Accuracy=0.11979166666666667\n",
      "Epoch 124 validation: Cross-entropy=2.4211249351501465, Accuracy=0.06565656512975693\n",
      "Epoch 125 train: Cross-entropy=2.376659221119351, Accuracy=0.11979166666666667\n",
      "Epoch 125 validation: Cross-entropy=2.4211623668670654, Accuracy=0.06565656512975693\n",
      "Epoch 126 train: Cross-entropy=2.37655946943495, Accuracy=0.11805555555555555\n",
      "Epoch 126 validation: Cross-entropy=2.4212002754211426, Accuracy=0.07070706784725189\n",
      "Epoch 127 train: Cross-entropy=2.3764600621329413, Accuracy=0.11805555555555555\n",
      "Epoch 127 validation: Cross-entropy=2.4212381839752197, Accuracy=0.07070706784725189\n",
      "Epoch 128 train: Cross-entropy=2.3763611449135675, Accuracy=0.11805555555555555\n",
      "Epoch 128 validation: Cross-entropy=2.421276330947876, Accuracy=0.07070706784725189\n",
      "Epoch 129 train: Cross-entropy=2.3762625323401556, Accuracy=0.11805555555555555\n",
      "Epoch 129 validation: Cross-entropy=2.421314239501953, Accuracy=0.07070706784725189\n",
      "Epoch 130 train: Cross-entropy=2.3761643038855658, Accuracy=0.11805555555555555\n",
      "Epoch 130 validation: Cross-entropy=2.4213521480560303, Accuracy=0.07070706784725189\n",
      "Epoch 131 train: Cross-entropy=2.376066419813368, Accuracy=0.11805555555555555\n",
      "Epoch 131 validation: Cross-entropy=2.4213900566101074, Accuracy=0.07070706784725189\n",
      "Epoch 132 train: Cross-entropy=2.3759689066145153, Accuracy=0.11805555555555555\n",
      "Epoch 132 validation: Cross-entropy=2.4214279651641846, Accuracy=0.07070706784725189\n",
      "Epoch 133 train: Cross-entropy=2.3758717510435314, Accuracy=0.11805555555555555\n",
      "Epoch 133 validation: Cross-entropy=2.42146635055542, Accuracy=0.07070706784725189\n",
      "Epoch 134 train: Cross-entropy=2.3757749795913696, Accuracy=0.11805555555555555\n",
      "Epoch 134 validation: Cross-entropy=2.421504497528076, Accuracy=0.07070706784725189\n",
      "Epoch 135 train: Cross-entropy=2.3756785525215998, Accuracy=0.11631944444444445\n",
      "Epoch 135 validation: Cross-entropy=2.4215424060821533, Accuracy=0.07575757801532745\n",
      "Epoch 136 train: Cross-entropy=2.3755824830796985, Accuracy=0.11631944444444445\n",
      "Epoch 136 validation: Cross-entropy=2.4215803146362305, Accuracy=0.07575757801532745\n",
      "Epoch 137 train: Cross-entropy=2.3754866653018527, Accuracy=0.11631944444444445\n",
      "Epoch 137 validation: Cross-entropy=2.4216184616088867, Accuracy=0.07575757801532745\n",
      "Epoch 138 train: Cross-entropy=2.3753913905885486, Accuracy=0.11805555555555555\n",
      "Epoch 138 validation: Cross-entropy=2.421656847000122, Accuracy=0.08080808073282242\n",
      "Epoch 139 train: Cross-entropy=2.375296261575487, Accuracy=0.11805555555555555\n",
      "Epoch 139 validation: Cross-entropy=2.421694755554199, Accuracy=0.08080808073282242\n",
      "Epoch 140 train: Cross-entropy=2.375201609399584, Accuracy=0.11805555555555555\n",
      "Epoch 140 validation: Cross-entropy=2.4217331409454346, Accuracy=0.08080808073282242\n",
      "Epoch 141 train: Cross-entropy=2.375107314851549, Accuracy=0.11805555555555555\n",
      "Epoch 141 validation: Cross-entropy=2.42177152633667, Accuracy=0.08080808073282242\n",
      "Epoch 142 train: Cross-entropy=2.3750132984585233, Accuracy=0.11979166666666667\n",
      "Epoch 142 validation: Cross-entropy=2.421809673309326, Accuracy=0.08080808073282242\n",
      "Epoch 143 train: Cross-entropy=2.374919639693366, Accuracy=0.11979166666666667\n",
      "Epoch 143 validation: Cross-entropy=2.4218478202819824, Accuracy=0.08080808073282242\n",
      "Epoch 144 train: Cross-entropy=2.374826338556078, Accuracy=0.11979166666666667\n",
      "Epoch 144 validation: Cross-entropy=2.4218862056732178, Accuracy=0.08080808073282242\n",
      "Epoch 145 train: Cross-entropy=2.3747333685557046, Accuracy=0.11979166666666667\n",
      "Epoch 145 validation: Cross-entropy=2.421924591064453, Accuracy=0.08080808073282242\n",
      "Epoch 146 train: Cross-entropy=2.374640623728434, Accuracy=0.11979166666666667\n",
      "Epoch 146 validation: Cross-entropy=2.4219627380371094, Accuracy=0.08080808073282242\n",
      "Epoch 147 train: Cross-entropy=2.3745484484566584, Accuracy=0.11979166666666667\n",
      "Epoch 147 validation: Cross-entropy=2.4220011234283447, Accuracy=0.08080808073282242\n",
      "Epoch 148 train: Cross-entropy=2.374456432130602, Accuracy=0.11979166666666667\n",
      "Epoch 148 validation: Cross-entropy=2.42203950881958, Accuracy=0.08080808073282242\n",
      "Epoch 149 train: Cross-entropy=2.3743647601869373, Accuracy=0.11979166666666667\n",
      "Epoch 149 validation: Cross-entropy=2.4220781326293945, Accuracy=0.08080808073282242\n",
      "Epoch 150 train: Cross-entropy=2.3742734326256647, Accuracy=0.11979166666666667\n",
      "Epoch 150 validation: Cross-entropy=2.422116279602051, Accuracy=0.08080808073282242\n",
      "Epoch 151 train: Cross-entropy=2.3741825024286904, Accuracy=0.11979166666666667\n",
      "Epoch 151 validation: Cross-entropy=2.422154664993286, Accuracy=0.08080808073282242\n",
      "Epoch 152 train: Cross-entropy=2.3740918106502957, Accuracy=0.11805555555555555\n",
      "Epoch 152 validation: Cross-entropy=2.4221930503845215, Accuracy=0.08080808073282242\n",
      "Epoch 153 train: Cross-entropy=2.3740014500088162, Accuracy=0.11805555555555555\n",
      "Epoch 153 validation: Cross-entropy=2.422231435775757, Accuracy=0.08080808073282242\n",
      "Epoch 154 train: Cross-entropy=2.3739114072587757, Accuracy=0.11805555555555555\n",
      "Epoch 154 validation: Cross-entropy=2.422269821166992, Accuracy=0.08080808073282242\n",
      "Epoch 155 train: Cross-entropy=2.3738217221366034, Accuracy=0.11805555555555555\n",
      "Epoch 155 validation: Cross-entropy=2.4223082065582275, Accuracy=0.07575757801532745\n",
      "Epoch 156 train: Cross-entropy=2.3737323019239636, Accuracy=0.11979166666666667\n",
      "Epoch 156 validation: Cross-entropy=2.422346591949463, Accuracy=0.07575757801532745\n",
      "Epoch 157 train: Cross-entropy=2.3736431996027627, Accuracy=0.12152777777777778\n",
      "Epoch 157 validation: Cross-entropy=2.4223852157592773, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 train: Cross-entropy=2.3735544549094305, Accuracy=0.12152777777777778\n",
      "Epoch 158 validation: Cross-entropy=2.4224236011505127, Accuracy=0.07575757801532745\n",
      "Epoch 159 train: Cross-entropy=2.3734659486346774, Accuracy=0.1232638888888889\n",
      "Epoch 159 validation: Cross-entropy=2.422461986541748, Accuracy=0.07575757801532745\n",
      "Epoch 160 train: Cross-entropy=2.373377905951606, Accuracy=0.1232638888888889\n",
      "Epoch 160 validation: Cross-entropy=2.4225003719329834, Accuracy=0.07575757801532745\n",
      "Epoch 161 train: Cross-entropy=2.37329003545973, Accuracy=0.1232638888888889\n",
      "Epoch 161 validation: Cross-entropy=2.422538995742798, Accuracy=0.07575757801532745\n",
      "Epoch 162 train: Cross-entropy=2.3732025490866766, Accuracy=0.1232638888888889\n",
      "Epoch 162 validation: Cross-entropy=2.4225776195526123, Accuracy=0.07575757801532745\n",
      "Epoch 163 train: Cross-entropy=2.3731152878867254, Accuracy=0.1232638888888889\n",
      "Epoch 163 validation: Cross-entropy=2.4226160049438477, Accuracy=0.07575757801532745\n",
      "Epoch 164 train: Cross-entropy=2.37302835782369, Accuracy=0.1232638888888889\n",
      "Epoch 164 validation: Cross-entropy=2.422654390335083, Accuracy=0.08080808073282242\n",
      "Epoch 165 train: Cross-entropy=2.3729418251249523, Accuracy=0.1232638888888889\n",
      "Epoch 165 validation: Cross-entropy=2.4226927757263184, Accuracy=0.08080808073282242\n",
      "Epoch 166 train: Cross-entropy=2.3728555308447943, Accuracy=0.1232638888888889\n",
      "Epoch 166 validation: Cross-entropy=2.422731399536133, Accuracy=0.08080808073282242\n",
      "Epoch 167 train: Cross-entropy=2.3727693955103555, Accuracy=0.125\n",
      "Epoch 167 validation: Cross-entropy=2.4227702617645264, Accuracy=0.08080808073282242\n",
      "Epoch 168 train: Cross-entropy=2.3726837502585516, Accuracy=0.125\n",
      "Epoch 168 validation: Cross-entropy=2.4228084087371826, Accuracy=0.08080808073282242\n",
      "Epoch 169 train: Cross-entropy=2.3725983699162803, Accuracy=0.125\n",
      "Epoch 169 validation: Cross-entropy=2.422847032546997, Accuracy=0.08080808073282242\n",
      "Epoch 170 train: Cross-entropy=2.372513188256158, Accuracy=0.125\n",
      "Epoch 170 validation: Cross-entropy=2.4228854179382324, Accuracy=0.08080808073282242\n",
      "Epoch 171 train: Cross-entropy=2.372428390714857, Accuracy=0.125\n",
      "Epoch 171 validation: Cross-entropy=2.422924041748047, Accuracy=0.08080808073282242\n",
      "Epoch 172 train: Cross-entropy=2.372343897819519, Accuracy=0.125\n",
      "Epoch 172 validation: Cross-entropy=2.4229626655578613, Accuracy=0.07575757801532745\n",
      "Epoch 173 train: Cross-entropy=2.372259590360853, Accuracy=0.125\n",
      "Epoch 173 validation: Cross-entropy=2.4230010509490967, Accuracy=0.07575757801532745\n",
      "Epoch 174 train: Cross-entropy=2.3721756670210095, Accuracy=0.125\n",
      "Epoch 174 validation: Cross-entropy=2.423039674758911, Accuracy=0.07575757801532745\n",
      "Epoch 175 train: Cross-entropy=2.372092021836175, Accuracy=0.125\n",
      "Epoch 175 validation: Cross-entropy=2.4230782985687256, Accuracy=0.07575757801532745\n",
      "Epoch 176 train: Cross-entropy=2.3720086680518255, Accuracy=0.125\n",
      "Epoch 176 validation: Cross-entropy=2.42311692237854, Accuracy=0.07575757801532745\n",
      "Epoch 177 train: Cross-entropy=2.371925526195102, Accuracy=0.125\n",
      "Epoch 177 validation: Cross-entropy=2.4231553077697754, Accuracy=0.07575757801532745\n",
      "Epoch 178 train: Cross-entropy=2.3718427419662476, Accuracy=0.1232638888888889\n",
      "Epoch 178 validation: Cross-entropy=2.4231936931610107, Accuracy=0.07575757801532745\n",
      "Epoch 179 train: Cross-entropy=2.371760129928589, Accuracy=0.1232638888888889\n",
      "Epoch 179 validation: Cross-entropy=2.423232316970825, Accuracy=0.07575757801532745\n",
      "Epoch 180 train: Cross-entropy=2.371677862273322, Accuracy=0.1232638888888889\n",
      "Epoch 180 validation: Cross-entropy=2.4232707023620605, Accuracy=0.07575757801532745\n",
      "Epoch 181 train: Cross-entropy=2.3715959390004477, Accuracy=0.1232638888888889\n",
      "Epoch 181 validation: Cross-entropy=2.423309326171875, Accuracy=0.07575757801532745\n",
      "Epoch 182 train: Cross-entropy=2.371514254146152, Accuracy=0.125\n",
      "Epoch 182 validation: Cross-entropy=2.4233479499816895, Accuracy=0.07575757801532745\n",
      "Epoch 183 train: Cross-entropy=2.371432794464959, Accuracy=0.125\n",
      "Epoch 183 validation: Cross-entropy=2.423386335372925, Accuracy=0.07575757801532745\n",
      "Epoch 184 train: Cross-entropy=2.3713515864478216, Accuracy=0.125\n",
      "Epoch 184 validation: Cross-entropy=2.42342472076416, Accuracy=0.07575757801532745\n",
      "Epoch 185 train: Cross-entropy=2.3712707890404596, Accuracy=0.125\n",
      "Epoch 185 validation: Cross-entropy=2.4234633445739746, Accuracy=0.07575757801532745\n",
      "Epoch 186 train: Cross-entropy=2.37119013733334, Accuracy=0.125\n",
      "Epoch 186 validation: Cross-entropy=2.42350172996521, Accuracy=0.07575757801532745\n",
      "Epoch 187 train: Cross-entropy=2.3711097770267062, Accuracy=0.125\n",
      "Epoch 187 validation: Cross-entropy=2.4235405921936035, Accuracy=0.07575757801532745\n",
      "Epoch 188 train: Cross-entropy=2.371029747856988, Accuracy=0.125\n",
      "Epoch 188 validation: Cross-entropy=2.4235787391662598, Accuracy=0.07575757801532745\n",
      "Epoch 189 train: Cross-entropy=2.3709499571058483, Accuracy=0.125\n",
      "Epoch 189 validation: Cross-entropy=2.423617362976074, Accuracy=0.07575757801532745\n",
      "Epoch 190 train: Cross-entropy=2.3708704047732883, Accuracy=0.125\n",
      "Epoch 190 validation: Cross-entropy=2.4236557483673096, Accuracy=0.07575757801532745\n",
      "Epoch 191 train: Cross-entropy=2.3707911173502603, Accuracy=0.125\n",
      "Epoch 191 validation: Cross-entropy=2.423694610595703, Accuracy=0.07575757801532745\n",
      "Epoch 192 train: Cross-entropy=2.3707121213277182, Accuracy=0.125\n",
      "Epoch 192 validation: Cross-entropy=2.4237325191497803, Accuracy=0.07575757801532745\n",
      "Epoch 193 train: Cross-entropy=2.370633363723755, Accuracy=0.125\n",
      "Epoch 193 validation: Cross-entropy=2.4237711429595947, Accuracy=0.07575757801532745\n",
      "Epoch 194 train: Cross-entropy=2.3705548445383706, Accuracy=0.125\n",
      "Epoch 194 validation: Cross-entropy=2.42380952835083, Accuracy=0.07575757801532745\n",
      "Epoch 195 train: Cross-entropy=2.370476656489902, Accuracy=0.125\n",
      "Epoch 195 validation: Cross-entropy=2.4238479137420654, Accuracy=0.08080808073282242\n",
      "Epoch 196 train: Cross-entropy=2.3703987730873957, Accuracy=0.125\n",
      "Epoch 196 validation: Cross-entropy=2.423886299133301, Accuracy=0.08080808073282242\n",
      "Epoch 197 train: Cross-entropy=2.370320995648702, Accuracy=0.125\n",
      "Epoch 197 validation: Cross-entropy=2.423924684524536, Accuracy=0.08080808073282242\n",
      "Epoch 198 train: Cross-entropy=2.3702434831195407, Accuracy=0.125\n",
      "Epoch 198 validation: Cross-entropy=2.4239630699157715, Accuracy=0.08080808073282242\n",
      "Epoch 199 train: Cross-entropy=2.3701662487453885, Accuracy=0.125\n",
      "Epoch 199 validation: Cross-entropy=2.424001455307007, Accuracy=0.08080808073282242\n",
      "Epoch 0 train: Cross-entropy=2.436695244577196, Accuracy=0.10416666666666667\n",
      "Epoch 0 validation: Cross-entropy=2.412684917449951, Accuracy=0.10606060922145844\n",
      "Epoch 1 train: Cross-entropy=2.418519457181295, Accuracy=0.10590277777777778\n",
      "Epoch 1 validation: Cross-entropy=2.4058735370635986, Accuracy=0.08585858345031738\n",
      "Epoch 2 train: Cross-entropy=2.407616045739916, Accuracy=0.10416666666666667\n",
      "Epoch 2 validation: Cross-entropy=2.4034740924835205, Accuracy=0.07575757801532745\n",
      "Epoch 3 train: Cross-entropy=2.401547458436754, Accuracy=0.109375\n",
      "Epoch 3 validation: Cross-entropy=2.4031291007995605, Accuracy=0.07070706784725189\n",
      "Epoch 4 train: Cross-entropy=2.3980697658326893, Accuracy=0.10590277777777778\n",
      "Epoch 4 validation: Cross-entropy=2.403660297393799, Accuracy=0.08585858345031738\n",
      "Epoch 5 train: Cross-entropy=2.395999881956312, Accuracy=0.11458333333333333\n",
      "Epoch 5 validation: Cross-entropy=2.404500722885132, Accuracy=0.09595959633588791\n",
      "Epoch 6 train: Cross-entropy=2.3947058651182385, Accuracy=0.10590277777777778\n",
      "Epoch 6 validation: Cross-entropy=2.405385971069336, Accuracy=0.09595959633588791\n",
      "Epoch 7 train: Cross-entropy=2.3938434521357217, Accuracy=0.11284722222222222\n",
      "Epoch 7 validation: Cross-entropy=2.406203269958496, Accuracy=0.08585858345031738\n",
      "Epoch 8 train: Cross-entropy=2.393223351902432, Accuracy=0.11805555555555555\n",
      "Epoch 8 validation: Cross-entropy=2.4069108963012695, Accuracy=0.08585858345031738\n",
      "Epoch 9 train: Cross-entropy=2.392740249633789, Accuracy=0.11805555555555555\n",
      "Epoch 9 validation: Cross-entropy=2.4075043201446533, Accuracy=0.09090909361839294\n",
      "Epoch 10 train: Cross-entropy=2.392335149976942, Accuracy=0.11979166666666667\n",
      "Epoch 10 validation: Cross-entropy=2.4079928398132324, Accuracy=0.09090909361839294\n",
      "Epoch 11 train: Cross-entropy=2.3919752173953586, Accuracy=0.11805555555555555\n",
      "Epoch 11 validation: Cross-entropy=2.408391237258911, Accuracy=0.08585858345031738\n",
      "Epoch 12 train: Cross-entropy=2.3916418287489147, Accuracy=0.11979166666666667\n",
      "Epoch 12 validation: Cross-entropy=2.4087154865264893, Accuracy=0.08585858345031738\n",
      "Epoch 13 train: Cross-entropy=2.391324202219645, Accuracy=0.11979166666666667\n",
      "Epoch 13 validation: Cross-entropy=2.40898060798645, Accuracy=0.08585858345031738\n",
      "Epoch 14 train: Cross-entropy=2.391016721725464, Accuracy=0.11631944444444445\n",
      "Epoch 14 validation: Cross-entropy=2.4091978073120117, Accuracy=0.08585858345031738\n",
      "Epoch 15 train: Cross-entropy=2.390715758005778, Accuracy=0.11805555555555555\n",
      "Epoch 15 validation: Cross-entropy=2.4093782901763916, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 train: Cross-entropy=2.3904194434483848, Accuracy=0.12152777777777778\n",
      "Epoch 16 validation: Cross-entropy=2.409529209136963, Accuracy=0.09595959633588791\n",
      "Epoch 17 train: Cross-entropy=2.390126771397061, Accuracy=0.12152777777777778\n",
      "Epoch 17 validation: Cross-entropy=2.4096579551696777, Accuracy=0.09595959633588791\n",
      "Epoch 18 train: Cross-entropy=2.389837132559882, Accuracy=0.11979166666666667\n",
      "Epoch 18 validation: Cross-entropy=2.409769296646118, Accuracy=0.09595959633588791\n",
      "Epoch 19 train: Cross-entropy=2.389550050099691, Accuracy=0.11979166666666667\n",
      "Epoch 19 validation: Cross-entropy=2.409867763519287, Accuracy=0.09595959633588791\n",
      "Epoch 20 train: Cross-entropy=2.389265537261963, Accuracy=0.1232638888888889\n",
      "Epoch 20 validation: Cross-entropy=2.409956216812134, Accuracy=0.09595959633588791\n",
      "Epoch 21 train: Cross-entropy=2.38898327615526, Accuracy=0.1232638888888889\n",
      "Epoch 21 validation: Cross-entropy=2.410036563873291, Accuracy=0.09595959633588791\n",
      "Epoch 22 train: Cross-entropy=2.388703359497918, Accuracy=0.125\n",
      "Epoch 22 validation: Cross-entropy=2.410111665725708, Accuracy=0.09090909361839294\n",
      "Epoch 23 train: Cross-entropy=2.388425628344218, Accuracy=0.1267361111111111\n",
      "Epoch 23 validation: Cross-entropy=2.410182476043701, Accuracy=0.09090909361839294\n",
      "Epoch 24 train: Cross-entropy=2.3881500959396362, Accuracy=0.1267361111111111\n",
      "Epoch 24 validation: Cross-entropy=2.410250186920166, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.3878767755296497, Accuracy=0.1284722222222222\n",
      "Epoch 25 validation: Cross-entropy=2.4103152751922607, Accuracy=0.09090909361839294\n",
      "Epoch 26 train: Cross-entropy=2.387605653868781, Accuracy=0.1284722222222222\n",
      "Epoch 26 validation: Cross-entropy=2.41037917137146, Accuracy=0.09090909361839294\n",
      "Epoch 27 train: Cross-entropy=2.3873366117477417, Accuracy=0.1267361111111111\n",
      "Epoch 27 validation: Cross-entropy=2.4104421138763428, Accuracy=0.09090909361839294\n",
      "Epoch 28 train: Cross-entropy=2.387069662412008, Accuracy=0.1232638888888889\n",
      "Epoch 28 validation: Cross-entropy=2.41050386428833, Accuracy=0.09090909361839294\n",
      "Epoch 29 train: Cross-entropy=2.3868048985799155, Accuracy=0.1232638888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4105658531188965, Accuracy=0.09090909361839294\n",
      "Epoch 30 train: Cross-entropy=2.3865420950783625, Accuracy=0.1267361111111111\n",
      "Epoch 30 validation: Cross-entropy=2.4106271266937256, Accuracy=0.09090909361839294\n",
      "Epoch 31 train: Cross-entropy=2.386281410853068, Accuracy=0.1267361111111111\n",
      "Epoch 31 validation: Cross-entropy=2.410688877105713, Accuracy=0.09090909361839294\n",
      "Epoch 32 train: Cross-entropy=2.386022792922126, Accuracy=0.125\n",
      "Epoch 32 validation: Cross-entropy=2.410750389099121, Accuracy=0.09090909361839294\n",
      "Epoch 33 train: Cross-entropy=2.3857661220762463, Accuracy=0.1232638888888889\n",
      "Epoch 33 validation: Cross-entropy=2.4108121395111084, Accuracy=0.09595959633588791\n",
      "Epoch 34 train: Cross-entropy=2.385511491033766, Accuracy=0.12152777777777778\n",
      "Epoch 34 validation: Cross-entropy=2.410874605178833, Accuracy=0.09595959633588791\n",
      "Epoch 35 train: Cross-entropy=2.3852588335673013, Accuracy=0.1232638888888889\n",
      "Epoch 35 validation: Cross-entropy=2.4109370708465576, Accuracy=0.09595959633588791\n",
      "Epoch 36 train: Cross-entropy=2.385008136431376, Accuracy=0.12152777777777778\n",
      "Epoch 36 validation: Cross-entropy=2.4110004901885986, Accuracy=0.09090909361839294\n",
      "Epoch 37 train: Cross-entropy=2.384759306907654, Accuracy=0.12152777777777778\n",
      "Epoch 37 validation: Cross-entropy=2.4110641479492188, Accuracy=0.09595959633588791\n",
      "Epoch 38 train: Cross-entropy=2.384512530432807, Accuracy=0.12152777777777778\n",
      "Epoch 38 validation: Cross-entropy=2.411127805709839, Accuracy=0.09595959633588791\n",
      "Epoch 39 train: Cross-entropy=2.384267568588257, Accuracy=0.12152777777777778\n",
      "Epoch 39 validation: Cross-entropy=2.4111926555633545, Accuracy=0.10101009905338287\n",
      "Epoch 40 train: Cross-entropy=2.3840244743559094, Accuracy=0.11979166666666667\n",
      "Epoch 40 validation: Cross-entropy=2.411257266998291, Accuracy=0.10101009905338287\n",
      "Epoch 41 train: Cross-entropy=2.3837832609812417, Accuracy=0.12152777777777778\n",
      "Epoch 41 validation: Cross-entropy=2.411323070526123, Accuracy=0.10101009905338287\n",
      "Epoch 42 train: Cross-entropy=2.3835438092549643, Accuracy=0.1232638888888889\n",
      "Epoch 42 validation: Cross-entropy=2.411388874053955, Accuracy=0.10101009905338287\n",
      "Epoch 43 train: Cross-entropy=2.383306278122796, Accuracy=0.125\n",
      "Epoch 43 validation: Cross-entropy=2.4114553928375244, Accuracy=0.10101009905338287\n",
      "Epoch 44 train: Cross-entropy=2.3830704424116345, Accuracy=0.125\n",
      "Epoch 44 validation: Cross-entropy=2.411522150039673, Accuracy=0.10101009905338287\n",
      "Epoch 45 train: Cross-entropy=2.3828364080852933, Accuracy=0.125\n",
      "Epoch 45 validation: Cross-entropy=2.4115896224975586, Accuracy=0.10101009905338287\n",
      "Epoch 46 train: Cross-entropy=2.382604135407342, Accuracy=0.125\n",
      "Epoch 46 validation: Cross-entropy=2.4116575717926025, Accuracy=0.09595959633588791\n",
      "Epoch 47 train: Cross-entropy=2.382373677359687, Accuracy=0.1284722222222222\n",
      "Epoch 47 validation: Cross-entropy=2.411726236343384, Accuracy=0.09595959633588791\n",
      "Epoch 48 train: Cross-entropy=2.3821448485056558, Accuracy=0.1284722222222222\n",
      "Epoch 48 validation: Cross-entropy=2.411794900894165, Accuracy=0.09090909361839294\n",
      "Epoch 49 train: Cross-entropy=2.3819177680545383, Accuracy=0.1284722222222222\n",
      "Epoch 49 validation: Cross-entropy=2.4118640422821045, Accuracy=0.09090909361839294\n",
      "Epoch 50 train: Cross-entropy=2.3816923565334744, Accuracy=0.13020833333333334\n",
      "Epoch 50 validation: Cross-entropy=2.411933660507202, Accuracy=0.08585858345031738\n",
      "Epoch 51 train: Cross-entropy=2.381468547715081, Accuracy=0.1284722222222222\n",
      "Epoch 51 validation: Cross-entropy=2.412003755569458, Accuracy=0.08585858345031738\n",
      "Epoch 52 train: Cross-entropy=2.381246487299601, Accuracy=0.13194444444444445\n",
      "Epoch 52 validation: Cross-entropy=2.412074327468872, Accuracy=0.08585858345031738\n",
      "Epoch 53 train: Cross-entropy=2.3810260428322687, Accuracy=0.13368055555555555\n",
      "Epoch 53 validation: Cross-entropy=2.4121451377868652, Accuracy=0.08585858345031738\n",
      "Epoch 54 train: Cross-entropy=2.3808070951037936, Accuracy=0.13368055555555555\n",
      "Epoch 54 validation: Cross-entropy=2.4122164249420166, Accuracy=0.08585858345031738\n",
      "Epoch 55 train: Cross-entropy=2.380589895778232, Accuracy=0.13541666666666666\n",
      "Epoch 55 validation: Cross-entropy=2.412288188934326, Accuracy=0.08585858345031738\n",
      "Epoch 56 train: Cross-entropy=2.380374166700575, Accuracy=0.13541666666666666\n",
      "Epoch 56 validation: Cross-entropy=2.412360191345215, Accuracy=0.08585858345031738\n",
      "Epoch 57 train: Cross-entropy=2.380160027080112, Accuracy=0.1371527777777778\n",
      "Epoch 57 validation: Cross-entropy=2.4124326705932617, Accuracy=0.08585858345031738\n",
      "Epoch 58 train: Cross-entropy=2.3799474239349365, Accuracy=0.1371527777777778\n",
      "Epoch 58 validation: Cross-entropy=2.4125053882598877, Accuracy=0.08585858345031738\n",
      "Epoch 59 train: Cross-entropy=2.3797363572650485, Accuracy=0.1388888888888889\n",
      "Epoch 59 validation: Cross-entropy=2.412578582763672, Accuracy=0.08585858345031738\n",
      "Epoch 60 train: Cross-entropy=2.3795268138249717, Accuracy=0.140625\n",
      "Epoch 60 validation: Cross-entropy=2.412652015686035, Accuracy=0.08585858345031738\n",
      "Epoch 61 train: Cross-entropy=2.379318767123752, Accuracy=0.1388888888888889\n",
      "Epoch 61 validation: Cross-entropy=2.4127259254455566, Accuracy=0.08585858345031738\n",
      "Epoch 62 train: Cross-entropy=2.3791122436523438, Accuracy=0.1388888888888889\n",
      "Epoch 62 validation: Cross-entropy=2.412799835205078, Accuracy=0.09090909361839294\n",
      "Epoch 63 train: Cross-entropy=2.378907216919793, Accuracy=0.1388888888888889\n",
      "Epoch 63 validation: Cross-entropy=2.412874460220337, Accuracy=0.09090909361839294\n",
      "Epoch 64 train: Cross-entropy=2.3787035279803805, Accuracy=0.140625\n",
      "Epoch 64 validation: Cross-entropy=2.4129490852355957, Accuracy=0.09090909361839294\n",
      "Epoch 65 train: Cross-entropy=2.3785013092888727, Accuracy=0.140625\n",
      "Epoch 65 validation: Cross-entropy=2.4130241870880127, Accuracy=0.09090909361839294\n",
      "Epoch 66 train: Cross-entropy=2.378300560845269, Accuracy=0.140625\n",
      "Epoch 66 validation: Cross-entropy=2.4130992889404297, Accuracy=0.09090909361839294\n",
      "Epoch 67 train: Cross-entropy=2.3781011634402804, Accuracy=0.1388888888888889\n",
      "Epoch 67 validation: Cross-entropy=2.413175106048584, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 train: Cross-entropy=2.3779032362831964, Accuracy=0.1388888888888889\n",
      "Epoch 68 validation: Cross-entropy=2.4132509231567383, Accuracy=0.09090909361839294\n",
      "Epoch 69 train: Cross-entropy=2.3777065674463906, Accuracy=0.1388888888888889\n",
      "Epoch 69 validation: Cross-entropy=2.413327217102051, Accuracy=0.08585858345031738\n",
      "Epoch 70 train: Cross-entropy=2.377511395348443, Accuracy=0.1388888888888889\n",
      "Epoch 70 validation: Cross-entropy=2.4134035110473633, Accuracy=0.08585858345031738\n",
      "Epoch 71 train: Cross-entropy=2.37731753455268, Accuracy=0.1388888888888889\n",
      "Epoch 71 validation: Cross-entropy=2.413480281829834, Accuracy=0.08585858345031738\n",
      "Epoch 72 train: Cross-entropy=2.377125038041009, Accuracy=0.1388888888888889\n",
      "Epoch 72 validation: Cross-entropy=2.4135570526123047, Accuracy=0.08585858345031738\n",
      "Epoch 73 train: Cross-entropy=2.3769338130950928, Accuracy=0.1371527777777778\n",
      "Epoch 73 validation: Cross-entropy=2.4136340618133545, Accuracy=0.08080808073282242\n",
      "Epoch 74 train: Cross-entropy=2.3767438464694552, Accuracy=0.1371527777777778\n",
      "Epoch 74 validation: Cross-entropy=2.4137113094329834, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.376555323600769, Accuracy=0.1388888888888889\n",
      "Epoch 75 validation: Cross-entropy=2.4137890338897705, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.3763679530885486, Accuracy=0.140625\n",
      "Epoch 76 validation: Cross-entropy=2.4138667583465576, Accuracy=0.08080808073282242\n",
      "Epoch 77 train: Cross-entropy=2.3761819203694663, Accuracy=0.1423611111111111\n",
      "Epoch 77 validation: Cross-entropy=2.413944721221924, Accuracy=0.08080808073282242\n",
      "Epoch 78 train: Cross-entropy=2.375997092988756, Accuracy=0.1440972222222222\n",
      "Epoch 78 validation: Cross-entropy=2.4140231609344482, Accuracy=0.08080808073282242\n",
      "Epoch 79 train: Cross-entropy=2.375813643137614, Accuracy=0.14583333333333334\n",
      "Epoch 79 validation: Cross-entropy=2.4141013622283936, Accuracy=0.08080808073282242\n",
      "Epoch 80 train: Cross-entropy=2.3756313721338906, Accuracy=0.14756944444444445\n",
      "Epoch 80 validation: Cross-entropy=2.414179801940918, Accuracy=0.07575757801532745\n",
      "Epoch 81 train: Cross-entropy=2.37545022699568, Accuracy=0.14756944444444445\n",
      "Epoch 81 validation: Cross-entropy=2.4142589569091797, Accuracy=0.07575757801532745\n",
      "Epoch 82 train: Cross-entropy=2.3752703931596546, Accuracy=0.14756944444444445\n",
      "Epoch 82 validation: Cross-entropy=2.414337396621704, Accuracy=0.07575757801532745\n",
      "Epoch 83 train: Cross-entropy=2.3750917514165244, Accuracy=0.14756944444444445\n",
      "Epoch 83 validation: Cross-entropy=2.414416790008545, Accuracy=0.07575757801532745\n",
      "Epoch 84 train: Cross-entropy=2.3749142752753363, Accuracy=0.14756944444444445\n",
      "Epoch 84 validation: Cross-entropy=2.4144959449768066, Accuracy=0.07575757801532745\n",
      "Epoch 85 train: Cross-entropy=2.374738030963474, Accuracy=0.14930555555555555\n",
      "Epoch 85 validation: Cross-entropy=2.4145753383636475, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.3745628462897406, Accuracy=0.14756944444444445\n",
      "Epoch 86 validation: Cross-entropy=2.4146547317504883, Accuracy=0.07575757801532745\n",
      "Epoch 87 train: Cross-entropy=2.374388893445333, Accuracy=0.14756944444444445\n",
      "Epoch 87 validation: Cross-entropy=2.4147346019744873, Accuracy=0.07575757801532745\n",
      "Epoch 88 train: Cross-entropy=2.374216079711914, Accuracy=0.14756944444444445\n",
      "Epoch 88 validation: Cross-entropy=2.4148142337799072, Accuracy=0.07575757801532745\n",
      "Epoch 89 train: Cross-entropy=2.374044352107578, Accuracy=0.14756944444444445\n",
      "Epoch 89 validation: Cross-entropy=2.4148945808410645, Accuracy=0.07575757801532745\n",
      "Epoch 90 train: Cross-entropy=2.373873816596137, Accuracy=0.14756944444444445\n",
      "Epoch 90 validation: Cross-entropy=2.4149742126464844, Accuracy=0.07575757801532745\n",
      "Epoch 91 train: Cross-entropy=2.3737043274773493, Accuracy=0.14930555555555555\n",
      "Epoch 91 validation: Cross-entropy=2.4150545597076416, Accuracy=0.07575757801532745\n",
      "Epoch 92 train: Cross-entropy=2.3735359642240734, Accuracy=0.14756944444444445\n",
      "Epoch 92 validation: Cross-entropy=2.415135145187378, Accuracy=0.07575757801532745\n",
      "Epoch 93 train: Cross-entropy=2.3733686606089273, Accuracy=0.14930555555555555\n",
      "Epoch 93 validation: Cross-entropy=2.415215492248535, Accuracy=0.07070706784725189\n",
      "Epoch 94 train: Cross-entropy=2.3732024563683405, Accuracy=0.14930555555555555\n",
      "Epoch 94 validation: Cross-entropy=2.4152960777282715, Accuracy=0.07070706784725189\n",
      "Epoch 95 train: Cross-entropy=2.3730373250113592, Accuracy=0.14756944444444445\n",
      "Epoch 95 validation: Cross-entropy=2.415376901626587, Accuracy=0.07070706784725189\n",
      "Epoch 96 train: Cross-entropy=2.3728732532925076, Accuracy=0.14756944444444445\n",
      "Epoch 96 validation: Cross-entropy=2.4154574871063232, Accuracy=0.07070706784725189\n",
      "Epoch 97 train: Cross-entropy=2.372710188229879, Accuracy=0.14756944444444445\n",
      "Epoch 97 validation: Cross-entropy=2.4155383110046387, Accuracy=0.07070706784725189\n",
      "Epoch 98 train: Cross-entropy=2.3725481828053794, Accuracy=0.14756944444444445\n",
      "Epoch 98 validation: Cross-entropy=2.415619134902954, Accuracy=0.07070706784725189\n",
      "Epoch 99 train: Cross-entropy=2.372387237019009, Accuracy=0.14756944444444445\n",
      "Epoch 99 validation: Cross-entropy=2.4157004356384277, Accuracy=0.07070706784725189\n",
      "Epoch 100 train: Cross-entropy=2.3722272978888617, Accuracy=0.14583333333333334\n",
      "Epoch 100 validation: Cross-entropy=2.415781259536743, Accuracy=0.08080808073282242\n",
      "Epoch 101 train: Cross-entropy=2.372068405151367, Accuracy=0.14583333333333334\n",
      "Epoch 101 validation: Cross-entropy=2.4158623218536377, Accuracy=0.08080808073282242\n",
      "Epoch 102 train: Cross-entropy=2.371910426351759, Accuracy=0.14583333333333334\n",
      "Epoch 102 validation: Cross-entropy=2.4159438610076904, Accuracy=0.08080808073282242\n",
      "Epoch 103 train: Cross-entropy=2.371753520435757, Accuracy=0.14583333333333334\n",
      "Epoch 103 validation: Cross-entropy=2.416024923324585, Accuracy=0.08080808073282242\n",
      "Epoch 104 train: Cross-entropy=2.3715976079305015, Accuracy=0.14583333333333334\n",
      "Epoch 104 validation: Cross-entropy=2.4161064624786377, Accuracy=0.08080808073282242\n",
      "Epoch 105 train: Cross-entropy=2.371442543135749, Accuracy=0.14583333333333334\n",
      "Epoch 105 validation: Cross-entropy=2.4161877632141113, Accuracy=0.08080808073282242\n",
      "Epoch 106 train: Cross-entropy=2.3712885114881725, Accuracy=0.14583333333333334\n",
      "Epoch 106 validation: Cross-entropy=2.416269063949585, Accuracy=0.08080808073282242\n",
      "Epoch 107 train: Cross-entropy=2.371135460005866, Accuracy=0.14583333333333334\n",
      "Epoch 107 validation: Cross-entropy=2.416350841522217, Accuracy=0.08080808073282242\n",
      "Epoch 108 train: Cross-entropy=2.3709833092159696, Accuracy=0.14583333333333334\n",
      "Epoch 108 validation: Cross-entropy=2.4164321422576904, Accuracy=0.08080808073282242\n",
      "Epoch 109 train: Cross-entropy=2.3708321121003895, Accuracy=0.1440972222222222\n",
      "Epoch 109 validation: Cross-entropy=2.416513681411743, Accuracy=0.08080808073282242\n",
      "Epoch 110 train: Cross-entropy=2.3706818554136486, Accuracy=0.1440972222222222\n",
      "Epoch 110 validation: Cross-entropy=2.416595458984375, Accuracy=0.08080808073282242\n",
      "Epoch 111 train: Cross-entropy=2.3705325259102716, Accuracy=0.1440972222222222\n",
      "Epoch 111 validation: Cross-entropy=2.4166769981384277, Accuracy=0.08080808073282242\n",
      "Epoch 112 train: Cross-entropy=2.3703840573628745, Accuracy=0.1440972222222222\n",
      "Epoch 112 validation: Cross-entropy=2.4167587757110596, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.3702365027533636, Accuracy=0.1423611111111111\n",
      "Epoch 113 validation: Cross-entropy=2.4168405532836914, Accuracy=0.08080808073282242\n",
      "Epoch 114 train: Cross-entropy=2.370089888572693, Accuracy=0.1423611111111111\n",
      "Epoch 114 validation: Cross-entropy=2.4169223308563232, Accuracy=0.08585858345031738\n",
      "Epoch 115 train: Cross-entropy=2.3699440823660956, Accuracy=0.1423611111111111\n",
      "Epoch 115 validation: Cross-entropy=2.417003870010376, Accuracy=0.08585858345031738\n",
      "Epoch 116 train: Cross-entropy=2.369799256324768, Accuracy=0.1423611111111111\n",
      "Epoch 116 validation: Cross-entropy=2.417085647583008, Accuracy=0.08585858345031738\n",
      "Epoch 117 train: Cross-entropy=2.369655277993944, Accuracy=0.1423611111111111\n",
      "Epoch 117 validation: Cross-entropy=2.4171671867370605, Accuracy=0.08585858345031738\n",
      "Epoch 118 train: Cross-entropy=2.3695120679007635, Accuracy=0.1423611111111111\n",
      "Epoch 118 validation: Cross-entropy=2.4172492027282715, Accuracy=0.08585858345031738\n",
      "Epoch 119 train: Cross-entropy=2.3693698379728527, Accuracy=0.1423611111111111\n",
      "Epoch 119 validation: Cross-entropy=2.4173309803009033, Accuracy=0.08585858345031738\n",
      "Epoch 120 train: Cross-entropy=2.369228402773539, Accuracy=0.1423611111111111\n",
      "Epoch 120 validation: Cross-entropy=2.417412757873535, Accuracy=0.09090909361839294\n",
      "Epoch 121 train: Cross-entropy=2.369087709320916, Accuracy=0.1423611111111111\n",
      "Epoch 121 validation: Cross-entropy=2.417494297027588, Accuracy=0.09090909361839294\n",
      "Epoch 122 train: Cross-entropy=2.3689479960335627, Accuracy=0.1440972222222222\n",
      "Epoch 122 validation: Cross-entropy=2.4175760746002197, Accuracy=0.09090909361839294\n",
      "Epoch 123 train: Cross-entropy=2.368809011247423, Accuracy=0.1423611111111111\n",
      "Epoch 123 validation: Cross-entropy=2.4176578521728516, Accuracy=0.09090909361839294\n",
      "Epoch 124 train: Cross-entropy=2.3686709139082165, Accuracy=0.140625\n",
      "Epoch 124 validation: Cross-entropy=2.4177396297454834, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 train: Cross-entropy=2.3685335980521307, Accuracy=0.140625\n",
      "Epoch 125 validation: Cross-entropy=2.4178214073181152, Accuracy=0.08585858345031738\n",
      "Epoch 126 train: Cross-entropy=2.3683970901701183, Accuracy=0.140625\n",
      "Epoch 126 validation: Cross-entropy=2.417902946472168, Accuracy=0.08585858345031738\n",
      "Epoch 127 train: Cross-entropy=2.36826135052575, Accuracy=0.1423611111111111\n",
      "Epoch 127 validation: Cross-entropy=2.4179847240448, Accuracy=0.08585858345031738\n",
      "Epoch 128 train: Cross-entropy=2.3681264056099787, Accuracy=0.1423611111111111\n",
      "Epoch 128 validation: Cross-entropy=2.4180662631988525, Accuracy=0.08585858345031738\n",
      "Epoch 129 train: Cross-entropy=2.367992295159234, Accuracy=0.1423611111111111\n",
      "Epoch 129 validation: Cross-entropy=2.4181478023529053, Accuracy=0.08585858345031738\n",
      "Epoch 130 train: Cross-entropy=2.3678589264551797, Accuracy=0.1423611111111111\n",
      "Epoch 130 validation: Cross-entropy=2.418229579925537, Accuracy=0.08585858345031738\n",
      "Epoch 131 train: Cross-entropy=2.3677263392342462, Accuracy=0.1423611111111111\n",
      "Epoch 131 validation: Cross-entropy=2.41831111907959, Accuracy=0.08080808073282242\n",
      "Epoch 132 train: Cross-entropy=2.36759442753262, Accuracy=0.1423611111111111\n",
      "Epoch 132 validation: Cross-entropy=2.4183926582336426, Accuracy=0.08080808073282242\n",
      "Epoch 133 train: Cross-entropy=2.367463323805067, Accuracy=0.140625\n",
      "Epoch 133 validation: Cross-entropy=2.4184741973876953, Accuracy=0.08080808073282242\n",
      "Epoch 134 train: Cross-entropy=2.3673329750696817, Accuracy=0.1388888888888889\n",
      "Epoch 134 validation: Cross-entropy=2.418555736541748, Accuracy=0.08080808073282242\n",
      "Epoch 135 train: Cross-entropy=2.367203368080987, Accuracy=0.1388888888888889\n",
      "Epoch 135 validation: Cross-entropy=2.4186367988586426, Accuracy=0.08585858345031738\n",
      "Epoch 136 train: Cross-entropy=2.3670745160844593, Accuracy=0.1388888888888889\n",
      "Epoch 136 validation: Cross-entropy=2.418717861175537, Accuracy=0.08585858345031738\n",
      "Epoch 137 train: Cross-entropy=2.3669464190800986, Accuracy=0.1388888888888889\n",
      "Epoch 137 validation: Cross-entropy=2.41879940032959, Accuracy=0.08585858345031738\n",
      "Epoch 138 train: Cross-entropy=2.3668190240859985, Accuracy=0.1388888888888889\n",
      "Epoch 138 validation: Cross-entropy=2.4188804626464844, Accuracy=0.08585858345031738\n",
      "Epoch 139 train: Cross-entropy=2.366692304611206, Accuracy=0.1388888888888889\n",
      "Epoch 139 validation: Cross-entropy=2.418962001800537, Accuracy=0.08585858345031738\n",
      "Epoch 140 train: Cross-entropy=2.366566300392151, Accuracy=0.1388888888888889\n",
      "Epoch 140 validation: Cross-entropy=2.4190430641174316, Accuracy=0.08585858345031738\n",
      "Epoch 141 train: Cross-entropy=2.3664409716924033, Accuracy=0.140625\n",
      "Epoch 141 validation: Cross-entropy=2.419124126434326, Accuracy=0.08585858345031738\n",
      "Epoch 142 train: Cross-entropy=2.3663164244757757, Accuracy=0.140625\n",
      "Epoch 142 validation: Cross-entropy=2.4192051887512207, Accuracy=0.08585858345031738\n",
      "Epoch 143 train: Cross-entropy=2.3661925660239325, Accuracy=0.140625\n",
      "Epoch 143 validation: Cross-entropy=2.419285535812378, Accuracy=0.08585858345031738\n",
      "Epoch 144 train: Cross-entropy=2.3660693566004434, Accuracy=0.1388888888888889\n",
      "Epoch 144 validation: Cross-entropy=2.4193665981292725, Accuracy=0.08585858345031738\n",
      "Epoch 145 train: Cross-entropy=2.365946796205309, Accuracy=0.1388888888888889\n",
      "Epoch 145 validation: Cross-entropy=2.419447660446167, Accuracy=0.08585858345031738\n",
      "Epoch 146 train: Cross-entropy=2.365824964311388, Accuracy=0.1388888888888889\n",
      "Epoch 146 validation: Cross-entropy=2.4195284843444824, Accuracy=0.08585858345031738\n",
      "Epoch 147 train: Cross-entropy=2.3657037814458213, Accuracy=0.1388888888888889\n",
      "Epoch 147 validation: Cross-entropy=2.4196090698242188, Accuracy=0.08080808073282242\n",
      "Epoch 148 train: Cross-entropy=2.3655832608540854, Accuracy=0.1388888888888889\n",
      "Epoch 148 validation: Cross-entropy=2.419689655303955, Accuracy=0.08080808073282242\n",
      "Epoch 149 train: Cross-entropy=2.3654634157816568, Accuracy=0.1388888888888889\n",
      "Epoch 149 validation: Cross-entropy=2.4197700023651123, Accuracy=0.08080808073282242\n",
      "Epoch 150 train: Cross-entropy=2.365344206492106, Accuracy=0.1388888888888889\n",
      "Epoch 150 validation: Cross-entropy=2.4198505878448486, Accuracy=0.08080808073282242\n",
      "Epoch 151 train: Cross-entropy=2.3652256197399564, Accuracy=0.140625\n",
      "Epoch 151 validation: Cross-entropy=2.419930934906006, Accuracy=0.08080808073282242\n",
      "Epoch 152 train: Cross-entropy=2.3651077217525907, Accuracy=0.140625\n",
      "Epoch 152 validation: Cross-entropy=2.420011043548584, Accuracy=0.08080808073282242\n",
      "Epoch 153 train: Cross-entropy=2.3649904330571494, Accuracy=0.140625\n",
      "Epoch 153 validation: Cross-entropy=2.420091390609741, Accuracy=0.08080808073282242\n",
      "Epoch 154 train: Cross-entropy=2.3648738198810153, Accuracy=0.140625\n",
      "Epoch 154 validation: Cross-entropy=2.4201714992523193, Accuracy=0.08080808073282242\n",
      "Epoch 155 train: Cross-entropy=2.3647578159968057, Accuracy=0.140625\n",
      "Epoch 155 validation: Cross-entropy=2.4202513694763184, Accuracy=0.08080808073282242\n",
      "Epoch 156 train: Cross-entropy=2.3646423551771374, Accuracy=0.1388888888888889\n",
      "Epoch 156 validation: Cross-entropy=2.4203314781188965, Accuracy=0.08080808073282242\n",
      "Epoch 157 train: Cross-entropy=2.3645275698767767, Accuracy=0.140625\n",
      "Epoch 157 validation: Cross-entropy=2.4204113483428955, Accuracy=0.08080808073282242\n",
      "Epoch 158 train: Cross-entropy=2.364413446850247, Accuracy=0.140625\n",
      "Epoch 158 validation: Cross-entropy=2.4204909801483154, Accuracy=0.08585858345031738\n",
      "Epoch 159 train: Cross-entropy=2.3642998536427817, Accuracy=0.140625\n",
      "Epoch 159 validation: Cross-entropy=2.4205706119537354, Accuracy=0.08585858345031738\n",
      "Epoch 160 train: Cross-entropy=2.3641868829727173, Accuracy=0.140625\n",
      "Epoch 160 validation: Cross-entropy=2.4206502437591553, Accuracy=0.08585858345031738\n",
      "Epoch 161 train: Cross-entropy=2.3640744951036243, Accuracy=0.140625\n",
      "Epoch 161 validation: Cross-entropy=2.420729398727417, Accuracy=0.08585858345031738\n",
      "Epoch 162 train: Cross-entropy=2.3639627032809787, Accuracy=0.140625\n",
      "Epoch 162 validation: Cross-entropy=2.420808792114258, Accuracy=0.08585858345031738\n",
      "Epoch 163 train: Cross-entropy=2.3638515075047812, Accuracy=0.140625\n",
      "Epoch 163 validation: Cross-entropy=2.4208884239196777, Accuracy=0.08585858345031738\n",
      "Epoch 164 train: Cross-entropy=2.3637408547931247, Accuracy=0.140625\n",
      "Epoch 164 validation: Cross-entropy=2.4209673404693604, Accuracy=0.08585858345031738\n",
      "Epoch 165 train: Cross-entropy=2.363630864355299, Accuracy=0.140625\n",
      "Epoch 165 validation: Cross-entropy=2.421046495437622, Accuracy=0.08080808073282242\n",
      "Epoch 166 train: Cross-entropy=2.363521377245585, Accuracy=0.140625\n",
      "Epoch 166 validation: Cross-entropy=2.4211254119873047, Accuracy=0.08080808073282242\n",
      "Epoch 167 train: Cross-entropy=2.363412446445889, Accuracy=0.140625\n",
      "Epoch 167 validation: Cross-entropy=2.4212043285369873, Accuracy=0.08080808073282242\n",
      "Epoch 168 train: Cross-entropy=2.363304204410977, Accuracy=0.140625\n",
      "Epoch 168 validation: Cross-entropy=2.42128324508667, Accuracy=0.08080808073282242\n",
      "Epoch 169 train: Cross-entropy=2.3631963862313166, Accuracy=0.140625\n",
      "Epoch 169 validation: Cross-entropy=2.4213616847991943, Accuracy=0.08080808073282242\n",
      "Epoch 170 train: Cross-entropy=2.363089164098104, Accuracy=0.140625\n",
      "Epoch 170 validation: Cross-entropy=2.421440362930298, Accuracy=0.08585858345031738\n",
      "Epoch 171 train: Cross-entropy=2.3629824188020496, Accuracy=0.140625\n",
      "Epoch 171 validation: Cross-entropy=2.4215190410614014, Accuracy=0.08585858345031738\n",
      "Epoch 172 train: Cross-entropy=2.362876296043396, Accuracy=0.140625\n",
      "Epoch 172 validation: Cross-entropy=2.4215970039367676, Accuracy=0.08585858345031738\n",
      "Epoch 173 train: Cross-entropy=2.362770756085714, Accuracy=0.140625\n",
      "Epoch 173 validation: Cross-entropy=2.421675205230713, Accuracy=0.08585858345031738\n",
      "Epoch 174 train: Cross-entropy=2.362665706210666, Accuracy=0.1423611111111111\n",
      "Epoch 174 validation: Cross-entropy=2.421753168106079, Accuracy=0.08585858345031738\n",
      "Epoch 175 train: Cross-entropy=2.362561172909207, Accuracy=0.1440972222222222\n",
      "Epoch 175 validation: Cross-entropy=2.4218313694000244, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.362457169426812, Accuracy=0.14583333333333334\n",
      "Epoch 176 validation: Cross-entropy=2.4219090938568115, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.3623537752363415, Accuracy=0.14583333333333334\n",
      "Epoch 177 validation: Cross-entropy=2.4219868183135986, Accuracy=0.09090909361839294\n",
      "Epoch 178 train: Cross-entropy=2.362250804901123, Accuracy=0.14583333333333334\n",
      "Epoch 178 validation: Cross-entropy=2.4220645427703857, Accuracy=0.09090909361839294\n",
      "Epoch 179 train: Cross-entropy=2.3621483511394925, Accuracy=0.1440972222222222\n",
      "Epoch 179 validation: Cross-entropy=2.4221420288085938, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180 train: Cross-entropy=2.362046480178833, Accuracy=0.1440972222222222\n",
      "Epoch 180 validation: Cross-entropy=2.4222190380096436, Accuracy=0.09090909361839294\n",
      "Epoch 181 train: Cross-entropy=2.361945046318902, Accuracy=0.1440972222222222\n",
      "Epoch 181 validation: Cross-entropy=2.4222965240478516, Accuracy=0.09090909361839294\n",
      "Epoch 182 train: Cross-entropy=2.3618440760506525, Accuracy=0.1423611111111111\n",
      "Epoch 182 validation: Cross-entropy=2.4223737716674805, Accuracy=0.09090909361839294\n",
      "Epoch 183 train: Cross-entropy=2.3617437018288507, Accuracy=0.1440972222222222\n",
      "Epoch 183 validation: Cross-entropy=2.4224507808685303, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.361643764707777, Accuracy=0.1440972222222222\n",
      "Epoch 184 validation: Cross-entropy=2.42252779006958, Accuracy=0.08585858345031738\n",
      "Epoch 185 train: Cross-entropy=2.3615444236331515, Accuracy=0.1440972222222222\n",
      "Epoch 185 validation: Cross-entropy=2.422604560852051, Accuracy=0.08585858345031738\n",
      "Epoch 186 train: Cross-entropy=2.3614454534318714, Accuracy=0.1440972222222222\n",
      "Epoch 186 validation: Cross-entropy=2.4226810932159424, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.3613470792770386, Accuracy=0.1423611111111111\n",
      "Epoch 187 validation: Cross-entropy=2.422757625579834, Accuracy=0.08585858345031738\n",
      "Epoch 188 train: Cross-entropy=2.3612490362591214, Accuracy=0.1423611111111111\n",
      "Epoch 188 validation: Cross-entropy=2.4228339195251465, Accuracy=0.08585858345031738\n",
      "Epoch 189 train: Cross-entropy=2.3611516025331287, Accuracy=0.1423611111111111\n",
      "Epoch 189 validation: Cross-entropy=2.422910213470459, Accuracy=0.08585858345031738\n",
      "Epoch 190 train: Cross-entropy=2.3610545794169107, Accuracy=0.1423611111111111\n",
      "Epoch 190 validation: Cross-entropy=2.4229862689971924, Accuracy=0.08585858345031738\n",
      "Epoch 191 train: Cross-entropy=2.360958046383328, Accuracy=0.1423611111111111\n",
      "Epoch 191 validation: Cross-entropy=2.423062324523926, Accuracy=0.08585858345031738\n",
      "Epoch 192 train: Cross-entropy=2.360861990186903, Accuracy=0.1423611111111111\n",
      "Epoch 192 validation: Cross-entropy=2.42313814163208, Accuracy=0.08585858345031738\n",
      "Epoch 193 train: Cross-entropy=2.3607663578457303, Accuracy=0.1423611111111111\n",
      "Epoch 193 validation: Cross-entropy=2.4232137203216553, Accuracy=0.08585858345031738\n",
      "Epoch 194 train: Cross-entropy=2.360671189096239, Accuracy=0.1423611111111111\n",
      "Epoch 194 validation: Cross-entropy=2.4232895374298096, Accuracy=0.08585858345031738\n",
      "Epoch 195 train: Cross-entropy=2.3605764706929526, Accuracy=0.1423611111111111\n",
      "Epoch 195 validation: Cross-entropy=2.4233651161193848, Accuracy=0.08585858345031738\n",
      "Epoch 196 train: Cross-entropy=2.3604822953542075, Accuracy=0.1423611111111111\n",
      "Epoch 196 validation: Cross-entropy=2.4234402179718018, Accuracy=0.08585858345031738\n",
      "Epoch 197 train: Cross-entropy=2.3603884908888073, Accuracy=0.1423611111111111\n",
      "Epoch 197 validation: Cross-entropy=2.4235153198242188, Accuracy=0.08585858345031738\n",
      "Epoch 198 train: Cross-entropy=2.360295136769613, Accuracy=0.1423611111111111\n",
      "Epoch 198 validation: Cross-entropy=2.4235904216766357, Accuracy=0.09090909361839294\n",
      "Epoch 199 train: Cross-entropy=2.3602022197511463, Accuracy=0.1423611111111111\n",
      "Epoch 199 validation: Cross-entropy=2.4236655235290527, Accuracy=0.09090909361839294\n",
      "Epoch 0 train: Cross-entropy=2.4521879620022244, Accuracy=0.09027777777777778\n",
      "Epoch 0 validation: Cross-entropy=2.4239156246185303, Accuracy=0.08080808073282242\n",
      "Epoch 1 train: Cross-entropy=2.4132964081234403, Accuracy=0.09895833333333333\n",
      "Epoch 1 validation: Cross-entropy=2.40910005569458, Accuracy=0.10101009905338287\n",
      "Epoch 2 train: Cross-entropy=2.4004127184549966, Accuracy=0.10069444444444445\n",
      "Epoch 2 validation: Cross-entropy=2.4071290493011475, Accuracy=0.10101009905338287\n",
      "Epoch 3 train: Cross-entropy=2.396395140224033, Accuracy=0.10416666666666667\n",
      "Epoch 3 validation: Cross-entropy=2.407742500305176, Accuracy=0.08585858345031738\n",
      "Epoch 4 train: Cross-entropy=2.3948320282830133, Accuracy=0.0954861111111111\n",
      "Epoch 4 validation: Cross-entropy=2.408620595932007, Accuracy=0.08585858345031738\n",
      "Epoch 5 train: Cross-entropy=2.393965893321567, Accuracy=0.10590277777777778\n",
      "Epoch 5 validation: Cross-entropy=2.409317970275879, Accuracy=0.09090909361839294\n",
      "Epoch 6 train: Cross-entropy=2.3933019240697226, Accuracy=0.10590277777777778\n",
      "Epoch 6 validation: Cross-entropy=2.4098165035247803, Accuracy=0.09595959633588791\n",
      "Epoch 7 train: Cross-entropy=2.3927002218034534, Accuracy=0.11284722222222222\n",
      "Epoch 7 validation: Cross-entropy=2.4101738929748535, Accuracy=0.09595959633588791\n",
      "Epoch 8 train: Cross-entropy=2.392121341493395, Accuracy=0.11805555555555555\n",
      "Epoch 8 validation: Cross-entropy=2.4104411602020264, Accuracy=0.09595959633588791\n",
      "Epoch 9 train: Cross-entropy=2.3915541966756186, Accuracy=0.11458333333333333\n",
      "Epoch 9 validation: Cross-entropy=2.410654306411743, Accuracy=0.09595959633588791\n",
      "Epoch 10 train: Cross-entropy=2.39099567466312, Accuracy=0.11284722222222222\n",
      "Epoch 10 validation: Cross-entropy=2.410836935043335, Accuracy=0.09595959633588791\n",
      "Epoch 11 train: Cross-entropy=2.390444689326816, Accuracy=0.11631944444444445\n",
      "Epoch 11 validation: Cross-entropy=2.411001682281494, Accuracy=0.09595959633588791\n",
      "Epoch 12 train: Cross-entropy=2.389901041984558, Accuracy=0.11458333333333333\n",
      "Epoch 12 validation: Cross-entropy=2.4111568927764893, Accuracy=0.09595959633588791\n",
      "Epoch 13 train: Cross-entropy=2.38936440149943, Accuracy=0.11631944444444445\n",
      "Epoch 13 validation: Cross-entropy=2.4113073348999023, Accuracy=0.09090909361839294\n",
      "Epoch 14 train: Cross-entropy=2.388834794362386, Accuracy=0.11284722222222222\n",
      "Epoch 14 validation: Cross-entropy=2.4114558696746826, Accuracy=0.09090909361839294\n",
      "Epoch 15 train: Cross-entropy=2.388311915927463, Accuracy=0.11284722222222222\n",
      "Epoch 15 validation: Cross-entropy=2.411604166030884, Accuracy=0.09090909361839294\n",
      "Epoch 16 train: Cross-entropy=2.387795739703708, Accuracy=0.11284722222222222\n",
      "Epoch 16 validation: Cross-entropy=2.411752939224243, Accuracy=0.09090909361839294\n",
      "Epoch 17 train: Cross-entropy=2.3872860934999256, Accuracy=0.11458333333333333\n",
      "Epoch 17 validation: Cross-entropy=2.411902904510498, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.386782897843255, Accuracy=0.11458333333333333\n",
      "Epoch 18 validation: Cross-entropy=2.4120543003082275, Accuracy=0.09595959633588791\n",
      "Epoch 19 train: Cross-entropy=2.386285980542501, Accuracy=0.11631944444444445\n",
      "Epoch 19 validation: Cross-entropy=2.4122071266174316, Accuracy=0.10101009905338287\n",
      "Epoch 20 train: Cross-entropy=2.3857954343159995, Accuracy=0.11631944444444445\n",
      "Epoch 20 validation: Cross-entropy=2.4123611450195312, Accuracy=0.10101009905338287\n",
      "Epoch 21 train: Cross-entropy=2.385310822063022, Accuracy=0.11805555555555555\n",
      "Epoch 21 validation: Cross-entropy=2.4125173091888428, Accuracy=0.10606060922145844\n",
      "Epoch 22 train: Cross-entropy=2.384832249747382, Accuracy=0.11284722222222222\n",
      "Epoch 22 validation: Cross-entropy=2.41267466545105, Accuracy=0.1111111119389534\n",
      "Epoch 23 train: Cross-entropy=2.38435951868693, Accuracy=0.11805555555555555\n",
      "Epoch 23 validation: Cross-entropy=2.4128334522247314, Accuracy=0.1111111119389534\n",
      "Epoch 24 train: Cross-entropy=2.3838926951090493, Accuracy=0.11805555555555555\n",
      "Epoch 24 validation: Cross-entropy=2.412993907928467, Accuracy=0.1111111119389534\n",
      "Epoch 25 train: Cross-entropy=2.383431461122301, Accuracy=0.11805555555555555\n",
      "Epoch 25 validation: Cross-entropy=2.4131555557250977, Accuracy=0.1111111119389534\n",
      "Epoch 26 train: Cross-entropy=2.3829758167266846, Accuracy=0.11631944444444445\n",
      "Epoch 26 validation: Cross-entropy=2.413318634033203, Accuracy=0.1111111119389534\n",
      "Epoch 27 train: Cross-entropy=2.3825257619222007, Accuracy=0.11979166666666667\n",
      "Epoch 27 validation: Cross-entropy=2.413483142852783, Accuracy=0.10606060922145844\n",
      "Epoch 28 train: Cross-entropy=2.382081084781223, Accuracy=0.1232638888888889\n",
      "Epoch 28 validation: Cross-entropy=2.413648843765259, Accuracy=0.10606060922145844\n",
      "Epoch 29 train: Cross-entropy=2.3816416263580322, Accuracy=0.125\n",
      "Epoch 29 validation: Cross-entropy=2.413815498352051, Accuracy=0.10606060922145844\n",
      "Epoch 30 train: Cross-entropy=2.3812074926164417, Accuracy=0.1267361111111111\n",
      "Epoch 30 validation: Cross-entropy=2.4139833450317383, Accuracy=0.10606060922145844\n",
      "Epoch 31 train: Cross-entropy=2.380778524610731, Accuracy=0.1284722222222222\n",
      "Epoch 31 validation: Cross-entropy=2.414152145385742, Accuracy=0.10606060922145844\n",
      "Epoch 32 train: Cross-entropy=2.380354497167799, Accuracy=0.13020833333333334\n",
      "Epoch 32 validation: Cross-entropy=2.4143226146698, Accuracy=0.10606060922145844\n",
      "Epoch 33 train: Cross-entropy=2.3799355030059814, Accuracy=0.13541666666666666\n",
      "Epoch 33 validation: Cross-entropy=2.4144935607910156, Accuracy=0.10606060922145844\n",
      "Epoch 34 train: Cross-entropy=2.3795214096705117, Accuracy=0.13368055555555555\n",
      "Epoch 34 validation: Cross-entropy=2.414665460586548, Accuracy=0.10606060922145844\n",
      "Epoch 35 train: Cross-entropy=2.379112058215671, Accuracy=0.13194444444444445\n",
      "Epoch 35 validation: Cross-entropy=2.4148383140563965, Accuracy=0.1111111119389534\n",
      "Epoch 36 train: Cross-entropy=2.3787074751324124, Accuracy=0.13368055555555555\n",
      "Epoch 36 validation: Cross-entropy=2.4150118827819824, Accuracy=0.1111111119389534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 train: Cross-entropy=2.3783075279659696, Accuracy=0.13194444444444445\n",
      "Epoch 37 validation: Cross-entropy=2.415186643600464, Accuracy=0.1111111119389534\n",
      "Epoch 38 train: Cross-entropy=2.3779121372434826, Accuracy=0.13194444444444445\n",
      "Epoch 38 validation: Cross-entropy=2.4153616428375244, Accuracy=0.1111111119389534\n",
      "Epoch 39 train: Cross-entropy=2.3775213294559054, Accuracy=0.13194444444444445\n",
      "Epoch 39 validation: Cross-entropy=2.4155378341674805, Accuracy=0.1111111119389534\n",
      "Epoch 40 train: Cross-entropy=2.377134839693705, Accuracy=0.13194444444444445\n",
      "Epoch 40 validation: Cross-entropy=2.4157145023345947, Accuracy=0.1111111119389534\n",
      "Epoch 41 train: Cross-entropy=2.3767527209387884, Accuracy=0.13194444444444445\n",
      "Epoch 41 validation: Cross-entropy=2.415891408920288, Accuracy=0.1111111119389534\n",
      "Epoch 42 train: Cross-entropy=2.3763749069637723, Accuracy=0.1284722222222222\n",
      "Epoch 42 validation: Cross-entropy=2.416069507598877, Accuracy=0.10606060922145844\n",
      "Epoch 43 train: Cross-entropy=2.3760012785593667, Accuracy=0.1284722222222222\n",
      "Epoch 43 validation: Cross-entropy=2.416248083114624, Accuracy=0.10606060922145844\n",
      "Epoch 44 train: Cross-entropy=2.3756317694981894, Accuracy=0.1284722222222222\n",
      "Epoch 44 validation: Cross-entropy=2.4164271354675293, Accuracy=0.10101009905338287\n",
      "Epoch 45 train: Cross-entropy=2.3752664592530994, Accuracy=0.1284722222222222\n",
      "Epoch 45 validation: Cross-entropy=2.4166066646575928, Accuracy=0.10101009905338287\n",
      "Epoch 46 train: Cross-entropy=2.374905096160041, Accuracy=0.13368055555555555\n",
      "Epoch 46 validation: Cross-entropy=2.4167866706848145, Accuracy=0.10101009905338287\n",
      "Epoch 47 train: Cross-entropy=2.374547759691874, Accuracy=0.13541666666666666\n",
      "Epoch 47 validation: Cross-entropy=2.416966676712036, Accuracy=0.10101009905338287\n",
      "Epoch 48 train: Cross-entropy=2.3741941452026367, Accuracy=0.13541666666666666\n",
      "Epoch 48 validation: Cross-entropy=2.417147636413574, Accuracy=0.09595959633588791\n",
      "Epoch 49 train: Cross-entropy=2.3738444911109076, Accuracy=0.13541666666666666\n",
      "Epoch 49 validation: Cross-entropy=2.4173288345336914, Accuracy=0.09595959633588791\n",
      "Epoch 50 train: Cross-entropy=2.3734985325071545, Accuracy=0.13194444444444445\n",
      "Epoch 50 validation: Cross-entropy=2.4175102710723877, Accuracy=0.10101009905338287\n",
      "Epoch 51 train: Cross-entropy=2.3731563488642373, Accuracy=0.13541666666666666\n",
      "Epoch 51 validation: Cross-entropy=2.417692184448242, Accuracy=0.10101009905338287\n",
      "Epoch 52 train: Cross-entropy=2.37281780772739, Accuracy=0.13368055555555555\n",
      "Epoch 52 validation: Cross-entropy=2.4178740978240967, Accuracy=0.10101009905338287\n",
      "Epoch 53 train: Cross-entropy=2.3724828826056585, Accuracy=0.13020833333333334\n",
      "Epoch 53 validation: Cross-entropy=2.4180564880371094, Accuracy=0.10101009905338287\n",
      "Epoch 54 train: Cross-entropy=2.3721513748168945, Accuracy=0.13194444444444445\n",
      "Epoch 54 validation: Cross-entropy=2.418239116668701, Accuracy=0.10101009905338287\n",
      "Epoch 55 train: Cross-entropy=2.371823443306817, Accuracy=0.13194444444444445\n",
      "Epoch 55 validation: Cross-entropy=2.418421983718872, Accuracy=0.10101009905338287\n",
      "Epoch 56 train: Cross-entropy=2.371498982111613, Accuracy=0.13541666666666666\n",
      "Epoch 56 validation: Cross-entropy=2.418604850769043, Accuracy=0.10101009905338287\n",
      "Epoch 57 train: Cross-entropy=2.3711778587765164, Accuracy=0.1371527777777778\n",
      "Epoch 57 validation: Cross-entropy=2.418787717819214, Accuracy=0.10101009905338287\n",
      "Epoch 58 train: Cross-entropy=2.370860046810574, Accuracy=0.13541666666666666\n",
      "Epoch 58 validation: Cross-entropy=2.418971300125122, Accuracy=0.10101009905338287\n",
      "Epoch 59 train: Cross-entropy=2.370545599195692, Accuracy=0.13541666666666666\n",
      "Epoch 59 validation: Cross-entropy=2.419154167175293, Accuracy=0.10101009905338287\n",
      "Epoch 60 train: Cross-entropy=2.3702342907587686, Accuracy=0.13020833333333334\n",
      "Epoch 60 validation: Cross-entropy=2.419337749481201, Accuracy=0.10101009905338287\n",
      "Epoch 61 train: Cross-entropy=2.369926187727186, Accuracy=0.1284722222222222\n",
      "Epoch 61 validation: Cross-entropy=2.4195210933685303, Accuracy=0.09595959633588791\n",
      "Epoch 62 train: Cross-entropy=2.3696212106280856, Accuracy=0.13020833333333334\n",
      "Epoch 62 validation: Cross-entropy=2.4197046756744385, Accuracy=0.09595959633588791\n",
      "Epoch 63 train: Cross-entropy=2.36931930647956, Accuracy=0.13020833333333334\n",
      "Epoch 63 validation: Cross-entropy=2.4198880195617676, Accuracy=0.09595959633588791\n",
      "Epoch 64 train: Cross-entropy=2.369020462036133, Accuracy=0.13194444444444445\n",
      "Epoch 64 validation: Cross-entropy=2.420071601867676, Accuracy=0.09595959633588791\n",
      "Epoch 65 train: Cross-entropy=2.368724650806851, Accuracy=0.13368055555555555\n",
      "Epoch 65 validation: Cross-entropy=2.420255184173584, Accuracy=0.09595959633588791\n",
      "Epoch 66 train: Cross-entropy=2.368431740336948, Accuracy=0.13368055555555555\n",
      "Epoch 66 validation: Cross-entropy=2.420438528060913, Accuracy=0.09595959633588791\n",
      "Epoch 67 train: Cross-entropy=2.3681417968538074, Accuracy=0.13368055555555555\n",
      "Epoch 67 validation: Cross-entropy=2.420621871948242, Accuracy=0.09595959633588791\n",
      "Epoch 68 train: Cross-entropy=2.367854701148139, Accuracy=0.13541666666666666\n",
      "Epoch 68 validation: Cross-entropy=2.420804977416992, Accuracy=0.09595959633588791\n",
      "Epoch 69 train: Cross-entropy=2.3675703472561307, Accuracy=0.1371527777777778\n",
      "Epoch 69 validation: Cross-entropy=2.4209883213043213, Accuracy=0.09595959633588791\n",
      "Epoch 70 train: Cross-entropy=2.3672888808780246, Accuracy=0.1371527777777778\n",
      "Epoch 70 validation: Cross-entropy=2.4211714267730713, Accuracy=0.10101009905338287\n",
      "Epoch 71 train: Cross-entropy=2.3670101165771484, Accuracy=0.1388888888888889\n",
      "Epoch 71 validation: Cross-entropy=2.421354293823242, Accuracy=0.10101009905338287\n",
      "Epoch 72 train: Cross-entropy=2.3667340808444552, Accuracy=0.140625\n",
      "Epoch 72 validation: Cross-entropy=2.421536922454834, Accuracy=0.10101009905338287\n",
      "Epoch 73 train: Cross-entropy=2.3664606942070856, Accuracy=0.140625\n",
      "Epoch 73 validation: Cross-entropy=2.421719551086426, Accuracy=0.10101009905338287\n",
      "Epoch 74 train: Cross-entropy=2.366189890437656, Accuracy=0.1423611111111111\n",
      "Epoch 74 validation: Cross-entropy=2.4219021797180176, Accuracy=0.10101009905338287\n",
      "Epoch 75 train: Cross-entropy=2.36592169602712, Accuracy=0.1423611111111111\n",
      "Epoch 75 validation: Cross-entropy=2.422084331512451, Accuracy=0.10101009905338287\n",
      "Epoch 76 train: Cross-entropy=2.365656031502618, Accuracy=0.1423611111111111\n",
      "Epoch 76 validation: Cross-entropy=2.4222664833068848, Accuracy=0.10101009905338287\n",
      "Epoch 77 train: Cross-entropy=2.3653930160734387, Accuracy=0.1423611111111111\n",
      "Epoch 77 validation: Cross-entropy=2.42244815826416, Accuracy=0.10101009905338287\n",
      "Epoch 78 train: Cross-entropy=2.3651323318481445, Accuracy=0.1440972222222222\n",
      "Epoch 78 validation: Cross-entropy=2.4226295948028564, Accuracy=0.10101009905338287\n",
      "Epoch 79 train: Cross-entropy=2.364874084790548, Accuracy=0.1440972222222222\n",
      "Epoch 79 validation: Cross-entropy=2.4228107929229736, Accuracy=0.10101009905338287\n",
      "Epoch 80 train: Cross-entropy=2.364618354373508, Accuracy=0.14583333333333334\n",
      "Epoch 80 validation: Cross-entropy=2.42299222946167, Accuracy=0.10101009905338287\n",
      "Epoch 81 train: Cross-entropy=2.364364994896783, Accuracy=0.14583333333333334\n",
      "Epoch 81 validation: Cross-entropy=2.42317271232605, Accuracy=0.10101009905338287\n",
      "Epoch 82 train: Cross-entropy=2.364113966623942, Accuracy=0.14930555555555555\n",
      "Epoch 82 validation: Cross-entropy=2.4233531951904297, Accuracy=0.10101009905338287\n",
      "Epoch 83 train: Cross-entropy=2.363865190082126, Accuracy=0.14930555555555555\n",
      "Epoch 83 validation: Cross-entropy=2.4235336780548096, Accuracy=0.10101009905338287\n",
      "Epoch 84 train: Cross-entropy=2.363618744744195, Accuracy=0.15104166666666666\n",
      "Epoch 84 validation: Cross-entropy=2.423713207244873, Accuracy=0.10101009905338287\n",
      "Epoch 85 train: Cross-entropy=2.363374524646335, Accuracy=0.15104166666666666\n",
      "Epoch 85 validation: Cross-entropy=2.4238929748535156, Accuracy=0.09595959633588791\n",
      "Epoch 86 train: Cross-entropy=2.3631325165430703, Accuracy=0.14930555555555555\n",
      "Epoch 86 validation: Cross-entropy=2.424072027206421, Accuracy=0.09595959633588791\n",
      "Epoch 87 train: Cross-entropy=2.3628927601708307, Accuracy=0.14930555555555555\n",
      "Epoch 87 validation: Cross-entropy=2.424250841140747, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 train: Cross-entropy=2.362655176056756, Accuracy=0.14930555555555555\n",
      "Epoch 88 validation: Cross-entropy=2.4244296550750732, Accuracy=0.09595959633588791\n",
      "Epoch 89 train: Cross-entropy=2.3624196582370334, Accuracy=0.14930555555555555\n",
      "Epoch 89 validation: Cross-entropy=2.424607515335083, Accuracy=0.09595959633588791\n",
      "Epoch 90 train: Cross-entropy=2.3621861934661865, Accuracy=0.14930555555555555\n",
      "Epoch 90 validation: Cross-entropy=2.424785614013672, Accuracy=0.09090909361839294\n",
      "Epoch 91 train: Cross-entropy=2.3619548744625516, Accuracy=0.14930555555555555\n",
      "Epoch 91 validation: Cross-entropy=2.4249627590179443, Accuracy=0.10101009905338287\n",
      "Epoch 92 train: Cross-entropy=2.3617255687713623, Accuracy=0.14756944444444445\n",
      "Epoch 92 validation: Cross-entropy=2.425140142440796, Accuracy=0.10101009905338287\n",
      "Epoch 93 train: Cross-entropy=2.361498342620002, Accuracy=0.14930555555555555\n",
      "Epoch 93 validation: Cross-entropy=2.42531681060791, Accuracy=0.10101009905338287\n",
      "Epoch 94 train: Cross-entropy=2.361273037062751, Accuracy=0.14930555555555555\n",
      "Epoch 94 validation: Cross-entropy=2.425492763519287, Accuracy=0.1111111119389534\n",
      "Epoch 95 train: Cross-entropy=2.361049758063422, Accuracy=0.14930555555555555\n",
      "Epoch 95 validation: Cross-entropy=2.425668716430664, Accuracy=0.1111111119389534\n",
      "Epoch 96 train: Cross-entropy=2.3608283731672497, Accuracy=0.15104166666666666\n",
      "Epoch 96 validation: Cross-entropy=2.425844192504883, Accuracy=0.1111111119389534\n",
      "Epoch 97 train: Cross-entropy=2.3606088956197104, Accuracy=0.15104166666666666\n",
      "Epoch 97 validation: Cross-entropy=2.4260191917419434, Accuracy=0.1111111119389534\n",
      "Epoch 98 train: Cross-entropy=2.36039129892985, Accuracy=0.15104166666666666\n",
      "Epoch 98 validation: Cross-entropy=2.4261934757232666, Accuracy=0.1111111119389534\n",
      "Epoch 99 train: Cross-entropy=2.3601756360795765, Accuracy=0.15104166666666666\n",
      "Epoch 99 validation: Cross-entropy=2.42636775970459, Accuracy=0.1111111119389534\n",
      "Epoch 100 train: Cross-entropy=2.3599617216322155, Accuracy=0.1527777777777778\n",
      "Epoch 100 validation: Cross-entropy=2.426541328430176, Accuracy=0.1111111119389534\n",
      "Epoch 101 train: Cross-entropy=2.359749674797058, Accuracy=0.1527777777777778\n",
      "Epoch 101 validation: Cross-entropy=2.4267146587371826, Accuracy=0.1111111119389534\n",
      "Epoch 102 train: Cross-entropy=2.3595394028557672, Accuracy=0.1527777777777778\n",
      "Epoch 102 validation: Cross-entropy=2.426887273788452, Accuracy=0.1111111119389534\n",
      "Epoch 103 train: Cross-entropy=2.3593309190538196, Accuracy=0.1527777777777778\n",
      "Epoch 103 validation: Cross-entropy=2.4270598888397217, Accuracy=0.10606060922145844\n",
      "Epoch 104 train: Cross-entropy=2.359124183654785, Accuracy=0.1527777777777778\n",
      "Epoch 104 validation: Cross-entropy=2.427231550216675, Accuracy=0.10606060922145844\n",
      "Epoch 105 train: Cross-entropy=2.3589191834131875, Accuracy=0.1545138888888889\n",
      "Epoch 105 validation: Cross-entropy=2.4274027347564697, Accuracy=0.10606060922145844\n",
      "Epoch 106 train: Cross-entropy=2.358715878592597, Accuracy=0.15625\n",
      "Epoch 106 validation: Cross-entropy=2.4275736808776855, Accuracy=0.10606060922145844\n",
      "Epoch 107 train: Cross-entropy=2.3585142294565835, Accuracy=0.15625\n",
      "Epoch 107 validation: Cross-entropy=2.427743911743164, Accuracy=0.10606060922145844\n",
      "Epoch 108 train: Cross-entropy=2.358314288987054, Accuracy=0.15625\n",
      "Epoch 108 validation: Cross-entropy=2.4279139041900635, Accuracy=0.10606060922145844\n",
      "Epoch 109 train: Cross-entropy=2.358115937974718, Accuracy=0.15625\n",
      "Epoch 109 validation: Cross-entropy=2.4280834197998047, Accuracy=0.10606060922145844\n",
      "Epoch 110 train: Cross-entropy=2.3579192426469593, Accuracy=0.1545138888888889\n",
      "Epoch 110 validation: Cross-entropy=2.4282522201538086, Accuracy=0.10606060922145844\n",
      "Epoch 111 train: Cross-entropy=2.357724083794488, Accuracy=0.15625\n",
      "Epoch 111 validation: Cross-entropy=2.4284207820892334, Accuracy=0.10606060922145844\n",
      "Epoch 112 train: Cross-entropy=2.3575305806265936, Accuracy=0.1579861111111111\n",
      "Epoch 112 validation: Cross-entropy=2.4285888671875, Accuracy=0.10606060922145844\n",
      "Epoch 113 train: Cross-entropy=2.35733864042494, Accuracy=0.1579861111111111\n",
      "Epoch 113 validation: Cross-entropy=2.42875599861145, Accuracy=0.10606060922145844\n",
      "Epoch 114 train: Cross-entropy=2.357148210207621, Accuracy=0.1579861111111111\n",
      "Epoch 114 validation: Cross-entropy=2.428922653198242, Accuracy=0.10606060922145844\n",
      "Epoch 115 train: Cross-entropy=2.3569593297110663, Accuracy=0.1545138888888889\n",
      "Epoch 115 validation: Cross-entropy=2.4290895462036133, Accuracy=0.10606060922145844\n",
      "Epoch 116 train: Cross-entropy=2.356771853235033, Accuracy=0.1545138888888889\n",
      "Epoch 116 validation: Cross-entropy=2.429255247116089, Accuracy=0.10606060922145844\n",
      "Epoch 117 train: Cross-entropy=2.3565859529707165, Accuracy=0.1545138888888889\n",
      "Epoch 117 validation: Cross-entropy=2.4294204711914062, Accuracy=0.10606060922145844\n",
      "Epoch 118 train: Cross-entropy=2.356401522954305, Accuracy=0.1545138888888889\n",
      "Epoch 118 validation: Cross-entropy=2.4295854568481445, Accuracy=0.10606060922145844\n",
      "Epoch 119 train: Cross-entropy=2.356218523449368, Accuracy=0.1545138888888889\n",
      "Epoch 119 validation: Cross-entropy=2.4297497272491455, Accuracy=0.10606060922145844\n",
      "Epoch 120 train: Cross-entropy=2.3560368882285223, Accuracy=0.1527777777777778\n",
      "Epoch 120 validation: Cross-entropy=2.429913282394409, Accuracy=0.10606060922145844\n",
      "Epoch 121 train: Cross-entropy=2.3558567100101047, Accuracy=0.1527777777777778\n",
      "Epoch 121 validation: Cross-entropy=2.4300765991210938, Accuracy=0.10606060922145844\n",
      "Epoch 122 train: Cross-entropy=2.355678015285068, Accuracy=0.1527777777777778\n",
      "Epoch 122 validation: Cross-entropy=2.430239200592041, Accuracy=0.10606060922145844\n",
      "Epoch 123 train: Cross-entropy=2.3555006053712635, Accuracy=0.1527777777777778\n",
      "Epoch 123 validation: Cross-entropy=2.43040132522583, Accuracy=0.10606060922145844\n",
      "Epoch 124 train: Cross-entropy=2.35532463921441, Accuracy=0.1527777777777778\n",
      "Epoch 124 validation: Cross-entropy=2.43056321144104, Accuracy=0.10606060922145844\n",
      "Epoch 125 train: Cross-entropy=2.355149918132358, Accuracy=0.1527777777777778\n",
      "Epoch 125 validation: Cross-entropy=2.4307239055633545, Accuracy=0.10606060922145844\n",
      "Epoch 126 train: Cross-entropy=2.3549766143163047, Accuracy=0.1527777777777778\n",
      "Epoch 126 validation: Cross-entropy=2.43088436126709, Accuracy=0.10606060922145844\n",
      "Epoch 127 train: Cross-entropy=2.354804582066006, Accuracy=0.1527777777777778\n",
      "Epoch 127 validation: Cross-entropy=2.431044340133667, Accuracy=0.10606060922145844\n",
      "Epoch 128 train: Cross-entropy=2.3546338611178927, Accuracy=0.1527777777777778\n",
      "Epoch 128 validation: Cross-entropy=2.431203842163086, Accuracy=0.10606060922145844\n",
      "Epoch 129 train: Cross-entropy=2.3544644514719644, Accuracy=0.15104166666666666\n",
      "Epoch 129 validation: Cross-entropy=2.4313626289367676, Accuracy=0.10606060922145844\n",
      "Epoch 130 train: Cross-entropy=2.354296233918932, Accuracy=0.15104166666666666\n",
      "Epoch 130 validation: Cross-entropy=2.431520938873291, Accuracy=0.10606060922145844\n",
      "Epoch 131 train: Cross-entropy=2.3541294071409435, Accuracy=0.14930555555555555\n",
      "Epoch 131 validation: Cross-entropy=2.4316790103912354, Accuracy=0.10606060922145844\n",
      "Epoch 132 train: Cross-entropy=2.3539637327194214, Accuracy=0.14930555555555555\n",
      "Epoch 132 validation: Cross-entropy=2.431835889816284, Accuracy=0.10606060922145844\n",
      "Epoch 133 train: Cross-entropy=2.353799303372701, Accuracy=0.14930555555555555\n",
      "Epoch 133 validation: Cross-entropy=2.431992769241333, Accuracy=0.10606060922145844\n",
      "Epoch 134 train: Cross-entropy=2.3536360926098294, Accuracy=0.14930555555555555\n",
      "Epoch 134 validation: Cross-entropy=2.4321484565734863, Accuracy=0.10606060922145844\n",
      "Epoch 135 train: Cross-entropy=2.3534740342034235, Accuracy=0.14930555555555555\n",
      "Epoch 135 validation: Cross-entropy=2.4323039054870605, Accuracy=0.10606060922145844\n",
      "Epoch 136 train: Cross-entropy=2.353313273853726, Accuracy=0.14930555555555555\n",
      "Epoch 136 validation: Cross-entropy=2.4324591159820557, Accuracy=0.10606060922145844\n",
      "Epoch 137 train: Cross-entropy=2.3531536393695407, Accuracy=0.14930555555555555\n",
      "Epoch 137 validation: Cross-entropy=2.4326133728027344, Accuracy=0.10606060922145844\n",
      "Epoch 138 train: Cross-entropy=2.352995170487298, Accuracy=0.14930555555555555\n",
      "Epoch 138 validation: Cross-entropy=2.432767152786255, Accuracy=0.10606060922145844\n",
      "Epoch 139 train: Cross-entropy=2.3528377877341375, Accuracy=0.14930555555555555\n",
      "Epoch 139 validation: Cross-entropy=2.432920455932617, Accuracy=0.10606060922145844\n",
      "Epoch 140 train: Cross-entropy=2.3526815705829196, Accuracy=0.14756944444444445\n",
      "Epoch 140 validation: Cross-entropy=2.4330732822418213, Accuracy=0.10606060922145844\n",
      "Epoch 141 train: Cross-entropy=2.352526585261027, Accuracy=0.14930555555555555\n",
      "Epoch 141 validation: Cross-entropy=2.433225393295288, Accuracy=0.10606060922145844\n",
      "Epoch 142 train: Cross-entropy=2.3523725668589273, Accuracy=0.15104166666666666\n",
      "Epoch 142 validation: Cross-entropy=2.4333770275115967, Accuracy=0.10606060922145844\n",
      "Epoch 143 train: Cross-entropy=2.3522197008132935, Accuracy=0.1527777777777778\n",
      "Epoch 143 validation: Cross-entropy=2.433527708053589, Accuracy=0.10606060922145844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 train: Cross-entropy=2.352067920896742, Accuracy=0.1527777777777778\n",
      "Epoch 144 validation: Cross-entropy=2.43367862701416, Accuracy=0.10606060922145844\n",
      "Epoch 145 train: Cross-entropy=2.3519172271092734, Accuracy=0.1545138888888889\n",
      "Epoch 145 validation: Cross-entropy=2.433828592300415, Accuracy=0.10606060922145844\n",
      "Epoch 146 train: Cross-entropy=2.3517675399780273, Accuracy=0.1545138888888889\n",
      "Epoch 146 validation: Cross-entropy=2.4339776039123535, Accuracy=0.10101009905338287\n",
      "Epoch 147 train: Cross-entropy=2.3516189787122936, Accuracy=0.1545138888888889\n",
      "Epoch 147 validation: Cross-entropy=2.434126377105713, Accuracy=0.10101009905338287\n",
      "Epoch 148 train: Cross-entropy=2.35147143734826, Accuracy=0.1545138888888889\n",
      "Epoch 148 validation: Cross-entropy=2.434274435043335, Accuracy=0.09595959633588791\n",
      "Epoch 149 train: Cross-entropy=2.351324889394972, Accuracy=0.1545138888888889\n",
      "Epoch 149 validation: Cross-entropy=2.434422254562378, Accuracy=0.09595959633588791\n",
      "Epoch 150 train: Cross-entropy=2.3511793745888605, Accuracy=0.1545138888888889\n",
      "Epoch 150 validation: Cross-entropy=2.4345691204071045, Accuracy=0.09595959633588791\n",
      "Epoch 151 train: Cross-entropy=2.3510348796844482, Accuracy=0.1545138888888889\n",
      "Epoch 151 validation: Cross-entropy=2.434715747833252, Accuracy=0.09595959633588791\n",
      "Epoch 152 train: Cross-entropy=2.350891351699829, Accuracy=0.1527777777777778\n",
      "Epoch 152 validation: Cross-entropy=2.434861660003662, Accuracy=0.09595959633588791\n",
      "Epoch 153 train: Cross-entropy=2.350748856862386, Accuracy=0.1527777777777778\n",
      "Epoch 153 validation: Cross-entropy=2.435007095336914, Accuracy=0.09595959633588791\n",
      "Epoch 154 train: Cross-entropy=2.3506073554356894, Accuracy=0.1527777777777778\n",
      "Epoch 154 validation: Cross-entropy=2.435152053833008, Accuracy=0.09595959633588791\n",
      "Epoch 155 train: Cross-entropy=2.3504667149649725, Accuracy=0.1527777777777778\n",
      "Epoch 155 validation: Cross-entropy=2.435296058654785, Accuracy=0.09595959633588791\n",
      "Epoch 156 train: Cross-entropy=2.350327147377862, Accuracy=0.1527777777777778\n",
      "Epoch 156 validation: Cross-entropy=2.4354398250579834, Accuracy=0.09595959633588791\n",
      "Epoch 157 train: Cross-entropy=2.350188453992208, Accuracy=0.1527777777777778\n",
      "Epoch 157 validation: Cross-entropy=2.4355828762054443, Accuracy=0.09595959633588791\n",
      "Epoch 158 train: Cross-entropy=2.3500507540173, Accuracy=0.1527777777777778\n",
      "Epoch 158 validation: Cross-entropy=2.435725688934326, Accuracy=0.09595959633588791\n",
      "Epoch 159 train: Cross-entropy=2.3499139149983725, Accuracy=0.1527777777777778\n",
      "Epoch 159 validation: Cross-entropy=2.4358675479888916, Accuracy=0.09595959633588791\n",
      "Epoch 160 train: Cross-entropy=2.3497779766718545, Accuracy=0.1527777777777778\n",
      "Epoch 160 validation: Cross-entropy=2.436009168624878, Accuracy=0.09595959633588791\n",
      "Epoch 161 train: Cross-entropy=2.349643031756083, Accuracy=0.1527777777777778\n",
      "Epoch 161 validation: Cross-entropy=2.436150074005127, Accuracy=0.09595959633588791\n",
      "Epoch 162 train: Cross-entropy=2.3495089213053384, Accuracy=0.1527777777777778\n",
      "Epoch 162 validation: Cross-entropy=2.4362902641296387, Accuracy=0.09595959633588791\n",
      "Epoch 163 train: Cross-entropy=2.3493756585650973, Accuracy=0.1527777777777778\n",
      "Epoch 163 validation: Cross-entropy=2.436429977416992, Accuracy=0.09595959633588791\n",
      "Epoch 164 train: Cross-entropy=2.349243309762743, Accuracy=0.1527777777777778\n",
      "Epoch 164 validation: Cross-entropy=2.4365689754486084, Accuracy=0.09595959633588791\n",
      "Epoch 165 train: Cross-entropy=2.349111888143751, Accuracy=0.1527777777777778\n",
      "Epoch 165 validation: Cross-entropy=2.4367079734802246, Accuracy=0.09595959633588791\n",
      "Epoch 166 train: Cross-entropy=2.3489812877443104, Accuracy=0.1545138888888889\n",
      "Epoch 166 validation: Cross-entropy=2.4368457794189453, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.348851548300849, Accuracy=0.1527777777777778\n",
      "Epoch 167 validation: Cross-entropy=2.436983585357666, Accuracy=0.09595959633588791\n",
      "Epoch 168 train: Cross-entropy=2.3487226565678916, Accuracy=0.1545138888888889\n",
      "Epoch 168 validation: Cross-entropy=2.4371204376220703, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.3485945198271008, Accuracy=0.1545138888888889\n",
      "Epoch 169 validation: Cross-entropy=2.4372572898864746, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.34846732351515, Accuracy=0.1545138888888889\n",
      "Epoch 170 validation: Cross-entropy=2.4373929500579834, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.3483408557044134, Accuracy=0.1545138888888889\n",
      "Epoch 171 validation: Cross-entropy=2.437528371810913, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.34821527534061, Accuracy=0.1545138888888889\n",
      "Epoch 172 validation: Cross-entropy=2.4376633167266846, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.348090489705404, Accuracy=0.1527777777777778\n",
      "Epoch 173 validation: Cross-entropy=2.4377975463867188, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.3479664590623646, Accuracy=0.1527777777777778\n",
      "Epoch 174 validation: Cross-entropy=2.4379312992095947, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.347843196656969, Accuracy=0.1527777777777778\n",
      "Epoch 175 validation: Cross-entropy=2.4380643367767334, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.347720834943983, Accuracy=0.15104166666666666\n",
      "Epoch 176 validation: Cross-entropy=2.438196897506714, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.347599148750305, Accuracy=0.15104166666666666\n",
      "Epoch 177 validation: Cross-entropy=2.438328981399536, Accuracy=0.09090909361839294\n",
      "Epoch 178 train: Cross-entropy=2.3474781778123646, Accuracy=0.15104166666666666\n",
      "Epoch 178 validation: Cross-entropy=2.4384605884552, Accuracy=0.09090909361839294\n",
      "Epoch 179 train: Cross-entropy=2.347358054584927, Accuracy=0.15104166666666666\n",
      "Epoch 179 validation: Cross-entropy=2.438591718673706, Accuracy=0.09090909361839294\n",
      "Epoch 180 train: Cross-entropy=2.347238606876797, Accuracy=0.15104166666666666\n",
      "Epoch 180 validation: Cross-entropy=2.4387218952178955, Accuracy=0.09090909361839294\n",
      "Epoch 181 train: Cross-entropy=2.347119993633694, Accuracy=0.15104166666666666\n",
      "Epoch 181 validation: Cross-entropy=2.438852071762085, Accuracy=0.09090909361839294\n",
      "Epoch 182 train: Cross-entropy=2.3470020956463284, Accuracy=0.15104166666666666\n",
      "Epoch 182 validation: Cross-entropy=2.438981533050537, Accuracy=0.09090909361839294\n",
      "Epoch 183 train: Cross-entropy=2.3468848599327936, Accuracy=0.15104166666666666\n",
      "Epoch 183 validation: Cross-entropy=2.439110279083252, Accuracy=0.09090909361839294\n",
      "Epoch 184 train: Cross-entropy=2.3467683924569025, Accuracy=0.1527777777777778\n",
      "Epoch 184 validation: Cross-entropy=2.4392383098602295, Accuracy=0.09090909361839294\n",
      "Epoch 185 train: Cross-entropy=2.3466526534822254, Accuracy=0.1527777777777778\n",
      "Epoch 185 validation: Cross-entropy=2.439366579055786, Accuracy=0.09090909361839294\n",
      "Epoch 186 train: Cross-entropy=2.346537616517809, Accuracy=0.1545138888888889\n",
      "Epoch 186 validation: Cross-entropy=2.4394936561584473, Accuracy=0.09090909361839294\n",
      "Epoch 187 train: Cross-entropy=2.3464232683181763, Accuracy=0.1545138888888889\n",
      "Epoch 187 validation: Cross-entropy=2.43962025642395, Accuracy=0.09090909361839294\n",
      "Epoch 188 train: Cross-entropy=2.346309635374281, Accuracy=0.1545138888888889\n",
      "Epoch 188 validation: Cross-entropy=2.439746618270874, Accuracy=0.09090909361839294\n",
      "Epoch 189 train: Cross-entropy=2.3461966514587402, Accuracy=0.1545138888888889\n",
      "Epoch 189 validation: Cross-entropy=2.4398722648620605, Accuracy=0.09090909361839294\n",
      "Epoch 190 train: Cross-entropy=2.34608440928989, Accuracy=0.1545138888888889\n",
      "Epoch 190 validation: Cross-entropy=2.439997434616089, Accuracy=0.09090909361839294\n",
      "Epoch 191 train: Cross-entropy=2.3459727896584406, Accuracy=0.1545138888888889\n",
      "Epoch 191 validation: Cross-entropy=2.440122127532959, Accuracy=0.09090909361839294\n",
      "Epoch 192 train: Cross-entropy=2.345861872037252, Accuracy=0.1545138888888889\n",
      "Epoch 192 validation: Cross-entropy=2.440246343612671, Accuracy=0.09090909361839294\n",
      "Epoch 193 train: Cross-entropy=2.3457516034444175, Accuracy=0.15625\n",
      "Epoch 193 validation: Cross-entropy=2.4403698444366455, Accuracy=0.09090909361839294\n",
      "Epoch 194 train: Cross-entropy=2.34564201037089, Accuracy=0.15625\n",
      "Epoch 194 validation: Cross-entropy=2.440492868423462, Accuracy=0.09090909361839294\n",
      "Epoch 195 train: Cross-entropy=2.3455329868528576, Accuracy=0.15625\n",
      "Epoch 195 validation: Cross-entropy=2.440615653991699, Accuracy=0.09090909361839294\n",
      "Epoch 196 train: Cross-entropy=2.3454247315724692, Accuracy=0.1579861111111111\n",
      "Epoch 196 validation: Cross-entropy=2.440737724304199, Accuracy=0.09090909361839294\n",
      "Epoch 197 train: Cross-entropy=2.3453170193566217, Accuracy=0.1579861111111111\n",
      "Epoch 197 validation: Cross-entropy=2.440859079360962, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198 train: Cross-entropy=2.3452100223965116, Accuracy=0.1579861111111111\n",
      "Epoch 198 validation: Cross-entropy=2.4409801959991455, Accuracy=0.09090909361839294\n",
      "Epoch 199 train: Cross-entropy=2.3451036082373724, Accuracy=0.1579861111111111\n",
      "Epoch 199 validation: Cross-entropy=2.441100835800171, Accuracy=0.09090909361839294\n",
      "Epoch 0 train: Cross-entropy=2.409717043240865, Accuracy=0.08506944444444445\n",
      "Epoch 0 validation: Cross-entropy=2.413153648376465, Accuracy=0.06565656512975693\n",
      "Epoch 1 train: Cross-entropy=2.4012542168299356, Accuracy=0.08159722222222222\n",
      "Epoch 1 validation: Cross-entropy=2.4132823944091797, Accuracy=0.07070706784725189\n",
      "Epoch 2 train: Cross-entropy=2.3996342023213706, Accuracy=0.08854166666666667\n",
      "Epoch 2 validation: Cross-entropy=2.413649559020996, Accuracy=0.07070706784725189\n",
      "Epoch 3 train: Cross-entropy=2.3980449967914157, Accuracy=0.0954861111111111\n",
      "Epoch 3 validation: Cross-entropy=2.413792610168457, Accuracy=0.07070706784725189\n",
      "Epoch 4 train: Cross-entropy=2.396496680047777, Accuracy=0.0954861111111111\n",
      "Epoch 4 validation: Cross-entropy=2.413923740386963, Accuracy=0.08080808073282242\n",
      "Epoch 5 train: Cross-entropy=2.3950208028157554, Accuracy=0.10243055555555555\n",
      "Epoch 5 validation: Cross-entropy=2.4140801429748535, Accuracy=0.08080808073282242\n",
      "Epoch 6 train: Cross-entropy=2.393611788749695, Accuracy=0.10590277777777778\n",
      "Epoch 6 validation: Cross-entropy=2.414257287979126, Accuracy=0.08585858345031738\n",
      "Epoch 7 train: Cross-entropy=2.392264644304911, Accuracy=0.109375\n",
      "Epoch 7 validation: Cross-entropy=2.4144513607025146, Accuracy=0.07575757801532745\n",
      "Epoch 8 train: Cross-entropy=2.3909755680296154, Accuracy=0.11284722222222222\n",
      "Epoch 8 validation: Cross-entropy=2.4146604537963867, Accuracy=0.07575757801532745\n",
      "Epoch 9 train: Cross-entropy=2.3897407584720187, Accuracy=0.11458333333333333\n",
      "Epoch 9 validation: Cross-entropy=2.4148831367492676, Accuracy=0.08080808073282242\n",
      "Epoch 10 train: Cross-entropy=2.388557023472256, Accuracy=0.11805555555555555\n",
      "Epoch 10 validation: Cross-entropy=2.4151177406311035, Accuracy=0.08080808073282242\n",
      "Epoch 11 train: Cross-entropy=2.3874212900797525, Accuracy=0.11805555555555555\n",
      "Epoch 11 validation: Cross-entropy=2.415363073348999, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.386330670780606, Accuracy=0.1267361111111111\n",
      "Epoch 12 validation: Cross-entropy=2.4156174659729004, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.3852825429704456, Accuracy=0.1284722222222222\n",
      "Epoch 13 validation: Cross-entropy=2.415879726409912, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.384274535708957, Accuracy=0.13020833333333334\n",
      "Epoch 14 validation: Cross-entropy=2.416149616241455, Accuracy=0.07575757801532745\n",
      "Epoch 15 train: Cross-entropy=2.3833042648103504, Accuracy=0.13194444444444445\n",
      "Epoch 15 validation: Cross-entropy=2.4164257049560547, Accuracy=0.08080808073282242\n",
      "Epoch 16 train: Cross-entropy=2.382369730207655, Accuracy=0.13020833333333334\n",
      "Epoch 16 validation: Cross-entropy=2.4167070388793945, Accuracy=0.08080808073282242\n",
      "Epoch 17 train: Cross-entropy=2.3814689848158093, Accuracy=0.1284722222222222\n",
      "Epoch 17 validation: Cross-entropy=2.4169929027557373, Accuracy=0.08080808073282242\n",
      "Epoch 18 train: Cross-entropy=2.380600174268087, Accuracy=0.13194444444444445\n",
      "Epoch 18 validation: Cross-entropy=2.417282819747925, Accuracy=0.08080808073282242\n",
      "Epoch 19 train: Cross-entropy=2.3797615898980036, Accuracy=0.13368055555555555\n",
      "Epoch 19 validation: Cross-entropy=2.4175758361816406, Accuracy=0.08080808073282242\n",
      "Epoch 20 train: Cross-entropy=2.378951655493842, Accuracy=0.13194444444444445\n",
      "Epoch 20 validation: Cross-entropy=2.4178712368011475, Accuracy=0.08080808073282242\n",
      "Epoch 21 train: Cross-entropy=2.378168953789605, Accuracy=0.13368055555555555\n",
      "Epoch 21 validation: Cross-entropy=2.4181694984436035, Accuracy=0.08080808073282242\n",
      "Epoch 22 train: Cross-entropy=2.377412133746677, Accuracy=0.13020833333333334\n",
      "Epoch 22 validation: Cross-entropy=2.418468952178955, Accuracy=0.08080808073282242\n",
      "Epoch 23 train: Cross-entropy=2.3766798310809665, Accuracy=0.1284722222222222\n",
      "Epoch 23 validation: Cross-entropy=2.4187698364257812, Accuracy=0.07575757801532745\n",
      "Epoch 24 train: Cross-entropy=2.3759709199269614, Accuracy=0.13020833333333334\n",
      "Epoch 24 validation: Cross-entropy=2.419071674346924, Accuracy=0.08585858345031738\n",
      "Epoch 25 train: Cross-entropy=2.3752841684553356, Accuracy=0.13541666666666666\n",
      "Epoch 25 validation: Cross-entropy=2.4193739891052246, Accuracy=0.08585858345031738\n",
      "Epoch 26 train: Cross-entropy=2.3746186229917736, Accuracy=0.1371527777777778\n",
      "Epoch 26 validation: Cross-entropy=2.4196765422821045, Accuracy=0.08080808073282242\n",
      "Epoch 27 train: Cross-entropy=2.373973263634576, Accuracy=0.140625\n",
      "Epoch 27 validation: Cross-entropy=2.4199790954589844, Accuracy=0.08080808073282242\n",
      "Epoch 28 train: Cross-entropy=2.373347030745612, Accuracy=0.140625\n",
      "Epoch 28 validation: Cross-entropy=2.420281171798706, Accuracy=0.08080808073282242\n",
      "Epoch 29 train: Cross-entropy=2.3727391958236694, Accuracy=0.140625\n",
      "Epoch 29 validation: Cross-entropy=2.4205825328826904, Accuracy=0.07575757801532745\n",
      "Epoch 30 train: Cross-entropy=2.3721488979127674, Accuracy=0.1423611111111111\n",
      "Epoch 30 validation: Cross-entropy=2.4208836555480957, Accuracy=0.07575757801532745\n",
      "Epoch 31 train: Cross-entropy=2.371575461493598, Accuracy=0.140625\n",
      "Epoch 31 validation: Cross-entropy=2.4211833477020264, Accuracy=0.08080808073282242\n",
      "Epoch 32 train: Cross-entropy=2.3710180388556585, Accuracy=0.1388888888888889\n",
      "Epoch 32 validation: Cross-entropy=2.4214818477630615, Accuracy=0.08080808073282242\n",
      "Epoch 33 train: Cross-entropy=2.370475822024875, Accuracy=0.14583333333333334\n",
      "Epoch 33 validation: Cross-entropy=2.4217793941497803, Accuracy=0.08080808073282242\n",
      "Epoch 34 train: Cross-entropy=2.369948387145996, Accuracy=0.1423611111111111\n",
      "Epoch 34 validation: Cross-entropy=2.4220752716064453, Accuracy=0.08080808073282242\n",
      "Epoch 35 train: Cross-entropy=2.369435045454237, Accuracy=0.1423611111111111\n",
      "Epoch 35 validation: Cross-entropy=2.4223694801330566, Accuracy=0.08585858345031738\n",
      "Epoch 36 train: Cross-entropy=2.368935161166721, Accuracy=0.1423611111111111\n",
      "Epoch 36 validation: Cross-entropy=2.4226622581481934, Accuracy=0.09090909361839294\n",
      "Epoch 37 train: Cross-entropy=2.368448164727953, Accuracy=0.1423611111111111\n",
      "Epoch 37 validation: Cross-entropy=2.422952890396118, Accuracy=0.09090909361839294\n",
      "Epoch 38 train: Cross-entropy=2.367973632282681, Accuracy=0.1423611111111111\n",
      "Epoch 38 validation: Cross-entropy=2.4232418537139893, Accuracy=0.09090909361839294\n",
      "Epoch 39 train: Cross-entropy=2.367511100239224, Accuracy=0.14583333333333334\n",
      "Epoch 39 validation: Cross-entropy=2.4235289096832275, Accuracy=0.09090909361839294\n",
      "Epoch 40 train: Cross-entropy=2.367059972551134, Accuracy=0.14756944444444445\n",
      "Epoch 40 validation: Cross-entropy=2.423813581466675, Accuracy=0.08585858345031738\n",
      "Epoch 41 train: Cross-entropy=2.3666197988722057, Accuracy=0.14930555555555555\n",
      "Epoch 41 validation: Cross-entropy=2.4240965843200684, Accuracy=0.09090909361839294\n",
      "Epoch 42 train: Cross-entropy=2.366190208329095, Accuracy=0.1527777777777778\n",
      "Epoch 42 validation: Cross-entropy=2.42437744140625, Accuracy=0.09595959633588791\n",
      "Epoch 43 train: Cross-entropy=2.3657708830303616, Accuracy=0.1527777777777778\n",
      "Epoch 43 validation: Cross-entropy=2.4246559143066406, Accuracy=0.09595959633588791\n",
      "Epoch 44 train: Cross-entropy=2.3653614388571844, Accuracy=0.15104166666666666\n",
      "Epoch 44 validation: Cross-entropy=2.4249322414398193, Accuracy=0.09090909361839294\n",
      "Epoch 45 train: Cross-entropy=2.364961412217882, Accuracy=0.15104166666666666\n",
      "Epoch 45 validation: Cross-entropy=2.425205945968628, Accuracy=0.09090909361839294\n",
      "Epoch 46 train: Cross-entropy=2.3645704454845853, Accuracy=0.15104166666666666\n",
      "Epoch 46 validation: Cross-entropy=2.4254777431488037, Accuracy=0.09090909361839294\n",
      "Epoch 47 train: Cross-entropy=2.3641882869932385, Accuracy=0.14930555555555555\n",
      "Epoch 47 validation: Cross-entropy=2.4257469177246094, Accuracy=0.09090909361839294\n",
      "Epoch 48 train: Cross-entropy=2.3638146188524036, Accuracy=0.14930555555555555\n",
      "Epoch 48 validation: Cross-entropy=2.426013946533203, Accuracy=0.08080808073282242\n",
      "Epoch 49 train: Cross-entropy=2.3634491629070706, Accuracy=0.15104166666666666\n",
      "Epoch 49 validation: Cross-entropy=2.4262783527374268, Accuracy=0.08080808073282242\n",
      "Epoch 50 train: Cross-entropy=2.3630915217929416, Accuracy=0.15104166666666666\n",
      "Epoch 50 validation: Cross-entropy=2.4265406131744385, Accuracy=0.08585858345031738\n",
      "Epoch 51 train: Cross-entropy=2.3627416292826333, Accuracy=0.15104166666666666\n",
      "Epoch 51 validation: Cross-entropy=2.42680025100708, Accuracy=0.08585858345031738\n",
      "Epoch 52 train: Cross-entropy=2.362399008538988, Accuracy=0.1527777777777778\n",
      "Epoch 52 validation: Cross-entropy=2.427057981491089, Accuracy=0.08585858345031738\n",
      "Epoch 53 train: Cross-entropy=2.362063580089145, Accuracy=0.1527777777777778\n",
      "Epoch 53 validation: Cross-entropy=2.4273130893707275, Accuracy=0.08585858345031738\n",
      "Epoch 54 train: Cross-entropy=2.3617350260416665, Accuracy=0.1545138888888889\n",
      "Epoch 54 validation: Cross-entropy=2.427565574645996, Accuracy=0.08585858345031738\n",
      "Epoch 55 train: Cross-entropy=2.361413147714403, Accuracy=0.15625\n",
      "Epoch 55 validation: Cross-entropy=2.4278159141540527, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 train: Cross-entropy=2.3610977464252048, Accuracy=0.1527777777777778\n",
      "Epoch 56 validation: Cross-entropy=2.42806339263916, Accuracy=0.08080808073282242\n",
      "Epoch 57 train: Cross-entropy=2.3607885705100164, Accuracy=0.15104166666666666\n",
      "Epoch 57 validation: Cross-entropy=2.428309202194214, Accuracy=0.08080808073282242\n",
      "Epoch 58 train: Cross-entropy=2.3604855272505016, Accuracy=0.15104166666666666\n",
      "Epoch 58 validation: Cross-entropy=2.4285521507263184, Accuracy=0.08080808073282242\n",
      "Epoch 59 train: Cross-entropy=2.360188219282362, Accuracy=0.15104166666666666\n",
      "Epoch 59 validation: Cross-entropy=2.428792953491211, Accuracy=0.08080808073282242\n",
      "Epoch 60 train: Cross-entropy=2.359896673096551, Accuracy=0.1527777777777778\n",
      "Epoch 60 validation: Cross-entropy=2.4290313720703125, Accuracy=0.08080808073282242\n",
      "Epoch 61 train: Cross-entropy=2.359610637029012, Accuracy=0.1527777777777778\n",
      "Epoch 61 validation: Cross-entropy=2.429267168045044, Accuracy=0.08080808073282242\n",
      "Epoch 62 train: Cross-entropy=2.3593299786249795, Accuracy=0.1527777777777778\n",
      "Epoch 62 validation: Cross-entropy=2.4295010566711426, Accuracy=0.08080808073282242\n",
      "Epoch 63 train: Cross-entropy=2.3590544859568277, Accuracy=0.1527777777777778\n",
      "Epoch 63 validation: Cross-entropy=2.42973256111145, Accuracy=0.08080808073282242\n",
      "Epoch 64 train: Cross-entropy=2.358784039815267, Accuracy=0.1527777777777778\n",
      "Epoch 64 validation: Cross-entropy=2.429961681365967, Accuracy=0.08080808073282242\n",
      "Epoch 65 train: Cross-entropy=2.3585184945000544, Accuracy=0.1545138888888889\n",
      "Epoch 65 validation: Cross-entropy=2.4301884174346924, Accuracy=0.08080808073282242\n",
      "Epoch 66 train: Cross-entropy=2.358257704310947, Accuracy=0.1545138888888889\n",
      "Epoch 66 validation: Cross-entropy=2.430412769317627, Accuracy=0.08080808073282242\n",
      "Epoch 67 train: Cross-entropy=2.3580015103022256, Accuracy=0.1545138888888889\n",
      "Epoch 67 validation: Cross-entropy=2.430635452270508, Accuracy=0.08080808073282242\n",
      "Epoch 68 train: Cross-entropy=2.357749833001031, Accuracy=0.1545138888888889\n",
      "Epoch 68 validation: Cross-entropy=2.4308552742004395, Accuracy=0.08080808073282242\n",
      "Epoch 69 train: Cross-entropy=2.357502539952596, Accuracy=0.1545138888888889\n",
      "Epoch 69 validation: Cross-entropy=2.4310731887817383, Accuracy=0.08080808073282242\n",
      "Epoch 70 train: Cross-entropy=2.357259498702155, Accuracy=0.1527777777777778\n",
      "Epoch 70 validation: Cross-entropy=2.431288957595825, Accuracy=0.08080808073282242\n",
      "Epoch 71 train: Cross-entropy=2.3570204973220825, Accuracy=0.14930555555555555\n",
      "Epoch 71 validation: Cross-entropy=2.4315025806427, Accuracy=0.08080808073282242\n",
      "Epoch 72 train: Cross-entropy=2.356785602039761, Accuracy=0.14930555555555555\n",
      "Epoch 72 validation: Cross-entropy=2.431713581085205, Accuracy=0.08080808073282242\n",
      "Epoch 73 train: Cross-entropy=2.3565546009275646, Accuracy=0.14756944444444445\n",
      "Epoch 73 validation: Cross-entropy=2.4319229125976562, Accuracy=0.08080808073282242\n",
      "Epoch 74 train: Cross-entropy=2.3563274012671576, Accuracy=0.14930555555555555\n",
      "Epoch 74 validation: Cross-entropy=2.4321300983428955, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.35610392358568, Accuracy=0.14930555555555555\n",
      "Epoch 75 validation: Cross-entropy=2.432335376739502, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.3558840221828885, Accuracy=0.15104166666666666\n",
      "Epoch 76 validation: Cross-entropy=2.4325382709503174, Accuracy=0.08080808073282242\n",
      "Epoch 77 train: Cross-entropy=2.3556676970587835, Accuracy=0.15104166666666666\n",
      "Epoch 77 validation: Cross-entropy=2.432739496231079, Accuracy=0.08080808073282242\n",
      "Epoch 78 train: Cross-entropy=2.355454749531216, Accuracy=0.14930555555555555\n",
      "Epoch 78 validation: Cross-entropy=2.43293833732605, Accuracy=0.08080808073282242\n",
      "Epoch 79 train: Cross-entropy=2.355245206091139, Accuracy=0.14756944444444445\n",
      "Epoch 79 validation: Cross-entropy=2.4331352710723877, Accuracy=0.08585858345031738\n",
      "Epoch 80 train: Cross-entropy=2.355038868056403, Accuracy=0.14756944444444445\n",
      "Epoch 80 validation: Cross-entropy=2.433330535888672, Accuracy=0.08585858345031738\n",
      "Epoch 81 train: Cross-entropy=2.354835695690579, Accuracy=0.14756944444444445\n",
      "Epoch 81 validation: Cross-entropy=2.433523654937744, Accuracy=0.08585858345031738\n",
      "Epoch 82 train: Cross-entropy=2.354635649257236, Accuracy=0.14756944444444445\n",
      "Epoch 82 validation: Cross-entropy=2.4337148666381836, Accuracy=0.08585858345031738\n",
      "Epoch 83 train: Cross-entropy=2.3544387022654214, Accuracy=0.14756944444444445\n",
      "Epoch 83 validation: Cross-entropy=2.433903932571411, Accuracy=0.08585858345031738\n",
      "Epoch 84 train: Cross-entropy=2.354244695769416, Accuracy=0.14930555555555555\n",
      "Epoch 84 validation: Cross-entropy=2.434091329574585, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.3540535635418363, Accuracy=0.14930555555555555\n",
      "Epoch 85 validation: Cross-entropy=2.434276819229126, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.3538651863733926, Accuracy=0.15104166666666666\n",
      "Epoch 86 validation: Cross-entropy=2.4344606399536133, Accuracy=0.08080808073282242\n",
      "Epoch 87 train: Cross-entropy=2.353679643736945, Accuracy=0.15104166666666666\n",
      "Epoch 87 validation: Cross-entropy=2.4346425533294678, Accuracy=0.08080808073282242\n",
      "Epoch 88 train: Cross-entropy=2.3534967369503446, Accuracy=0.1527777777777778\n",
      "Epoch 88 validation: Cross-entropy=2.4348225593566895, Accuracy=0.08080808073282242\n",
      "Epoch 89 train: Cross-entropy=2.353316479259067, Accuracy=0.1527777777777778\n",
      "Epoch 89 validation: Cross-entropy=2.4350011348724365, Accuracy=0.08080808073282242\n",
      "Epoch 90 train: Cross-entropy=2.3531387514538236, Accuracy=0.1527777777777778\n",
      "Epoch 90 validation: Cross-entropy=2.435177803039551, Accuracy=0.08080808073282242\n",
      "Epoch 91 train: Cross-entropy=2.35296360651652, Accuracy=0.1527777777777778\n",
      "Epoch 91 validation: Cross-entropy=2.4353525638580322, Accuracy=0.08080808073282242\n",
      "Epoch 92 train: Cross-entropy=2.352790845765008, Accuracy=0.1527777777777778\n",
      "Epoch 92 validation: Cross-entropy=2.43552565574646, Accuracy=0.08080808073282242\n",
      "Epoch 93 train: Cross-entropy=2.35262049569024, Accuracy=0.1527777777777778\n",
      "Epoch 93 validation: Cross-entropy=2.435697317123413, Accuracy=0.08080808073282242\n",
      "Epoch 94 train: Cross-entropy=2.3524524900648327, Accuracy=0.1527777777777778\n",
      "Epoch 94 validation: Cross-entropy=2.4358670711517334, Accuracy=0.08080808073282242\n",
      "Epoch 95 train: Cross-entropy=2.3522868288887873, Accuracy=0.1527777777777778\n",
      "Epoch 95 validation: Cross-entropy=2.436035394668579, Accuracy=0.08080808073282242\n",
      "Epoch 96 train: Cross-entropy=2.352123432689243, Accuracy=0.15104166666666666\n",
      "Epoch 96 validation: Cross-entropy=2.436201810836792, Accuracy=0.08080808073282242\n",
      "Epoch 97 train: Cross-entropy=2.351962169011434, Accuracy=0.15104166666666666\n",
      "Epoch 97 validation: Cross-entropy=2.4363667964935303, Accuracy=0.08080808073282242\n",
      "Epoch 98 train: Cross-entropy=2.35180311732822, Accuracy=0.15104166666666666\n",
      "Epoch 98 validation: Cross-entropy=2.436530113220215, Accuracy=0.08080808073282242\n",
      "Epoch 99 train: Cross-entropy=2.3516461319393582, Accuracy=0.1545138888888889\n",
      "Epoch 99 validation: Cross-entropy=2.436691999435425, Accuracy=0.08080808073282242\n",
      "Epoch 100 train: Cross-entropy=2.3514912128448486, Accuracy=0.1545138888888889\n",
      "Epoch 100 validation: Cross-entropy=2.436852216720581, Accuracy=0.08080808073282242\n",
      "Epoch 101 train: Cross-entropy=2.351338346799215, Accuracy=0.1545138888888889\n",
      "Epoch 101 validation: Cross-entropy=2.4370110034942627, Accuracy=0.08080808073282242\n",
      "Epoch 102 train: Cross-entropy=2.3511873881022134, Accuracy=0.1545138888888889\n",
      "Epoch 102 validation: Cross-entropy=2.4371681213378906, Accuracy=0.08080808073282242\n",
      "Epoch 103 train: Cross-entropy=2.3510384692086115, Accuracy=0.1545138888888889\n",
      "Epoch 103 validation: Cross-entropy=2.437323808670044, Accuracy=0.08080808073282242\n",
      "Epoch 104 train: Cross-entropy=2.3508914179272122, Accuracy=0.1545138888888889\n",
      "Epoch 104 validation: Cross-entropy=2.4374783039093018, Accuracy=0.08080808073282242\n",
      "Epoch 105 train: Cross-entropy=2.3507462210125394, Accuracy=0.1545138888888889\n",
      "Epoch 105 validation: Cross-entropy=2.4376308917999268, Accuracy=0.08080808073282242\n",
      "Epoch 106 train: Cross-entropy=2.35060281223721, Accuracy=0.1545138888888889\n",
      "Epoch 106 validation: Cross-entropy=2.4377827644348145, Accuracy=0.08080808073282242\n",
      "Epoch 107 train: Cross-entropy=2.3504611783557467, Accuracy=0.1545138888888889\n",
      "Epoch 107 validation: Cross-entropy=2.4379329681396484, Accuracy=0.08080808073282242\n",
      "Epoch 108 train: Cross-entropy=2.35032139884101, Accuracy=0.1545138888888889\n",
      "Epoch 108 validation: Cross-entropy=2.4380815029144287, Accuracy=0.08080808073282242\n",
      "Epoch 109 train: Cross-entropy=2.350183301501804, Accuracy=0.1545138888888889\n",
      "Epoch 109 validation: Cross-entropy=2.4382286071777344, Accuracy=0.08080808073282242\n",
      "Epoch 110 train: Cross-entropy=2.3500468730926514, Accuracy=0.1545138888888889\n",
      "Epoch 110 validation: Cross-entropy=2.4383745193481445, Accuracy=0.08080808073282242\n",
      "Epoch 111 train: Cross-entropy=2.3499121401045056, Accuracy=0.15104166666666666\n",
      "Epoch 111 validation: Cross-entropy=2.43851900100708, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 train: Cross-entropy=2.3497790230645075, Accuracy=0.15104166666666666\n",
      "Epoch 112 validation: Cross-entropy=2.438662528991699, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.34964746899075, Accuracy=0.15104166666666666\n",
      "Epoch 113 validation: Cross-entropy=2.4388041496276855, Accuracy=0.08080808073282242\n",
      "Epoch 114 train: Cross-entropy=2.3495175176196628, Accuracy=0.15104166666666666\n",
      "Epoch 114 validation: Cross-entropy=2.4389450550079346, Accuracy=0.08080808073282242\n",
      "Epoch 115 train: Cross-entropy=2.349389089478387, Accuracy=0.15104166666666666\n",
      "Epoch 115 validation: Cross-entropy=2.439084529876709, Accuracy=0.08080808073282242\n",
      "Epoch 116 train: Cross-entropy=2.3492622110578747, Accuracy=0.14930555555555555\n",
      "Epoch 116 validation: Cross-entropy=2.4392223358154297, Accuracy=0.08080808073282242\n",
      "Epoch 117 train: Cross-entropy=2.3491367366578846, Accuracy=0.14930555555555555\n",
      "Epoch 117 validation: Cross-entropy=2.439359426498413, Accuracy=0.08080808073282242\n",
      "Epoch 118 train: Cross-entropy=2.3490127192603216, Accuracy=0.14930555555555555\n",
      "Epoch 118 validation: Cross-entropy=2.439495086669922, Accuracy=0.08080808073282242\n",
      "Epoch 119 train: Cross-entropy=2.348890198601617, Accuracy=0.14756944444444445\n",
      "Epoch 119 validation: Cross-entropy=2.439629554748535, Accuracy=0.08080808073282242\n",
      "Epoch 120 train: Cross-entropy=2.34876905547248, Accuracy=0.14756944444444445\n",
      "Epoch 120 validation: Cross-entropy=2.439762830734253, Accuracy=0.08080808073282242\n",
      "Epoch 121 train: Cross-entropy=2.3486492104000516, Accuracy=0.14756944444444445\n",
      "Epoch 121 validation: Cross-entropy=2.439894914627075, Accuracy=0.08080808073282242\n",
      "Epoch 122 train: Cross-entropy=2.3485308488210044, Accuracy=0.14756944444444445\n",
      "Epoch 122 validation: Cross-entropy=2.440025806427002, Accuracy=0.08080808073282242\n",
      "Epoch 123 train: Cross-entropy=2.348413732316759, Accuracy=0.14930555555555555\n",
      "Epoch 123 validation: Cross-entropy=2.440155506134033, Accuracy=0.07575757801532745\n",
      "Epoch 124 train: Cross-entropy=2.3482980330785117, Accuracy=0.14930555555555555\n",
      "Epoch 124 validation: Cross-entropy=2.440284252166748, Accuracy=0.07575757801532745\n",
      "Epoch 125 train: Cross-entropy=2.3481834597057767, Accuracy=0.14930555555555555\n",
      "Epoch 125 validation: Cross-entropy=2.4404115676879883, Accuracy=0.07575757801532745\n",
      "Epoch 126 train: Cross-entropy=2.34807026386261, Accuracy=0.14930555555555555\n",
      "Epoch 126 validation: Cross-entropy=2.440538167953491, Accuracy=0.07575757801532745\n",
      "Epoch 127 train: Cross-entropy=2.347958286603292, Accuracy=0.14930555555555555\n",
      "Epoch 127 validation: Cross-entropy=2.4406633377075195, Accuracy=0.07575757801532745\n",
      "Epoch 128 train: Cross-entropy=2.347847501436869, Accuracy=0.14930555555555555\n",
      "Epoch 128 validation: Cross-entropy=2.4407875537872314, Accuracy=0.07575757801532745\n",
      "Epoch 129 train: Cross-entropy=2.3477379083633423, Accuracy=0.14930555555555555\n",
      "Epoch 129 validation: Cross-entropy=2.440910816192627, Accuracy=0.07575757801532745\n",
      "Epoch 130 train: Cross-entropy=2.3476295603646173, Accuracy=0.14930555555555555\n",
      "Epoch 130 validation: Cross-entropy=2.441032886505127, Accuracy=0.07575757801532745\n",
      "Epoch 131 train: Cross-entropy=2.3475223382314048, Accuracy=0.14930555555555555\n",
      "Epoch 131 validation: Cross-entropy=2.4411540031433105, Accuracy=0.07575757801532745\n",
      "Epoch 132 train: Cross-entropy=2.3474162817001343, Accuracy=0.14930555555555555\n",
      "Epoch 132 validation: Cross-entropy=2.4412739276885986, Accuracy=0.07575757801532745\n",
      "Epoch 133 train: Cross-entropy=2.347311364279853, Accuracy=0.14930555555555555\n",
      "Epoch 133 validation: Cross-entropy=2.4413933753967285, Accuracy=0.07575757801532745\n",
      "Epoch 134 train: Cross-entropy=2.3472074800067477, Accuracy=0.14930555555555555\n",
      "Epoch 134 validation: Cross-entropy=2.441511392593384, Accuracy=0.07575757801532745\n",
      "Epoch 135 train: Cross-entropy=2.3471047083536782, Accuracy=0.14930555555555555\n",
      "Epoch 135 validation: Cross-entropy=2.4416279792785645, Accuracy=0.07575757801532745\n",
      "Epoch 136 train: Cross-entropy=2.3470030625661216, Accuracy=0.14930555555555555\n",
      "Epoch 136 validation: Cross-entropy=2.441744327545166, Accuracy=0.07575757801532745\n",
      "Epoch 137 train: Cross-entropy=2.3469024101893106, Accuracy=0.14930555555555555\n",
      "Epoch 137 validation: Cross-entropy=2.441859483718872, Accuracy=0.07575757801532745\n",
      "Epoch 138 train: Cross-entropy=2.3468028836780124, Accuracy=0.14930555555555555\n",
      "Epoch 138 validation: Cross-entropy=2.4419734477996826, Accuracy=0.07575757801532745\n",
      "Epoch 139 train: Cross-entropy=2.3467043240865073, Accuracy=0.14930555555555555\n",
      "Epoch 139 validation: Cross-entropy=2.442086696624756, Accuracy=0.07575757801532745\n",
      "Epoch 140 train: Cross-entropy=2.346606797642178, Accuracy=0.15104166666666666\n",
      "Epoch 140 validation: Cross-entropy=2.442199230194092, Accuracy=0.07575757801532745\n",
      "Epoch 141 train: Cross-entropy=2.3465101851357355, Accuracy=0.14930555555555555\n",
      "Epoch 141 validation: Cross-entropy=2.442310333251953, Accuracy=0.07575757801532745\n",
      "Epoch 142 train: Cross-entropy=2.3464145792855158, Accuracy=0.14930555555555555\n",
      "Epoch 142 validation: Cross-entropy=2.4424209594726562, Accuracy=0.07575757801532745\n",
      "Epoch 143 train: Cross-entropy=2.3463200198279486, Accuracy=0.14930555555555555\n",
      "Epoch 143 validation: Cross-entropy=2.442530632019043, Accuracy=0.07575757801532745\n",
      "Epoch 144 train: Cross-entropy=2.346226347817315, Accuracy=0.14930555555555555\n",
      "Epoch 144 validation: Cross-entropy=2.442639112472534, Accuracy=0.07575757801532745\n",
      "Epoch 145 train: Cross-entropy=2.3461336427264743, Accuracy=0.14930555555555555\n",
      "Epoch 145 validation: Cross-entropy=2.442747116088867, Accuracy=0.08080808073282242\n",
      "Epoch 146 train: Cross-entropy=2.3460418118370905, Accuracy=0.14930555555555555\n",
      "Epoch 146 validation: Cross-entropy=2.4428539276123047, Accuracy=0.08080808073282242\n",
      "Epoch 147 train: Cross-entropy=2.3459508816401162, Accuracy=0.14930555555555555\n",
      "Epoch 147 validation: Cross-entropy=2.442960262298584, Accuracy=0.08080808073282242\n",
      "Epoch 148 train: Cross-entropy=2.345860825644599, Accuracy=0.14930555555555555\n",
      "Epoch 148 validation: Cross-entropy=2.4430651664733887, Accuracy=0.08080808073282242\n",
      "Epoch 149 train: Cross-entropy=2.345771723323398, Accuracy=0.14930555555555555\n",
      "Epoch 149 validation: Cross-entropy=2.4431698322296143, Accuracy=0.08080808073282242\n",
      "Epoch 150 train: Cross-entropy=2.3456834819581776, Accuracy=0.14930555555555555\n",
      "Epoch 150 validation: Cross-entropy=2.4432733058929443, Accuracy=0.08080808073282242\n",
      "Epoch 151 train: Cross-entropy=2.3455960618125067, Accuracy=0.14930555555555555\n",
      "Epoch 151 validation: Cross-entropy=2.443376064300537, Accuracy=0.08080808073282242\n",
      "Epoch 152 train: Cross-entropy=2.3455094496409097, Accuracy=0.14930555555555555\n",
      "Epoch 152 validation: Cross-entropy=2.4434781074523926, Accuracy=0.08080808073282242\n",
      "Epoch 153 train: Cross-entropy=2.345423764652676, Accuracy=0.14930555555555555\n",
      "Epoch 153 validation: Cross-entropy=2.4435794353485107, Accuracy=0.08080808073282242\n",
      "Epoch 154 train: Cross-entropy=2.345338808165656, Accuracy=0.14930555555555555\n",
      "Epoch 154 validation: Cross-entropy=2.4436795711517334, Accuracy=0.08080808073282242\n",
      "Epoch 155 train: Cross-entropy=2.345254725880093, Accuracy=0.14930555555555555\n",
      "Epoch 155 validation: Cross-entropy=2.443779468536377, Accuracy=0.08080808073282242\n",
      "Epoch 156 train: Cross-entropy=2.345171398586697, Accuracy=0.14930555555555555\n",
      "Epoch 156 validation: Cross-entropy=2.443878173828125, Accuracy=0.08080808073282242\n",
      "Epoch 157 train: Cross-entropy=2.3450888660218983, Accuracy=0.15104166666666666\n",
      "Epoch 157 validation: Cross-entropy=2.4439761638641357, Accuracy=0.08080808073282242\n",
      "Epoch 158 train: Cross-entropy=2.345007141431173, Accuracy=0.15104166666666666\n",
      "Epoch 158 validation: Cross-entropy=2.4440736770629883, Accuracy=0.08080808073282242\n",
      "Epoch 159 train: Cross-entropy=2.3449261453416614, Accuracy=0.15104166666666666\n",
      "Epoch 159 validation: Cross-entropy=2.4441704750061035, Accuracy=0.08080808073282242\n",
      "Epoch 160 train: Cross-entropy=2.3448459439807467, Accuracy=0.15104166666666666\n",
      "Epoch 160 validation: Cross-entropy=2.4442660808563232, Accuracy=0.08585858345031738\n",
      "Epoch 161 train: Cross-entropy=2.3447663916481867, Accuracy=0.15104166666666666\n",
      "Epoch 161 validation: Cross-entropy=2.444361448287964, Accuracy=0.08585858345031738\n",
      "Epoch 162 train: Cross-entropy=2.344687713517083, Accuracy=0.15104166666666666\n",
      "Epoch 162 validation: Cross-entropy=2.444455623626709, Accuracy=0.08585858345031738\n",
      "Epoch 163 train: Cross-entropy=2.344609671168857, Accuracy=0.15104166666666666\n",
      "Epoch 163 validation: Cross-entropy=2.444549322128296, Accuracy=0.08585858345031738\n",
      "Epoch 164 train: Cross-entropy=2.344532330830892, Accuracy=0.15104166666666666\n",
      "Epoch 164 validation: Cross-entropy=2.4446423053741455, Accuracy=0.09090909361839294\n",
      "Epoch 165 train: Cross-entropy=2.344455771976047, Accuracy=0.15104166666666666\n",
      "Epoch 165 validation: Cross-entropy=2.444734573364258, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.3443799018859863, Accuracy=0.1527777777777778\n",
      "Epoch 166 validation: Cross-entropy=2.444826364517212, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167 train: Cross-entropy=2.3443046278423734, Accuracy=0.1527777777777778\n",
      "Epoch 167 validation: Cross-entropy=2.4449172019958496, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.344230148527357, Accuracy=0.1527777777777778\n",
      "Epoch 168 validation: Cross-entropy=2.445007562637329, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.344156265258789, Accuracy=0.1527777777777778\n",
      "Epoch 169 validation: Cross-entropy=2.4450976848602295, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.3440830177730985, Accuracy=0.1527777777777778\n",
      "Epoch 170 validation: Cross-entropy=2.4451863765716553, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.344010498788622, Accuracy=0.1527777777777778\n",
      "Epoch 171 validation: Cross-entropy=2.445274829864502, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.3439386155870228, Accuracy=0.15104166666666666\n",
      "Epoch 172 validation: Cross-entropy=2.4453623294830322, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.343867368168301, Accuracy=0.15104166666666666\n",
      "Epoch 173 validation: Cross-entropy=2.4454493522644043, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.3437966770595975, Accuracy=0.14930555555555555\n",
      "Epoch 174 validation: Cross-entropy=2.445535898208618, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.3437266747156777, Accuracy=0.14930555555555555\n",
      "Epoch 175 validation: Cross-entropy=2.4456217288970947, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.343657268418206, Accuracy=0.14930555555555555\n",
      "Epoch 176 validation: Cross-entropy=2.445706844329834, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.343588497903612, Accuracy=0.14930555555555555\n",
      "Epoch 177 validation: Cross-entropy=2.445791482925415, Accuracy=0.09090909361839294\n",
      "Epoch 178 train: Cross-entropy=2.343520257208082, Accuracy=0.14930555555555555\n",
      "Epoch 178 validation: Cross-entropy=2.445875644683838, Accuracy=0.08585858345031738\n",
      "Epoch 179 train: Cross-entropy=2.343452665540907, Accuracy=0.14930555555555555\n",
      "Epoch 179 validation: Cross-entropy=2.4459588527679443, Accuracy=0.08585858345031738\n",
      "Epoch 180 train: Cross-entropy=2.3433856434292264, Accuracy=0.14930555555555555\n",
      "Epoch 180 validation: Cross-entropy=2.4460418224334717, Accuracy=0.08585858345031738\n",
      "Epoch 181 train: Cross-entropy=2.343319217363993, Accuracy=0.14930555555555555\n",
      "Epoch 181 validation: Cross-entropy=2.4461240768432617, Accuracy=0.08585858345031738\n",
      "Epoch 182 train: Cross-entropy=2.343253321117825, Accuracy=0.14756944444444445\n",
      "Epoch 182 validation: Cross-entropy=2.4462056159973145, Accuracy=0.08585858345031738\n",
      "Epoch 183 train: Cross-entropy=2.343188007672628, Accuracy=0.14756944444444445\n",
      "Epoch 183 validation: Cross-entropy=2.446286678314209, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.343123263782925, Accuracy=0.14756944444444445\n",
      "Epoch 184 validation: Cross-entropy=2.4463672637939453, Accuracy=0.08585858345031738\n",
      "Epoch 185 train: Cross-entropy=2.3430590364668102, Accuracy=0.14756944444444445\n",
      "Epoch 185 validation: Cross-entropy=2.4464471340179443, Accuracy=0.08585858345031738\n",
      "Epoch 186 train: Cross-entropy=2.342995365460714, Accuracy=0.14756944444444445\n",
      "Epoch 186 validation: Cross-entropy=2.446526527404785, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.3429323037465415, Accuracy=0.14756944444444445\n",
      "Epoch 187 validation: Cross-entropy=2.446605682373047, Accuracy=0.08585858345031738\n",
      "Epoch 188 train: Cross-entropy=2.342869665887621, Accuracy=0.14756944444444445\n",
      "Epoch 188 validation: Cross-entropy=2.446683883666992, Accuracy=0.08585858345031738\n",
      "Epoch 189 train: Cross-entropy=2.3428075975841947, Accuracy=0.14756944444444445\n",
      "Epoch 189 validation: Cross-entropy=2.4467616081237793, Accuracy=0.08585858345031738\n",
      "Epoch 190 train: Cross-entropy=2.3427461120817394, Accuracy=0.14756944444444445\n",
      "Epoch 190 validation: Cross-entropy=2.446838855743408, Accuracy=0.08585858345031738\n",
      "Epoch 191 train: Cross-entropy=2.3426850504345365, Accuracy=0.14756944444444445\n",
      "Epoch 191 validation: Cross-entropy=2.446915626525879, Accuracy=0.08585858345031738\n",
      "Epoch 192 train: Cross-entropy=2.342624545097351, Accuracy=0.14756944444444445\n",
      "Epoch 192 validation: Cross-entropy=2.4469916820526123, Accuracy=0.08585858345031738\n",
      "Epoch 193 train: Cross-entropy=2.342564516597324, Accuracy=0.14756944444444445\n",
      "Epoch 193 validation: Cross-entropy=2.4470674991607666, Accuracy=0.08080808073282242\n",
      "Epoch 194 train: Cross-entropy=2.3425050179163613, Accuracy=0.14756944444444445\n",
      "Epoch 194 validation: Cross-entropy=2.4471423625946045, Accuracy=0.08080808073282242\n",
      "Epoch 195 train: Cross-entropy=2.3424459430906506, Accuracy=0.14930555555555555\n",
      "Epoch 195 validation: Cross-entropy=2.4472172260284424, Accuracy=0.07575757801532745\n",
      "Epoch 196 train: Cross-entropy=2.342387411329481, Accuracy=0.15104166666666666\n",
      "Epoch 196 validation: Cross-entropy=2.447291612625122, Accuracy=0.07575757801532745\n",
      "Epoch 197 train: Cross-entropy=2.3423293696509466, Accuracy=0.15104166666666666\n",
      "Epoch 197 validation: Cross-entropy=2.4473652839660645, Accuracy=0.07575757801532745\n",
      "Epoch 198 train: Cross-entropy=2.342271778318617, Accuracy=0.14930555555555555\n",
      "Epoch 198 validation: Cross-entropy=2.4474384784698486, Accuracy=0.07575757801532745\n",
      "Epoch 199 train: Cross-entropy=2.342214663823446, Accuracy=0.14930555555555555\n",
      "Epoch 199 validation: Cross-entropy=2.4475109577178955, Accuracy=0.07575757801532745\n",
      "Epoch 0 train: Cross-entropy=2.415248499976264, Accuracy=0.08159722222222222\n",
      "Epoch 0 validation: Cross-entropy=2.4164679050445557, Accuracy=0.07070706784725189\n",
      "Epoch 1 train: Cross-entropy=2.4097872177759805, Accuracy=0.06944444444444445\n",
      "Epoch 1 validation: Cross-entropy=2.4155819416046143, Accuracy=0.06565656512975693\n",
      "Epoch 2 train: Cross-entropy=2.4065412282943726, Accuracy=0.07465277777777778\n",
      "Epoch 2 validation: Cross-entropy=2.4159038066864014, Accuracy=0.06565656512975693\n",
      "Epoch 3 train: Cross-entropy=2.403501100010342, Accuracy=0.0798611111111111\n",
      "Epoch 3 validation: Cross-entropy=2.415806770324707, Accuracy=0.07070706784725189\n",
      "Epoch 4 train: Cross-entropy=2.4007807705137463, Accuracy=0.08333333333333333\n",
      "Epoch 4 validation: Cross-entropy=2.4158976078033447, Accuracy=0.07070706784725189\n",
      "Epoch 5 train: Cross-entropy=2.398218313852946, Accuracy=0.09027777777777778\n",
      "Epoch 5 validation: Cross-entropy=2.4160473346710205, Accuracy=0.0555555559694767\n",
      "Epoch 6 train: Cross-entropy=2.3958259688483343, Accuracy=0.09895833333333333\n",
      "Epoch 6 validation: Cross-entropy=2.4162611961364746, Accuracy=0.05050504952669144\n",
      "Epoch 7 train: Cross-entropy=2.3935846620135837, Accuracy=0.10069444444444445\n",
      "Epoch 7 validation: Cross-entropy=2.4165284633636475, Accuracy=0.06060606241226196\n",
      "Epoch 8 train: Cross-entropy=2.391481598218282, Accuracy=0.11284722222222222\n",
      "Epoch 8 validation: Cross-entropy=2.416841506958008, Accuracy=0.0555555559694767\n",
      "Epoch 9 train: Cross-entropy=2.3895049889882407, Accuracy=0.109375\n",
      "Epoch 9 validation: Cross-entropy=2.41719388961792, Accuracy=0.0555555559694767\n",
      "Epoch 10 train: Cross-entropy=2.3876442909240723, Accuracy=0.11805555555555555\n",
      "Epoch 10 validation: Cross-entropy=2.4175796508789062, Accuracy=0.06060606241226196\n",
      "Epoch 11 train: Cross-entropy=2.385890073246426, Accuracy=0.11979166666666667\n",
      "Epoch 11 validation: Cross-entropy=2.4179928302764893, Accuracy=0.07070706784725189\n",
      "Epoch 12 train: Cross-entropy=2.3842336336771646, Accuracy=0.1284722222222222\n",
      "Epoch 12 validation: Cross-entropy=2.4184298515319824, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.382667342821757, Accuracy=0.1284722222222222\n",
      "Epoch 13 validation: Cross-entropy=2.418886184692383, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.3811843395233154, Accuracy=0.1284722222222222\n",
      "Epoch 14 validation: Cross-entropy=2.419358253479004, Accuracy=0.07575757801532745\n",
      "Epoch 15 train: Cross-entropy=2.379778411653307, Accuracy=0.1284722222222222\n",
      "Epoch 15 validation: Cross-entropy=2.4198429584503174, Accuracy=0.07575757801532745\n",
      "Epoch 16 train: Cross-entropy=2.3784436649746366, Accuracy=0.13368055555555555\n",
      "Epoch 16 validation: Cross-entropy=2.420337677001953, Accuracy=0.07575757801532745\n",
      "Epoch 17 train: Cross-entropy=2.37717506620619, Accuracy=0.1284722222222222\n",
      "Epoch 17 validation: Cross-entropy=2.420840263366699, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 train: Cross-entropy=2.375967860221863, Accuracy=0.12152777777777778\n",
      "Epoch 18 validation: Cross-entropy=2.4213478565216064, Accuracy=0.07575757801532745\n",
      "Epoch 19 train: Cross-entropy=2.3748177687327066, Accuracy=0.12152777777777778\n",
      "Epoch 19 validation: Cross-entropy=2.4218590259552, Accuracy=0.07575757801532745\n",
      "Epoch 20 train: Cross-entropy=2.3737208710776434, Accuracy=0.125\n",
      "Epoch 20 validation: Cross-entropy=2.422372579574585, Accuracy=0.08080808073282242\n",
      "Epoch 21 train: Cross-entropy=2.3726737366782293, Accuracy=0.13020833333333334\n",
      "Epoch 21 validation: Cross-entropy=2.422886610031128, Accuracy=0.08080808073282242\n",
      "Epoch 22 train: Cross-entropy=2.3716730144288807, Accuracy=0.1284722222222222\n",
      "Epoch 22 validation: Cross-entropy=2.4233999252319336, Accuracy=0.09090909361839294\n",
      "Epoch 23 train: Cross-entropy=2.3707157240973578, Accuracy=0.1284722222222222\n",
      "Epoch 23 validation: Cross-entropy=2.4239113330841064, Accuracy=0.09090909361839294\n",
      "Epoch 24 train: Cross-entropy=2.3697990708880954, Accuracy=0.13368055555555555\n",
      "Epoch 24 validation: Cross-entropy=2.4244205951690674, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.3689206176333957, Accuracy=0.13541666666666666\n",
      "Epoch 25 validation: Cross-entropy=2.4249260425567627, Accuracy=0.09090909361839294\n",
      "Epoch 26 train: Cross-entropy=2.3680780198838978, Accuracy=0.1388888888888889\n",
      "Epoch 26 validation: Cross-entropy=2.425426959991455, Accuracy=0.08585858345031738\n",
      "Epoch 27 train: Cross-entropy=2.3672691583633423, Accuracy=0.140625\n",
      "Epoch 27 validation: Cross-entropy=2.4259238243103027, Accuracy=0.08080808073282242\n",
      "Epoch 28 train: Cross-entropy=2.366492085986667, Accuracy=0.1423611111111111\n",
      "Epoch 28 validation: Cross-entropy=2.426414966583252, Accuracy=0.08080808073282242\n",
      "Epoch 29 train: Cross-entropy=2.365744842423333, Accuracy=0.140625\n",
      "Epoch 29 validation: Cross-entropy=2.426900863647461, Accuracy=0.08080808073282242\n",
      "Epoch 30 train: Cross-entropy=2.3650259176890054, Accuracy=0.140625\n",
      "Epoch 30 validation: Cross-entropy=2.4273805618286133, Accuracy=0.08080808073282242\n",
      "Epoch 31 train: Cross-entropy=2.364333669344584, Accuracy=0.1371527777777778\n",
      "Epoch 31 validation: Cross-entropy=2.427853584289551, Accuracy=0.08080808073282242\n",
      "Epoch 32 train: Cross-entropy=2.3636666536331177, Accuracy=0.140625\n",
      "Epoch 32 validation: Cross-entropy=2.4283201694488525, Accuracy=0.08080808073282242\n",
      "Epoch 33 train: Cross-entropy=2.3630235724978976, Accuracy=0.140625\n",
      "Epoch 33 validation: Cross-entropy=2.4287796020507812, Accuracy=0.08080808073282242\n",
      "Epoch 34 train: Cross-entropy=2.3624032073550754, Accuracy=0.140625\n",
      "Epoch 34 validation: Cross-entropy=2.429232120513916, Accuracy=0.08080808073282242\n",
      "Epoch 35 train: Cross-entropy=2.361804207166036, Accuracy=0.140625\n",
      "Epoch 35 validation: Cross-entropy=2.429677724838257, Accuracy=0.08585858345031738\n",
      "Epoch 36 train: Cross-entropy=2.3612257374657526, Accuracy=0.1423611111111111\n",
      "Epoch 36 validation: Cross-entropy=2.4301159381866455, Accuracy=0.08585858345031738\n",
      "Epoch 37 train: Cross-entropy=2.3606666326522827, Accuracy=0.1423611111111111\n",
      "Epoch 37 validation: Cross-entropy=2.430546998977661, Accuracy=0.08585858345031738\n",
      "Epoch 38 train: Cross-entropy=2.3601259920332165, Accuracy=0.1440972222222222\n",
      "Epoch 38 validation: Cross-entropy=2.4309704303741455, Accuracy=0.08585858345031738\n",
      "Epoch 39 train: Cross-entropy=2.3596029943890042, Accuracy=0.14583333333333334\n",
      "Epoch 39 validation: Cross-entropy=2.431386709213257, Accuracy=0.08585858345031738\n",
      "Epoch 40 train: Cross-entropy=2.3590967522727118, Accuracy=0.14583333333333334\n",
      "Epoch 40 validation: Cross-entropy=2.431795597076416, Accuracy=0.08585858345031738\n",
      "Epoch 41 train: Cross-entropy=2.358606470955743, Accuracy=0.14756944444444445\n",
      "Epoch 41 validation: Cross-entropy=2.432197093963623, Accuracy=0.08585858345031738\n",
      "Epoch 42 train: Cross-entropy=2.358131527900696, Accuracy=0.14756944444444445\n",
      "Epoch 42 validation: Cross-entropy=2.432591676712036, Accuracy=0.08585858345031738\n",
      "Epoch 43 train: Cross-entropy=2.357671168115404, Accuracy=0.14756944444444445\n",
      "Epoch 43 validation: Cross-entropy=2.432978391647339, Accuracy=0.08585858345031738\n",
      "Epoch 44 train: Cross-entropy=2.357224782307943, Accuracy=0.14756944444444445\n",
      "Epoch 44 validation: Cross-entropy=2.4333581924438477, Accuracy=0.08585858345031738\n",
      "Epoch 45 train: Cross-entropy=2.3567918009228177, Accuracy=0.14583333333333334\n",
      "Epoch 45 validation: Cross-entropy=2.4337308406829834, Accuracy=0.08585858345031738\n",
      "Epoch 46 train: Cross-entropy=2.356371588177151, Accuracy=0.14756944444444445\n",
      "Epoch 46 validation: Cross-entropy=2.434096336364746, Accuracy=0.08080808073282242\n",
      "Epoch 47 train: Cross-entropy=2.3559636539883084, Accuracy=0.14756944444444445\n",
      "Epoch 47 validation: Cross-entropy=2.434454917907715, Accuracy=0.08080808073282242\n",
      "Epoch 48 train: Cross-entropy=2.355567455291748, Accuracy=0.14756944444444445\n",
      "Epoch 48 validation: Cross-entropy=2.4348065853118896, Accuracy=0.08080808073282242\n",
      "Epoch 49 train: Cross-entropy=2.355182581477695, Accuracy=0.14930555555555555\n",
      "Epoch 49 validation: Cross-entropy=2.4351515769958496, Accuracy=0.08080808073282242\n",
      "Epoch 50 train: Cross-entropy=2.354808529218038, Accuracy=0.14930555555555555\n",
      "Epoch 50 validation: Cross-entropy=2.4354898929595947, Accuracy=0.08080808073282242\n",
      "Epoch 51 train: Cross-entropy=2.3544448879030018, Accuracy=0.14930555555555555\n",
      "Epoch 51 validation: Cross-entropy=2.435821533203125, Accuracy=0.08080808073282242\n",
      "Epoch 52 train: Cross-entropy=2.354091352886624, Accuracy=0.15104166666666666\n",
      "Epoch 52 validation: Cross-entropy=2.4361467361450195, Accuracy=0.08585858345031738\n",
      "Epoch 53 train: Cross-entropy=2.3537473148769803, Accuracy=0.15104166666666666\n",
      "Epoch 53 validation: Cross-entropy=2.4364655017852783, Accuracy=0.08585858345031738\n",
      "Epoch 54 train: Cross-entropy=2.353412667910258, Accuracy=0.15104166666666666\n",
      "Epoch 54 validation: Cross-entropy=2.4367780685424805, Accuracy=0.08080808073282242\n",
      "Epoch 55 train: Cross-entropy=2.3530869483947754, Accuracy=0.15104166666666666\n",
      "Epoch 55 validation: Cross-entropy=2.437084674835205, Accuracy=0.08080808073282242\n",
      "Epoch 56 train: Cross-entropy=2.3527698119481406, Accuracy=0.15104166666666666\n",
      "Epoch 56 validation: Cross-entropy=2.437385082244873, Accuracy=0.08080808073282242\n",
      "Epoch 57 train: Cross-entropy=2.3524610333972507, Accuracy=0.15104166666666666\n",
      "Epoch 57 validation: Cross-entropy=2.4376792907714844, Accuracy=0.08080808073282242\n",
      "Epoch 58 train: Cross-entropy=2.3521602286232843, Accuracy=0.1527777777777778\n",
      "Epoch 58 validation: Cross-entropy=2.4379682540893555, Accuracy=0.08080808073282242\n",
      "Epoch 59 train: Cross-entropy=2.351867119471232, Accuracy=0.1527777777777778\n",
      "Epoch 59 validation: Cross-entropy=2.43825101852417, Accuracy=0.08080808073282242\n",
      "Epoch 60 train: Cross-entropy=2.3515815602408514, Accuracy=0.1545138888888889\n",
      "Epoch 60 validation: Cross-entropy=2.438528299331665, Accuracy=0.08080808073282242\n",
      "Epoch 61 train: Cross-entropy=2.3513031005859375, Accuracy=0.1545138888888889\n",
      "Epoch 61 validation: Cross-entropy=2.43880033493042, Accuracy=0.08080808073282242\n",
      "Epoch 62 train: Cross-entropy=2.351031714015537, Accuracy=0.15104166666666666\n",
      "Epoch 62 validation: Cross-entropy=2.4390668869018555, Accuracy=0.08080808073282242\n",
      "Epoch 63 train: Cross-entropy=2.350766976674398, Accuracy=0.15104166666666666\n",
      "Epoch 63 validation: Cross-entropy=2.439328193664551, Accuracy=0.08080808073282242\n",
      "Epoch 64 train: Cross-entropy=2.3505088223351374, Accuracy=0.1527777777777778\n",
      "Epoch 64 validation: Cross-entropy=2.4395840167999268, Accuracy=0.08080808073282242\n",
      "Epoch 65 train: Cross-entropy=2.3502569331063166, Accuracy=0.1527777777777778\n",
      "Epoch 65 validation: Cross-entropy=2.4398353099823, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.350011150042216, Accuracy=0.1527777777777778\n",
      "Epoch 66 validation: Cross-entropy=2.4400811195373535, Accuracy=0.07575757801532745\n",
      "Epoch 67 train: Cross-entropy=2.3497712877061634, Accuracy=0.1527777777777778\n",
      "Epoch 67 validation: Cross-entropy=2.4403226375579834, Accuracy=0.07575757801532745\n",
      "Epoch 68 train: Cross-entropy=2.349537173906962, Accuracy=0.1527777777777778\n",
      "Epoch 68 validation: Cross-entropy=2.440558910369873, Accuracy=0.07575757801532745\n",
      "Epoch 69 train: Cross-entropy=2.3493085967169867, Accuracy=0.1527777777777778\n",
      "Epoch 69 validation: Cross-entropy=2.440791368484497, Accuracy=0.07575757801532745\n",
      "Epoch 70 train: Cross-entropy=2.349085357454088, Accuracy=0.1527777777777778\n",
      "Epoch 70 validation: Cross-entropy=2.4410183429718018, Accuracy=0.07575757801532745\n",
      "Epoch 71 train: Cross-entropy=2.3488673766454062, Accuracy=0.15104166666666666\n",
      "Epoch 71 validation: Cross-entropy=2.4412412643432617, Accuracy=0.07575757801532745\n",
      "Epoch 72 train: Cross-entropy=2.348654376135932, Accuracy=0.14930555555555555\n",
      "Epoch 72 validation: Cross-entropy=2.441459894180298, Accuracy=0.07575757801532745\n",
      "Epoch 73 train: Cross-entropy=2.3484464089075723, Accuracy=0.14930555555555555\n",
      "Epoch 73 validation: Cross-entropy=2.4416744709014893, Accuracy=0.08080808073282242\n",
      "Epoch 74 train: Cross-entropy=2.348243104086982, Accuracy=0.14930555555555555\n",
      "Epoch 74 validation: Cross-entropy=2.4418842792510986, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.3480443822013006, Accuracy=0.15104166666666666\n",
      "Epoch 75 validation: Cross-entropy=2.4420905113220215, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.3478502697414823, Accuracy=0.15104166666666666\n",
      "Epoch 76 validation: Cross-entropy=2.4422926902770996, Accuracy=0.08080808073282242\n",
      "Epoch 77 train: Cross-entropy=2.347660462061564, Accuracy=0.15104166666666666\n",
      "Epoch 77 validation: Cross-entropy=2.442491054534912, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 train: Cross-entropy=2.347474972407023, Accuracy=0.1527777777777778\n",
      "Epoch 78 validation: Cross-entropy=2.442685604095459, Accuracy=0.08080808073282242\n",
      "Epoch 79 train: Cross-entropy=2.3472935491138034, Accuracy=0.1527777777777778\n",
      "Epoch 79 validation: Cross-entropy=2.442876100540161, Accuracy=0.08080808073282242\n",
      "Epoch 80 train: Cross-entropy=2.347115980254279, Accuracy=0.15625\n",
      "Epoch 80 validation: Cross-entropy=2.4430630207061768, Accuracy=0.08080808073282242\n",
      "Epoch 81 train: Cross-entropy=2.3469425042470298, Accuracy=0.15625\n",
      "Epoch 81 validation: Cross-entropy=2.443246841430664, Accuracy=0.08080808073282242\n",
      "Epoch 82 train: Cross-entropy=2.3467727369732327, Accuracy=0.1545138888888889\n",
      "Epoch 82 validation: Cross-entropy=2.4434268474578857, Accuracy=0.08080808073282242\n",
      "Epoch 83 train: Cross-entropy=2.346606718169318, Accuracy=0.1527777777777778\n",
      "Epoch 83 validation: Cross-entropy=2.443603277206421, Accuracy=0.08080808073282242\n",
      "Epoch 84 train: Cross-entropy=2.3464442226621838, Accuracy=0.1527777777777778\n",
      "Epoch 84 validation: Cross-entropy=2.443776845932007, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.346285197469923, Accuracy=0.1527777777777778\n",
      "Epoch 85 validation: Cross-entropy=2.4439468383789062, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.3461296558380127, Accuracy=0.1527777777777778\n",
      "Epoch 86 validation: Cross-entropy=2.4441134929656982, Accuracy=0.08080808073282242\n",
      "Epoch 87 train: Cross-entropy=2.3459774123297796, Accuracy=0.1527777777777778\n",
      "Epoch 87 validation: Cross-entropy=2.444277286529541, Accuracy=0.08080808073282242\n",
      "Epoch 88 train: Cross-entropy=2.345828413963318, Accuracy=0.1527777777777778\n",
      "Epoch 88 validation: Cross-entropy=2.4444379806518555, Accuracy=0.08080808073282242\n",
      "Epoch 89 train: Cross-entropy=2.3456824355655246, Accuracy=0.1527777777777778\n",
      "Epoch 89 validation: Cross-entropy=2.4445958137512207, Accuracy=0.08080808073282242\n",
      "Epoch 90 train: Cross-entropy=2.345539609591166, Accuracy=0.1527777777777778\n",
      "Epoch 90 validation: Cross-entropy=2.4447505474090576, Accuracy=0.08585858345031738\n",
      "Epoch 91 train: Cross-entropy=2.34539971086714, Accuracy=0.1527777777777778\n",
      "Epoch 91 validation: Cross-entropy=2.4449024200439453, Accuracy=0.08585858345031738\n",
      "Epoch 92 train: Cross-entropy=2.3452628586027355, Accuracy=0.1527777777777778\n",
      "Epoch 92 validation: Cross-entropy=2.445051670074463, Accuracy=0.08585858345031738\n",
      "Epoch 93 train: Cross-entropy=2.3451286951700845, Accuracy=0.1545138888888889\n",
      "Epoch 93 validation: Cross-entropy=2.4451980590820312, Accuracy=0.09090909361839294\n",
      "Epoch 94 train: Cross-entropy=2.3449974060058594, Accuracy=0.1545138888888889\n",
      "Epoch 94 validation: Cross-entropy=2.4453418254852295, Accuracy=0.09090909361839294\n",
      "Epoch 95 train: Cross-entropy=2.344868712955051, Accuracy=0.1545138888888889\n",
      "Epoch 95 validation: Cross-entropy=2.4454832077026367, Accuracy=0.09090909361839294\n",
      "Epoch 96 train: Cross-entropy=2.344742761717902, Accuracy=0.1545138888888889\n",
      "Epoch 96 validation: Cross-entropy=2.4456217288970947, Accuracy=0.09090909361839294\n",
      "Epoch 97 train: Cross-entropy=2.3446192741394043, Accuracy=0.1545138888888889\n",
      "Epoch 97 validation: Cross-entropy=2.4457578659057617, Accuracy=0.09090909361839294\n",
      "Epoch 98 train: Cross-entropy=2.3444983694288464, Accuracy=0.1545138888888889\n",
      "Epoch 98 validation: Cross-entropy=2.4458913803100586, Accuracy=0.09090909361839294\n",
      "Epoch 99 train: Cross-entropy=2.344379875395033, Accuracy=0.1545138888888889\n",
      "Epoch 99 validation: Cross-entropy=2.4460227489471436, Accuracy=0.09090909361839294\n",
      "Epoch 100 train: Cross-entropy=2.3442638317743936, Accuracy=0.15625\n",
      "Epoch 100 validation: Cross-entropy=2.4461514949798584, Accuracy=0.09090909361839294\n",
      "Epoch 101 train: Cross-entropy=2.344150119357639, Accuracy=0.15625\n",
      "Epoch 101 validation: Cross-entropy=2.4462783336639404, Accuracy=0.09090909361839294\n",
      "Epoch 102 train: Cross-entropy=2.3440386056900024, Accuracy=0.15625\n",
      "Epoch 102 validation: Cross-entropy=2.4464025497436523, Accuracy=0.09090909361839294\n",
      "Epoch 103 train: Cross-entropy=2.343929396735297, Accuracy=0.15625\n",
      "Epoch 103 validation: Cross-entropy=2.4465250968933105, Accuracy=0.09090909361839294\n",
      "Epoch 104 train: Cross-entropy=2.3438223203023276, Accuracy=0.15625\n",
      "Epoch 104 validation: Cross-entropy=2.4466450214385986, Accuracy=0.09595959633588791\n",
      "Epoch 105 train: Cross-entropy=2.3437172836727567, Accuracy=0.15625\n",
      "Epoch 105 validation: Cross-entropy=2.446763277053833, Accuracy=0.09595959633588791\n",
      "Epoch 106 train: Cross-entropy=2.3436144325468273, Accuracy=0.1579861111111111\n",
      "Epoch 106 validation: Cross-entropy=2.4468789100646973, Accuracy=0.09595959633588791\n",
      "Epoch 107 train: Cross-entropy=2.343513594733344, Accuracy=0.1579861111111111\n",
      "Epoch 107 validation: Cross-entropy=2.446992874145508, Accuracy=0.09595959633588791\n",
      "Epoch 108 train: Cross-entropy=2.343414823214213, Accuracy=0.1579861111111111\n",
      "Epoch 108 validation: Cross-entropy=2.4471049308776855, Accuracy=0.09595959633588791\n",
      "Epoch 109 train: Cross-entropy=2.3433178530799017, Accuracy=0.15625\n",
      "Epoch 109 validation: Cross-entropy=2.4472150802612305, Accuracy=0.09595959633588791\n",
      "Epoch 110 train: Cross-entropy=2.34322288301256, Accuracy=0.15625\n",
      "Epoch 110 validation: Cross-entropy=2.4473233222961426, Accuracy=0.09595959633588791\n",
      "Epoch 111 train: Cross-entropy=2.343129701084561, Accuracy=0.15625\n",
      "Epoch 111 validation: Cross-entropy=2.4474294185638428, Accuracy=0.09595959633588791\n",
      "Epoch 112 train: Cross-entropy=2.3430382940504284, Accuracy=0.15625\n",
      "Epoch 112 validation: Cross-entropy=2.4475340843200684, Accuracy=0.09595959633588791\n",
      "Epoch 113 train: Cross-entropy=2.342948741383023, Accuracy=0.15625\n",
      "Epoch 113 validation: Cross-entropy=2.447636842727661, Accuracy=0.09595959633588791\n",
      "Epoch 114 train: Cross-entropy=2.3428608311547174, Accuracy=0.15625\n",
      "Epoch 114 validation: Cross-entropy=2.4477379322052, Accuracy=0.09595959633588791\n",
      "Epoch 115 train: Cross-entropy=2.3427747355567083, Accuracy=0.15625\n",
      "Epoch 115 validation: Cross-entropy=2.4478373527526855, Accuracy=0.09595959633588791\n",
      "Epoch 116 train: Cross-entropy=2.342690216170417, Accuracy=0.1579861111111111\n",
      "Epoch 116 validation: Cross-entropy=2.447935104370117, Accuracy=0.09595959633588791\n",
      "Epoch 117 train: Cross-entropy=2.3426074186960855, Accuracy=0.15625\n",
      "Epoch 117 validation: Cross-entropy=2.448030948638916, Accuracy=0.09595959633588791\n",
      "Epoch 118 train: Cross-entropy=2.3425261047151356, Accuracy=0.15625\n",
      "Epoch 118 validation: Cross-entropy=2.4481258392333984, Accuracy=0.09595959633588791\n",
      "Epoch 119 train: Cross-entropy=2.342446393436856, Accuracy=0.15625\n",
      "Epoch 119 validation: Cross-entropy=2.44821834564209, Accuracy=0.09595959633588791\n",
      "Epoch 120 train: Cross-entropy=2.342368205388387, Accuracy=0.15625\n",
      "Epoch 120 validation: Cross-entropy=2.448309898376465, Accuracy=0.09595959633588791\n",
      "Epoch 121 train: Cross-entropy=2.342291474342346, Accuracy=0.15625\n",
      "Epoch 121 validation: Cross-entropy=2.4484002590179443, Accuracy=0.09595959633588791\n",
      "Epoch 122 train: Cross-entropy=2.342216240035163, Accuracy=0.15625\n",
      "Epoch 122 validation: Cross-entropy=2.448488473892212, Accuracy=0.09595959633588791\n",
      "Epoch 123 train: Cross-entropy=2.342142422993978, Accuracy=0.15625\n",
      "Epoch 123 validation: Cross-entropy=2.448575496673584, Accuracy=0.09595959633588791\n",
      "Epoch 124 train: Cross-entropy=2.3420700232187905, Accuracy=0.15625\n",
      "Epoch 124 validation: Cross-entropy=2.4486613273620605, Accuracy=0.09595959633588791\n",
      "Epoch 125 train: Cross-entropy=2.3419989479912653, Accuracy=0.15625\n",
      "Epoch 125 validation: Cross-entropy=2.4487457275390625, Accuracy=0.09595959633588791\n",
      "Epoch 126 train: Cross-entropy=2.3419292900297375, Accuracy=0.15625\n",
      "Epoch 126 validation: Cross-entropy=2.44882869720459, Accuracy=0.09595959633588791\n",
      "Epoch 127 train: Cross-entropy=2.3418609301249185, Accuracy=0.15625\n",
      "Epoch 127 validation: Cross-entropy=2.4489104747772217, Accuracy=0.09595959633588791\n",
      "Epoch 128 train: Cross-entropy=2.341793841785855, Accuracy=0.15625\n",
      "Epoch 128 validation: Cross-entropy=2.448991060256958, Accuracy=0.09595959633588791\n",
      "Epoch 129 train: Cross-entropy=2.341728025012546, Accuracy=0.15625\n",
      "Epoch 129 validation: Cross-entropy=2.4490702152252197, Accuracy=0.09595959633588791\n",
      "Epoch 130 train: Cross-entropy=2.3416634533140392, Accuracy=0.1579861111111111\n",
      "Epoch 130 validation: Cross-entropy=2.449147939682007, Accuracy=0.09595959633588791\n",
      "Epoch 131 train: Cross-entropy=2.3416000074810452, Accuracy=0.1579861111111111\n",
      "Epoch 131 validation: Cross-entropy=2.4492247104644775, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 train: Cross-entropy=2.3415378067228527, Accuracy=0.1579861111111111\n",
      "Epoch 132 validation: Cross-entropy=2.449300527572632, Accuracy=0.09595959633588791\n",
      "Epoch 133 train: Cross-entropy=2.3414768642849393, Accuracy=0.1579861111111111\n",
      "Epoch 133 validation: Cross-entropy=2.4493749141693115, Accuracy=0.09595959633588791\n",
      "Epoch 134 train: Cross-entropy=2.3414169285032482, Accuracy=0.1579861111111111\n",
      "Epoch 134 validation: Cross-entropy=2.449448347091675, Accuracy=0.09595959633588791\n",
      "Epoch 135 train: Cross-entropy=2.3413581583234997, Accuracy=0.1579861111111111\n",
      "Epoch 135 validation: Cross-entropy=2.4495205879211426, Accuracy=0.09595959633588791\n",
      "Epoch 136 train: Cross-entropy=2.3413005669911704, Accuracy=0.1579861111111111\n",
      "Epoch 136 validation: Cross-entropy=2.4495913982391357, Accuracy=0.09595959633588791\n",
      "Epoch 137 train: Cross-entropy=2.341243929333157, Accuracy=0.1579861111111111\n",
      "Epoch 137 validation: Cross-entropy=2.4496614933013916, Accuracy=0.09595959633588791\n",
      "Epoch 138 train: Cross-entropy=2.3411883778042264, Accuracy=0.15625\n",
      "Epoch 138 validation: Cross-entropy=2.449730634689331, Accuracy=0.09595959633588791\n",
      "Epoch 139 train: Cross-entropy=2.3411339124043784, Accuracy=0.15625\n",
      "Epoch 139 validation: Cross-entropy=2.449798583984375, Accuracy=0.09595959633588791\n",
      "Epoch 140 train: Cross-entropy=2.3410804006788464, Accuracy=0.15625\n",
      "Epoch 140 validation: Cross-entropy=2.4498655796051025, Accuracy=0.09595959633588791\n",
      "Epoch 141 train: Cross-entropy=2.341027948591444, Accuracy=0.15625\n",
      "Epoch 141 validation: Cross-entropy=2.4499313831329346, Accuracy=0.09595959633588791\n",
      "Epoch 142 train: Cross-entropy=2.340976450178358, Accuracy=0.1545138888888889\n",
      "Epoch 142 validation: Cross-entropy=2.44999623298645, Accuracy=0.09595959633588791\n",
      "Epoch 143 train: Cross-entropy=2.3409259054395886, Accuracy=0.1545138888888889\n",
      "Epoch 143 validation: Cross-entropy=2.4500603675842285, Accuracy=0.09595959633588791\n",
      "Epoch 144 train: Cross-entropy=2.3408762084113226, Accuracy=0.1545138888888889\n",
      "Epoch 144 validation: Cross-entropy=2.4501235485076904, Accuracy=0.09595959633588791\n",
      "Epoch 145 train: Cross-entropy=2.340827571021186, Accuracy=0.1545138888888889\n",
      "Epoch 145 validation: Cross-entropy=2.450186014175415, Accuracy=0.09595959633588791\n",
      "Epoch 146 train: Cross-entropy=2.3407797548505993, Accuracy=0.1545138888888889\n",
      "Epoch 146 validation: Cross-entropy=2.4502475261688232, Accuracy=0.09595959633588791\n",
      "Epoch 147 train: Cross-entropy=2.3407328526178994, Accuracy=0.1545138888888889\n",
      "Epoch 147 validation: Cross-entropy=2.450308084487915, Accuracy=0.09595959633588791\n",
      "Epoch 148 train: Cross-entropy=2.3406868510776095, Accuracy=0.1527777777777778\n",
      "Epoch 148 validation: Cross-entropy=2.4503676891326904, Accuracy=0.09595959633588791\n",
      "Epoch 149 train: Cross-entropy=2.3406416840023465, Accuracy=0.1527777777777778\n",
      "Epoch 149 validation: Cross-entropy=2.4504263401031494, Accuracy=0.09595959633588791\n",
      "Epoch 150 train: Cross-entropy=2.34059731165568, Accuracy=0.1527777777777778\n",
      "Epoch 150 validation: Cross-entropy=2.45048451423645, Accuracy=0.09595959633588791\n",
      "Epoch 151 train: Cross-entropy=2.340553773774041, Accuracy=0.1527777777777778\n",
      "Epoch 151 validation: Cross-entropy=2.4505417346954346, Accuracy=0.09595959633588791\n",
      "Epoch 152 train: Cross-entropy=2.340511057111952, Accuracy=0.1527777777777778\n",
      "Epoch 152 validation: Cross-entropy=2.4505984783172607, Accuracy=0.09595959633588791\n",
      "Epoch 153 train: Cross-entropy=2.3404691086875067, Accuracy=0.1527777777777778\n",
      "Epoch 153 validation: Cross-entropy=2.4506540298461914, Accuracy=0.09595959633588791\n",
      "Epoch 154 train: Cross-entropy=2.3404279814826117, Accuracy=0.1527777777777778\n",
      "Epoch 154 validation: Cross-entropy=2.4507088661193848, Accuracy=0.09090909361839294\n",
      "Epoch 155 train: Cross-entropy=2.340387609269884, Accuracy=0.1527777777777778\n",
      "Epoch 155 validation: Cross-entropy=2.45076322555542, Accuracy=0.09090909361839294\n",
      "Epoch 156 train: Cross-entropy=2.34034796555837, Accuracy=0.1545138888888889\n",
      "Epoch 156 validation: Cross-entropy=2.4508166313171387, Accuracy=0.09090909361839294\n",
      "Epoch 157 train: Cross-entropy=2.3403090371025934, Accuracy=0.1545138888888889\n",
      "Epoch 157 validation: Cross-entropy=2.450869083404541, Accuracy=0.09090909361839294\n",
      "Epoch 158 train: Cross-entropy=2.3402708768844604, Accuracy=0.1545138888888889\n",
      "Epoch 158 validation: Cross-entropy=2.4509212970733643, Accuracy=0.09090909361839294\n",
      "Epoch 159 train: Cross-entropy=2.3402333789401584, Accuracy=0.1545138888888889\n",
      "Epoch 159 validation: Cross-entropy=2.45097279548645, Accuracy=0.09090909361839294\n",
      "Epoch 160 train: Cross-entropy=2.3401966624789767, Accuracy=0.1545138888888889\n",
      "Epoch 160 validation: Cross-entropy=2.4510233402252197, Accuracy=0.09090909361839294\n",
      "Epoch 161 train: Cross-entropy=2.340160528818766, Accuracy=0.1545138888888889\n",
      "Epoch 161 validation: Cross-entropy=2.45107364654541, Accuracy=0.09090909361839294\n",
      "Epoch 162 train: Cross-entropy=2.3401251369052463, Accuracy=0.1545138888888889\n",
      "Epoch 162 validation: Cross-entropy=2.451122760772705, Accuracy=0.09090909361839294\n",
      "Epoch 163 train: Cross-entropy=2.3400903277926974, Accuracy=0.1545138888888889\n",
      "Epoch 163 validation: Cross-entropy=2.451171636581421, Accuracy=0.09090909361839294\n",
      "Epoch 164 train: Cross-entropy=2.340056194199456, Accuracy=0.1545138888888889\n",
      "Epoch 164 validation: Cross-entropy=2.4512200355529785, Accuracy=0.09090909361839294\n",
      "Epoch 165 train: Cross-entropy=2.3400227626164756, Accuracy=0.1545138888888889\n",
      "Epoch 165 validation: Cross-entropy=2.4512674808502197, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.339989847607083, Accuracy=0.1545138888888889\n",
      "Epoch 166 validation: Cross-entropy=2.4513142108917236, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.3399575683805676, Accuracy=0.1545138888888889\n",
      "Epoch 167 validation: Cross-entropy=2.4513609409332275, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.3399259779188366, Accuracy=0.1545138888888889\n",
      "Epoch 168 validation: Cross-entropy=2.451406717300415, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.339894864294264, Accuracy=0.1545138888888889\n",
      "Epoch 169 validation: Cross-entropy=2.4514520168304443, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.339864386452569, Accuracy=0.1527777777777778\n",
      "Epoch 170 validation: Cross-entropy=2.4514963626861572, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.3398345046573215, Accuracy=0.1545138888888889\n",
      "Epoch 171 validation: Cross-entropy=2.451540231704712, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.339805112944709, Accuracy=0.1545138888888889\n",
      "Epoch 172 validation: Cross-entropy=2.4515841007232666, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.3397762775421143, Accuracy=0.1545138888888889\n",
      "Epoch 173 validation: Cross-entropy=2.451627254486084, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.3397480646769204, Accuracy=0.1527777777777778\n",
      "Epoch 174 validation: Cross-entropy=2.451669931411743, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.339720302157932, Accuracy=0.1527777777777778\n",
      "Epoch 175 validation: Cross-entropy=2.451711654663086, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.3396931091944375, Accuracy=0.15625\n",
      "Epoch 176 validation: Cross-entropy=2.4517531394958496, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.3396663665771484, Accuracy=0.15625\n",
      "Epoch 177 validation: Cross-entropy=2.4517946243286133, Accuracy=0.09090909361839294\n",
      "Epoch 178 train: Cross-entropy=2.3396401935153537, Accuracy=0.15625\n",
      "Epoch 178 validation: Cross-entropy=2.4518349170684814, Accuracy=0.09090909361839294\n",
      "Epoch 179 train: Cross-entropy=2.3396144840452404, Accuracy=0.15625\n",
      "Epoch 179 validation: Cross-entropy=2.4518749713897705, Accuracy=0.09090909361839294\n",
      "Epoch 180 train: Cross-entropy=2.339589251412286, Accuracy=0.15625\n",
      "Epoch 180 validation: Cross-entropy=2.4519150257110596, Accuracy=0.09090909361839294\n",
      "Epoch 181 train: Cross-entropy=2.339564469125536, Accuracy=0.15625\n",
      "Epoch 181 validation: Cross-entropy=2.451953887939453, Accuracy=0.09090909361839294\n",
      "Epoch 182 train: Cross-entropy=2.3395401769214206, Accuracy=0.15625\n",
      "Epoch 182 validation: Cross-entropy=2.4519927501678467, Accuracy=0.09090909361839294\n",
      "Epoch 183 train: Cross-entropy=2.3395163218180337, Accuracy=0.15625\n",
      "Epoch 183 validation: Cross-entropy=2.452030897140503, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 train: Cross-entropy=2.339492983288235, Accuracy=0.15625\n",
      "Epoch 184 validation: Cross-entropy=2.45206880569458, Accuracy=0.09090909361839294\n",
      "Epoch 185 train: Cross-entropy=2.339470108350118, Accuracy=0.15625\n",
      "Epoch 185 validation: Cross-entropy=2.452106475830078, Accuracy=0.09090909361839294\n",
      "Epoch 186 train: Cross-entropy=2.33944751156701, Accuracy=0.15625\n",
      "Epoch 186 validation: Cross-entropy=2.452143669128418, Accuracy=0.09090909361839294\n",
      "Epoch 187 train: Cross-entropy=2.3394254975848727, Accuracy=0.15625\n",
      "Epoch 187 validation: Cross-entropy=2.4521801471710205, Accuracy=0.09090909361839294\n",
      "Epoch 188 train: Cross-entropy=2.3394038809670343, Accuracy=0.15625\n",
      "Epoch 188 validation: Cross-entropy=2.452216625213623, Accuracy=0.09090909361839294\n",
      "Epoch 189 train: Cross-entropy=2.339382621977064, Accuracy=0.1579861111111111\n",
      "Epoch 189 validation: Cross-entropy=2.4522523880004883, Accuracy=0.09090909361839294\n",
      "Epoch 190 train: Cross-entropy=2.3393617603513928, Accuracy=0.1579861111111111\n",
      "Epoch 190 validation: Cross-entropy=2.4522876739501953, Accuracy=0.09090909361839294\n",
      "Epoch 191 train: Cross-entropy=2.33934133582645, Accuracy=0.1597222222222222\n",
      "Epoch 191 validation: Cross-entropy=2.4523229598999023, Accuracy=0.09090909361839294\n",
      "Epoch 192 train: Cross-entropy=2.3393213086658053, Accuracy=0.1597222222222222\n",
      "Epoch 192 validation: Cross-entropy=2.4523580074310303, Accuracy=0.09090909361839294\n",
      "Epoch 193 train: Cross-entropy=2.339301665623983, Accuracy=0.1597222222222222\n",
      "Epoch 193 validation: Cross-entropy=2.452392339706421, Accuracy=0.09090909361839294\n",
      "Epoch 194 train: Cross-entropy=2.3392823934555054, Accuracy=0.1597222222222222\n",
      "Epoch 194 validation: Cross-entropy=2.4524264335632324, Accuracy=0.09090909361839294\n",
      "Epoch 195 train: Cross-entropy=2.339263492160373, Accuracy=0.1597222222222222\n",
      "Epoch 195 validation: Cross-entropy=2.4524600505828857, Accuracy=0.09090909361839294\n",
      "Epoch 196 train: Cross-entropy=2.339244935247633, Accuracy=0.1597222222222222\n",
      "Epoch 196 validation: Cross-entropy=2.45249342918396, Accuracy=0.09090909361839294\n",
      "Epoch 197 train: Cross-entropy=2.3392267492082386, Accuracy=0.1597222222222222\n",
      "Epoch 197 validation: Cross-entropy=2.452526092529297, Accuracy=0.09090909361839294\n",
      "Epoch 198 train: Cross-entropy=2.3392088810602822, Accuracy=0.16145833333333334\n",
      "Epoch 198 validation: Cross-entropy=2.452558755874634, Accuracy=0.09090909361839294\n",
      "Epoch 199 train: Cross-entropy=2.339191516240438, Accuracy=0.16145833333333334\n",
      "Epoch 199 validation: Cross-entropy=2.4525911808013916, Accuracy=0.09090909361839294\n",
      "Epoch 0 train: Cross-entropy=2.439157313770718, Accuracy=0.057291666666666664\n",
      "Epoch 0 validation: Cross-entropy=2.4072885513305664, Accuracy=0.09595959633588791\n",
      "Epoch 1 train: Cross-entropy=2.424284471405877, Accuracy=0.07291666666666667\n",
      "Epoch 1 validation: Cross-entropy=2.402634382247925, Accuracy=0.10606060922145844\n",
      "Epoch 2 train: Cross-entropy=2.4173543055852256, Accuracy=0.07465277777777778\n",
      "Epoch 2 validation: Cross-entropy=2.403688669204712, Accuracy=0.1111111119389534\n",
      "Epoch 3 train: Cross-entropy=2.4123741653230457, Accuracy=0.078125\n",
      "Epoch 3 validation: Cross-entropy=2.4049072265625, Accuracy=0.09090909361839294\n",
      "Epoch 4 train: Cross-entropy=2.408043146133423, Accuracy=0.0798611111111111\n",
      "Epoch 4 validation: Cross-entropy=2.406200885772705, Accuracy=0.07070706784725189\n",
      "Epoch 5 train: Cross-entropy=2.4041384723451404, Accuracy=0.078125\n",
      "Epoch 5 validation: Cross-entropy=2.4075918197631836, Accuracy=0.06565656512975693\n",
      "Epoch 6 train: Cross-entropy=2.400630964173211, Accuracy=0.08159722222222222\n",
      "Epoch 6 validation: Cross-entropy=2.40903639793396, Accuracy=0.06060606241226196\n",
      "Epoch 7 train: Cross-entropy=2.39746191766527, Accuracy=0.09722222222222222\n",
      "Epoch 7 validation: Cross-entropy=2.410511016845703, Accuracy=0.06060606241226196\n",
      "Epoch 8 train: Cross-entropy=2.394584642516242, Accuracy=0.10069444444444445\n",
      "Epoch 8 validation: Cross-entropy=2.411996603012085, Accuracy=0.06565656512975693\n",
      "Epoch 9 train: Cross-entropy=2.3919605016708374, Accuracy=0.10243055555555555\n",
      "Epoch 9 validation: Cross-entropy=2.4134786128997803, Accuracy=0.07070706784725189\n",
      "Epoch 10 train: Cross-entropy=2.389557229148017, Accuracy=0.10590277777777778\n",
      "Epoch 10 validation: Cross-entropy=2.4149460792541504, Accuracy=0.07575757801532745\n",
      "Epoch 11 train: Cross-entropy=2.3873478041754828, Accuracy=0.10416666666666667\n",
      "Epoch 11 validation: Cross-entropy=2.4163901805877686, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.3853091531329684, Accuracy=0.10416666666666667\n",
      "Epoch 12 validation: Cross-entropy=2.4178054332733154, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.3834218316608005, Accuracy=0.1076388888888889\n",
      "Epoch 13 validation: Cross-entropy=2.419187068939209, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.381669216685825, Accuracy=0.109375\n",
      "Epoch 14 validation: Cross-entropy=2.420531988143921, Accuracy=0.08585858345031738\n",
      "Epoch 15 train: Cross-entropy=2.3800370693206787, Accuracy=0.1076388888888889\n",
      "Epoch 15 validation: Cross-entropy=2.4218380451202393, Accuracy=0.08585858345031738\n",
      "Epoch 16 train: Cross-entropy=2.378513084517585, Accuracy=0.109375\n",
      "Epoch 16 validation: Cross-entropy=2.4231042861938477, Accuracy=0.09090909361839294\n",
      "Epoch 17 train: Cross-entropy=2.377086559931437, Accuracy=0.1076388888888889\n",
      "Epoch 17 validation: Cross-entropy=2.424329996109009, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.37574831644694, Accuracy=0.109375\n",
      "Epoch 18 validation: Cross-entropy=2.4255154132843018, Accuracy=0.09595959633588791\n",
      "Epoch 19 train: Cross-entropy=2.3744902080959744, Accuracy=0.1111111111111111\n",
      "Epoch 19 validation: Cross-entropy=2.4266598224639893, Accuracy=0.09595959633588791\n",
      "Epoch 20 train: Cross-entropy=2.3733051353030734, Accuracy=0.11458333333333333\n",
      "Epoch 20 validation: Cross-entropy=2.427764654159546, Accuracy=0.10101009905338287\n",
      "Epoch 21 train: Cross-entropy=2.3721868329577975, Accuracy=0.11458333333333333\n",
      "Epoch 21 validation: Cross-entropy=2.428830623626709, Accuracy=0.10606060922145844\n",
      "Epoch 22 train: Cross-entropy=2.3711298836602106, Accuracy=0.11458333333333333\n",
      "Epoch 22 validation: Cross-entropy=2.4298582077026367, Accuracy=0.10606060922145844\n",
      "Epoch 23 train: Cross-entropy=2.3701293336020575, Accuracy=0.11458333333333333\n",
      "Epoch 23 validation: Cross-entropy=2.4308483600616455, Accuracy=0.10606060922145844\n",
      "Epoch 24 train: Cross-entropy=2.3691806528303356, Accuracy=0.11805555555555555\n",
      "Epoch 24 validation: Cross-entropy=2.431802988052368, Accuracy=0.10101009905338287\n",
      "Epoch 25 train: Cross-entropy=2.3682801326115928, Accuracy=0.11979166666666667\n",
      "Epoch 25 validation: Cross-entropy=2.432722330093384, Accuracy=0.10101009905338287\n",
      "Epoch 26 train: Cross-entropy=2.367424143685235, Accuracy=0.11979166666666667\n",
      "Epoch 26 validation: Cross-entropy=2.433608293533325, Accuracy=0.10101009905338287\n",
      "Epoch 27 train: Cross-entropy=2.3666096925735474, Accuracy=0.11979166666666667\n",
      "Epoch 27 validation: Cross-entropy=2.4344615936279297, Accuracy=0.10101009905338287\n",
      "Epoch 28 train: Cross-entropy=2.3658337195714316, Accuracy=0.11979166666666667\n",
      "Epoch 28 validation: Cross-entropy=2.435283660888672, Accuracy=0.10101009905338287\n",
      "Epoch 29 train: Cross-entropy=2.3650936815473766, Accuracy=0.11979166666666667\n",
      "Epoch 29 validation: Cross-entropy=2.43607497215271, Accuracy=0.10606060922145844\n",
      "Epoch 30 train: Cross-entropy=2.3643873665067883, Accuracy=0.11979166666666667\n",
      "Epoch 30 validation: Cross-entropy=2.436837911605835, Accuracy=0.10606060922145844\n",
      "Epoch 31 train: Cross-entropy=2.363712509473165, Accuracy=0.11979166666666667\n",
      "Epoch 31 validation: Cross-entropy=2.437572479248047, Accuracy=0.10101009905338287\n",
      "Epoch 32 train: Cross-entropy=2.3630671898523965, Accuracy=0.12152777777777778\n",
      "Epoch 32 validation: Cross-entropy=2.4382805824279785, Accuracy=0.09595959633588791\n",
      "Epoch 33 train: Cross-entropy=2.3624495930141873, Accuracy=0.11979166666666667\n",
      "Epoch 33 validation: Cross-entropy=2.43896222114563, Accuracy=0.09595959633588791\n",
      "Epoch 34 train: Cross-entropy=2.3618582089742026, Accuracy=0.11979166666666667\n",
      "Epoch 34 validation: Cross-entropy=2.439619302749634, Accuracy=0.09595959633588791\n",
      "Epoch 35 train: Cross-entropy=2.3612913158204822, Accuracy=0.12152777777777778\n",
      "Epoch 35 validation: Cross-entropy=2.4402525424957275, Accuracy=0.09595959633588791\n",
      "Epoch 36 train: Cross-entropy=2.360747708214654, Accuracy=0.1232638888888889\n",
      "Epoch 36 validation: Cross-entropy=2.4408631324768066, Accuracy=0.09595959633588791\n",
      "Epoch 37 train: Cross-entropy=2.360226035118103, Accuracy=0.1232638888888889\n",
      "Epoch 37 validation: Cross-entropy=2.44145131111145, Accuracy=0.09595959633588791\n",
      "Epoch 38 train: Cross-entropy=2.3597251574198403, Accuracy=0.1267361111111111\n",
      "Epoch 38 validation: Cross-entropy=2.442018508911133, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 train: Cross-entropy=2.3592438565360174, Accuracy=0.1267361111111111\n",
      "Epoch 39 validation: Cross-entropy=2.442565441131592, Accuracy=0.09595959633588791\n",
      "Epoch 40 train: Cross-entropy=2.3587812847561307, Accuracy=0.1267361111111111\n",
      "Epoch 40 validation: Cross-entropy=2.4430930614471436, Accuracy=0.09595959633588791\n",
      "Epoch 41 train: Cross-entropy=2.358336249987284, Accuracy=0.13020833333333334\n",
      "Epoch 41 validation: Cross-entropy=2.443601608276367, Accuracy=0.09595959633588791\n",
      "Epoch 42 train: Cross-entropy=2.357908156183031, Accuracy=0.13020833333333334\n",
      "Epoch 42 validation: Cross-entropy=2.444092035293579, Accuracy=0.09595959633588791\n",
      "Epoch 43 train: Cross-entropy=2.357495996687147, Accuracy=0.13194444444444445\n",
      "Epoch 43 validation: Cross-entropy=2.4445652961730957, Accuracy=0.09595959633588791\n",
      "Epoch 44 train: Cross-entropy=2.35709908273485, Accuracy=0.13194444444444445\n",
      "Epoch 44 validation: Cross-entropy=2.445021867752075, Accuracy=0.09595959633588791\n",
      "Epoch 45 train: Cross-entropy=2.356716593106588, Accuracy=0.13541666666666666\n",
      "Epoch 45 validation: Cross-entropy=2.445462226867676, Accuracy=0.09595959633588791\n",
      "Epoch 46 train: Cross-entropy=2.35634798473782, Accuracy=0.13541666666666666\n",
      "Epoch 46 validation: Cross-entropy=2.4458868503570557, Accuracy=0.09595959633588791\n",
      "Epoch 47 train: Cross-entropy=2.3559924761454263, Accuracy=0.13541666666666666\n",
      "Epoch 47 validation: Cross-entropy=2.4462971687316895, Accuracy=0.09595959633588791\n",
      "Epoch 48 train: Cross-entropy=2.3556496832105847, Accuracy=0.13541666666666666\n",
      "Epoch 48 validation: Cross-entropy=2.44669246673584, Accuracy=0.09595959633588791\n",
      "Epoch 49 train: Cross-entropy=2.355318930413988, Accuracy=0.13541666666666666\n",
      "Epoch 49 validation: Cross-entropy=2.4470744132995605, Accuracy=0.09595959633588791\n",
      "Epoch 50 train: Cross-entropy=2.3549996084637113, Accuracy=0.13541666666666666\n",
      "Epoch 50 validation: Cross-entropy=2.4474432468414307, Accuracy=0.09595959633588791\n",
      "Epoch 51 train: Cross-entropy=2.354691412713793, Accuracy=0.13541666666666666\n",
      "Epoch 51 validation: Cross-entropy=2.447798728942871, Accuracy=0.09595959633588791\n",
      "Epoch 52 train: Cross-entropy=2.3543936941358776, Accuracy=0.13541666666666666\n",
      "Epoch 52 validation: Cross-entropy=2.4481420516967773, Accuracy=0.09595959633588791\n",
      "Epoch 53 train: Cross-entropy=2.3541061083475747, Accuracy=0.13541666666666666\n",
      "Epoch 53 validation: Cross-entropy=2.4484736919403076, Accuracy=0.09595959633588791\n",
      "Epoch 54 train: Cross-entropy=2.3538282447391086, Accuracy=0.13541666666666666\n",
      "Epoch 54 validation: Cross-entropy=2.448793649673462, Accuracy=0.09595959633588791\n",
      "Epoch 55 train: Cross-entropy=2.353559719191657, Accuracy=0.13541666666666666\n",
      "Epoch 55 validation: Cross-entropy=2.4491026401519775, Accuracy=0.09595959633588791\n",
      "Epoch 56 train: Cross-entropy=2.3533001475863986, Accuracy=0.13541666666666666\n",
      "Epoch 56 validation: Cross-entropy=2.4494006633758545, Accuracy=0.09595959633588791\n",
      "Epoch 57 train: Cross-entropy=2.3530490928226047, Accuracy=0.13541666666666666\n",
      "Epoch 57 validation: Cross-entropy=2.44968843460083, Accuracy=0.09595959633588791\n",
      "Epoch 58 train: Cross-entropy=2.3528063429726496, Accuracy=0.13541666666666666\n",
      "Epoch 58 validation: Cross-entropy=2.4499661922454834, Accuracy=0.09595959633588791\n",
      "Epoch 59 train: Cross-entropy=2.352571580145094, Accuracy=0.13541666666666666\n",
      "Epoch 59 validation: Cross-entropy=2.4502344131469727, Accuracy=0.09595959633588791\n",
      "Epoch 60 train: Cross-entropy=2.3523444069756403, Accuracy=0.1371527777777778\n",
      "Epoch 60 validation: Cross-entropy=2.450493335723877, Accuracy=0.09595959633588791\n",
      "Epoch 61 train: Cross-entropy=2.352124638027615, Accuracy=0.1371527777777778\n",
      "Epoch 61 validation: Cross-entropy=2.4507431983947754, Accuracy=0.09595959633588791\n",
      "Epoch 62 train: Cross-entropy=2.35191191567315, Accuracy=0.1371527777777778\n",
      "Epoch 62 validation: Cross-entropy=2.450984477996826, Accuracy=0.09595959633588791\n",
      "Epoch 63 train: Cross-entropy=2.3517060809665256, Accuracy=0.1371527777777778\n",
      "Epoch 63 validation: Cross-entropy=2.45121693611145, Accuracy=0.09595959633588791\n",
      "Epoch 64 train: Cross-entropy=2.3515067630343967, Accuracy=0.1371527777777778\n",
      "Epoch 64 validation: Cross-entropy=2.451441526412964, Accuracy=0.09595959633588791\n",
      "Epoch 65 train: Cross-entropy=2.3513138559129505, Accuracy=0.1371527777777778\n",
      "Epoch 65 validation: Cross-entropy=2.451658248901367, Accuracy=0.09595959633588791\n",
      "Epoch 66 train: Cross-entropy=2.3511270549562244, Accuracy=0.1388888888888889\n",
      "Epoch 66 validation: Cross-entropy=2.4518675804138184, Accuracy=0.09595959633588791\n",
      "Epoch 67 train: Cross-entropy=2.350946201218499, Accuracy=0.1371527777777778\n",
      "Epoch 67 validation: Cross-entropy=2.4520692825317383, Accuracy=0.09595959633588791\n",
      "Epoch 68 train: Cross-entropy=2.350771043035719, Accuracy=0.1371527777777778\n",
      "Epoch 68 validation: Cross-entropy=2.4522640705108643, Accuracy=0.09595959633588791\n",
      "Epoch 69 train: Cross-entropy=2.3506013684802585, Accuracy=0.1371527777777778\n",
      "Epoch 69 validation: Cross-entropy=2.452451467514038, Accuracy=0.09595959633588791\n",
      "Epoch 70 train: Cross-entropy=2.350437137815687, Accuracy=0.1371527777777778\n",
      "Epoch 70 validation: Cross-entropy=2.4526326656341553, Accuracy=0.09595959633588791\n",
      "Epoch 71 train: Cross-entropy=2.3502779404322305, Accuracy=0.1371527777777778\n",
      "Epoch 71 validation: Cross-entropy=2.4528071880340576, Accuracy=0.09595959633588791\n",
      "Epoch 72 train: Cross-entropy=2.3501238558027477, Accuracy=0.1371527777777778\n",
      "Epoch 72 validation: Cross-entropy=2.452975273132324, Accuracy=0.09595959633588791\n",
      "Epoch 73 train: Cross-entropy=2.3499744865629406, Accuracy=0.1371527777777778\n",
      "Epoch 73 validation: Cross-entropy=2.4531373977661133, Accuracy=0.09595959633588791\n",
      "Epoch 74 train: Cross-entropy=2.349829819467333, Accuracy=0.1371527777777778\n",
      "Epoch 74 validation: Cross-entropy=2.453294038772583, Accuracy=0.09595959633588791\n",
      "Epoch 75 train: Cross-entropy=2.3496896823247275, Accuracy=0.1371527777777778\n",
      "Epoch 75 validation: Cross-entropy=2.453444242477417, Accuracy=0.09595959633588791\n",
      "Epoch 76 train: Cross-entropy=2.3495539824167886, Accuracy=0.1371527777777778\n",
      "Epoch 76 validation: Cross-entropy=2.4535892009735107, Accuracy=0.09090909361839294\n",
      "Epoch 77 train: Cross-entropy=2.349422401852078, Accuracy=0.1371527777777778\n",
      "Epoch 77 validation: Cross-entropy=2.4537289142608643, Accuracy=0.09090909361839294\n",
      "Epoch 78 train: Cross-entropy=2.3492950995763144, Accuracy=0.1371527777777778\n",
      "Epoch 78 validation: Cross-entropy=2.4538633823394775, Accuracy=0.09090909361839294\n",
      "Epoch 79 train: Cross-entropy=2.3491717179616294, Accuracy=0.1371527777777778\n",
      "Epoch 79 validation: Cross-entropy=2.4539928436279297, Accuracy=0.09090909361839294\n",
      "Epoch 80 train: Cross-entropy=2.3490521377987332, Accuracy=0.1388888888888889\n",
      "Epoch 80 validation: Cross-entropy=2.4541172981262207, Accuracy=0.09090909361839294\n",
      "Epoch 81 train: Cross-entropy=2.3489363855785794, Accuracy=0.140625\n",
      "Epoch 81 validation: Cross-entropy=2.4542369842529297, Accuracy=0.09090909361839294\n",
      "Epoch 82 train: Cross-entropy=2.3488242758644953, Accuracy=0.1423611111111111\n",
      "Epoch 82 validation: Cross-entropy=2.4543521404266357, Accuracy=0.09090909361839294\n",
      "Epoch 83 train: Cross-entropy=2.3487156364652844, Accuracy=0.1423611111111111\n",
      "Epoch 83 validation: Cross-entropy=2.4544625282287598, Accuracy=0.09090909361839294\n",
      "Epoch 84 train: Cross-entropy=2.348610440889994, Accuracy=0.1423611111111111\n",
      "Epoch 84 validation: Cross-entropy=2.454568862915039, Accuracy=0.09090909361839294\n",
      "Epoch 85 train: Cross-entropy=2.3485085831748114, Accuracy=0.1423611111111111\n",
      "Epoch 85 validation: Cross-entropy=2.4546709060668945, Accuracy=0.09090909361839294\n",
      "Epoch 86 train: Cross-entropy=2.3484099043740168, Accuracy=0.1423611111111111\n",
      "Epoch 86 validation: Cross-entropy=2.4547688961029053, Accuracy=0.09090909361839294\n",
      "Epoch 87 train: Cross-entropy=2.3483144574695163, Accuracy=0.1423611111111111\n",
      "Epoch 87 validation: Cross-entropy=2.4548630714416504, Accuracy=0.09090909361839294\n",
      "Epoch 88 train: Cross-entropy=2.3482220437791614, Accuracy=0.1423611111111111\n",
      "Epoch 88 validation: Cross-entropy=2.454953193664551, Accuracy=0.09090909361839294\n",
      "Epoch 89 train: Cross-entropy=2.348132544093662, Accuracy=0.1423611111111111\n",
      "Epoch 89 validation: Cross-entropy=2.4550392627716064, Accuracy=0.09090909361839294\n",
      "Epoch 90 train: Cross-entropy=2.348045984903971, Accuracy=0.1423611111111111\n",
      "Epoch 90 validation: Cross-entropy=2.4551219940185547, Accuracy=0.09090909361839294\n",
      "Epoch 91 train: Cross-entropy=2.3479621675279407, Accuracy=0.1440972222222222\n",
      "Epoch 91 validation: Cross-entropy=2.4552013874053955, Accuracy=0.09090909361839294\n",
      "Epoch 92 train: Cross-entropy=2.3478811184565225, Accuracy=0.1440972222222222\n",
      "Epoch 92 validation: Cross-entropy=2.4552769660949707, Accuracy=0.09090909361839294\n",
      "Epoch 93 train: Cross-entropy=2.347802718480428, Accuracy=0.1440972222222222\n",
      "Epoch 93 validation: Cross-entropy=2.4553494453430176, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 train: Cross-entropy=2.3477268748813205, Accuracy=0.14583333333333334\n",
      "Epoch 94 validation: Cross-entropy=2.455418348312378, Accuracy=0.09090909361839294\n",
      "Epoch 95 train: Cross-entropy=2.347653521431817, Accuracy=0.14583333333333334\n",
      "Epoch 95 validation: Cross-entropy=2.455484628677368, Accuracy=0.09090909361839294\n",
      "Epoch 96 train: Cross-entropy=2.347582631640964, Accuracy=0.1440972222222222\n",
      "Epoch 96 validation: Cross-entropy=2.455547571182251, Accuracy=0.09090909361839294\n",
      "Epoch 97 train: Cross-entropy=2.3475140465630426, Accuracy=0.1440972222222222\n",
      "Epoch 97 validation: Cross-entropy=2.4556074142456055, Accuracy=0.09090909361839294\n",
      "Epoch 98 train: Cross-entropy=2.3474478986528187, Accuracy=0.1440972222222222\n",
      "Epoch 98 validation: Cross-entropy=2.4556643962860107, Accuracy=0.09090909361839294\n",
      "Epoch 99 train: Cross-entropy=2.3473839892281427, Accuracy=0.1423611111111111\n",
      "Epoch 99 validation: Cross-entropy=2.455718994140625, Accuracy=0.09090909361839294\n",
      "Epoch 100 train: Cross-entropy=2.3473222388161554, Accuracy=0.1423611111111111\n",
      "Epoch 100 validation: Cross-entropy=2.455770254135132, Accuracy=0.09090909361839294\n",
      "Epoch 101 train: Cross-entropy=2.3472626076804266, Accuracy=0.1440972222222222\n",
      "Epoch 101 validation: Cross-entropy=2.4558193683624268, Accuracy=0.09090909361839294\n",
      "Epoch 102 train: Cross-entropy=2.34720508257548, Accuracy=0.1440972222222222\n",
      "Epoch 102 validation: Cross-entropy=2.4558653831481934, Accuracy=0.09090909361839294\n",
      "Epoch 103 train: Cross-entropy=2.3471495045555963, Accuracy=0.1440972222222222\n",
      "Epoch 103 validation: Cross-entropy=2.455909252166748, Accuracy=0.09090909361839294\n",
      "Epoch 104 train: Cross-entropy=2.3470960325664945, Accuracy=0.1440972222222222\n",
      "Epoch 104 validation: Cross-entropy=2.4559504985809326, Accuracy=0.09090909361839294\n",
      "Epoch 105 train: Cross-entropy=2.3470443884531655, Accuracy=0.1440972222222222\n",
      "Epoch 105 validation: Cross-entropy=2.455989360809326, Accuracy=0.09090909361839294\n",
      "Epoch 106 train: Cross-entropy=2.3469947046703763, Accuracy=0.1440972222222222\n",
      "Epoch 106 validation: Cross-entropy=2.456026315689087, Accuracy=0.09090909361839294\n",
      "Epoch 107 train: Cross-entropy=2.3469467957814536, Accuracy=0.1440972222222222\n",
      "Epoch 107 validation: Cross-entropy=2.4560606479644775, Accuracy=0.09090909361839294\n",
      "Epoch 108 train: Cross-entropy=2.3469006617863974, Accuracy=0.1440972222222222\n",
      "Epoch 108 validation: Cross-entropy=2.4560928344726562, Accuracy=0.09090909361839294\n",
      "Epoch 109 train: Cross-entropy=2.3468563159306846, Accuracy=0.1440972222222222\n",
      "Epoch 109 validation: Cross-entropy=2.456122875213623, Accuracy=0.09090909361839294\n",
      "Epoch 110 train: Cross-entropy=2.3468136257595487, Accuracy=0.1440972222222222\n",
      "Epoch 110 validation: Cross-entropy=2.456151247024536, Accuracy=0.09090909361839294\n",
      "Epoch 111 train: Cross-entropy=2.346772644254896, Accuracy=0.14583333333333334\n",
      "Epoch 111 validation: Cross-entropy=2.456176996231079, Accuracy=0.09090909361839294\n",
      "Epoch 112 train: Cross-entropy=2.3467332786983914, Accuracy=0.14583333333333334\n",
      "Epoch 112 validation: Cross-entropy=2.4562013149261475, Accuracy=0.09090909361839294\n",
      "Epoch 113 train: Cross-entropy=2.3466954231262207, Accuracy=0.1440972222222222\n",
      "Epoch 113 validation: Cross-entropy=2.456223487854004, Accuracy=0.09090909361839294\n",
      "Epoch 114 train: Cross-entropy=2.346659157011244, Accuracy=0.1440972222222222\n",
      "Epoch 114 validation: Cross-entropy=2.4562437534332275, Accuracy=0.09090909361839294\n",
      "Epoch 115 train: Cross-entropy=2.346624347898695, Accuracy=0.14583333333333334\n",
      "Epoch 115 validation: Cross-entropy=2.4562623500823975, Accuracy=0.09090909361839294\n",
      "Epoch 116 train: Cross-entropy=2.346591075261434, Accuracy=0.14583333333333334\n",
      "Epoch 116 validation: Cross-entropy=2.4562795162200928, Accuracy=0.09090909361839294\n",
      "Epoch 117 train: Cross-entropy=2.3465591139263577, Accuracy=0.14756944444444445\n",
      "Epoch 117 validation: Cross-entropy=2.456294536590576, Accuracy=0.09090909361839294\n",
      "Epoch 118 train: Cross-entropy=2.3465286228391857, Accuracy=0.14756944444444445\n",
      "Epoch 118 validation: Cross-entropy=2.456308126449585, Accuracy=0.09595959633588791\n",
      "Epoch 119 train: Cross-entropy=2.346499522527059, Accuracy=0.14756944444444445\n",
      "Epoch 119 validation: Cross-entropy=2.45632004737854, Accuracy=0.09595959633588791\n",
      "Epoch 120 train: Cross-entropy=2.3464717070261636, Accuracy=0.14756944444444445\n",
      "Epoch 120 validation: Cross-entropy=2.4563305377960205, Accuracy=0.09595959633588791\n",
      "Epoch 121 train: Cross-entropy=2.346445189581977, Accuracy=0.14756944444444445\n",
      "Epoch 121 validation: Cross-entropy=2.4563395977020264, Accuracy=0.09595959633588791\n",
      "Epoch 122 train: Cross-entropy=2.3464199437035456, Accuracy=0.14756944444444445\n",
      "Epoch 122 validation: Cross-entropy=2.4563469886779785, Accuracy=0.09595959633588791\n",
      "Epoch 123 train: Cross-entropy=2.3463959428999157, Accuracy=0.14756944444444445\n",
      "Epoch 123 validation: Cross-entropy=2.456353187561035, Accuracy=0.09595959633588791\n",
      "Epoch 124 train: Cross-entropy=2.346373120943705, Accuracy=0.14930555555555555\n",
      "Epoch 124 validation: Cross-entropy=2.456357717514038, Accuracy=0.09595959633588791\n",
      "Epoch 125 train: Cross-entropy=2.3463515440622964, Accuracy=0.14756944444444445\n",
      "Epoch 125 validation: Cross-entropy=2.4563610553741455, Accuracy=0.09595959633588791\n",
      "Epoch 126 train: Cross-entropy=2.346331079800924, Accuracy=0.14756944444444445\n",
      "Epoch 126 validation: Cross-entropy=2.4563629627227783, Accuracy=0.09595959633588791\n",
      "Epoch 127 train: Cross-entropy=2.3463117943869696, Accuracy=0.14756944444444445\n",
      "Epoch 127 validation: Cross-entropy=2.4563639163970947, Accuracy=0.09595959633588791\n",
      "Epoch 128 train: Cross-entropy=2.3462935156292386, Accuracy=0.14756944444444445\n",
      "Epoch 128 validation: Cross-entropy=2.4563634395599365, Accuracy=0.09595959633588791\n",
      "Epoch 129 train: Cross-entropy=2.34627636273702, Accuracy=0.14756944444444445\n",
      "Epoch 129 validation: Cross-entropy=2.456361770629883, Accuracy=0.09595959633588791\n",
      "Epoch 130 train: Cross-entropy=2.346260256237454, Accuracy=0.14756944444444445\n",
      "Epoch 130 validation: Cross-entropy=2.4563589096069336, Accuracy=0.09595959633588791\n",
      "Epoch 131 train: Cross-entropy=2.3462451696395874, Accuracy=0.14756944444444445\n",
      "Epoch 131 validation: Cross-entropy=2.456355094909668, Accuracy=0.09595959633588791\n",
      "Epoch 132 train: Cross-entropy=2.3462310896979437, Accuracy=0.14583333333333334\n",
      "Epoch 132 validation: Cross-entropy=2.456350088119507, Accuracy=0.09090909361839294\n",
      "Epoch 133 train: Cross-entropy=2.346218056148953, Accuracy=0.14583333333333334\n",
      "Epoch 133 validation: Cross-entropy=2.4563441276550293, Accuracy=0.09090909361839294\n",
      "Epoch 134 train: Cross-entropy=2.346205883555942, Accuracy=0.14583333333333334\n",
      "Epoch 134 validation: Cross-entropy=2.4563369750976562, Accuracy=0.09090909361839294\n",
      "Epoch 135 train: Cross-entropy=2.3461947308646307, Accuracy=0.14583333333333334\n",
      "Epoch 135 validation: Cross-entropy=2.456328868865967, Accuracy=0.09090909361839294\n",
      "Epoch 136 train: Cross-entropy=2.3461844523747764, Accuracy=0.14583333333333334\n",
      "Epoch 136 validation: Cross-entropy=2.456319808959961, Accuracy=0.09090909361839294\n",
      "Epoch 137 train: Cross-entropy=2.346175048086378, Accuracy=0.14583333333333334\n",
      "Epoch 137 validation: Cross-entropy=2.4563097953796387, Accuracy=0.09090909361839294\n",
      "Epoch 138 train: Cross-entropy=2.3461665047539606, Accuracy=0.14583333333333334\n",
      "Epoch 138 validation: Cross-entropy=2.456299066543579, Accuracy=0.09090909361839294\n",
      "Epoch 139 train: Cross-entropy=2.346158888604906, Accuracy=0.14583333333333334\n",
      "Epoch 139 validation: Cross-entropy=2.456287145614624, Accuracy=0.09090909361839294\n",
      "Epoch 140 train: Cross-entropy=2.346152106920878, Accuracy=0.14583333333333334\n",
      "Epoch 140 validation: Cross-entropy=2.4562747478485107, Accuracy=0.09090909361839294\n",
      "Epoch 141 train: Cross-entropy=2.3461460404925876, Accuracy=0.14583333333333334\n",
      "Epoch 141 validation: Cross-entropy=2.45626163482666, Accuracy=0.09090909361839294\n",
      "Epoch 142 train: Cross-entropy=2.3461407952838473, Accuracy=0.14583333333333334\n",
      "Epoch 142 validation: Cross-entropy=2.456247091293335, Accuracy=0.09090909361839294\n",
      "Epoch 143 train: Cross-entropy=2.3461363977856107, Accuracy=0.1423611111111111\n",
      "Epoch 143 validation: Cross-entropy=2.4562318325042725, Accuracy=0.09090909361839294\n",
      "Epoch 144 train: Cross-entropy=2.3461327287885876, Accuracy=0.1423611111111111\n",
      "Epoch 144 validation: Cross-entropy=2.4562160968780518, Accuracy=0.09090909361839294\n",
      "Epoch 145 train: Cross-entropy=2.346129854520162, Accuracy=0.1423611111111111\n",
      "Epoch 145 validation: Cross-entropy=2.4561996459960938, Accuracy=0.09090909361839294\n",
      "Epoch 146 train: Cross-entropy=2.3461276557710438, Accuracy=0.1423611111111111\n",
      "Epoch 146 validation: Cross-entropy=2.4561827182769775, Accuracy=0.09090909361839294\n",
      "Epoch 147 train: Cross-entropy=2.3461261325412326, Accuracy=0.1423611111111111\n",
      "Epoch 147 validation: Cross-entropy=2.456164836883545, Accuracy=0.09090909361839294\n",
      "Epoch 148 train: Cross-entropy=2.346125351058112, Accuracy=0.1423611111111111\n",
      "Epoch 148 validation: Cross-entropy=2.456146240234375, Accuracy=0.09090909361839294\n",
      "Epoch 149 train: Cross-entropy=2.346125218603346, Accuracy=0.1423611111111111\n",
      "Epoch 149 validation: Cross-entropy=2.456127166748047, Accuracy=0.09090909361839294\n",
      "Epoch 150 train: Cross-entropy=2.346125841140747, Accuracy=0.1423611111111111\n",
      "Epoch 150 validation: Cross-entropy=2.4561076164245605, Accuracy=0.09090909361839294\n",
      "Epoch 151 train: Cross-entropy=2.3461270332336426, Accuracy=0.1440972222222222\n",
      "Epoch 151 validation: Cross-entropy=2.456087112426758, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 train: Cross-entropy=2.3461288346184626, Accuracy=0.1440972222222222\n",
      "Epoch 152 validation: Cross-entropy=2.456066131591797, Accuracy=0.09090909361839294\n",
      "Epoch 153 train: Cross-entropy=2.34613135125902, Accuracy=0.1440972222222222\n",
      "Epoch 153 validation: Cross-entropy=2.4560446739196777, Accuracy=0.09090909361839294\n",
      "Epoch 154 train: Cross-entropy=2.346134384473165, Accuracy=0.1440972222222222\n",
      "Epoch 154 validation: Cross-entropy=2.4560227394104004, Accuracy=0.09090909361839294\n",
      "Epoch 155 train: Cross-entropy=2.346138013733758, Accuracy=0.1440972222222222\n",
      "Epoch 155 validation: Cross-entropy=2.456000328063965, Accuracy=0.09090909361839294\n",
      "Epoch 156 train: Cross-entropy=2.3461422787772284, Accuracy=0.1440972222222222\n",
      "Epoch 156 validation: Cross-entropy=2.455977201461792, Accuracy=0.09090909361839294\n",
      "Epoch 157 train: Cross-entropy=2.3461471133761935, Accuracy=0.1440972222222222\n",
      "Epoch 157 validation: Cross-entropy=2.45595383644104, Accuracy=0.09090909361839294\n",
      "Epoch 158 train: Cross-entropy=2.3461524513032703, Accuracy=0.1440972222222222\n",
      "Epoch 158 validation: Cross-entropy=2.455929756164551, Accuracy=0.09090909361839294\n",
      "Epoch 159 train: Cross-entropy=2.3461583852767944, Accuracy=0.1440972222222222\n",
      "Epoch 159 validation: Cross-entropy=2.4559054374694824, Accuracy=0.09090909361839294\n",
      "Epoch 160 train: Cross-entropy=2.346164835823907, Accuracy=0.1440972222222222\n",
      "Epoch 160 validation: Cross-entropy=2.455880641937256, Accuracy=0.09090909361839294\n",
      "Epoch 161 train: Cross-entropy=2.346171736717224, Accuracy=0.1440972222222222\n",
      "Epoch 161 validation: Cross-entropy=2.455855131149292, Accuracy=0.09090909361839294\n",
      "Epoch 162 train: Cross-entropy=2.3461791939205594, Accuracy=0.1440972222222222\n",
      "Epoch 162 validation: Cross-entropy=2.455829620361328, Accuracy=0.09090909361839294\n",
      "Epoch 163 train: Cross-entropy=2.3461871809429593, Accuracy=0.1440972222222222\n",
      "Epoch 163 validation: Cross-entropy=2.455803871154785, Accuracy=0.09090909361839294\n",
      "Epoch 164 train: Cross-entropy=2.3461955653296576, Accuracy=0.1440972222222222\n",
      "Epoch 164 validation: Cross-entropy=2.455777168273926, Accuracy=0.09090909361839294\n",
      "Epoch 165 train: Cross-entropy=2.346204506026374, Accuracy=0.1440972222222222\n",
      "Epoch 165 validation: Cross-entropy=2.4557507038116455, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.3462138308419123, Accuracy=0.1440972222222222\n",
      "Epoch 166 validation: Cross-entropy=2.455723762512207, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.3462236324946084, Accuracy=0.1440972222222222\n",
      "Epoch 167 validation: Cross-entropy=2.4556961059570312, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.346233858002557, Accuracy=0.1440972222222222\n",
      "Epoch 168 validation: Cross-entropy=2.4556686878204346, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.3462445735931396, Accuracy=0.1440972222222222\n",
      "Epoch 169 validation: Cross-entropy=2.4556407928466797, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.3462556997934976, Accuracy=0.140625\n",
      "Epoch 170 validation: Cross-entropy=2.4556121826171875, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.3462672233581543, Accuracy=0.140625\n",
      "Epoch 171 validation: Cross-entropy=2.4555835723876953, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.346279117796156, Accuracy=0.140625\n",
      "Epoch 172 validation: Cross-entropy=2.4555552005767822, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.3462913433710733, Accuracy=0.140625\n",
      "Epoch 173 validation: Cross-entropy=2.455526113510132, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.3463040457831488, Accuracy=0.140625\n",
      "Epoch 174 validation: Cross-entropy=2.4554967880249023, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.346317105823093, Accuracy=0.140625\n",
      "Epoch 175 validation: Cross-entropy=2.4554672241210938, Accuracy=0.09595959633588791\n",
      "Epoch 176 train: Cross-entropy=2.346330549981859, Accuracy=0.140625\n",
      "Epoch 176 validation: Cross-entropy=2.455437660217285, Accuracy=0.09595959633588791\n",
      "Epoch 177 train: Cross-entropy=2.346344312032064, Accuracy=0.140625\n",
      "Epoch 177 validation: Cross-entropy=2.4554078578948975, Accuracy=0.09595959633588791\n",
      "Epoch 178 train: Cross-entropy=2.346358405219184, Accuracy=0.140625\n",
      "Epoch 178 validation: Cross-entropy=2.4553778171539307, Accuracy=0.09595959633588791\n",
      "Epoch 179 train: Cross-entropy=2.346372816297743, Accuracy=0.140625\n",
      "Epoch 179 validation: Cross-entropy=2.4553472995758057, Accuracy=0.09595959633588791\n",
      "Epoch 180 train: Cross-entropy=2.3463876379860773, Accuracy=0.140625\n",
      "Epoch 180 validation: Cross-entropy=2.4553170204162598, Accuracy=0.09595959633588791\n",
      "Epoch 181 train: Cross-entropy=2.3464026716020374, Accuracy=0.140625\n",
      "Epoch 181 validation: Cross-entropy=2.4552865028381348, Accuracy=0.09595959633588791\n",
      "Epoch 182 train: Cross-entropy=2.3464181555642023, Accuracy=0.140625\n",
      "Epoch 182 validation: Cross-entropy=2.4552557468414307, Accuracy=0.09595959633588791\n",
      "Epoch 183 train: Cross-entropy=2.3464338646994696, Accuracy=0.140625\n",
      "Epoch 183 validation: Cross-entropy=2.4552249908447266, Accuracy=0.09595959633588791\n",
      "Epoch 184 train: Cross-entropy=2.3464499182171292, Accuracy=0.140625\n",
      "Epoch 184 validation: Cross-entropy=2.4551939964294434, Accuracy=0.09595959633588791\n",
      "Epoch 185 train: Cross-entropy=2.346466210153368, Accuracy=0.140625\n",
      "Epoch 185 validation: Cross-entropy=2.45516300201416, Accuracy=0.09595959633588791\n",
      "Epoch 186 train: Cross-entropy=2.3464827272627087, Accuracy=0.140625\n",
      "Epoch 186 validation: Cross-entropy=2.455132007598877, Accuracy=0.09595959633588791\n",
      "Epoch 187 train: Cross-entropy=2.346499615245395, Accuracy=0.140625\n",
      "Epoch 187 validation: Cross-entropy=2.4551002979278564, Accuracy=0.09595959633588791\n",
      "Epoch 188 train: Cross-entropy=2.346516768137614, Accuracy=0.140625\n",
      "Epoch 188 validation: Cross-entropy=2.4550693035125732, Accuracy=0.09595959633588791\n",
      "Epoch 189 train: Cross-entropy=2.346534185939365, Accuracy=0.140625\n",
      "Epoch 189 validation: Cross-entropy=2.4550375938415527, Accuracy=0.09090909361839294\n",
      "Epoch 190 train: Cross-entropy=2.3465518289142184, Accuracy=0.140625\n",
      "Epoch 190 validation: Cross-entropy=2.4550058841705322, Accuracy=0.09090909361839294\n",
      "Epoch 191 train: Cross-entropy=2.3465697235531278, Accuracy=0.1423611111111111\n",
      "Epoch 191 validation: Cross-entropy=2.454974412918091, Accuracy=0.09090909361839294\n",
      "Epoch 192 train: Cross-entropy=2.346587883101569, Accuracy=0.1423611111111111\n",
      "Epoch 192 validation: Cross-entropy=2.4549427032470703, Accuracy=0.09090909361839294\n",
      "Epoch 193 train: Cross-entropy=2.3466062678231134, Accuracy=0.1423611111111111\n",
      "Epoch 193 validation: Cross-entropy=2.45491099357605, Accuracy=0.09090909361839294\n",
      "Epoch 194 train: Cross-entropy=2.34662487771776, Accuracy=0.1423611111111111\n",
      "Epoch 194 validation: Cross-entropy=2.45487904548645, Accuracy=0.09090909361839294\n",
      "Epoch 195 train: Cross-entropy=2.3466436862945557, Accuracy=0.1423611111111111\n",
      "Epoch 195 validation: Cross-entropy=2.454847574234009, Accuracy=0.08585858345031738\n",
      "Epoch 196 train: Cross-entropy=2.3466627730263605, Accuracy=0.1423611111111111\n",
      "Epoch 196 validation: Cross-entropy=2.45481538772583, Accuracy=0.08585858345031738\n",
      "Epoch 197 train: Cross-entropy=2.3466820187038846, Accuracy=0.1423611111111111\n",
      "Epoch 197 validation: Cross-entropy=2.4547836780548096, Accuracy=0.08585858345031738\n",
      "Epoch 198 train: Cross-entropy=2.3467015160454645, Accuracy=0.1423611111111111\n",
      "Epoch 198 validation: Cross-entropy=2.45475172996521, Accuracy=0.08585858345031738\n",
      "Epoch 199 train: Cross-entropy=2.346721132596334, Accuracy=0.140625\n",
      "Epoch 199 validation: Cross-entropy=2.4547197818756104, Accuracy=0.08585858345031738\n",
      "Epoch 0 train: Cross-entropy=2.4788208405176797, Accuracy=0.0798611111111111\n",
      "Epoch 0 validation: Cross-entropy=2.4464645385742188, Accuracy=0.12121212482452393\n",
      "Epoch 1 train: Cross-entropy=2.4468180338541665, Accuracy=0.07118055555555555\n",
      "Epoch 1 validation: Cross-entropy=2.4249424934387207, Accuracy=0.1111111119389534\n",
      "Epoch 2 train: Cross-entropy=2.423743830786811, Accuracy=0.08159722222222222\n",
      "Epoch 2 validation: Cross-entropy=2.4143452644348145, Accuracy=0.08080808073282242\n",
      "Epoch 3 train: Cross-entropy=2.411453432506985, Accuracy=0.08159722222222222\n",
      "Epoch 3 validation: Cross-entropy=2.410125255584717, Accuracy=0.06060606241226196\n",
      "Epoch 4 train: Cross-entropy=2.4051978058285184, Accuracy=0.07118055555555555\n",
      "Epoch 4 validation: Cross-entropy=2.4088263511657715, Accuracy=0.08585858345031738\n",
      "Epoch 5 train: Cross-entropy=2.401948160595364, Accuracy=0.08680555555555555\n",
      "Epoch 5 validation: Cross-entropy=2.4087471961975098, Accuracy=0.08585858345031738\n",
      "Epoch 6 train: Cross-entropy=2.400170180532667, Accuracy=0.09375\n",
      "Epoch 6 validation: Cross-entropy=2.409120798110962, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train: Cross-entropy=2.3991158405939736, Accuracy=0.09027777777777778\n",
      "Epoch 7 validation: Cross-entropy=2.4096152782440186, Accuracy=0.08585858345031738\n",
      "Epoch 8 train: Cross-entropy=2.398420082198249, Accuracy=0.09027777777777778\n",
      "Epoch 8 validation: Cross-entropy=2.410095453262329, Accuracy=0.10101009905338287\n",
      "Epoch 9 train: Cross-entropy=2.3979035880830555, Accuracy=0.09027777777777778\n",
      "Epoch 9 validation: Cross-entropy=2.4105148315429688, Accuracy=0.08585858345031738\n",
      "Epoch 10 train: Cross-entropy=2.3974773751364813, Accuracy=0.09375\n",
      "Epoch 10 validation: Cross-entropy=2.4108633995056152, Accuracy=0.08585858345031738\n",
      "Epoch 11 train: Cross-entropy=2.3970972696940103, Accuracy=0.09375\n",
      "Epoch 11 validation: Cross-entropy=2.4111475944519043, Accuracy=0.07575757801532745\n",
      "Epoch 12 train: Cross-entropy=2.396741509437561, Accuracy=0.0920138888888889\n",
      "Epoch 12 validation: Cross-entropy=2.411376953125, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.3963989284303455, Accuracy=0.09375\n",
      "Epoch 13 validation: Cross-entropy=2.411562919616699, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.3960643212000527, Accuracy=0.09895833333333333\n",
      "Epoch 14 validation: Cross-entropy=2.411714553833008, Accuracy=0.07575757801532745\n",
      "Epoch 15 train: Cross-entropy=2.3957349591785007, Accuracy=0.10069444444444445\n",
      "Epoch 15 validation: Cross-entropy=2.4118406772613525, Accuracy=0.07575757801532745\n",
      "Epoch 16 train: Cross-entropy=2.395409451590644, Accuracy=0.10416666666666667\n",
      "Epoch 16 validation: Cross-entropy=2.4119465351104736, Accuracy=0.07575757801532745\n",
      "Epoch 17 train: Cross-entropy=2.395087308353848, Accuracy=0.1076388888888889\n",
      "Epoch 17 validation: Cross-entropy=2.4120378494262695, Accuracy=0.07575757801532745\n",
      "Epoch 18 train: Cross-entropy=2.3947681056128607, Accuracy=0.10590277777777778\n",
      "Epoch 18 validation: Cross-entropy=2.4121179580688477, Accuracy=0.07575757801532745\n",
      "Epoch 19 train: Cross-entropy=2.3944519095950656, Accuracy=0.10590277777777778\n",
      "Epoch 19 validation: Cross-entropy=2.4121904373168945, Accuracy=0.07575757801532745\n",
      "Epoch 20 train: Cross-entropy=2.39413845539093, Accuracy=0.10416666666666667\n",
      "Epoch 20 validation: Cross-entropy=2.4122567176818848, Accuracy=0.07575757801532745\n",
      "Epoch 21 train: Cross-entropy=2.3938277430004544, Accuracy=0.10416666666666667\n",
      "Epoch 21 validation: Cross-entropy=2.4123189449310303, Accuracy=0.07575757801532745\n",
      "Epoch 22 train: Cross-entropy=2.3935198651419745, Accuracy=0.10590277777777778\n",
      "Epoch 22 validation: Cross-entropy=2.4123775959014893, Accuracy=0.07575757801532745\n",
      "Epoch 23 train: Cross-entropy=2.3932145833969116, Accuracy=0.10590277777777778\n",
      "Epoch 23 validation: Cross-entropy=2.4124350547790527, Accuracy=0.07070706784725189\n",
      "Epoch 24 train: Cross-entropy=2.3929120302200317, Accuracy=0.10590277777777778\n",
      "Epoch 24 validation: Cross-entropy=2.4124903678894043, Accuracy=0.07070706784725189\n",
      "Epoch 25 train: Cross-entropy=2.392612192365858, Accuracy=0.10590277777777778\n",
      "Epoch 25 validation: Cross-entropy=2.4125449657440186, Accuracy=0.07070706784725189\n",
      "Epoch 26 train: Cross-entropy=2.3923149638705783, Accuracy=0.10590277777777778\n",
      "Epoch 26 validation: Cross-entropy=2.4125990867614746, Accuracy=0.07070706784725189\n",
      "Epoch 27 train: Cross-entropy=2.392020238770379, Accuracy=0.10590277777777778\n",
      "Epoch 27 validation: Cross-entropy=2.4126529693603516, Accuracy=0.07070706784725189\n",
      "Epoch 28 train: Cross-entropy=2.3917281760109796, Accuracy=0.1076388888888889\n",
      "Epoch 28 validation: Cross-entropy=2.4127066135406494, Accuracy=0.07575757801532745\n",
      "Epoch 29 train: Cross-entropy=2.3914385769102307, Accuracy=0.1076388888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4127609729766846, Accuracy=0.07575757801532745\n",
      "Epoch 30 train: Cross-entropy=2.3911515871683755, Accuracy=0.10590277777777778\n",
      "Epoch 30 validation: Cross-entropy=2.4128146171569824, Accuracy=0.07575757801532745\n",
      "Epoch 31 train: Cross-entropy=2.3908669153849282, Accuracy=0.1076388888888889\n",
      "Epoch 31 validation: Cross-entropy=2.4128692150115967, Accuracy=0.07575757801532745\n",
      "Epoch 32 train: Cross-entropy=2.3905847602420383, Accuracy=0.1076388888888889\n",
      "Epoch 32 validation: Cross-entropy=2.412923812866211, Accuracy=0.07575757801532745\n",
      "Epoch 33 train: Cross-entropy=2.390305068757799, Accuracy=0.1076388888888889\n",
      "Epoch 33 validation: Cross-entropy=2.4129788875579834, Accuracy=0.07575757801532745\n",
      "Epoch 34 train: Cross-entropy=2.3900276157591076, Accuracy=0.1076388888888889\n",
      "Epoch 34 validation: Cross-entropy=2.413034439086914, Accuracy=0.07575757801532745\n",
      "Epoch 35 train: Cross-entropy=2.3897525866826377, Accuracy=0.10590277777777778\n",
      "Epoch 35 validation: Cross-entropy=2.413090229034424, Accuracy=0.07575757801532745\n",
      "Epoch 36 train: Cross-entropy=2.3894798623190985, Accuracy=0.10590277777777778\n",
      "Epoch 36 validation: Cross-entropy=2.413146495819092, Accuracy=0.07575757801532745\n",
      "Epoch 37 train: Cross-entropy=2.389209442668491, Accuracy=0.10416666666666667\n",
      "Epoch 37 validation: Cross-entropy=2.413203477859497, Accuracy=0.07575757801532745\n",
      "Epoch 38 train: Cross-entropy=2.388941182030572, Accuracy=0.10416666666666667\n",
      "Epoch 38 validation: Cross-entropy=2.4132606983184814, Accuracy=0.07575757801532745\n",
      "Epoch 39 train: Cross-entropy=2.3886752128601074, Accuracy=0.10416666666666667\n",
      "Epoch 39 validation: Cross-entropy=2.413318395614624, Accuracy=0.07575757801532745\n",
      "Epoch 40 train: Cross-entropy=2.388411455684238, Accuracy=0.1076388888888889\n",
      "Epoch 40 validation: Cross-entropy=2.4133760929107666, Accuracy=0.07575757801532745\n",
      "Epoch 41 train: Cross-entropy=2.3881498177846274, Accuracy=0.1076388888888889\n",
      "Epoch 41 validation: Cross-entropy=2.4134345054626465, Accuracy=0.07575757801532745\n",
      "Epoch 42 train: Cross-entropy=2.3878902991612754, Accuracy=0.10590277777777778\n",
      "Epoch 42 validation: Cross-entropy=2.4134933948516846, Accuracy=0.07575757801532745\n",
      "Epoch 43 train: Cross-entropy=2.387632966041565, Accuracy=0.10590277777777778\n",
      "Epoch 43 validation: Cross-entropy=2.413552761077881, Accuracy=0.07575757801532745\n",
      "Epoch 44 train: Cross-entropy=2.387377619743347, Accuracy=0.10590277777777778\n",
      "Epoch 44 validation: Cross-entropy=2.4136123657226562, Accuracy=0.07575757801532745\n",
      "Epoch 45 train: Cross-entropy=2.387124392721388, Accuracy=0.10590277777777778\n",
      "Epoch 45 validation: Cross-entropy=2.41367244720459, Accuracy=0.07575757801532745\n",
      "Epoch 46 train: Cross-entropy=2.386873165766398, Accuracy=0.1076388888888889\n",
      "Epoch 46 validation: Cross-entropy=2.4137327671051025, Accuracy=0.07575757801532745\n",
      "Epoch 47 train: Cross-entropy=2.386623978614807, Accuracy=0.1076388888888889\n",
      "Epoch 47 validation: Cross-entropy=2.4137933254241943, Accuracy=0.07575757801532745\n",
      "Epoch 48 train: Cross-entropy=2.386376738548279, Accuracy=0.109375\n",
      "Epoch 48 validation: Cross-entropy=2.4138543605804443, Accuracy=0.07575757801532745\n",
      "Epoch 49 train: Cross-entropy=2.3861314985487194, Accuracy=0.109375\n",
      "Epoch 49 validation: Cross-entropy=2.4139158725738525, Accuracy=0.07575757801532745\n",
      "Epoch 50 train: Cross-entropy=2.38588813940684, Accuracy=0.109375\n",
      "Epoch 50 validation: Cross-entropy=2.41397762298584, Accuracy=0.07575757801532745\n",
      "Epoch 51 train: Cross-entropy=2.38564670085907, Accuracy=0.1111111111111111\n",
      "Epoch 51 validation: Cross-entropy=2.4140396118164062, Accuracy=0.07575757801532745\n",
      "Epoch 52 train: Cross-entropy=2.3854071696599326, Accuracy=0.11458333333333333\n",
      "Epoch 52 validation: Cross-entropy=2.4141018390655518, Accuracy=0.07575757801532745\n",
      "Epoch 53 train: Cross-entropy=2.3851695193184748, Accuracy=0.11458333333333333\n",
      "Epoch 53 validation: Cross-entropy=2.4141645431518555, Accuracy=0.07575757801532745\n",
      "Epoch 54 train: Cross-entropy=2.38493369685279, Accuracy=0.11458333333333333\n",
      "Epoch 54 validation: Cross-entropy=2.4142274856567383, Accuracy=0.07575757801532745\n",
      "Epoch 55 train: Cross-entropy=2.384699583053589, Accuracy=0.11458333333333333\n",
      "Epoch 55 validation: Cross-entropy=2.4142906665802, Accuracy=0.07575757801532745\n",
      "Epoch 56 train: Cross-entropy=2.3844674030939736, Accuracy=0.11979166666666667\n",
      "Epoch 56 validation: Cross-entropy=2.4143543243408203, Accuracy=0.07575757801532745\n",
      "Epoch 57 train: Cross-entropy=2.3842369980282254, Accuracy=0.11979166666666667\n",
      "Epoch 57 validation: Cross-entropy=2.4144179821014404, Accuracy=0.07575757801532745\n",
      "Epoch 58 train: Cross-entropy=2.3840082618925305, Accuracy=0.11979166666666667\n",
      "Epoch 58 validation: Cross-entropy=2.4144821166992188, Accuracy=0.07575757801532745\n",
      "Epoch 59 train: Cross-entropy=2.383781247668796, Accuracy=0.11979166666666667\n",
      "Epoch 59 validation: Cross-entropy=2.414546251296997, Accuracy=0.07575757801532745\n",
      "Epoch 60 train: Cross-entropy=2.3835560613208346, Accuracy=0.11979166666666667\n",
      "Epoch 60 validation: Cross-entropy=2.4146108627319336, Accuracy=0.07575757801532745\n",
      "Epoch 61 train: Cross-entropy=2.3833324246936374, Accuracy=0.12152777777777778\n",
      "Epoch 61 validation: Cross-entropy=2.41467547416687, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 train: Cross-entropy=2.38311058945126, Accuracy=0.12152777777777778\n",
      "Epoch 62 validation: Cross-entropy=2.4147403240203857, Accuracy=0.07575757801532745\n",
      "Epoch 63 train: Cross-entropy=2.3828903304206, Accuracy=0.12152777777777778\n",
      "Epoch 63 validation: Cross-entropy=2.4148058891296387, Accuracy=0.07575757801532745\n",
      "Epoch 64 train: Cross-entropy=2.3826717270745172, Accuracy=0.1232638888888889\n",
      "Epoch 64 validation: Cross-entropy=2.4148712158203125, Accuracy=0.07575757801532745\n",
      "Epoch 65 train: Cross-entropy=2.382454752922058, Accuracy=0.1232638888888889\n",
      "Epoch 65 validation: Cross-entropy=2.4149367809295654, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.382239328490363, Accuracy=0.1232638888888889\n",
      "Epoch 66 validation: Cross-entropy=2.4150025844573975, Accuracy=0.07575757801532745\n",
      "Epoch 67 train: Cross-entropy=2.3820255597432456, Accuracy=0.1232638888888889\n",
      "Epoch 67 validation: Cross-entropy=2.4150683879852295, Accuracy=0.07575757801532745\n",
      "Epoch 68 train: Cross-entropy=2.381813261244032, Accuracy=0.1232638888888889\n",
      "Epoch 68 validation: Cross-entropy=2.4151346683502197, Accuracy=0.07575757801532745\n",
      "Epoch 69 train: Cross-entropy=2.3816026184293957, Accuracy=0.125\n",
      "Epoch 69 validation: Cross-entropy=2.41520094871521, Accuracy=0.07575757801532745\n",
      "Epoch 70 train: Cross-entropy=2.381393406126234, Accuracy=0.125\n",
      "Epoch 70 validation: Cross-entropy=2.4152677059173584, Accuracy=0.07575757801532745\n",
      "Epoch 71 train: Cross-entropy=2.381185664070977, Accuracy=0.125\n",
      "Epoch 71 validation: Cross-entropy=2.415334463119507, Accuracy=0.07575757801532745\n",
      "Epoch 72 train: Cross-entropy=2.380979551209344, Accuracy=0.125\n",
      "Epoch 72 validation: Cross-entropy=2.4154012203216553, Accuracy=0.07575757801532745\n",
      "Epoch 73 train: Cross-entropy=2.3807747893863254, Accuracy=0.125\n",
      "Epoch 73 validation: Cross-entropy=2.415468215942383, Accuracy=0.08080808073282242\n",
      "Epoch 74 train: Cross-entropy=2.380571577284071, Accuracy=0.125\n",
      "Epoch 74 validation: Cross-entropy=2.4155354499816895, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.380369689729479, Accuracy=0.125\n",
      "Epoch 75 validation: Cross-entropy=2.415602445602417, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.3801693121592202, Accuracy=0.1232638888888889\n",
      "Epoch 76 validation: Cross-entropy=2.415670394897461, Accuracy=0.08080808073282242\n",
      "Epoch 77 train: Cross-entropy=2.3799703386094837, Accuracy=0.1232638888888889\n",
      "Epoch 77 validation: Cross-entropy=2.4157376289367676, Accuracy=0.08080808073282242\n",
      "Epoch 78 train: Cross-entropy=2.379772742589315, Accuracy=0.125\n",
      "Epoch 78 validation: Cross-entropy=2.4158058166503906, Accuracy=0.08080808073282242\n",
      "Epoch 79 train: Cross-entropy=2.379576497607761, Accuracy=0.125\n",
      "Epoch 79 validation: Cross-entropy=2.4158732891082764, Accuracy=0.08080808073282242\n",
      "Epoch 80 train: Cross-entropy=2.3793816566467285, Accuracy=0.125\n",
      "Epoch 80 validation: Cross-entropy=2.4159412384033203, Accuracy=0.08080808073282242\n",
      "Epoch 81 train: Cross-entropy=2.379188153478834, Accuracy=0.125\n",
      "Epoch 81 validation: Cross-entropy=2.4160094261169434, Accuracy=0.08080808073282242\n",
      "Epoch 82 train: Cross-entropy=2.3789959881040783, Accuracy=0.125\n",
      "Epoch 82 validation: Cross-entropy=2.4160776138305664, Accuracy=0.08080808073282242\n",
      "Epoch 83 train: Cross-entropy=2.3788051207860312, Accuracy=0.1232638888888889\n",
      "Epoch 83 validation: Cross-entropy=2.4161460399627686, Accuracy=0.08080808073282242\n",
      "Epoch 84 train: Cross-entropy=2.378615630997552, Accuracy=0.125\n",
      "Epoch 84 validation: Cross-entropy=2.4162142276763916, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.3784273995293512, Accuracy=0.125\n",
      "Epoch 85 validation: Cross-entropy=2.416282892227173, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.3782404131359525, Accuracy=0.125\n",
      "Epoch 86 validation: Cross-entropy=2.416351318359375, Accuracy=0.07575757801532745\n",
      "Epoch 87 train: Cross-entropy=2.378054698308309, Accuracy=0.125\n",
      "Epoch 87 validation: Cross-entropy=2.4164199829101562, Accuracy=0.07575757801532745\n",
      "Epoch 88 train: Cross-entropy=2.377870215309991, Accuracy=0.125\n",
      "Epoch 88 validation: Cross-entropy=2.4164888858795166, Accuracy=0.07575757801532745\n",
      "Epoch 89 train: Cross-entropy=2.3776870568593345, Accuracy=0.125\n",
      "Epoch 89 validation: Cross-entropy=2.416557550430298, Accuracy=0.07575757801532745\n",
      "Epoch 90 train: Cross-entropy=2.3775050242741904, Accuracy=0.125\n",
      "Epoch 90 validation: Cross-entropy=2.4166266918182373, Accuracy=0.07575757801532745\n",
      "Epoch 91 train: Cross-entropy=2.377324250009325, Accuracy=0.125\n",
      "Epoch 91 validation: Cross-entropy=2.4166953563690186, Accuracy=0.07575757801532745\n",
      "Epoch 92 train: Cross-entropy=2.377144707573785, Accuracy=0.1232638888888889\n",
      "Epoch 92 validation: Cross-entropy=2.416764497756958, Accuracy=0.07575757801532745\n",
      "Epoch 93 train: Cross-entropy=2.3769662380218506, Accuracy=0.125\n",
      "Epoch 93 validation: Cross-entropy=2.4168336391448975, Accuracy=0.07575757801532745\n",
      "Epoch 94 train: Cross-entropy=2.3767890797721014, Accuracy=0.125\n",
      "Epoch 94 validation: Cross-entropy=2.416902542114258, Accuracy=0.07575757801532745\n",
      "Epoch 95 train: Cross-entropy=2.376613073878818, Accuracy=0.1267361111111111\n",
      "Epoch 95 validation: Cross-entropy=2.4169719219207764, Accuracy=0.07070706784725189\n",
      "Epoch 96 train: Cross-entropy=2.376438114378187, Accuracy=0.1267361111111111\n",
      "Epoch 96 validation: Cross-entropy=2.417041301727295, Accuracy=0.07070706784725189\n",
      "Epoch 97 train: Cross-entropy=2.376264360215929, Accuracy=0.1267361111111111\n",
      "Epoch 97 validation: Cross-entropy=2.4171104431152344, Accuracy=0.06565656512975693\n",
      "Epoch 98 train: Cross-entropy=2.3760917319191828, Accuracy=0.1267361111111111\n",
      "Epoch 98 validation: Cross-entropy=2.417180061340332, Accuracy=0.06565656512975693\n",
      "Epoch 99 train: Cross-entropy=2.375920202996996, Accuracy=0.125\n",
      "Epoch 99 validation: Cross-entropy=2.4172494411468506, Accuracy=0.06565656512975693\n",
      "Epoch 100 train: Cross-entropy=2.375749799940321, Accuracy=0.1267361111111111\n",
      "Epoch 100 validation: Cross-entropy=2.417318820953369, Accuracy=0.06565656512975693\n",
      "Epoch 101 train: Cross-entropy=2.375580522749159, Accuracy=0.1232638888888889\n",
      "Epoch 101 validation: Cross-entropy=2.4173882007598877, Accuracy=0.06060606241226196\n",
      "Epoch 102 train: Cross-entropy=2.375412278705173, Accuracy=0.1232638888888889\n",
      "Epoch 102 validation: Cross-entropy=2.4174578189849854, Accuracy=0.06060606241226196\n",
      "Epoch 103 train: Cross-entropy=2.375245067808363, Accuracy=0.125\n",
      "Epoch 103 validation: Cross-entropy=2.417527437210083, Accuracy=0.06060606241226196\n",
      "Epoch 104 train: Cross-entropy=2.3750789297951593, Accuracy=0.1267361111111111\n",
      "Epoch 104 validation: Cross-entropy=2.4175970554351807, Accuracy=0.06060606241226196\n",
      "Epoch 105 train: Cross-entropy=2.3749139573838978, Accuracy=0.1267361111111111\n",
      "Epoch 105 validation: Cross-entropy=2.417666435241699, Accuracy=0.06060606241226196\n",
      "Epoch 106 train: Cross-entropy=2.374749938646952, Accuracy=0.1267361111111111\n",
      "Epoch 106 validation: Cross-entropy=2.417736053466797, Accuracy=0.06060606241226196\n",
      "Epoch 107 train: Cross-entropy=2.3745869398117065, Accuracy=0.1267361111111111\n",
      "Epoch 107 validation: Cross-entropy=2.4178056716918945, Accuracy=0.06060606241226196\n",
      "Epoch 108 train: Cross-entropy=2.374425013860067, Accuracy=0.1267361111111111\n",
      "Epoch 108 validation: Cross-entropy=2.417875051498413, Accuracy=0.06060606241226196\n",
      "Epoch 109 train: Cross-entropy=2.3742640813191733, Accuracy=0.1267361111111111\n",
      "Epoch 109 validation: Cross-entropy=2.41794490814209, Accuracy=0.0555555559694767\n",
      "Epoch 110 train: Cross-entropy=2.3741040892071195, Accuracy=0.1267361111111111\n",
      "Epoch 110 validation: Cross-entropy=2.4180147647857666, Accuracy=0.0555555559694767\n",
      "Epoch 111 train: Cross-entropy=2.3739451699786716, Accuracy=0.1267361111111111\n",
      "Epoch 111 validation: Cross-entropy=2.4180843830108643, Accuracy=0.0555555559694767\n",
      "Epoch 112 train: Cross-entropy=2.3737871646881104, Accuracy=0.125\n",
      "Epoch 112 validation: Cross-entropy=2.418154001235962, Accuracy=0.0555555559694767\n",
      "Epoch 113 train: Cross-entropy=2.3736302057902017, Accuracy=0.125\n",
      "Epoch 113 validation: Cross-entropy=2.4182236194610596, Accuracy=0.0555555559694767\n",
      "Epoch 114 train: Cross-entropy=2.3734741608301797, Accuracy=0.1267361111111111\n",
      "Epoch 114 validation: Cross-entropy=2.4182932376861572, Accuracy=0.0555555559694767\n",
      "Epoch 115 train: Cross-entropy=2.3733190960354276, Accuracy=0.1267361111111111\n",
      "Epoch 115 validation: Cross-entropy=2.418363094329834, Accuracy=0.0555555559694767\n",
      "Epoch 116 train: Cross-entropy=2.373164905442132, Accuracy=0.1267361111111111\n",
      "Epoch 116 validation: Cross-entropy=2.4184329509735107, Accuracy=0.0555555559694767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 train: Cross-entropy=2.373011668523153, Accuracy=0.1267361111111111\n",
      "Epoch 117 validation: Cross-entropy=2.4185023307800293, Accuracy=0.0555555559694767\n",
      "Epoch 118 train: Cross-entropy=2.372859477996826, Accuracy=0.1267361111111111\n",
      "Epoch 118 validation: Cross-entropy=2.418571949005127, Accuracy=0.0555555559694767\n",
      "Epoch 119 train: Cross-entropy=2.3727080292171903, Accuracy=0.1267361111111111\n",
      "Epoch 119 validation: Cross-entropy=2.4186413288116455, Accuracy=0.0555555559694767\n",
      "Epoch 120 train: Cross-entropy=2.372557587093777, Accuracy=0.1284722222222222\n",
      "Epoch 120 validation: Cross-entropy=2.418710947036743, Accuracy=0.0555555559694767\n",
      "Epoch 121 train: Cross-entropy=2.3724080986446805, Accuracy=0.1284722222222222\n",
      "Epoch 121 validation: Cross-entropy=2.41878080368042, Accuracy=0.06060606241226196\n",
      "Epoch 122 train: Cross-entropy=2.3722593784332275, Accuracy=0.1284722222222222\n",
      "Epoch 122 validation: Cross-entropy=2.4188504219055176, Accuracy=0.06060606241226196\n",
      "Epoch 123 train: Cross-entropy=2.372111585405138, Accuracy=0.1284722222222222\n",
      "Epoch 123 validation: Cross-entropy=2.4189200401306152, Accuracy=0.06060606241226196\n",
      "Epoch 124 train: Cross-entropy=2.371964613596598, Accuracy=0.125\n",
      "Epoch 124 validation: Cross-entropy=2.418989658355713, Accuracy=0.06060606241226196\n",
      "Epoch 125 train: Cross-entropy=2.371818635198805, Accuracy=0.1267361111111111\n",
      "Epoch 125 validation: Cross-entropy=2.4190590381622314, Accuracy=0.06060606241226196\n",
      "Epoch 126 train: Cross-entropy=2.371673438284132, Accuracy=0.1267361111111111\n",
      "Epoch 126 validation: Cross-entropy=2.41912841796875, Accuracy=0.06060606241226196\n",
      "Epoch 127 train: Cross-entropy=2.371529142061869, Accuracy=0.1267361111111111\n",
      "Epoch 127 validation: Cross-entropy=2.4191977977752686, Accuracy=0.06060606241226196\n",
      "Epoch 128 train: Cross-entropy=2.371385587586297, Accuracy=0.1267361111111111\n",
      "Epoch 128 validation: Cross-entropy=2.419267416000366, Accuracy=0.06060606241226196\n",
      "Epoch 129 train: Cross-entropy=2.3712430000305176, Accuracy=0.1284722222222222\n",
      "Epoch 129 validation: Cross-entropy=2.419337034225464, Accuracy=0.06060606241226196\n",
      "Epoch 130 train: Cross-entropy=2.3711011674669056, Accuracy=0.1284722222222222\n",
      "Epoch 130 validation: Cross-entropy=2.4194061756134033, Accuracy=0.06060606241226196\n",
      "Epoch 131 train: Cross-entropy=2.3709601958592734, Accuracy=0.13020833333333334\n",
      "Epoch 131 validation: Cross-entropy=2.419475555419922, Accuracy=0.06060606241226196\n",
      "Epoch 132 train: Cross-entropy=2.370820018980238, Accuracy=0.13020833333333334\n",
      "Epoch 132 validation: Cross-entropy=2.4195449352264404, Accuracy=0.06060606241226196\n",
      "Epoch 133 train: Cross-entropy=2.3706806103388467, Accuracy=0.13020833333333334\n",
      "Epoch 133 validation: Cross-entropy=2.419614315032959, Accuracy=0.06060606241226196\n",
      "Epoch 134 train: Cross-entropy=2.3705420096715293, Accuracy=0.13020833333333334\n",
      "Epoch 134 validation: Cross-entropy=2.4196832180023193, Accuracy=0.06060606241226196\n",
      "Epoch 135 train: Cross-entropy=2.370404256714715, Accuracy=0.13020833333333334\n",
      "Epoch 135 validation: Cross-entropy=2.419752597808838, Accuracy=0.06060606241226196\n",
      "Epoch 136 train: Cross-entropy=2.3702672587500677, Accuracy=0.13020833333333334\n",
      "Epoch 136 validation: Cross-entropy=2.4198217391967773, Accuracy=0.06060606241226196\n",
      "Epoch 137 train: Cross-entropy=2.370130909813775, Accuracy=0.13020833333333334\n",
      "Epoch 137 validation: Cross-entropy=2.419891119003296, Accuracy=0.06060606241226196\n",
      "Epoch 138 train: Cross-entropy=2.369995448324415, Accuracy=0.13020833333333334\n",
      "Epoch 138 validation: Cross-entropy=2.419959783554077, Accuracy=0.06060606241226196\n",
      "Epoch 139 train: Cross-entropy=2.369860741827223, Accuracy=0.13020833333333334\n",
      "Epoch 139 validation: Cross-entropy=2.4200291633605957, Accuracy=0.06060606241226196\n",
      "Epoch 140 train: Cross-entropy=2.3697269360224404, Accuracy=0.13194444444444445\n",
      "Epoch 140 validation: Cross-entropy=2.420097827911377, Accuracy=0.06060606241226196\n",
      "Epoch 141 train: Cross-entropy=2.369593713018629, Accuracy=0.13194444444444445\n",
      "Epoch 141 validation: Cross-entropy=2.4201667308807373, Accuracy=0.06060606241226196\n",
      "Epoch 142 train: Cross-entropy=2.369461258252462, Accuracy=0.13194444444444445\n",
      "Epoch 142 validation: Cross-entropy=2.4202356338500977, Accuracy=0.06060606241226196\n",
      "Epoch 143 train: Cross-entropy=2.3693295849694147, Accuracy=0.13194444444444445\n",
      "Epoch 143 validation: Cross-entropy=2.420304775238037, Accuracy=0.06060606241226196\n",
      "Epoch 144 train: Cross-entropy=2.3691985607147217, Accuracy=0.13194444444444445\n",
      "Epoch 144 validation: Cross-entropy=2.4203732013702393, Accuracy=0.06565656512975693\n",
      "Epoch 145 train: Cross-entropy=2.3690683444341025, Accuracy=0.13194444444444445\n",
      "Epoch 145 validation: Cross-entropy=2.4204418659210205, Accuracy=0.06565656512975693\n",
      "Epoch 146 train: Cross-entropy=2.3689388036727905, Accuracy=0.13194444444444445\n",
      "Epoch 146 validation: Cross-entropy=2.4205105304718018, Accuracy=0.06565656512975693\n",
      "Epoch 147 train: Cross-entropy=2.368809978167216, Accuracy=0.13194444444444445\n",
      "Epoch 147 validation: Cross-entropy=2.420579195022583, Accuracy=0.06565656512975693\n",
      "Epoch 148 train: Cross-entropy=2.368681854671902, Accuracy=0.13194444444444445\n",
      "Epoch 148 validation: Cross-entropy=2.420647621154785, Accuracy=0.06565656512975693\n",
      "Epoch 149 train: Cross-entropy=2.3685544861687555, Accuracy=0.13194444444444445\n",
      "Epoch 149 validation: Cross-entropy=2.4207162857055664, Accuracy=0.06565656512975693\n",
      "Epoch 150 train: Cross-entropy=2.3684277534484863, Accuracy=0.13368055555555555\n",
      "Epoch 150 validation: Cross-entropy=2.4207847118377686, Accuracy=0.06565656512975693\n",
      "Epoch 151 train: Cross-entropy=2.368301683002048, Accuracy=0.13194444444444445\n",
      "Epoch 151 validation: Cross-entropy=2.4208531379699707, Accuracy=0.06565656512975693\n",
      "Epoch 152 train: Cross-entropy=2.3681763145658703, Accuracy=0.13194444444444445\n",
      "Epoch 152 validation: Cross-entropy=2.4209213256835938, Accuracy=0.06565656512975693\n",
      "Epoch 153 train: Cross-entropy=2.368051634894477, Accuracy=0.13541666666666666\n",
      "Epoch 153 validation: Cross-entropy=2.4209892749786377, Accuracy=0.06565656512975693\n",
      "Epoch 154 train: Cross-entropy=2.367927657233344, Accuracy=0.13541666666666666\n",
      "Epoch 154 validation: Cross-entropy=2.42105770111084, Accuracy=0.06565656512975693\n",
      "Epoch 155 train: Cross-entropy=2.367804249127706, Accuracy=0.1371527777777778\n",
      "Epoch 155 validation: Cross-entropy=2.421125650405884, Accuracy=0.06565656512975693\n",
      "Epoch 156 train: Cross-entropy=2.3676815960142346, Accuracy=0.1371527777777778\n",
      "Epoch 156 validation: Cross-entropy=2.421193838119507, Accuracy=0.06565656512975693\n",
      "Epoch 157 train: Cross-entropy=2.3675595919291177, Accuracy=0.1371527777777778\n",
      "Epoch 157 validation: Cross-entropy=2.4212615489959717, Accuracy=0.06565656512975693\n",
      "Epoch 158 train: Cross-entropy=2.3674382501178317, Accuracy=0.1371527777777778\n",
      "Epoch 158 validation: Cross-entropy=2.4213294982910156, Accuracy=0.06565656512975693\n",
      "Epoch 159 train: Cross-entropy=2.367317411634657, Accuracy=0.1388888888888889\n",
      "Epoch 159 validation: Cross-entropy=2.4213974475860596, Accuracy=0.06565656512975693\n",
      "Epoch 160 train: Cross-entropy=2.3671973678800793, Accuracy=0.1371527777777778\n",
      "Epoch 160 validation: Cross-entropy=2.4214651584625244, Accuracy=0.06565656512975693\n",
      "Epoch 161 train: Cross-entropy=2.367077867190043, Accuracy=0.1371527777777778\n",
      "Epoch 161 validation: Cross-entropy=2.4215328693389893, Accuracy=0.06565656512975693\n",
      "Epoch 162 train: Cross-entropy=2.3669590420193143, Accuracy=0.1388888888888889\n",
      "Epoch 162 validation: Cross-entropy=2.421600103378296, Accuracy=0.06565656512975693\n",
      "Epoch 163 train: Cross-entropy=2.3668408658769398, Accuracy=0.1388888888888889\n",
      "Epoch 163 validation: Cross-entropy=2.4216678142547607, Accuracy=0.06565656512975693\n",
      "Epoch 164 train: Cross-entropy=2.366723206308153, Accuracy=0.1388888888888889\n",
      "Epoch 164 validation: Cross-entropy=2.4217355251312256, Accuracy=0.07070706784725189\n",
      "Epoch 165 train: Cross-entropy=2.366606248749627, Accuracy=0.1388888888888889\n",
      "Epoch 165 validation: Cross-entropy=2.4218027591705322, Accuracy=0.07070706784725189\n",
      "Epoch 166 train: Cross-entropy=2.366489847501119, Accuracy=0.1388888888888889\n",
      "Epoch 166 validation: Cross-entropy=2.421869993209839, Accuracy=0.07070706784725189\n",
      "Epoch 167 train: Cross-entropy=2.366374068790012, Accuracy=0.1388888888888889\n",
      "Epoch 167 validation: Cross-entropy=2.4219372272491455, Accuracy=0.07070706784725189\n",
      "Epoch 168 train: Cross-entropy=2.3662588463889227, Accuracy=0.1388888888888889\n",
      "Epoch 168 validation: Cross-entropy=2.422004222869873, Accuracy=0.07070706784725189\n",
      "Epoch 169 train: Cross-entropy=2.366144299507141, Accuracy=0.1388888888888889\n",
      "Epoch 169 validation: Cross-entropy=2.4220714569091797, Accuracy=0.07070706784725189\n",
      "Epoch 170 train: Cross-entropy=2.3660302559534707, Accuracy=0.1388888888888889\n",
      "Epoch 170 validation: Cross-entropy=2.4221384525299072, Accuracy=0.07070706784725189\n",
      "Epoch 171 train: Cross-entropy=2.365916861428155, Accuracy=0.1388888888888889\n",
      "Epoch 171 validation: Cross-entropy=2.4222054481506348, Accuracy=0.07070706784725189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 train: Cross-entropy=2.36580400996738, Accuracy=0.140625\n",
      "Epoch 172 validation: Cross-entropy=2.422272205352783, Accuracy=0.07070706784725189\n",
      "Epoch 173 train: Cross-entropy=2.365691754553053, Accuracy=0.140625\n",
      "Epoch 173 validation: Cross-entropy=2.4223389625549316, Accuracy=0.06565656512975693\n",
      "Epoch 174 train: Cross-entropy=2.365580028957791, Accuracy=0.1423611111111111\n",
      "Epoch 174 validation: Cross-entropy=2.42240571975708, Accuracy=0.06565656512975693\n",
      "Epoch 175 train: Cross-entropy=2.3654688861635, Accuracy=0.1423611111111111\n",
      "Epoch 175 validation: Cross-entropy=2.4224722385406494, Accuracy=0.06565656512975693\n",
      "Epoch 176 train: Cross-entropy=2.365358312924703, Accuracy=0.1423611111111111\n",
      "Epoch 176 validation: Cross-entropy=2.4225387573242188, Accuracy=0.06565656512975693\n",
      "Epoch 177 train: Cross-entropy=2.3652482827504477, Accuracy=0.1423611111111111\n",
      "Epoch 177 validation: Cross-entropy=2.422605037689209, Accuracy=0.06060606241226196\n",
      "Epoch 178 train: Cross-entropy=2.365138782395257, Accuracy=0.1423611111111111\n",
      "Epoch 178 validation: Cross-entropy=2.4226715564727783, Accuracy=0.06060606241226196\n",
      "Epoch 179 train: Cross-entropy=2.3650298383500843, Accuracy=0.1423611111111111\n",
      "Epoch 179 validation: Cross-entropy=2.4227378368377686, Accuracy=0.06060606241226196\n",
      "Epoch 180 train: Cross-entropy=2.3649215830696955, Accuracy=0.1423611111111111\n",
      "Epoch 180 validation: Cross-entropy=2.4228038787841797, Accuracy=0.06060606241226196\n",
      "Epoch 181 train: Cross-entropy=2.3648136721716986, Accuracy=0.1423611111111111\n",
      "Epoch 181 validation: Cross-entropy=2.422869920730591, Accuracy=0.06060606241226196\n",
      "Epoch 182 train: Cross-entropy=2.364706370565626, Accuracy=0.1423611111111111\n",
      "Epoch 182 validation: Cross-entropy=2.422936201095581, Accuracy=0.06060606241226196\n",
      "Epoch 183 train: Cross-entropy=2.3645995325512357, Accuracy=0.1440972222222222\n",
      "Epoch 183 validation: Cross-entropy=2.423002004623413, Accuracy=0.0555555559694767\n",
      "Epoch 184 train: Cross-entropy=2.364493317074246, Accuracy=0.1440972222222222\n",
      "Epoch 184 validation: Cross-entropy=2.423068046569824, Accuracy=0.0555555559694767\n",
      "Epoch 185 train: Cross-entropy=2.364387591679891, Accuracy=0.1440972222222222\n",
      "Epoch 185 validation: Cross-entropy=2.423133611679077, Accuracy=0.0555555559694767\n",
      "Epoch 186 train: Cross-entropy=2.3642823696136475, Accuracy=0.1440972222222222\n",
      "Epoch 186 validation: Cross-entropy=2.42319917678833, Accuracy=0.0555555559694767\n",
      "Epoch 187 train: Cross-entropy=2.364177624384562, Accuracy=0.1440972222222222\n",
      "Epoch 187 validation: Cross-entropy=2.423264741897583, Accuracy=0.0555555559694767\n",
      "Epoch 188 train: Cross-entropy=2.3640734354654946, Accuracy=0.1440972222222222\n",
      "Epoch 188 validation: Cross-entropy=2.423330307006836, Accuracy=0.0555555559694767\n",
      "Epoch 189 train: Cross-entropy=2.3639697896109686, Accuracy=0.14583333333333334\n",
      "Epoch 189 validation: Cross-entropy=2.423395872116089, Accuracy=0.0555555559694767\n",
      "Epoch 190 train: Cross-entropy=2.3638665941026478, Accuracy=0.14583333333333334\n",
      "Epoch 190 validation: Cross-entropy=2.4234607219696045, Accuracy=0.0555555559694767\n",
      "Epoch 191 train: Cross-entropy=2.363763862186008, Accuracy=0.14583333333333334\n",
      "Epoch 191 validation: Cross-entropy=2.4235260486602783, Accuracy=0.0555555559694767\n",
      "Epoch 192 train: Cross-entropy=2.36366163359748, Accuracy=0.14583333333333334\n",
      "Epoch 192 validation: Cross-entropy=2.423591136932373, Accuracy=0.0555555559694767\n",
      "Epoch 193 train: Cross-entropy=2.3635600010553994, Accuracy=0.14583333333333334\n",
      "Epoch 193 validation: Cross-entropy=2.4236562252044678, Accuracy=0.0555555559694767\n",
      "Epoch 194 train: Cross-entropy=2.363458765877618, Accuracy=0.14583333333333334\n",
      "Epoch 194 validation: Cross-entropy=2.4237210750579834, Accuracy=0.0555555559694767\n",
      "Epoch 195 train: Cross-entropy=2.3633580340279474, Accuracy=0.14756944444444445\n",
      "Epoch 195 validation: Cross-entropy=2.423786163330078, Accuracy=0.0555555559694767\n",
      "Epoch 196 train: Cross-entropy=2.363257792260912, Accuracy=0.14756944444444445\n",
      "Epoch 196 validation: Cross-entropy=2.4238510131835938, Accuracy=0.0555555559694767\n",
      "Epoch 197 train: Cross-entropy=2.363158000840081, Accuracy=0.14756944444444445\n",
      "Epoch 197 validation: Cross-entropy=2.4239156246185303, Accuracy=0.0555555559694767\n",
      "Epoch 198 train: Cross-entropy=2.3630587259928384, Accuracy=0.14756944444444445\n",
      "Epoch 198 validation: Cross-entropy=2.4239799976348877, Accuracy=0.0555555559694767\n",
      "Epoch 199 train: Cross-entropy=2.362959861755371, Accuracy=0.14756944444444445\n",
      "Epoch 199 validation: Cross-entropy=2.424044609069824, Accuracy=0.0555555559694767\n",
      "Epoch 0 train: Cross-entropy=2.452625181939867, Accuracy=0.09722222222222222\n",
      "Epoch 0 validation: Cross-entropy=2.4652671813964844, Accuracy=0.07575757801532745\n",
      "Epoch 1 train: Cross-entropy=2.4177606370713978, Accuracy=0.10243055555555555\n",
      "Epoch 1 validation: Cross-entropy=2.4350156784057617, Accuracy=0.07575757801532745\n",
      "Epoch 2 train: Cross-entropy=2.401409387588501, Accuracy=0.11805555555555555\n",
      "Epoch 2 validation: Cross-entropy=2.4219541549682617, Accuracy=0.08585858345031738\n",
      "Epoch 3 train: Cross-entropy=2.396513475312127, Accuracy=0.10069444444444445\n",
      "Epoch 3 validation: Cross-entropy=2.416675090789795, Accuracy=0.08585858345031738\n",
      "Epoch 4 train: Cross-entropy=2.39506733417511, Accuracy=0.10243055555555555\n",
      "Epoch 4 validation: Cross-entropy=2.4145684242248535, Accuracy=0.09595959633588791\n",
      "Epoch 5 train: Cross-entropy=2.3943699068493314, Accuracy=0.09895833333333333\n",
      "Epoch 5 validation: Cross-entropy=2.4137864112854004, Accuracy=0.10606060922145844\n",
      "Epoch 6 train: Cross-entropy=2.393758323457506, Accuracy=0.0954861111111111\n",
      "Epoch 6 validation: Cross-entropy=2.41355562210083, Accuracy=0.10101009905338287\n",
      "Epoch 7 train: Cross-entropy=2.393127931488885, Accuracy=0.09722222222222222\n",
      "Epoch 7 validation: Cross-entropy=2.413543462753296, Accuracy=0.10101009905338287\n",
      "Epoch 8 train: Cross-entropy=2.392484254307217, Accuracy=0.09722222222222222\n",
      "Epoch 8 validation: Cross-entropy=2.4136111736297607, Accuracy=0.10101009905338287\n",
      "Epoch 9 train: Cross-entropy=2.3918403651979236, Accuracy=0.09895833333333333\n",
      "Epoch 9 validation: Cross-entropy=2.4137051105499268, Accuracy=0.10101009905338287\n",
      "Epoch 10 train: Cross-entropy=2.391202833917406, Accuracy=0.09895833333333333\n",
      "Epoch 10 validation: Cross-entropy=2.4138078689575195, Accuracy=0.10101009905338287\n",
      "Epoch 11 train: Cross-entropy=2.3905741506152682, Accuracy=0.10069444444444445\n",
      "Epoch 11 validation: Cross-entropy=2.413914442062378, Accuracy=0.10101009905338287\n",
      "Epoch 12 train: Cross-entropy=2.3899549643198648, Accuracy=0.10416666666666667\n",
      "Epoch 12 validation: Cross-entropy=2.4140233993530273, Accuracy=0.10101009905338287\n",
      "Epoch 13 train: Cross-entropy=2.3893451955583362, Accuracy=0.10416666666666667\n",
      "Epoch 13 validation: Cross-entropy=2.414135456085205, Accuracy=0.10101009905338287\n",
      "Epoch 14 train: Cross-entropy=2.3887445396847196, Accuracy=0.109375\n",
      "Epoch 14 validation: Cross-entropy=2.414250373840332, Accuracy=0.09090909361839294\n",
      "Epoch 15 train: Cross-entropy=2.3881530231899686, Accuracy=0.109375\n",
      "Epoch 15 validation: Cross-entropy=2.414368152618408, Accuracy=0.09090909361839294\n",
      "Epoch 16 train: Cross-entropy=2.387570169236925, Accuracy=0.11284722222222222\n",
      "Epoch 16 validation: Cross-entropy=2.4144890308380127, Accuracy=0.09090909361839294\n",
      "Epoch 17 train: Cross-entropy=2.3869959513346353, Accuracy=0.11458333333333333\n",
      "Epoch 17 validation: Cross-entropy=2.4146125316619873, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.386430170800951, Accuracy=0.11631944444444445\n",
      "Epoch 18 validation: Cross-entropy=2.414738416671753, Accuracy=0.09090909361839294\n",
      "Epoch 19 train: Cross-entropy=2.3858725362353854, Accuracy=0.11631944444444445\n",
      "Epoch 19 validation: Cross-entropy=2.414867401123047, Accuracy=0.09090909361839294\n",
      "Epoch 20 train: Cross-entropy=2.3853231271107993, Accuracy=0.11458333333333333\n",
      "Epoch 20 validation: Cross-entropy=2.414998769760132, Accuracy=0.09090909361839294\n",
      "Epoch 21 train: Cross-entropy=2.3847815990448, Accuracy=0.11458333333333333\n",
      "Epoch 21 validation: Cross-entropy=2.415132522583008, Accuracy=0.09595959633588791\n",
      "Epoch 22 train: Cross-entropy=2.384247819582621, Accuracy=0.11284722222222222\n",
      "Epoch 22 validation: Cross-entropy=2.415268898010254, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 train: Cross-entropy=2.383721696005927, Accuracy=0.11284722222222222\n",
      "Epoch 23 validation: Cross-entropy=2.415407180786133, Accuracy=0.10101009905338287\n",
      "Epoch 24 train: Cross-entropy=2.3832029634051852, Accuracy=0.11458333333333333\n",
      "Epoch 24 validation: Cross-entropy=2.4155476093292236, Accuracy=0.10101009905338287\n",
      "Epoch 25 train: Cross-entropy=2.3826916350258722, Accuracy=0.11631944444444445\n",
      "Epoch 25 validation: Cross-entropy=2.4156899452209473, Accuracy=0.10101009905338287\n",
      "Epoch 26 train: Cross-entropy=2.3821874724494085, Accuracy=0.11979166666666667\n",
      "Epoch 26 validation: Cross-entropy=2.415834426879883, Accuracy=0.10101009905338287\n",
      "Epoch 27 train: Cross-entropy=2.381690422693888, Accuracy=0.1232638888888889\n",
      "Epoch 27 validation: Cross-entropy=2.4159810543060303, Accuracy=0.10101009905338287\n",
      "Epoch 28 train: Cross-entropy=2.3812003003226385, Accuracy=0.11979166666666667\n",
      "Epoch 28 validation: Cross-entropy=2.4161291122436523, Accuracy=0.09090909361839294\n",
      "Epoch 29 train: Cross-entropy=2.380716919898987, Accuracy=0.11979166666666667\n",
      "Epoch 29 validation: Cross-entropy=2.416278839111328, Accuracy=0.09090909361839294\n",
      "Epoch 30 train: Cross-entropy=2.380240241686503, Accuracy=0.12152777777777778\n",
      "Epoch 30 validation: Cross-entropy=2.4164302349090576, Accuracy=0.09595959633588791\n",
      "Epoch 31 train: Cross-entropy=2.3797700272666082, Accuracy=0.1232638888888889\n",
      "Epoch 31 validation: Cross-entropy=2.4165830612182617, Accuracy=0.09595959633588791\n",
      "Epoch 32 train: Cross-entropy=2.3793063826031156, Accuracy=0.1267361111111111\n",
      "Epoch 32 validation: Cross-entropy=2.4167377948760986, Accuracy=0.09595959633588791\n",
      "Epoch 33 train: Cross-entropy=2.378848844104343, Accuracy=0.1284722222222222\n",
      "Epoch 33 validation: Cross-entropy=2.41689395904541, Accuracy=0.09595959633588791\n",
      "Epoch 34 train: Cross-entropy=2.3783975972069635, Accuracy=0.1284722222222222\n",
      "Epoch 34 validation: Cross-entropy=2.417051076889038, Accuracy=0.09595959633588791\n",
      "Epoch 35 train: Cross-entropy=2.377952496210734, Accuracy=0.13368055555555555\n",
      "Epoch 35 validation: Cross-entropy=2.4172096252441406, Accuracy=0.09595959633588791\n",
      "Epoch 36 train: Cross-entropy=2.3775132497151694, Accuracy=0.13194444444444445\n",
      "Epoch 36 validation: Cross-entropy=2.4173696041107178, Accuracy=0.09595959633588791\n",
      "Epoch 37 train: Cross-entropy=2.377079897456699, Accuracy=0.13541666666666666\n",
      "Epoch 37 validation: Cross-entropy=2.4175305366516113, Accuracy=0.09090909361839294\n",
      "Epoch 38 train: Cross-entropy=2.3766522539986505, Accuracy=0.1371527777777778\n",
      "Epoch 38 validation: Cross-entropy=2.4176924228668213, Accuracy=0.09090909361839294\n",
      "Epoch 39 train: Cross-entropy=2.3762302928500705, Accuracy=0.13541666666666666\n",
      "Epoch 39 validation: Cross-entropy=2.4178555011749268, Accuracy=0.08585858345031738\n",
      "Epoch 40 train: Cross-entropy=2.375813947783576, Accuracy=0.13541666666666666\n",
      "Epoch 40 validation: Cross-entropy=2.4180195331573486, Accuracy=0.08585858345031738\n",
      "Epoch 41 train: Cross-entropy=2.3754028611712985, Accuracy=0.13368055555555555\n",
      "Epoch 41 validation: Cross-entropy=2.418184280395508, Accuracy=0.08585858345031738\n",
      "Epoch 42 train: Cross-entropy=2.3749971522225275, Accuracy=0.13020833333333334\n",
      "Epoch 42 validation: Cross-entropy=2.4183504581451416, Accuracy=0.08585858345031738\n",
      "Epoch 43 train: Cross-entropy=2.374596847428216, Accuracy=0.13194444444444445\n",
      "Epoch 43 validation: Cross-entropy=2.4185171127319336, Accuracy=0.08585858345031738\n",
      "Epoch 44 train: Cross-entropy=2.3742015891604953, Accuracy=0.13368055555555555\n",
      "Epoch 44 validation: Cross-entropy=2.418684720993042, Accuracy=0.08585858345031738\n",
      "Epoch 45 train: Cross-entropy=2.373811403910319, Accuracy=0.13194444444444445\n",
      "Epoch 45 validation: Cross-entropy=2.4188528060913086, Accuracy=0.08585858345031738\n",
      "Epoch 46 train: Cross-entropy=2.3734261989593506, Accuracy=0.13541666666666666\n",
      "Epoch 46 validation: Cross-entropy=2.4190213680267334, Accuracy=0.08585858345031738\n",
      "Epoch 47 train: Cross-entropy=2.373045881589254, Accuracy=0.1388888888888889\n",
      "Epoch 47 validation: Cross-entropy=2.4191908836364746, Accuracy=0.09090909361839294\n",
      "Epoch 48 train: Cross-entropy=2.372670385572645, Accuracy=0.1371527777777778\n",
      "Epoch 48 validation: Cross-entropy=2.419361114501953, Accuracy=0.09595959633588791\n",
      "Epoch 49 train: Cross-entropy=2.3722995784547596, Accuracy=0.140625\n",
      "Epoch 49 validation: Cross-entropy=2.41953182220459, Accuracy=0.09090909361839294\n",
      "Epoch 50 train: Cross-entropy=2.3719334602355957, Accuracy=0.140625\n",
      "Epoch 50 validation: Cross-entropy=2.419703245162964, Accuracy=0.09090909361839294\n",
      "Epoch 51 train: Cross-entropy=2.3715718189875283, Accuracy=0.1423611111111111\n",
      "Epoch 51 validation: Cross-entropy=2.419874668121338, Accuracy=0.09090909361839294\n",
      "Epoch 52 train: Cross-entropy=2.37121484014723, Accuracy=0.140625\n",
      "Epoch 52 validation: Cross-entropy=2.420046806335449, Accuracy=0.09090909361839294\n",
      "Epoch 53 train: Cross-entropy=2.3708620071411133, Accuracy=0.1388888888888889\n",
      "Epoch 53 validation: Cross-entropy=2.4202189445495605, Accuracy=0.08585858345031738\n",
      "Epoch 54 train: Cross-entropy=2.3705136908425226, Accuracy=0.1388888888888889\n",
      "Epoch 54 validation: Cross-entropy=2.420391798019409, Accuracy=0.09090909361839294\n",
      "Epoch 55 train: Cross-entropy=2.370169520378113, Accuracy=0.140625\n",
      "Epoch 55 validation: Cross-entropy=2.420565128326416, Accuracy=0.09090909361839294\n",
      "Epoch 56 train: Cross-entropy=2.3698295752207437, Accuracy=0.1371527777777778\n",
      "Epoch 56 validation: Cross-entropy=2.4207382202148438, Accuracy=0.09090909361839294\n",
      "Epoch 57 train: Cross-entropy=2.369493749406603, Accuracy=0.13368055555555555\n",
      "Epoch 57 validation: Cross-entropy=2.4209117889404297, Accuracy=0.09090909361839294\n",
      "Epoch 58 train: Cross-entropy=2.3691619237264, Accuracy=0.13194444444444445\n",
      "Epoch 58 validation: Cross-entropy=2.4210855960845947, Accuracy=0.09090909361839294\n",
      "Epoch 59 train: Cross-entropy=2.3688341246710882, Accuracy=0.13541666666666666\n",
      "Epoch 59 validation: Cross-entropy=2.421259641647339, Accuracy=0.09090909361839294\n",
      "Epoch 60 train: Cross-entropy=2.3685102462768555, Accuracy=0.13541666666666666\n",
      "Epoch 60 validation: Cross-entropy=2.421433925628662, Accuracy=0.09090909361839294\n",
      "Epoch 61 train: Cross-entropy=2.368190195825365, Accuracy=0.1371527777777778\n",
      "Epoch 61 validation: Cross-entropy=2.4216079711914062, Accuracy=0.09090909361839294\n",
      "Epoch 62 train: Cross-entropy=2.3678739070892334, Accuracy=0.140625\n",
      "Epoch 62 validation: Cross-entropy=2.4217822551727295, Accuracy=0.09090909361839294\n",
      "Epoch 63 train: Cross-entropy=2.367561380068461, Accuracy=0.1423611111111111\n",
      "Epoch 63 validation: Cross-entropy=2.421956777572632, Accuracy=0.08080808073282242\n",
      "Epoch 64 train: Cross-entropy=2.367252548535665, Accuracy=0.1423611111111111\n",
      "Epoch 64 validation: Cross-entropy=2.422131061553955, Accuracy=0.08080808073282242\n",
      "Epoch 65 train: Cross-entropy=2.3669472402996488, Accuracy=0.1440972222222222\n",
      "Epoch 65 validation: Cross-entropy=2.4223055839538574, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.366645442114936, Accuracy=0.1423611111111111\n",
      "Epoch 66 validation: Cross-entropy=2.4224798679351807, Accuracy=0.07070706784725189\n",
      "Epoch 67 train: Cross-entropy=2.36634718047248, Accuracy=0.140625\n",
      "Epoch 67 validation: Cross-entropy=2.422654390335083, Accuracy=0.07070706784725189\n",
      "Epoch 68 train: Cross-entropy=2.3660522964265613, Accuracy=0.1423611111111111\n",
      "Epoch 68 validation: Cross-entropy=2.4228286743164062, Accuracy=0.07070706784725189\n",
      "Epoch 69 train: Cross-entropy=2.3657608959409924, Accuracy=0.140625\n",
      "Epoch 69 validation: Cross-entropy=2.4230029582977295, Accuracy=0.07070706784725189\n",
      "Epoch 70 train: Cross-entropy=2.3654727141062417, Accuracy=0.14583333333333334\n",
      "Epoch 70 validation: Cross-entropy=2.4231767654418945, Accuracy=0.07070706784725189\n",
      "Epoch 71 train: Cross-entropy=2.365187896622552, Accuracy=0.14583333333333334\n",
      "Epoch 71 validation: Cross-entropy=2.4233505725860596, Accuracy=0.07070706784725189\n",
      "Epoch 72 train: Cross-entropy=2.36490617858039, Accuracy=0.1440972222222222\n",
      "Epoch 72 validation: Cross-entropy=2.4235243797302246, Accuracy=0.07575757801532745\n",
      "Epoch 73 train: Cross-entropy=2.3646276659435697, Accuracy=0.14583333333333334\n",
      "Epoch 73 validation: Cross-entropy=2.4236979484558105, Accuracy=0.07575757801532745\n",
      "Epoch 74 train: Cross-entropy=2.364352265993754, Accuracy=0.14583333333333334\n",
      "Epoch 74 validation: Cross-entropy=2.4238715171813965, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.364079886012607, Accuracy=0.14756944444444445\n",
      "Epoch 75 validation: Cross-entropy=2.4240448474884033, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.363810565736559, Accuracy=0.14756944444444445\n",
      "Epoch 76 validation: Cross-entropy=2.424217700958252, Accuracy=0.07070706784725189\n",
      "Epoch 77 train: Cross-entropy=2.3635442654291787, Accuracy=0.14756944444444445\n",
      "Epoch 77 validation: Cross-entropy=2.4243903160095215, Accuracy=0.07070706784725189\n",
      "Epoch 78 train: Cross-entropy=2.363280826144748, Accuracy=0.14756944444444445\n",
      "Epoch 78 validation: Cross-entropy=2.424562692642212, Accuracy=0.06565656512975693\n",
      "Epoch 79 train: Cross-entropy=2.3630202611287436, Accuracy=0.14583333333333334\n",
      "Epoch 79 validation: Cross-entropy=2.4247350692749023, Accuracy=0.06565656512975693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 train: Cross-entropy=2.3627625041537814, Accuracy=0.14583333333333334\n",
      "Epoch 80 validation: Cross-entropy=2.4249067306518555, Accuracy=0.06565656512975693\n",
      "Epoch 81 train: Cross-entropy=2.362507594956292, Accuracy=0.14583333333333334\n",
      "Epoch 81 validation: Cross-entropy=2.4250781536102295, Accuracy=0.06565656512975693\n",
      "Epoch 82 train: Cross-entropy=2.362255401081509, Accuracy=0.14756944444444445\n",
      "Epoch 82 validation: Cross-entropy=2.4252493381500244, Accuracy=0.06565656512975693\n",
      "Epoch 83 train: Cross-entropy=2.362005935774909, Accuracy=0.14583333333333334\n",
      "Epoch 83 validation: Cross-entropy=2.425420045852661, Accuracy=0.06565656512975693\n",
      "Epoch 84 train: Cross-entropy=2.361759146054586, Accuracy=0.14756944444444445\n",
      "Epoch 84 validation: Cross-entropy=2.425590753555298, Accuracy=0.06565656512975693\n",
      "Epoch 85 train: Cross-entropy=2.3615149127112494, Accuracy=0.14756944444444445\n",
      "Epoch 85 validation: Cross-entropy=2.4257607460021973, Accuracy=0.06565656512975693\n",
      "Epoch 86 train: Cross-entropy=2.3612733284632363, Accuracy=0.14756944444444445\n",
      "Epoch 86 validation: Cross-entropy=2.4259305000305176, Accuracy=0.06565656512975693\n",
      "Epoch 87 train: Cross-entropy=2.3610343270831637, Accuracy=0.14756944444444445\n",
      "Epoch 87 validation: Cross-entropy=2.4260997772216797, Accuracy=0.06565656512975693\n",
      "Epoch 88 train: Cross-entropy=2.3607977628707886, Accuracy=0.14583333333333334\n",
      "Epoch 88 validation: Cross-entropy=2.4262688159942627, Accuracy=0.07070706784725189\n",
      "Epoch 89 train: Cross-entropy=2.360563728544447, Accuracy=0.1440972222222222\n",
      "Epoch 89 validation: Cross-entropy=2.4264369010925293, Accuracy=0.07070706784725189\n",
      "Epoch 90 train: Cross-entropy=2.3603320121765137, Accuracy=0.14583333333333334\n",
      "Epoch 90 validation: Cross-entropy=2.426605224609375, Accuracy=0.07070706784725189\n",
      "Epoch 91 train: Cross-entropy=2.360102825694614, Accuracy=0.1440972222222222\n",
      "Epoch 91 validation: Cross-entropy=2.4267728328704834, Accuracy=0.07575757801532745\n",
      "Epoch 92 train: Cross-entropy=2.3598759041892157, Accuracy=0.1440972222222222\n",
      "Epoch 92 validation: Cross-entropy=2.4269399642944336, Accuracy=0.07575757801532745\n",
      "Epoch 93 train: Cross-entropy=2.3596513668696084, Accuracy=0.1440972222222222\n",
      "Epoch 93 validation: Cross-entropy=2.4271063804626465, Accuracy=0.07575757801532745\n",
      "Epoch 94 train: Cross-entropy=2.3594290945265026, Accuracy=0.14583333333333334\n",
      "Epoch 94 validation: Cross-entropy=2.4272725582122803, Accuracy=0.07575757801532745\n",
      "Epoch 95 train: Cross-entropy=2.359209073914422, Accuracy=0.1423611111111111\n",
      "Epoch 95 validation: Cross-entropy=2.4274380207061768, Accuracy=0.07575757801532745\n",
      "Epoch 96 train: Cross-entropy=2.3589913182788425, Accuracy=0.140625\n",
      "Epoch 96 validation: Cross-entropy=2.4276037216186523, Accuracy=0.07575757801532745\n",
      "Epoch 97 train: Cross-entropy=2.3587757878833346, Accuracy=0.140625\n",
      "Epoch 97 validation: Cross-entropy=2.4277679920196533, Accuracy=0.07575757801532745\n",
      "Epoch 98 train: Cross-entropy=2.3585623370276556, Accuracy=0.140625\n",
      "Epoch 98 validation: Cross-entropy=2.4279322624206543, Accuracy=0.07575757801532745\n",
      "Epoch 99 train: Cross-entropy=2.3583510716756186, Accuracy=0.140625\n",
      "Epoch 99 validation: Cross-entropy=2.428096055984497, Accuracy=0.07575757801532745\n",
      "Epoch 100 train: Cross-entropy=2.3581418991088867, Accuracy=0.1388888888888889\n",
      "Epoch 100 validation: Cross-entropy=2.4282591342926025, Accuracy=0.07575757801532745\n",
      "Epoch 101 train: Cross-entropy=2.3579348060819836, Accuracy=0.140625\n",
      "Epoch 101 validation: Cross-entropy=2.42842173576355, Accuracy=0.07575757801532745\n",
      "Epoch 102 train: Cross-entropy=2.3577297396130033, Accuracy=0.140625\n",
      "Epoch 102 validation: Cross-entropy=2.4285836219787598, Accuracy=0.07575757801532745\n",
      "Epoch 103 train: Cross-entropy=2.357526765929328, Accuracy=0.140625\n",
      "Epoch 103 validation: Cross-entropy=2.4287452697753906, Accuracy=0.07575757801532745\n",
      "Epoch 104 train: Cross-entropy=2.357325633366903, Accuracy=0.1388888888888889\n",
      "Epoch 104 validation: Cross-entropy=2.428905963897705, Accuracy=0.07070706784725189\n",
      "Epoch 105 train: Cross-entropy=2.3571266068352594, Accuracy=0.140625\n",
      "Epoch 105 validation: Cross-entropy=2.4290661811828613, Accuracy=0.07070706784725189\n",
      "Epoch 106 train: Cross-entropy=2.3569294214248657, Accuracy=0.1423611111111111\n",
      "Epoch 106 validation: Cross-entropy=2.4292259216308594, Accuracy=0.07070706784725189\n",
      "Epoch 107 train: Cross-entropy=2.3567340903811984, Accuracy=0.1440972222222222\n",
      "Epoch 107 validation: Cross-entropy=2.429385185241699, Accuracy=0.07575757801532745\n",
      "Epoch 108 train: Cross-entropy=2.3565407726499767, Accuracy=0.14583333333333334\n",
      "Epoch 108 validation: Cross-entropy=2.4295437335968018, Accuracy=0.07575757801532745\n",
      "Epoch 109 train: Cross-entropy=2.356349229812622, Accuracy=0.14583333333333334\n",
      "Epoch 109 validation: Cross-entropy=2.429702043533325, Accuracy=0.07575757801532745\n",
      "Epoch 110 train: Cross-entropy=2.3561595413419933, Accuracy=0.14583333333333334\n",
      "Epoch 110 validation: Cross-entropy=2.4298593997955322, Accuracy=0.07575757801532745\n",
      "Epoch 111 train: Cross-entropy=2.355971614519755, Accuracy=0.14583333333333334\n",
      "Epoch 111 validation: Cross-entropy=2.430016040802002, Accuracy=0.07575757801532745\n",
      "Epoch 112 train: Cross-entropy=2.3557855553097196, Accuracy=0.14583333333333334\n",
      "Epoch 112 validation: Cross-entropy=2.4301719665527344, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.355601125293308, Accuracy=0.14583333333333334\n",
      "Epoch 113 validation: Cross-entropy=2.430327892303467, Accuracy=0.08080808073282242\n",
      "Epoch 114 train: Cross-entropy=2.3554184569252863, Accuracy=0.14583333333333334\n",
      "Epoch 114 validation: Cross-entropy=2.430482864379883, Accuracy=0.08080808073282242\n",
      "Epoch 115 train: Cross-entropy=2.3552375634511313, Accuracy=0.14756944444444445\n",
      "Epoch 115 validation: Cross-entropy=2.4306373596191406, Accuracy=0.08080808073282242\n",
      "Epoch 116 train: Cross-entropy=2.3550582859251232, Accuracy=0.14756944444444445\n",
      "Epoch 116 validation: Cross-entropy=2.430791139602661, Accuracy=0.08080808073282242\n",
      "Epoch 117 train: Cross-entropy=2.3548807038201227, Accuracy=0.14756944444444445\n",
      "Epoch 117 validation: Cross-entropy=2.4309444427490234, Accuracy=0.08080808073282242\n",
      "Epoch 118 train: Cross-entropy=2.3547047509087458, Accuracy=0.14756944444444445\n",
      "Epoch 118 validation: Cross-entropy=2.4310970306396484, Accuracy=0.08080808073282242\n",
      "Epoch 119 train: Cross-entropy=2.3545304669274225, Accuracy=0.14756944444444445\n",
      "Epoch 119 validation: Cross-entropy=2.431248903274536, Accuracy=0.08585858345031738\n",
      "Epoch 120 train: Cross-entropy=2.3543577194213867, Accuracy=0.14756944444444445\n",
      "Epoch 120 validation: Cross-entropy=2.4313998222351074, Accuracy=0.08585858345031738\n",
      "Epoch 121 train: Cross-entropy=2.3541865613725452, Accuracy=0.14756944444444445\n",
      "Epoch 121 validation: Cross-entropy=2.4315505027770996, Accuracy=0.08585858345031738\n",
      "Epoch 122 train: Cross-entropy=2.354016900062561, Accuracy=0.14756944444444445\n",
      "Epoch 122 validation: Cross-entropy=2.4317009449005127, Accuracy=0.08585858345031738\n",
      "Epoch 123 train: Cross-entropy=2.3538489076826306, Accuracy=0.14756944444444445\n",
      "Epoch 123 validation: Cross-entropy=2.4318501949310303, Accuracy=0.08585858345031738\n",
      "Epoch 124 train: Cross-entropy=2.3536823193232217, Accuracy=0.14756944444444445\n",
      "Epoch 124 validation: Cross-entropy=2.4319989681243896, Accuracy=0.08585858345031738\n",
      "Epoch 125 train: Cross-entropy=2.3535172674391003, Accuracy=0.14756944444444445\n",
      "Epoch 125 validation: Cross-entropy=2.4321470260620117, Accuracy=0.08585858345031738\n",
      "Epoch 126 train: Cross-entropy=2.3533536195755005, Accuracy=0.1527777777777778\n",
      "Epoch 126 validation: Cross-entropy=2.4322941303253174, Accuracy=0.08585858345031738\n",
      "Epoch 127 train: Cross-entropy=2.3531916009055243, Accuracy=0.1545138888888889\n",
      "Epoch 127 validation: Cross-entropy=2.432441473007202, Accuracy=0.08585858345031738\n",
      "Epoch 128 train: Cross-entropy=2.3530308405558267, Accuracy=0.1527777777777778\n",
      "Epoch 128 validation: Cross-entropy=2.4325876235961914, Accuracy=0.08585858345031738\n",
      "Epoch 129 train: Cross-entropy=2.35287164317237, Accuracy=0.1527777777777778\n",
      "Epoch 129 validation: Cross-entropy=2.4327330589294434, Accuracy=0.08585858345031738\n",
      "Epoch 130 train: Cross-entropy=2.3527136776182385, Accuracy=0.1527777777777778\n",
      "Epoch 130 validation: Cross-entropy=2.432878017425537, Accuracy=0.08585858345031738\n",
      "Epoch 131 train: Cross-entropy=2.352557275030348, Accuracy=0.15625\n",
      "Epoch 131 validation: Cross-entropy=2.4330222606658936, Accuracy=0.08585858345031738\n",
      "Epoch 132 train: Cross-entropy=2.3524021440082126, Accuracy=0.15625\n",
      "Epoch 132 validation: Cross-entropy=2.4331657886505127, Accuracy=0.08585858345031738\n",
      "Epoch 133 train: Cross-entropy=2.3522483110427856, Accuracy=0.1579861111111111\n",
      "Epoch 133 validation: Cross-entropy=2.4333088397979736, Accuracy=0.08585858345031738\n",
      "Epoch 134 train: Cross-entropy=2.3520958688524036, Accuracy=0.1579861111111111\n",
      "Epoch 134 validation: Cross-entropy=2.433450937271118, Accuracy=0.08585858345031738\n",
      "Epoch 135 train: Cross-entropy=2.351944777700636, Accuracy=0.1579861111111111\n",
      "Epoch 135 validation: Cross-entropy=2.4335925579071045, Accuracy=0.08585858345031738\n",
      "Epoch 136 train: Cross-entropy=2.3517949713601007, Accuracy=0.1579861111111111\n",
      "Epoch 136 validation: Cross-entropy=2.4337334632873535, Accuracy=0.08585858345031738\n",
      "Epoch 137 train: Cross-entropy=2.3516463571124606, Accuracy=0.1579861111111111\n",
      "Epoch 137 validation: Cross-entropy=2.4338738918304443, Accuracy=0.08585858345031738\n",
      "Epoch 138 train: Cross-entropy=2.3514990939034357, Accuracy=0.1579861111111111\n",
      "Epoch 138 validation: Cross-entropy=2.4340133666992188, Accuracy=0.08585858345031738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 train: Cross-entropy=2.351353089014689, Accuracy=0.1579861111111111\n",
      "Epoch 139 validation: Cross-entropy=2.434152364730835, Accuracy=0.08585858345031738\n",
      "Epoch 140 train: Cross-entropy=2.351208223236932, Accuracy=0.1579861111111111\n",
      "Epoch 140 validation: Cross-entropy=2.434290885925293, Accuracy=0.08585858345031738\n",
      "Epoch 141 train: Cross-entropy=2.3510646952523127, Accuracy=0.1579861111111111\n",
      "Epoch 141 validation: Cross-entropy=2.4344284534454346, Accuracy=0.08585858345031738\n",
      "Epoch 142 train: Cross-entropy=2.3509223461151123, Accuracy=0.1597222222222222\n",
      "Epoch 142 validation: Cross-entropy=2.434565782546997, Accuracy=0.08585858345031738\n",
      "Epoch 143 train: Cross-entropy=2.3507810963524713, Accuracy=0.1597222222222222\n",
      "Epoch 143 validation: Cross-entropy=2.434702157974243, Accuracy=0.08585858345031738\n",
      "Epoch 144 train: Cross-entropy=2.3506411711374917, Accuracy=0.1597222222222222\n",
      "Epoch 144 validation: Cross-entropy=2.434837818145752, Accuracy=0.08585858345031738\n",
      "Epoch 145 train: Cross-entropy=2.350502332051595, Accuracy=0.16145833333333334\n",
      "Epoch 145 validation: Cross-entropy=2.4349730014801025, Accuracy=0.08585858345031738\n",
      "Epoch 146 train: Cross-entropy=2.350364605585734, Accuracy=0.16145833333333334\n",
      "Epoch 146 validation: Cross-entropy=2.435107469558716, Accuracy=0.08585858345031738\n",
      "Epoch 147 train: Cross-entropy=2.3502280844582453, Accuracy=0.16145833333333334\n",
      "Epoch 147 validation: Cross-entropy=2.435241222381592, Accuracy=0.08585858345031738\n",
      "Epoch 148 train: Cross-entropy=2.3500926229688854, Accuracy=0.16145833333333334\n",
      "Epoch 148 validation: Cross-entropy=2.4353744983673096, Accuracy=0.09090909361839294\n",
      "Epoch 149 train: Cross-entropy=2.349958313835992, Accuracy=0.16145833333333334\n",
      "Epoch 149 validation: Cross-entropy=2.435506820678711, Accuracy=0.09090909361839294\n",
      "Epoch 150 train: Cross-entropy=2.349825077586704, Accuracy=0.16145833333333334\n",
      "Epoch 150 validation: Cross-entropy=2.435638666152954, Accuracy=0.09090909361839294\n",
      "Epoch 151 train: Cross-entropy=2.3496929672029285, Accuracy=0.16145833333333334\n",
      "Epoch 151 validation: Cross-entropy=2.435770034790039, Accuracy=0.09090909361839294\n",
      "Epoch 152 train: Cross-entropy=2.349561929702759, Accuracy=0.16145833333333334\n",
      "Epoch 152 validation: Cross-entropy=2.4359006881713867, Accuracy=0.09090909361839294\n",
      "Epoch 153 train: Cross-entropy=2.3494318988588123, Accuracy=0.16145833333333334\n",
      "Epoch 153 validation: Cross-entropy=2.436030626296997, Accuracy=0.09090909361839294\n",
      "Epoch 154 train: Cross-entropy=2.3493029408984714, Accuracy=0.16319444444444445\n",
      "Epoch 154 validation: Cross-entropy=2.436159610748291, Accuracy=0.09090909361839294\n",
      "Epoch 155 train: Cross-entropy=2.3491749366124473, Accuracy=0.1597222222222222\n",
      "Epoch 155 validation: Cross-entropy=2.4362881183624268, Accuracy=0.09090909361839294\n",
      "Epoch 156 train: Cross-entropy=2.3490480846828885, Accuracy=0.16145833333333334\n",
      "Epoch 156 validation: Cross-entropy=2.4364163875579834, Accuracy=0.09090909361839294\n",
      "Epoch 157 train: Cross-entropy=2.3489221334457397, Accuracy=0.16145833333333334\n",
      "Epoch 157 validation: Cross-entropy=2.4365437030792236, Accuracy=0.09090909361839294\n",
      "Epoch 158 train: Cross-entropy=2.348797175619337, Accuracy=0.16145833333333334\n",
      "Epoch 158 validation: Cross-entropy=2.4366700649261475, Accuracy=0.09090909361839294\n",
      "Epoch 159 train: Cross-entropy=2.3486732244491577, Accuracy=0.16145833333333334\n",
      "Epoch 159 validation: Cross-entropy=2.4367966651916504, Accuracy=0.09090909361839294\n",
      "Epoch 160 train: Cross-entropy=2.348550306426154, Accuracy=0.16145833333333334\n",
      "Epoch 160 validation: Cross-entropy=2.4369218349456787, Accuracy=0.09090909361839294\n",
      "Epoch 161 train: Cross-entropy=2.348428381813897, Accuracy=0.16145833333333334\n",
      "Epoch 161 validation: Cross-entropy=2.437046766281128, Accuracy=0.09090909361839294\n",
      "Epoch 162 train: Cross-entropy=2.3483073578940497, Accuracy=0.16145833333333334\n",
      "Epoch 162 validation: Cross-entropy=2.4371707439422607, Accuracy=0.09090909361839294\n",
      "Epoch 163 train: Cross-entropy=2.348187247912089, Accuracy=0.16145833333333334\n",
      "Epoch 163 validation: Cross-entropy=2.4372944831848145, Accuracy=0.09090909361839294\n",
      "Epoch 164 train: Cross-entropy=2.3480679988861084, Accuracy=0.16145833333333334\n",
      "Epoch 164 validation: Cross-entropy=2.4374170303344727, Accuracy=0.09090909361839294\n",
      "Epoch 165 train: Cross-entropy=2.3479497962527804, Accuracy=0.16145833333333334\n",
      "Epoch 165 validation: Cross-entropy=2.4375393390655518, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.3478324678209095, Accuracy=0.16145833333333334\n",
      "Epoch 166 validation: Cross-entropy=2.4376614093780518, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.347716040081448, Accuracy=0.16145833333333334\n",
      "Epoch 167 validation: Cross-entropy=2.4377822875976562, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.34760049978892, Accuracy=0.16145833333333334\n",
      "Epoch 168 validation: Cross-entropy=2.4379026889801025, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.347485886679755, Accuracy=0.16145833333333334\n",
      "Epoch 169 validation: Cross-entropy=2.4380223751068115, Accuracy=0.09090909361839294\n",
      "Epoch 170 train: Cross-entropy=2.347372055053711, Accuracy=0.16145833333333334\n",
      "Epoch 170 validation: Cross-entropy=2.4381415843963623, Accuracy=0.09090909361839294\n",
      "Epoch 171 train: Cross-entropy=2.3472591506110296, Accuracy=0.16145833333333334\n",
      "Epoch 171 validation: Cross-entropy=2.438260078430176, Accuracy=0.09090909361839294\n",
      "Epoch 172 train: Cross-entropy=2.3471471071243286, Accuracy=0.16145833333333334\n",
      "Epoch 172 validation: Cross-entropy=2.438377857208252, Accuracy=0.09090909361839294\n",
      "Epoch 173 train: Cross-entropy=2.3470358186297946, Accuracy=0.16145833333333334\n",
      "Epoch 173 validation: Cross-entropy=2.43849515914917, Accuracy=0.09090909361839294\n",
      "Epoch 174 train: Cross-entropy=2.3469254440731473, Accuracy=0.16145833333333334\n",
      "Epoch 174 validation: Cross-entropy=2.4386117458343506, Accuracy=0.09090909361839294\n",
      "Epoch 175 train: Cross-entropy=2.346815903981527, Accuracy=0.16145833333333334\n",
      "Epoch 175 validation: Cross-entropy=2.438727855682373, Accuracy=0.09090909361839294\n",
      "Epoch 176 train: Cross-entropy=2.34670709239112, Accuracy=0.16145833333333334\n",
      "Epoch 176 validation: Cross-entropy=2.4388434886932373, Accuracy=0.09090909361839294\n",
      "Epoch 177 train: Cross-entropy=2.3465991814931235, Accuracy=0.16145833333333334\n",
      "Epoch 177 validation: Cross-entropy=2.438958168029785, Accuracy=0.09090909361839294\n",
      "Epoch 178 train: Cross-entropy=2.3464921050601535, Accuracy=0.16145833333333334\n",
      "Epoch 178 validation: Cross-entropy=2.439072370529175, Accuracy=0.09090909361839294\n",
      "Epoch 179 train: Cross-entropy=2.3463856511645846, Accuracy=0.16145833333333334\n",
      "Epoch 179 validation: Cross-entropy=2.4391860961914062, Accuracy=0.09090909361839294\n",
      "Epoch 180 train: Cross-entropy=2.346280097961426, Accuracy=0.16145833333333334\n",
      "Epoch 180 validation: Cross-entropy=2.4392991065979004, Accuracy=0.09090909361839294\n",
      "Epoch 181 train: Cross-entropy=2.346175286504957, Accuracy=0.16145833333333334\n",
      "Epoch 181 validation: Cross-entropy=2.4394118785858154, Accuracy=0.09090909361839294\n",
      "Epoch 182 train: Cross-entropy=2.3460713492499456, Accuracy=0.16319444444444445\n",
      "Epoch 182 validation: Cross-entropy=2.439523458480835, Accuracy=0.09090909361839294\n",
      "Epoch 183 train: Cross-entropy=2.3459680212868586, Accuracy=0.16319444444444445\n",
      "Epoch 183 validation: Cross-entropy=2.4396345615386963, Accuracy=0.09090909361839294\n",
      "Epoch 184 train: Cross-entropy=2.3458655145433216, Accuracy=0.16319444444444445\n",
      "Epoch 184 validation: Cross-entropy=2.4397454261779785, Accuracy=0.09090909361839294\n",
      "Epoch 185 train: Cross-entropy=2.3457637098100452, Accuracy=0.16319444444444445\n",
      "Epoch 185 validation: Cross-entropy=2.4398553371429443, Accuracy=0.08585858345031738\n",
      "Epoch 186 train: Cross-entropy=2.3456627130508423, Accuracy=0.16319444444444445\n",
      "Epoch 186 validation: Cross-entropy=2.439964771270752, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.3455623388290405, Accuracy=0.16319444444444445\n",
      "Epoch 187 validation: Cross-entropy=2.4400739669799805, Accuracy=0.08585858345031738\n",
      "Epoch 188 train: Cross-entropy=2.345462772581312, Accuracy=0.16319444444444445\n",
      "Epoch 188 validation: Cross-entropy=2.4401822090148926, Accuracy=0.08585858345031738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 train: Cross-entropy=2.3453638421164618, Accuracy=0.16319444444444445\n",
      "Epoch 189 validation: Cross-entropy=2.4402897357940674, Accuracy=0.08585858345031738\n",
      "Epoch 190 train: Cross-entropy=2.345265653398302, Accuracy=0.16319444444444445\n",
      "Epoch 190 validation: Cross-entropy=2.440397024154663, Accuracy=0.08585858345031738\n",
      "Epoch 191 train: Cross-entropy=2.3451681799358792, Accuracy=0.16493055555555555\n",
      "Epoch 191 validation: Cross-entropy=2.4405035972595215, Accuracy=0.08585858345031738\n",
      "Epoch 192 train: Cross-entropy=2.345071408483717, Accuracy=0.16493055555555555\n",
      "Epoch 192 validation: Cross-entropy=2.4406096935272217, Accuracy=0.08585858345031738\n",
      "Epoch 193 train: Cross-entropy=2.344975219832526, Accuracy=0.16493055555555555\n",
      "Epoch 193 validation: Cross-entropy=2.4407150745391846, Accuracy=0.08585858345031738\n",
      "Epoch 194 train: Cross-entropy=2.3448798259099326, Accuracy=0.16493055555555555\n",
      "Epoch 194 validation: Cross-entropy=2.4408199787139893, Accuracy=0.08585858345031738\n",
      "Epoch 195 train: Cross-entropy=2.3447850280337863, Accuracy=0.16493055555555555\n",
      "Epoch 195 validation: Cross-entropy=2.4409241676330566, Accuracy=0.08585858345031738\n",
      "Epoch 196 train: Cross-entropy=2.344690932167901, Accuracy=0.16493055555555555\n",
      "Epoch 196 validation: Cross-entropy=2.441028118133545, Accuracy=0.08585858345031738\n",
      "Epoch 197 train: Cross-entropy=2.34459748533037, Accuracy=0.16493055555555555\n",
      "Epoch 197 validation: Cross-entropy=2.441131114959717, Accuracy=0.08585858345031738\n",
      "Epoch 198 train: Cross-entropy=2.3445047405030994, Accuracy=0.16493055555555555\n",
      "Epoch 198 validation: Cross-entropy=2.4412338733673096, Accuracy=0.08585858345031738\n",
      "Epoch 199 train: Cross-entropy=2.3444125784768, Accuracy=0.16493055555555555\n",
      "Epoch 199 validation: Cross-entropy=2.441335916519165, Accuracy=0.08585858345031738\n",
      "Epoch 0 train: Cross-entropy=2.414403385586209, Accuracy=0.08680555555555555\n",
      "Epoch 0 validation: Cross-entropy=2.422016143798828, Accuracy=0.07070706784725189\n",
      "Epoch 1 train: Cross-entropy=2.399504131740994, Accuracy=0.09375\n",
      "Epoch 1 validation: Cross-entropy=2.421724319458008, Accuracy=0.08585858345031738\n",
      "Epoch 2 train: Cross-entropy=2.3958891497717962, Accuracy=0.1076388888888889\n",
      "Epoch 2 validation: Cross-entropy=2.4212422370910645, Accuracy=0.06565656512975693\n",
      "Epoch 3 train: Cross-entropy=2.394392556614346, Accuracy=0.09895833333333333\n",
      "Epoch 3 validation: Cross-entropy=2.420306444168091, Accuracy=0.07575757801532745\n",
      "Epoch 4 train: Cross-entropy=2.393187324206034, Accuracy=0.10243055555555555\n",
      "Epoch 4 validation: Cross-entropy=2.420076608657837, Accuracy=0.08080808073282242\n",
      "Epoch 5 train: Cross-entropy=2.392001165284051, Accuracy=0.10590277777777778\n",
      "Epoch 5 validation: Cross-entropy=2.420171022415161, Accuracy=0.08585858345031738\n",
      "Epoch 6 train: Cross-entropy=2.39078786638048, Accuracy=0.109375\n",
      "Epoch 6 validation: Cross-entropy=2.4202771186828613, Accuracy=0.08080808073282242\n",
      "Epoch 7 train: Cross-entropy=2.3895929786894055, Accuracy=0.1076388888888889\n",
      "Epoch 7 validation: Cross-entropy=2.420344114303589, Accuracy=0.06565656512975693\n",
      "Epoch 8 train: Cross-entropy=2.3884355227152505, Accuracy=0.1076388888888889\n",
      "Epoch 8 validation: Cross-entropy=2.420405149459839, Accuracy=0.06060606241226196\n",
      "Epoch 9 train: Cross-entropy=2.3873137633005777, Accuracy=0.109375\n",
      "Epoch 9 validation: Cross-entropy=2.4204823970794678, Accuracy=0.06060606241226196\n",
      "Epoch 10 train: Cross-entropy=2.386223488383823, Accuracy=0.1076388888888889\n",
      "Epoch 10 validation: Cross-entropy=2.4205777645111084, Accuracy=0.06565656512975693\n",
      "Epoch 11 train: Cross-entropy=2.385162260797289, Accuracy=0.1111111111111111\n",
      "Epoch 11 validation: Cross-entropy=2.420686960220337, Accuracy=0.07070706784725189\n",
      "Epoch 12 train: Cross-entropy=2.384128967920939, Accuracy=0.11631944444444445\n",
      "Epoch 12 validation: Cross-entropy=2.4208085536956787, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.3831228150261774, Accuracy=0.12152777777777778\n",
      "Epoch 13 validation: Cross-entropy=2.420941114425659, Accuracy=0.07575757801532745\n",
      "Epoch 14 train: Cross-entropy=2.3821429279115467, Accuracy=0.1232638888888889\n",
      "Epoch 14 validation: Cross-entropy=2.42108416557312, Accuracy=0.08080808073282242\n",
      "Epoch 15 train: Cross-entropy=2.3811881939570108, Accuracy=0.125\n",
      "Epoch 15 validation: Cross-entropy=2.4212377071380615, Accuracy=0.08080808073282242\n",
      "Epoch 16 train: Cross-entropy=2.380257765452067, Accuracy=0.1284722222222222\n",
      "Epoch 16 validation: Cross-entropy=2.421400308609009, Accuracy=0.08585858345031738\n",
      "Epoch 17 train: Cross-entropy=2.3793508211771646, Accuracy=0.13541666666666666\n",
      "Epoch 17 validation: Cross-entropy=2.421571731567383, Accuracy=0.08585858345031738\n",
      "Epoch 18 train: Cross-entropy=2.3784664471944175, Accuracy=0.14583333333333334\n",
      "Epoch 18 validation: Cross-entropy=2.4217519760131836, Accuracy=0.09090909361839294\n",
      "Epoch 19 train: Cross-entropy=2.377603848775228, Accuracy=0.14756944444444445\n",
      "Epoch 19 validation: Cross-entropy=2.4219398498535156, Accuracy=0.09595959633588791\n",
      "Epoch 20 train: Cross-entropy=2.3767622444364758, Accuracy=0.14756944444444445\n",
      "Epoch 20 validation: Cross-entropy=2.4221348762512207, Accuracy=0.09090909361839294\n",
      "Epoch 21 train: Cross-entropy=2.3759409719043307, Accuracy=0.14930555555555555\n",
      "Epoch 21 validation: Cross-entropy=2.4223368167877197, Accuracy=0.09090909361839294\n",
      "Epoch 22 train: Cross-entropy=2.375139183468289, Accuracy=0.14756944444444445\n",
      "Epoch 22 validation: Cross-entropy=2.4225451946258545, Accuracy=0.09090909361839294\n",
      "Epoch 23 train: Cross-entropy=2.3743562830819025, Accuracy=0.15104166666666666\n",
      "Epoch 23 validation: Cross-entropy=2.4227590560913086, Accuracy=0.09090909361839294\n",
      "Epoch 24 train: Cross-entropy=2.373591740926107, Accuracy=0.1527777777777778\n",
      "Epoch 24 validation: Cross-entropy=2.4229791164398193, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.372844682799445, Accuracy=0.15625\n",
      "Epoch 25 validation: Cross-entropy=2.423204183578491, Accuracy=0.09595959633588791\n",
      "Epoch 26 train: Cross-entropy=2.3721146716011896, Accuracy=0.15625\n",
      "Epoch 26 validation: Cross-entropy=2.423434019088745, Accuracy=0.09595959633588791\n",
      "Epoch 27 train: Cross-entropy=2.3714011510213218, Accuracy=0.15625\n",
      "Epoch 27 validation: Cross-entropy=2.423668384552002, Accuracy=0.09595959633588791\n",
      "Epoch 28 train: Cross-entropy=2.3707034985224404, Accuracy=0.15625\n",
      "Epoch 28 validation: Cross-entropy=2.4239068031311035, Accuracy=0.09090909361839294\n",
      "Epoch 29 train: Cross-entropy=2.3700212902492948, Accuracy=0.1545138888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4241487979888916, Accuracy=0.09090909361839294\n",
      "Epoch 30 train: Cross-entropy=2.369353863928053, Accuracy=0.1527777777777778\n",
      "Epoch 30 validation: Cross-entropy=2.4243946075439453, Accuracy=0.10101009905338287\n",
      "Epoch 31 train: Cross-entropy=2.368700861930847, Accuracy=0.1579861111111111\n",
      "Epoch 31 validation: Cross-entropy=2.4246435165405273, Accuracy=0.09595959633588791\n",
      "Epoch 32 train: Cross-entropy=2.3680618868933783, Accuracy=0.15625\n",
      "Epoch 32 validation: Cross-entropy=2.4248952865600586, Accuracy=0.09595959633588791\n",
      "Epoch 33 train: Cross-entropy=2.367436329523722, Accuracy=0.1579861111111111\n",
      "Epoch 33 validation: Cross-entropy=2.425149917602539, Accuracy=0.09595959633588791\n",
      "Epoch 34 train: Cross-entropy=2.366823818948534, Accuracy=0.1597222222222222\n",
      "Epoch 34 validation: Cross-entropy=2.4254069328308105, Accuracy=0.09595959633588791\n",
      "Epoch 35 train: Cross-entropy=2.3662239445580378, Accuracy=0.1579861111111111\n",
      "Epoch 35 validation: Cross-entropy=2.425666332244873, Accuracy=0.09090909361839294\n",
      "Epoch 36 train: Cross-entropy=2.365636322233412, Accuracy=0.1579861111111111\n",
      "Epoch 36 validation: Cross-entropy=2.4259278774261475, Accuracy=0.08585858345031738\n",
      "Epoch 37 train: Cross-entropy=2.3650605811013117, Accuracy=0.1597222222222222\n",
      "Epoch 37 validation: Cross-entropy=2.4261910915374756, Accuracy=0.09090909361839294\n",
      "Epoch 38 train: Cross-entropy=2.3644964165157742, Accuracy=0.15625\n",
      "Epoch 38 validation: Cross-entropy=2.4264559745788574, Accuracy=0.09090909361839294\n",
      "Epoch 39 train: Cross-entropy=2.3639433251486883, Accuracy=0.1527777777777778\n",
      "Epoch 39 validation: Cross-entropy=2.426722288131714, Accuracy=0.09090909361839294\n",
      "Epoch 40 train: Cross-entropy=2.3634011348088584, Accuracy=0.1527777777777778\n",
      "Epoch 40 validation: Cross-entropy=2.426990032196045, Accuracy=0.09090909361839294\n",
      "Epoch 41 train: Cross-entropy=2.3628693421681723, Accuracy=0.15625\n",
      "Epoch 41 validation: Cross-entropy=2.4272584915161133, Accuracy=0.09090909361839294\n",
      "Epoch 42 train: Cross-entropy=2.3623478280173407, Accuracy=0.1579861111111111\n",
      "Epoch 42 validation: Cross-entropy=2.4275283813476562, Accuracy=0.09090909361839294\n",
      "Epoch 43 train: Cross-entropy=2.361836208237542, Accuracy=0.1545138888888889\n",
      "Epoch 43 validation: Cross-entropy=2.4277987480163574, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 train: Cross-entropy=2.361334138446384, Accuracy=0.1545138888888889\n",
      "Epoch 44 validation: Cross-entropy=2.428069829940796, Accuracy=0.09090909361839294\n",
      "Epoch 45 train: Cross-entropy=2.3608414464526706, Accuracy=0.1545138888888889\n",
      "Epoch 45 validation: Cross-entropy=2.4283416271209717, Accuracy=0.09090909361839294\n",
      "Epoch 46 train: Cross-entropy=2.3603576686647205, Accuracy=0.1545138888888889\n",
      "Epoch 46 validation: Cross-entropy=2.4286139011383057, Accuracy=0.09595959633588791\n",
      "Epoch 47 train: Cross-entropy=2.359882844818963, Accuracy=0.1527777777777778\n",
      "Epoch 47 validation: Cross-entropy=2.4288861751556396, Accuracy=0.09595959633588791\n",
      "Epoch 48 train: Cross-entropy=2.3594165907965765, Accuracy=0.1545138888888889\n",
      "Epoch 48 validation: Cross-entropy=2.4291584491729736, Accuracy=0.10101009905338287\n",
      "Epoch 49 train: Cross-entropy=2.358958601951599, Accuracy=0.1545138888888889\n",
      "Epoch 49 validation: Cross-entropy=2.429431200027466, Accuracy=0.10101009905338287\n",
      "Epoch 50 train: Cross-entropy=2.3585086001290216, Accuracy=0.1545138888888889\n",
      "Epoch 50 validation: Cross-entropy=2.429703950881958, Accuracy=0.10101009905338287\n",
      "Epoch 51 train: Cross-entropy=2.3580665588378906, Accuracy=0.15625\n",
      "Epoch 51 validation: Cross-entropy=2.429976224899292, Accuracy=0.10101009905338287\n",
      "Epoch 52 train: Cross-entropy=2.3576321601867676, Accuracy=0.1579861111111111\n",
      "Epoch 52 validation: Cross-entropy=2.430248737335205, Accuracy=0.10101009905338287\n",
      "Epoch 53 train: Cross-entropy=2.35720517900255, Accuracy=0.1545138888888889\n",
      "Epoch 53 validation: Cross-entropy=2.43052077293396, Accuracy=0.09595959633588791\n",
      "Epoch 54 train: Cross-entropy=2.3567853503757052, Accuracy=0.1545138888888889\n",
      "Epoch 54 validation: Cross-entropy=2.4307923316955566, Accuracy=0.09595959633588791\n",
      "Epoch 55 train: Cross-entropy=2.35637276702457, Accuracy=0.1527777777777778\n",
      "Epoch 55 validation: Cross-entropy=2.431063652038574, Accuracy=0.09090909361839294\n",
      "Epoch 56 train: Cross-entropy=2.3559669653574624, Accuracy=0.15104166666666666\n",
      "Epoch 56 validation: Cross-entropy=2.4313340187072754, Accuracy=0.09090909361839294\n",
      "Epoch 57 train: Cross-entropy=2.3555678526560464, Accuracy=0.15104166666666666\n",
      "Epoch 57 validation: Cross-entropy=2.4316041469573975, Accuracy=0.09090909361839294\n",
      "Epoch 58 train: Cross-entropy=2.3551752302381725, Accuracy=0.15104166666666666\n",
      "Epoch 58 validation: Cross-entropy=2.4318735599517822, Accuracy=0.09090909361839294\n",
      "Epoch 59 train: Cross-entropy=2.354789031876458, Accuracy=0.1527777777777778\n",
      "Epoch 59 validation: Cross-entropy=2.4321422576904297, Accuracy=0.09090909361839294\n",
      "Epoch 60 train: Cross-entropy=2.354408939679464, Accuracy=0.1545138888888889\n",
      "Epoch 60 validation: Cross-entropy=2.4324100017547607, Accuracy=0.08585858345031738\n",
      "Epoch 61 train: Cross-entropy=2.354034900665283, Accuracy=0.15625\n",
      "Epoch 61 validation: Cross-entropy=2.4326772689819336, Accuracy=0.08585858345031738\n",
      "Epoch 62 train: Cross-entropy=2.353666729397244, Accuracy=0.15625\n",
      "Epoch 62 validation: Cross-entropy=2.43294358253479, Accuracy=0.08080808073282242\n",
      "Epoch 63 train: Cross-entropy=2.3533043464024863, Accuracy=0.15625\n",
      "Epoch 63 validation: Cross-entropy=2.433208465576172, Accuracy=0.08080808073282242\n",
      "Epoch 64 train: Cross-entropy=2.352947539753384, Accuracy=0.1579861111111111\n",
      "Epoch 64 validation: Cross-entropy=2.4334728717803955, Accuracy=0.08080808073282242\n",
      "Epoch 65 train: Cross-entropy=2.352596229977078, Accuracy=0.15625\n",
      "Epoch 65 validation: Cross-entropy=2.433736562728882, Accuracy=0.08585858345031738\n",
      "Epoch 66 train: Cross-entropy=2.3522502051459417, Accuracy=0.15625\n",
      "Epoch 66 validation: Cross-entropy=2.4339988231658936, Accuracy=0.08585858345031738\n",
      "Epoch 67 train: Cross-entropy=2.3519093990325928, Accuracy=0.15625\n",
      "Epoch 67 validation: Cross-entropy=2.4342598915100098, Accuracy=0.08585858345031738\n",
      "Epoch 68 train: Cross-entropy=2.351573665936788, Accuracy=0.15625\n",
      "Epoch 68 validation: Cross-entropy=2.4345200061798096, Accuracy=0.08585858345031738\n",
      "Epoch 69 train: Cross-entropy=2.3512428998947144, Accuracy=0.15625\n",
      "Epoch 69 validation: Cross-entropy=2.434778928756714, Accuracy=0.08585858345031738\n",
      "Epoch 70 train: Cross-entropy=2.350917034678989, Accuracy=0.1579861111111111\n",
      "Epoch 70 validation: Cross-entropy=2.4350368976593018, Accuracy=0.08585858345031738\n",
      "Epoch 71 train: Cross-entropy=2.3505958318710327, Accuracy=0.15625\n",
      "Epoch 71 validation: Cross-entropy=2.435293674468994, Accuracy=0.08585858345031738\n",
      "Epoch 72 train: Cross-entropy=2.350279278225369, Accuracy=0.1579861111111111\n",
      "Epoch 72 validation: Cross-entropy=2.435548782348633, Accuracy=0.08585858345031738\n",
      "Epoch 73 train: Cross-entropy=2.349967267778185, Accuracy=0.1579861111111111\n",
      "Epoch 73 validation: Cross-entropy=2.435802936553955, Accuracy=0.08585858345031738\n",
      "Epoch 74 train: Cross-entropy=2.3496596150928073, Accuracy=0.1597222222222222\n",
      "Epoch 74 validation: Cross-entropy=2.436056137084961, Accuracy=0.09090909361839294\n",
      "Epoch 75 train: Cross-entropy=2.3493563731511435, Accuracy=0.1597222222222222\n",
      "Epoch 75 validation: Cross-entropy=2.436307668685913, Accuracy=0.09090909361839294\n",
      "Epoch 76 train: Cross-entropy=2.3490573432710438, Accuracy=0.1597222222222222\n",
      "Epoch 76 validation: Cross-entropy=2.4365577697753906, Accuracy=0.09090909361839294\n",
      "Epoch 77 train: Cross-entropy=2.3487624327341714, Accuracy=0.1597222222222222\n",
      "Epoch 77 validation: Cross-entropy=2.4368069171905518, Accuracy=0.09090909361839294\n",
      "Epoch 78 train: Cross-entropy=2.3484716282950506, Accuracy=0.1597222222222222\n",
      "Epoch 78 validation: Cross-entropy=2.4370548725128174, Accuracy=0.09090909361839294\n",
      "Epoch 79 train: Cross-entropy=2.348184691535102, Accuracy=0.1597222222222222\n",
      "Epoch 79 validation: Cross-entropy=2.4373011589050293, Accuracy=0.09090909361839294\n",
      "Epoch 80 train: Cross-entropy=2.3479016754362316, Accuracy=0.1597222222222222\n",
      "Epoch 80 validation: Cross-entropy=2.4375460147857666, Accuracy=0.09090909361839294\n",
      "Epoch 81 train: Cross-entropy=2.347622527016534, Accuracy=0.16145833333333334\n",
      "Epoch 81 validation: Cross-entropy=2.4377896785736084, Accuracy=0.09090909361839294\n",
      "Epoch 82 train: Cross-entropy=2.347346968120999, Accuracy=0.1597222222222222\n",
      "Epoch 82 validation: Cross-entropy=2.4380319118499756, Accuracy=0.09090909361839294\n",
      "Epoch 83 train: Cross-entropy=2.3470751312043934, Accuracy=0.1597222222222222\n",
      "Epoch 83 validation: Cross-entropy=2.438272714614868, Accuracy=0.09090909361839294\n",
      "Epoch 84 train: Cross-entropy=2.3468068970574274, Accuracy=0.1597222222222222\n",
      "Epoch 84 validation: Cross-entropy=2.438512086868286, Accuracy=0.09090909361839294\n",
      "Epoch 85 train: Cross-entropy=2.346542000770569, Accuracy=0.1579861111111111\n",
      "Epoch 85 validation: Cross-entropy=2.4387502670288086, Accuracy=0.09090909361839294\n",
      "Epoch 86 train: Cross-entropy=2.346280641025967, Accuracy=0.1579861111111111\n",
      "Epoch 86 validation: Cross-entropy=2.4389867782592773, Accuracy=0.09090909361839294\n",
      "Epoch 87 train: Cross-entropy=2.3460226323869495, Accuracy=0.1579861111111111\n",
      "Epoch 87 validation: Cross-entropy=2.4392218589782715, Accuracy=0.09090909361839294\n",
      "Epoch 88 train: Cross-entropy=2.345767948362562, Accuracy=0.1579861111111111\n",
      "Epoch 88 validation: Cross-entropy=2.439455509185791, Accuracy=0.09090909361839294\n",
      "Epoch 89 train: Cross-entropy=2.3455164035161338, Accuracy=0.1579861111111111\n",
      "Epoch 89 validation: Cross-entropy=2.439687967300415, Accuracy=0.09090909361839294\n",
      "Epoch 90 train: Cross-entropy=2.3452681038114758, Accuracy=0.1579861111111111\n",
      "Epoch 90 validation: Cross-entropy=2.4399189949035645, Accuracy=0.09090909361839294\n",
      "Epoch 91 train: Cross-entropy=2.345022863811917, Accuracy=0.1579861111111111\n",
      "Epoch 91 validation: Cross-entropy=2.4401485919952393, Accuracy=0.09090909361839294\n",
      "Epoch 92 train: Cross-entropy=2.344780683517456, Accuracy=0.1579861111111111\n",
      "Epoch 92 validation: Cross-entropy=2.4403762817382812, Accuracy=0.09090909361839294\n",
      "Epoch 93 train: Cross-entropy=2.344541417227851, Accuracy=0.1579861111111111\n",
      "Epoch 93 validation: Cross-entropy=2.440603256225586, Accuracy=0.09090909361839294\n",
      "Epoch 94 train: Cross-entropy=2.3443051046795316, Accuracy=0.1579861111111111\n",
      "Epoch 94 validation: Cross-entropy=2.440828323364258, Accuracy=0.09090909361839294\n",
      "Epoch 95 train: Cross-entropy=2.3440716663996377, Accuracy=0.15625\n",
      "Epoch 95 validation: Cross-entropy=2.441051721572876, Accuracy=0.09090909361839294\n",
      "Epoch 96 train: Cross-entropy=2.343841075897217, Accuracy=0.1579861111111111\n",
      "Epoch 96 validation: Cross-entropy=2.4412739276885986, Accuracy=0.09090909361839294\n",
      "Epoch 97 train: Cross-entropy=2.3436132669448853, Accuracy=0.1579861111111111\n",
      "Epoch 97 validation: Cross-entropy=2.441495180130005, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 train: Cross-entropy=2.343388080596924, Accuracy=0.1579861111111111\n",
      "Epoch 98 validation: Cross-entropy=2.4417145252227783, Accuracy=0.09090909361839294\n",
      "Epoch 99 train: Cross-entropy=2.3431656757990518, Accuracy=0.1579861111111111\n",
      "Epoch 99 validation: Cross-entropy=2.4419326782226562, Accuracy=0.09090909361839294\n",
      "Epoch 100 train: Cross-entropy=2.342945827378167, Accuracy=0.1579861111111111\n",
      "Epoch 100 validation: Cross-entropy=2.4421491622924805, Accuracy=0.09090909361839294\n",
      "Epoch 101 train: Cross-entropy=2.3427285618252225, Accuracy=0.1579861111111111\n",
      "Epoch 101 validation: Cross-entropy=2.44236421585083, Accuracy=0.09090909361839294\n",
      "Epoch 102 train: Cross-entropy=2.3425138923856945, Accuracy=0.1579861111111111\n",
      "Epoch 102 validation: Cross-entropy=2.442578077316284, Accuracy=0.09090909361839294\n",
      "Epoch 103 train: Cross-entropy=2.3423015938864813, Accuracy=0.1579861111111111\n",
      "Epoch 103 validation: Cross-entropy=2.4427902698516846, Accuracy=0.09090909361839294\n",
      "Epoch 104 train: Cross-entropy=2.342091785536872, Accuracy=0.1579861111111111\n",
      "Epoch 104 validation: Cross-entropy=2.4430012702941895, Accuracy=0.09090909361839294\n",
      "Epoch 105 train: Cross-entropy=2.341884348127577, Accuracy=0.1579861111111111\n",
      "Epoch 105 validation: Cross-entropy=2.4432106018066406, Accuracy=0.09090909361839294\n",
      "Epoch 106 train: Cross-entropy=2.3416792816585965, Accuracy=0.1579861111111111\n",
      "Epoch 106 validation: Cross-entropy=2.4434187412261963, Accuracy=0.09090909361839294\n",
      "Epoch 107 train: Cross-entropy=2.3414765728844538, Accuracy=0.1579861111111111\n",
      "Epoch 107 validation: Cross-entropy=2.4436254501342773, Accuracy=0.09090909361839294\n",
      "Epoch 108 train: Cross-entropy=2.341276102595859, Accuracy=0.1579861111111111\n",
      "Epoch 108 validation: Cross-entropy=2.443830728530884, Accuracy=0.09090909361839294\n",
      "Epoch 109 train: Cross-entropy=2.3410778443018594, Accuracy=0.1597222222222222\n",
      "Epoch 109 validation: Cross-entropy=2.4440345764160156, Accuracy=0.09090909361839294\n",
      "Epoch 110 train: Cross-entropy=2.340881837738885, Accuracy=0.1597222222222222\n",
      "Epoch 110 validation: Cross-entropy=2.444236993789673, Accuracy=0.09090909361839294\n",
      "Epoch 111 train: Cross-entropy=2.3406880034340753, Accuracy=0.1597222222222222\n",
      "Epoch 111 validation: Cross-entropy=2.4444382190704346, Accuracy=0.09090909361839294\n",
      "Epoch 112 train: Cross-entropy=2.3404962486690946, Accuracy=0.1597222222222222\n",
      "Epoch 112 validation: Cross-entropy=2.4446377754211426, Accuracy=0.09090909361839294\n",
      "Epoch 113 train: Cross-entropy=2.3403065866894193, Accuracy=0.1597222222222222\n",
      "Epoch 113 validation: Cross-entropy=2.444836139678955, Accuracy=0.09090909361839294\n",
      "Epoch 114 train: Cross-entropy=2.3401190439860025, Accuracy=0.1597222222222222\n",
      "Epoch 114 validation: Cross-entropy=2.445033311843872, Accuracy=0.09090909361839294\n",
      "Epoch 115 train: Cross-entropy=2.339933501349555, Accuracy=0.16145833333333334\n",
      "Epoch 115 validation: Cross-entropy=2.4452290534973145, Accuracy=0.09090909361839294\n",
      "Epoch 116 train: Cross-entropy=2.339749892552694, Accuracy=0.16145833333333334\n",
      "Epoch 116 validation: Cross-entropy=2.4454233646392822, Accuracy=0.09090909361839294\n",
      "Epoch 117 train: Cross-entropy=2.3395683103137546, Accuracy=0.16145833333333334\n",
      "Epoch 117 validation: Cross-entropy=2.4456162452697754, Accuracy=0.09595959633588791\n",
      "Epoch 118 train: Cross-entropy=2.3393886619144015, Accuracy=0.16145833333333334\n",
      "Epoch 118 validation: Cross-entropy=2.445807933807373, Accuracy=0.09595959633588791\n",
      "Epoch 119 train: Cross-entropy=2.339210854636298, Accuracy=0.16145833333333334\n",
      "Epoch 119 validation: Cross-entropy=2.445997953414917, Accuracy=0.09595959633588791\n",
      "Epoch 120 train: Cross-entropy=2.339034994443258, Accuracy=0.16145833333333334\n",
      "Epoch 120 validation: Cross-entropy=2.4461870193481445, Accuracy=0.09595959633588791\n",
      "Epoch 121 train: Cross-entropy=2.338861015107897, Accuracy=0.16145833333333334\n",
      "Epoch 121 validation: Cross-entropy=2.4463746547698975, Accuracy=0.09595959633588791\n",
      "Epoch 122 train: Cross-entropy=2.338688757684496, Accuracy=0.16145833333333334\n",
      "Epoch 122 validation: Cross-entropy=2.446561336517334, Accuracy=0.09595959633588791\n",
      "Epoch 123 train: Cross-entropy=2.3385183413823447, Accuracy=0.16145833333333334\n",
      "Epoch 123 validation: Cross-entropy=2.4467461109161377, Accuracy=0.09595959633588791\n",
      "Epoch 124 train: Cross-entropy=2.3383496205012, Accuracy=0.16319444444444445\n",
      "Epoch 124 validation: Cross-entropy=2.446929693222046, Accuracy=0.09595959633588791\n",
      "Epoch 125 train: Cross-entropy=2.3381826877593994, Accuracy=0.16319444444444445\n",
      "Epoch 125 validation: Cross-entropy=2.4471123218536377, Accuracy=0.09595959633588791\n",
      "Epoch 126 train: Cross-entropy=2.338017463684082, Accuracy=0.16319444444444445\n",
      "Epoch 126 validation: Cross-entropy=2.447293281555176, Accuracy=0.09595959633588791\n",
      "Epoch 127 train: Cross-entropy=2.3378539615207248, Accuracy=0.16319444444444445\n",
      "Epoch 127 validation: Cross-entropy=2.4474732875823975, Accuracy=0.09595959633588791\n",
      "Epoch 128 train: Cross-entropy=2.337692048814562, Accuracy=0.16319444444444445\n",
      "Epoch 128 validation: Cross-entropy=2.4476523399353027, Accuracy=0.09595959633588791\n",
      "Epoch 129 train: Cross-entropy=2.337531805038452, Accuracy=0.16493055555555555\n",
      "Epoch 129 validation: Cross-entropy=2.447829484939575, Accuracy=0.09595959633588791\n",
      "Epoch 130 train: Cross-entropy=2.3373731904559665, Accuracy=0.16493055555555555\n",
      "Epoch 130 validation: Cross-entropy=2.4480056762695312, Accuracy=0.09595959633588791\n",
      "Epoch 131 train: Cross-entropy=2.337216125594245, Accuracy=0.16493055555555555\n",
      "Epoch 131 validation: Cross-entropy=2.4481804370880127, Accuracy=0.09595959633588791\n",
      "Epoch 132 train: Cross-entropy=2.337060636944241, Accuracy=0.16493055555555555\n",
      "Epoch 132 validation: Cross-entropy=2.448354482650757, Accuracy=0.09595959633588791\n",
      "Epoch 133 train: Cross-entropy=2.336906671524048, Accuracy=0.16493055555555555\n",
      "Epoch 133 validation: Cross-entropy=2.448526620864868, Accuracy=0.09090909361839294\n",
      "Epoch 134 train: Cross-entropy=2.3367542823155723, Accuracy=0.16493055555555555\n",
      "Epoch 134 validation: Cross-entropy=2.4486982822418213, Accuracy=0.09090909361839294\n",
      "Epoch 135 train: Cross-entropy=2.336603363355001, Accuracy=0.16319444444444445\n",
      "Epoch 135 validation: Cross-entropy=2.4488680362701416, Accuracy=0.09090909361839294\n",
      "Epoch 136 train: Cross-entropy=2.3364538881513806, Accuracy=0.16319444444444445\n",
      "Epoch 136 validation: Cross-entropy=2.4490370750427246, Accuracy=0.09090909361839294\n",
      "Epoch 137 train: Cross-entropy=2.336305922932095, Accuracy=0.16319444444444445\n",
      "Epoch 137 validation: Cross-entropy=2.449204683303833, Accuracy=0.09090909361839294\n",
      "Epoch 138 train: Cross-entropy=2.336159414715237, Accuracy=0.16319444444444445\n",
      "Epoch 138 validation: Cross-entropy=2.449371099472046, Accuracy=0.09090909361839294\n",
      "Epoch 139 train: Cross-entropy=2.3360142707824707, Accuracy=0.16319444444444445\n",
      "Epoch 139 validation: Cross-entropy=2.4495363235473633, Accuracy=0.09090909361839294\n",
      "Epoch 140 train: Cross-entropy=2.335870544115702, Accuracy=0.16319444444444445\n",
      "Epoch 140 validation: Cross-entropy=2.4497005939483643, Accuracy=0.09595959633588791\n",
      "Epoch 141 train: Cross-entropy=2.3357281949785023, Accuracy=0.16319444444444445\n",
      "Epoch 141 validation: Cross-entropy=2.4498634338378906, Accuracy=0.09595959633588791\n",
      "Epoch 142 train: Cross-entropy=2.33558722337087, Accuracy=0.16493055555555555\n",
      "Epoch 142 validation: Cross-entropy=2.4500250816345215, Accuracy=0.09595959633588791\n",
      "Epoch 143 train: Cross-entropy=2.335447523328993, Accuracy=0.16493055555555555\n",
      "Epoch 143 validation: Cross-entropy=2.450186014175415, Accuracy=0.09595959633588791\n",
      "Epoch 144 train: Cross-entropy=2.3353091875712075, Accuracy=0.16493055555555555\n",
      "Epoch 144 validation: Cross-entropy=2.450345516204834, Accuracy=0.09090909361839294\n",
      "Epoch 145 train: Cross-entropy=2.3351722160975137, Accuracy=0.16493055555555555\n",
      "Epoch 145 validation: Cross-entropy=2.4505038261413574, Accuracy=0.09090909361839294\n",
      "Epoch 146 train: Cross-entropy=2.335036516189575, Accuracy=0.16493055555555555\n",
      "Epoch 146 validation: Cross-entropy=2.4506611824035645, Accuracy=0.09090909361839294\n",
      "Epoch 147 train: Cross-entropy=2.3349020216200085, Accuracy=0.16493055555555555\n",
      "Epoch 147 validation: Cross-entropy=2.450817108154297, Accuracy=0.09090909361839294\n",
      "Epoch 148 train: Cross-entropy=2.3347688383526273, Accuracy=0.16493055555555555\n",
      "Epoch 148 validation: Cross-entropy=2.450972318649292, Accuracy=0.09090909361839294\n",
      "Epoch 149 train: Cross-entropy=2.3346369134055243, Accuracy=0.16493055555555555\n",
      "Epoch 149 validation: Cross-entropy=2.4511263370513916, Accuracy=0.09090909361839294\n",
      "Epoch 150 train: Cross-entropy=2.3345061673058405, Accuracy=0.16493055555555555\n",
      "Epoch 150 validation: Cross-entropy=2.4512789249420166, Accuracy=0.09090909361839294\n",
      "Epoch 151 train: Cross-entropy=2.3343766132990518, Accuracy=0.16493055555555555\n",
      "Epoch 151 validation: Cross-entropy=2.4514310359954834, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 train: Cross-entropy=2.334248344103495, Accuracy=0.16493055555555555\n",
      "Epoch 152 validation: Cross-entropy=2.4515814781188965, Accuracy=0.09090909361839294\n",
      "Epoch 153 train: Cross-entropy=2.3341212272644043, Accuracy=0.16319444444444445\n",
      "Epoch 153 validation: Cross-entropy=2.451730966567993, Accuracy=0.09595959633588791\n",
      "Epoch 154 train: Cross-entropy=2.3339952495363026, Accuracy=0.16319444444444445\n",
      "Epoch 154 validation: Cross-entropy=2.4518797397613525, Accuracy=0.09595959633588791\n",
      "Epoch 155 train: Cross-entropy=2.333870437410143, Accuracy=0.16319444444444445\n",
      "Epoch 155 validation: Cross-entropy=2.4520270824432373, Accuracy=0.09595959633588791\n",
      "Epoch 156 train: Cross-entropy=2.333746698167589, Accuracy=0.16319444444444445\n",
      "Epoch 156 validation: Cross-entropy=2.4521737098693848, Accuracy=0.09595959633588791\n",
      "Epoch 157 train: Cross-entropy=2.333624071545071, Accuracy=0.16319444444444445\n",
      "Epoch 157 validation: Cross-entropy=2.4523191452026367, Accuracy=0.09595959633588791\n",
      "Epoch 158 train: Cross-entropy=2.333502663506402, Accuracy=0.16319444444444445\n",
      "Epoch 158 validation: Cross-entropy=2.4524636268615723, Accuracy=0.09595959633588791\n",
      "Epoch 159 train: Cross-entropy=2.3333822753694324, Accuracy=0.16319444444444445\n",
      "Epoch 159 validation: Cross-entropy=2.4526069164276123, Accuracy=0.09595959633588791\n",
      "Epoch 160 train: Cross-entropy=2.333263013097975, Accuracy=0.16145833333333334\n",
      "Epoch 160 validation: Cross-entropy=2.452749490737915, Accuracy=0.09595959633588791\n",
      "Epoch 161 train: Cross-entropy=2.3331447309917874, Accuracy=0.16145833333333334\n",
      "Epoch 161 validation: Cross-entropy=2.452890634536743, Accuracy=0.09595959633588791\n",
      "Epoch 162 train: Cross-entropy=2.333027548260159, Accuracy=0.16145833333333334\n",
      "Epoch 162 validation: Cross-entropy=2.453031063079834, Accuracy=0.09595959633588791\n",
      "Epoch 163 train: Cross-entropy=2.33291142516666, Accuracy=0.16145833333333334\n",
      "Epoch 163 validation: Cross-entropy=2.4531705379486084, Accuracy=0.09595959633588791\n",
      "Epoch 164 train: Cross-entropy=2.3327963749567666, Accuracy=0.16145833333333334\n",
      "Epoch 164 validation: Cross-entropy=2.4533088207244873, Accuracy=0.09595959633588791\n",
      "Epoch 165 train: Cross-entropy=2.3326822254392834, Accuracy=0.16145833333333334\n",
      "Epoch 165 validation: Cross-entropy=2.45344614982605, Accuracy=0.09090909361839294\n",
      "Epoch 166 train: Cross-entropy=2.332569122314453, Accuracy=0.16145833333333334\n",
      "Epoch 166 validation: Cross-entropy=2.453582525253296, Accuracy=0.09090909361839294\n",
      "Epoch 167 train: Cross-entropy=2.332457039091322, Accuracy=0.16145833333333334\n",
      "Epoch 167 validation: Cross-entropy=2.4537179470062256, Accuracy=0.09090909361839294\n",
      "Epoch 168 train: Cross-entropy=2.3323459890153675, Accuracy=0.16145833333333334\n",
      "Epoch 168 validation: Cross-entropy=2.453852891921997, Accuracy=0.09090909361839294\n",
      "Epoch 169 train: Cross-entropy=2.3322357866499157, Accuracy=0.1597222222222222\n",
      "Epoch 169 validation: Cross-entropy=2.453986167907715, Accuracy=0.09595959633588791\n",
      "Epoch 170 train: Cross-entropy=2.332126643922594, Accuracy=0.1597222222222222\n",
      "Epoch 170 validation: Cross-entropy=2.4541187286376953, Accuracy=0.09595959633588791\n",
      "Epoch 171 train: Cross-entropy=2.3320183886422052, Accuracy=0.1597222222222222\n",
      "Epoch 171 validation: Cross-entropy=2.4542503356933594, Accuracy=0.09595959633588791\n",
      "Epoch 172 train: Cross-entropy=2.3319110605451794, Accuracy=0.1597222222222222\n",
      "Epoch 172 validation: Cross-entropy=2.454381227493286, Accuracy=0.09595959633588791\n",
      "Epoch 173 train: Cross-entropy=2.331804699367947, Accuracy=0.1597222222222222\n",
      "Epoch 173 validation: Cross-entropy=2.4545106887817383, Accuracy=0.09595959633588791\n",
      "Epoch 174 train: Cross-entropy=2.3316992256376476, Accuracy=0.1597222222222222\n",
      "Epoch 174 validation: Cross-entropy=2.4546396732330322, Accuracy=0.09595959633588791\n",
      "Epoch 175 train: Cross-entropy=2.3315946790907116, Accuracy=0.1597222222222222\n",
      "Epoch 175 validation: Cross-entropy=2.4547674655914307, Accuracy=0.09595959633588791\n",
      "Epoch 176 train: Cross-entropy=2.3314909272723727, Accuracy=0.1597222222222222\n",
      "Epoch 176 validation: Cross-entropy=2.454894781112671, Accuracy=0.09595959633588791\n",
      "Epoch 177 train: Cross-entropy=2.331388235092163, Accuracy=0.1597222222222222\n",
      "Epoch 177 validation: Cross-entropy=2.4550209045410156, Accuracy=0.09595959633588791\n",
      "Epoch 178 train: Cross-entropy=2.3312862846586437, Accuracy=0.1597222222222222\n",
      "Epoch 178 validation: Cross-entropy=2.455146312713623, Accuracy=0.09595959633588791\n",
      "Epoch 179 train: Cross-entropy=2.3311851951811047, Accuracy=0.1597222222222222\n",
      "Epoch 179 validation: Cross-entropy=2.455270528793335, Accuracy=0.09595959633588791\n",
      "Epoch 180 train: Cross-entropy=2.3310850726233587, Accuracy=0.1597222222222222\n",
      "Epoch 180 validation: Cross-entropy=2.4553940296173096, Accuracy=0.09595959633588791\n",
      "Epoch 181 train: Cross-entropy=2.3309856520758734, Accuracy=0.1597222222222222\n",
      "Epoch 181 validation: Cross-entropy=2.455516815185547, Accuracy=0.09595959633588791\n",
      "Epoch 182 train: Cross-entropy=2.330887211693658, Accuracy=0.1597222222222222\n",
      "Epoch 182 validation: Cross-entropy=2.4556386470794678, Accuracy=0.09595959633588791\n",
      "Epoch 183 train: Cross-entropy=2.3307894468307495, Accuracy=0.1597222222222222\n",
      "Epoch 183 validation: Cross-entropy=2.455759286880493, Accuracy=0.09595959633588791\n",
      "Epoch 184 train: Cross-entropy=2.330692662133111, Accuracy=0.1579861111111111\n",
      "Epoch 184 validation: Cross-entropy=2.4558796882629395, Accuracy=0.09595959633588791\n",
      "Epoch 185 train: Cross-entropy=2.3305965529547796, Accuracy=0.1579861111111111\n",
      "Epoch 185 validation: Cross-entropy=2.4559988975524902, Accuracy=0.09595959633588791\n",
      "Epoch 186 train: Cross-entropy=2.3305013179779053, Accuracy=0.1579861111111111\n",
      "Epoch 186 validation: Cross-entropy=2.4561171531677246, Accuracy=0.09595959633588791\n",
      "Epoch 187 train: Cross-entropy=2.330406811502245, Accuracy=0.1579861111111111\n",
      "Epoch 187 validation: Cross-entropy=2.4562346935272217, Accuracy=0.09595959633588791\n",
      "Epoch 188 train: Cross-entropy=2.3303131659825644, Accuracy=0.1579861111111111\n",
      "Epoch 188 validation: Cross-entropy=2.4563512802124023, Accuracy=0.09595959633588791\n",
      "Epoch 189 train: Cross-entropy=2.3302202887005277, Accuracy=0.1579861111111111\n",
      "Epoch 189 validation: Cross-entropy=2.4564671516418457, Accuracy=0.09595959633588791\n",
      "Epoch 190 train: Cross-entropy=2.3301280736923218, Accuracy=0.1579861111111111\n",
      "Epoch 190 validation: Cross-entropy=2.4565820693969727, Accuracy=0.09595959633588791\n",
      "Epoch 191 train: Cross-entropy=2.330036719640096, Accuracy=0.1579861111111111\n",
      "Epoch 191 validation: Cross-entropy=2.4566965103149414, Accuracy=0.09595959633588791\n",
      "Epoch 192 train: Cross-entropy=2.329946027861701, Accuracy=0.1579861111111111\n",
      "Epoch 192 validation: Cross-entropy=2.4568099975585938, Accuracy=0.09595959633588791\n",
      "Epoch 193 train: Cross-entropy=2.3298561175664267, Accuracy=0.1579861111111111\n",
      "Epoch 193 validation: Cross-entropy=2.4569225311279297, Accuracy=0.09595959633588791\n",
      "Epoch 194 train: Cross-entropy=2.3297669755087957, Accuracy=0.1597222222222222\n",
      "Epoch 194 validation: Cross-entropy=2.4570345878601074, Accuracy=0.09595959633588791\n",
      "Epoch 195 train: Cross-entropy=2.329678495724996, Accuracy=0.1597222222222222\n",
      "Epoch 195 validation: Cross-entropy=2.4571456909179688, Accuracy=0.09595959633588791\n",
      "Epoch 196 train: Cross-entropy=2.329590850406223, Accuracy=0.16145833333333334\n",
      "Epoch 196 validation: Cross-entropy=2.4572560787200928, Accuracy=0.09595959633588791\n",
      "Epoch 197 train: Cross-entropy=2.3295038408703275, Accuracy=0.16145833333333334\n",
      "Epoch 197 validation: Cross-entropy=2.4573655128479004, Accuracy=0.09595959633588791\n",
      "Epoch 198 train: Cross-entropy=2.329417493608263, Accuracy=0.16145833333333334\n",
      "Epoch 198 validation: Cross-entropy=2.4574739933013916, Accuracy=0.09595959633588791\n",
      "Epoch 199 train: Cross-entropy=2.3293318483564587, Accuracy=0.16145833333333334\n",
      "Epoch 199 validation: Cross-entropy=2.4575822353363037, Accuracy=0.09595959633588791\n",
      "Epoch 0 train: Cross-entropy=2.4186838600370617, Accuracy=0.09375\n",
      "Epoch 0 validation: Cross-entropy=2.421095371246338, Accuracy=0.0555555559694767\n",
      "Epoch 1 train: Cross-entropy=2.39707785182529, Accuracy=0.09375\n",
      "Epoch 1 validation: Cross-entropy=2.410456418991089, Accuracy=0.09090909361839294\n",
      "Epoch 2 train: Cross-entropy=2.394883884323968, Accuracy=0.0954861111111111\n",
      "Epoch 2 validation: Cross-entropy=2.4156577587127686, Accuracy=0.07070706784725189\n",
      "Epoch 3 train: Cross-entropy=2.3913369443681507, Accuracy=0.0920138888888889\n",
      "Epoch 3 validation: Cross-entropy=2.4153149127960205, Accuracy=0.07070706784725189\n",
      "Epoch 4 train: Cross-entropy=2.388489762941996, Accuracy=0.09722222222222222\n",
      "Epoch 4 validation: Cross-entropy=2.414966106414795, Accuracy=0.07575757801532745\n",
      "Epoch 5 train: Cross-entropy=2.3860629399617515, Accuracy=0.10590277777777778\n",
      "Epoch 5 validation: Cross-entropy=2.415607213973999, Accuracy=0.07070706784725189\n",
      "Epoch 6 train: Cross-entropy=2.3837498823801675, Accuracy=0.1076388888888889\n",
      "Epoch 6 validation: Cross-entropy=2.416036605834961, Accuracy=0.06565656512975693\n",
      "Epoch 7 train: Cross-entropy=2.3816515074835882, Accuracy=0.11631944444444445\n",
      "Epoch 7 validation: Cross-entropy=2.416468858718872, Accuracy=0.06060606241226196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train: Cross-entropy=2.3797121577792697, Accuracy=0.1232638888888889\n",
      "Epoch 8 validation: Cross-entropy=2.416977643966675, Accuracy=0.0555555559694767\n",
      "Epoch 9 train: Cross-entropy=2.377911342514886, Accuracy=0.1267361111111111\n",
      "Epoch 9 validation: Cross-entropy=2.4175031185150146, Accuracy=0.06060606241226196\n",
      "Epoch 10 train: Cross-entropy=2.3762407700220742, Accuracy=0.13368055555555555\n",
      "Epoch 10 validation: Cross-entropy=2.4180450439453125, Accuracy=0.06060606241226196\n",
      "Epoch 11 train: Cross-entropy=2.3746833006540933, Accuracy=0.13368055555555555\n",
      "Epoch 11 validation: Cross-entropy=2.418602705001831, Accuracy=0.06565656512975693\n",
      "Epoch 12 train: Cross-entropy=2.3732275830374823, Accuracy=0.13368055555555555\n",
      "Epoch 12 validation: Cross-entropy=2.4191701412200928, Accuracy=0.07575757801532745\n",
      "Epoch 13 train: Cross-entropy=2.371863842010498, Accuracy=0.13194444444444445\n",
      "Epoch 13 validation: Cross-entropy=2.4197449684143066, Accuracy=0.08080808073282242\n",
      "Epoch 14 train: Cross-entropy=2.3705831898583307, Accuracy=0.13194444444444445\n",
      "Epoch 14 validation: Cross-entropy=2.4203238487243652, Accuracy=0.08585858345031738\n",
      "Epoch 15 train: Cross-entropy=2.3693776660495334, Accuracy=0.13541666666666666\n",
      "Epoch 15 validation: Cross-entropy=2.420905113220215, Accuracy=0.08585858345031738\n",
      "Epoch 16 train: Cross-entropy=2.368240568372938, Accuracy=0.1371527777777778\n",
      "Epoch 16 validation: Cross-entropy=2.4214866161346436, Accuracy=0.08080808073282242\n",
      "Epoch 17 train: Cross-entropy=2.367165856891208, Accuracy=0.1371527777777778\n",
      "Epoch 17 validation: Cross-entropy=2.4220666885375977, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.3661483791139393, Accuracy=0.1371527777777778\n",
      "Epoch 18 validation: Cross-entropy=2.42264461517334, Accuracy=0.09090909361839294\n",
      "Epoch 19 train: Cross-entropy=2.365183154741923, Accuracy=0.1371527777777778\n",
      "Epoch 19 validation: Cross-entropy=2.4232192039489746, Accuracy=0.09090909361839294\n",
      "Epoch 20 train: Cross-entropy=2.364266276359558, Accuracy=0.1371527777777778\n",
      "Epoch 20 validation: Cross-entropy=2.4237890243530273, Accuracy=0.09090909361839294\n",
      "Epoch 21 train: Cross-entropy=2.3633938100602894, Accuracy=0.1388888888888889\n",
      "Epoch 21 validation: Cross-entropy=2.42435359954834, Accuracy=0.09090909361839294\n",
      "Epoch 22 train: Cross-entropy=2.3625625371932983, Accuracy=0.140625\n",
      "Epoch 22 validation: Cross-entropy=2.424913167953491, Accuracy=0.08585858345031738\n",
      "Epoch 23 train: Cross-entropy=2.361769371562534, Accuracy=0.1388888888888889\n",
      "Epoch 23 validation: Cross-entropy=2.425466299057007, Accuracy=0.08080808073282242\n",
      "Epoch 24 train: Cross-entropy=2.361011677318149, Accuracy=0.13541666666666666\n",
      "Epoch 24 validation: Cross-entropy=2.4260129928588867, Accuracy=0.07575757801532745\n",
      "Epoch 25 train: Cross-entropy=2.3602870305379233, Accuracy=0.1371527777777778\n",
      "Epoch 25 validation: Cross-entropy=2.4265527725219727, Accuracy=0.07575757801532745\n",
      "Epoch 26 train: Cross-entropy=2.3595931132634482, Accuracy=0.140625\n",
      "Epoch 26 validation: Cross-entropy=2.4270853996276855, Accuracy=0.07575757801532745\n",
      "Epoch 27 train: Cross-entropy=2.3589280313915677, Accuracy=0.140625\n",
      "Epoch 27 validation: Cross-entropy=2.4276108741760254, Accuracy=0.07575757801532745\n",
      "Epoch 28 train: Cross-entropy=2.3582899305555554, Accuracy=0.1388888888888889\n",
      "Epoch 28 validation: Cross-entropy=2.428128957748413, Accuracy=0.07575757801532745\n",
      "Epoch 29 train: Cross-entropy=2.357677115334405, Accuracy=0.1388888888888889\n",
      "Epoch 29 validation: Cross-entropy=2.4286391735076904, Accuracy=0.08080808073282242\n",
      "Epoch 30 train: Cross-entropy=2.357088088989258, Accuracy=0.140625\n",
      "Epoch 30 validation: Cross-entropy=2.4291419982910156, Accuracy=0.08080808073282242\n",
      "Epoch 31 train: Cross-entropy=2.3565215269724527, Accuracy=0.140625\n",
      "Epoch 31 validation: Cross-entropy=2.4296369552612305, Accuracy=0.08585858345031738\n",
      "Epoch 32 train: Cross-entropy=2.355975959036085, Accuracy=0.1423611111111111\n",
      "Epoch 32 validation: Cross-entropy=2.430124282836914, Accuracy=0.08585858345031738\n",
      "Epoch 33 train: Cross-entropy=2.3554503520329795, Accuracy=0.1440972222222222\n",
      "Epoch 33 validation: Cross-entropy=2.430603504180908, Accuracy=0.08585858345031738\n",
      "Epoch 34 train: Cross-entropy=2.3549436595704822, Accuracy=0.14756944444444445\n",
      "Epoch 34 validation: Cross-entropy=2.431074857711792, Accuracy=0.09090909361839294\n",
      "Epoch 35 train: Cross-entropy=2.3544547028011746, Accuracy=0.14930555555555555\n",
      "Epoch 35 validation: Cross-entropy=2.4315388202667236, Accuracy=0.09090909361839294\n",
      "Epoch 36 train: Cross-entropy=2.3539826340145535, Accuracy=0.15104166666666666\n",
      "Epoch 36 validation: Cross-entropy=2.4319944381713867, Accuracy=0.09090909361839294\n",
      "Epoch 37 train: Cross-entropy=2.3535267379548817, Accuracy=0.1545138888888889\n",
      "Epoch 37 validation: Cross-entropy=2.4324426651000977, Accuracy=0.09090909361839294\n",
      "Epoch 38 train: Cross-entropy=2.3530859814749823, Accuracy=0.1545138888888889\n",
      "Epoch 38 validation: Cross-entropy=2.4328832626342773, Accuracy=0.09090909361839294\n",
      "Epoch 39 train: Cross-entropy=2.352659742037455, Accuracy=0.1579861111111111\n",
      "Epoch 39 validation: Cross-entropy=2.4333157539367676, Accuracy=0.09090909361839294\n",
      "Epoch 40 train: Cross-entropy=2.3522473573684692, Accuracy=0.1579861111111111\n",
      "Epoch 40 validation: Cross-entropy=2.4337410926818848, Accuracy=0.09090909361839294\n",
      "Epoch 41 train: Cross-entropy=2.3518480327394276, Accuracy=0.1597222222222222\n",
      "Epoch 41 validation: Cross-entropy=2.4341585636138916, Accuracy=0.09090909361839294\n",
      "Epoch 42 train: Cross-entropy=2.3514612118403115, Accuracy=0.1597222222222222\n",
      "Epoch 42 validation: Cross-entropy=2.4345686435699463, Accuracy=0.09090909361839294\n",
      "Epoch 43 train: Cross-entropy=2.3510863648520575, Accuracy=0.1597222222222222\n",
      "Epoch 43 validation: Cross-entropy=2.434971332550049, Accuracy=0.09090909361839294\n",
      "Epoch 44 train: Cross-entropy=2.3507230149375067, Accuracy=0.1597222222222222\n",
      "Epoch 44 validation: Cross-entropy=2.4353671073913574, Accuracy=0.09090909361839294\n",
      "Epoch 45 train: Cross-entropy=2.350370579295688, Accuracy=0.1597222222222222\n",
      "Epoch 45 validation: Cross-entropy=2.435755491256714, Accuracy=0.09090909361839294\n",
      "Epoch 46 train: Cross-entropy=2.350028541353014, Accuracy=0.1597222222222222\n",
      "Epoch 46 validation: Cross-entropy=2.4361369609832764, Accuracy=0.09090909361839294\n",
      "Epoch 47 train: Cross-entropy=2.349696464008755, Accuracy=0.1597222222222222\n",
      "Epoch 47 validation: Cross-entropy=2.4365110397338867, Accuracy=0.09090909361839294\n",
      "Epoch 48 train: Cross-entropy=2.3493739631440906, Accuracy=0.1597222222222222\n",
      "Epoch 48 validation: Cross-entropy=2.4368789196014404, Accuracy=0.09090909361839294\n",
      "Epoch 49 train: Cross-entropy=2.349060720867581, Accuracy=0.1597222222222222\n",
      "Epoch 49 validation: Cross-entropy=2.437239408493042, Accuracy=0.09090909361839294\n",
      "Epoch 50 train: Cross-entropy=2.3487562338511148, Accuracy=0.16145833333333334\n",
      "Epoch 50 validation: Cross-entropy=2.437593460083008, Accuracy=0.09090909361839294\n",
      "Epoch 51 train: Cross-entropy=2.34846031665802, Accuracy=0.1597222222222222\n",
      "Epoch 51 validation: Cross-entropy=2.437941312789917, Accuracy=0.08585858345031738\n",
      "Epoch 52 train: Cross-entropy=2.3481724394692316, Accuracy=0.1597222222222222\n",
      "Epoch 52 validation: Cross-entropy=2.4382822513580322, Accuracy=0.09090909361839294\n",
      "Epoch 53 train: Cross-entropy=2.3478923638661704, Accuracy=0.16145833333333334\n",
      "Epoch 53 validation: Cross-entropy=2.43861722946167, Accuracy=0.09090909361839294\n",
      "Epoch 54 train: Cross-entropy=2.347619811693827, Accuracy=0.16145833333333334\n",
      "Epoch 54 validation: Cross-entropy=2.43894624710083, Accuracy=0.09090909361839294\n",
      "Epoch 55 train: Cross-entropy=2.3473545047971935, Accuracy=0.16319444444444445\n",
      "Epoch 55 validation: Cross-entropy=2.4392688274383545, Accuracy=0.09595959633588791\n",
      "Epoch 56 train: Cross-entropy=2.3470961252848306, Accuracy=0.16145833333333334\n",
      "Epoch 56 validation: Cross-entropy=2.4395854473114014, Accuracy=0.09595959633588791\n",
      "Epoch 57 train: Cross-entropy=2.346844447983636, Accuracy=0.16145833333333334\n",
      "Epoch 57 validation: Cross-entropy=2.43989634513855, Accuracy=0.09595959633588791\n",
      "Epoch 58 train: Cross-entropy=2.3465993404388428, Accuracy=0.16145833333333334\n",
      "Epoch 58 validation: Cross-entropy=2.440201997756958, Accuracy=0.09595959633588791\n",
      "Epoch 59 train: Cross-entropy=2.346360352304247, Accuracy=0.16145833333333334\n",
      "Epoch 59 validation: Cross-entropy=2.4405014514923096, Accuracy=0.09595959633588791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 train: Cross-entropy=2.346127404106988, Accuracy=0.16145833333333334\n",
      "Epoch 60 validation: Cross-entropy=2.440795660018921, Accuracy=0.09595959633588791\n",
      "Epoch 61 train: Cross-entropy=2.3459002441830106, Accuracy=0.1597222222222222\n",
      "Epoch 61 validation: Cross-entropy=2.441084623336792, Accuracy=0.09595959633588791\n",
      "Epoch 62 train: Cross-entropy=2.345678726832072, Accuracy=0.1597222222222222\n",
      "Epoch 62 validation: Cross-entropy=2.441368341445923, Accuracy=0.09090909361839294\n",
      "Epoch 63 train: Cross-entropy=2.3454626003901162, Accuracy=0.1597222222222222\n",
      "Epoch 63 validation: Cross-entropy=2.4416470527648926, Accuracy=0.09090909361839294\n",
      "Epoch 64 train: Cross-entropy=2.345251679420471, Accuracy=0.1597222222222222\n",
      "Epoch 64 validation: Cross-entropy=2.441920518875122, Accuracy=0.09090909361839294\n",
      "Epoch 65 train: Cross-entropy=2.34504595067766, Accuracy=0.16145833333333334\n",
      "Epoch 65 validation: Cross-entropy=2.4421894550323486, Accuracy=0.09090909361839294\n",
      "Epoch 66 train: Cross-entropy=2.3448449770609536, Accuracy=0.16319444444444445\n",
      "Epoch 66 validation: Cross-entropy=2.442453145980835, Accuracy=0.09090909361839294\n",
      "Epoch 67 train: Cross-entropy=2.3446488645341663, Accuracy=0.16319444444444445\n",
      "Epoch 67 validation: Cross-entropy=2.4427125453948975, Accuracy=0.09090909361839294\n",
      "Epoch 68 train: Cross-entropy=2.3444573084513345, Accuracy=0.16319444444444445\n",
      "Epoch 68 validation: Cross-entropy=2.442967176437378, Accuracy=0.09090909361839294\n",
      "Epoch 69 train: Cross-entropy=2.3442701233757868, Accuracy=0.16319444444444445\n",
      "Epoch 69 validation: Cross-entropy=2.4432175159454346, Accuracy=0.09090909361839294\n",
      "Epoch 70 train: Cross-entropy=2.344087322552999, Accuracy=0.16145833333333334\n",
      "Epoch 70 validation: Cross-entropy=2.4434633255004883, Accuracy=0.09090909361839294\n",
      "Epoch 71 train: Cross-entropy=2.343908680809869, Accuracy=0.1579861111111111\n",
      "Epoch 71 validation: Cross-entropy=2.443704843521118, Accuracy=0.09090909361839294\n",
      "Epoch 72 train: Cross-entropy=2.34373410542806, Accuracy=0.1579861111111111\n",
      "Epoch 72 validation: Cross-entropy=2.4439425468444824, Accuracy=0.09090909361839294\n",
      "Epoch 73 train: Cross-entropy=2.343563503689236, Accuracy=0.1579861111111111\n",
      "Epoch 73 validation: Cross-entropy=2.444175958633423, Accuracy=0.09090909361839294\n",
      "Epoch 74 train: Cross-entropy=2.343396676911248, Accuracy=0.15625\n",
      "Epoch 74 validation: Cross-entropy=2.4444053173065186, Accuracy=0.09090909361839294\n",
      "Epoch 75 train: Cross-entropy=2.3432334661483765, Accuracy=0.1579861111111111\n",
      "Epoch 75 validation: Cross-entropy=2.444631338119507, Accuracy=0.09090909361839294\n",
      "Epoch 76 train: Cross-entropy=2.3430739641189575, Accuracy=0.1579861111111111\n",
      "Epoch 76 validation: Cross-entropy=2.444852828979492, Accuracy=0.09090909361839294\n",
      "Epoch 77 train: Cross-entropy=2.342917972140842, Accuracy=0.1579861111111111\n",
      "Epoch 77 validation: Cross-entropy=2.445070743560791, Accuracy=0.09090909361839294\n",
      "Epoch 78 train: Cross-entropy=2.342765304777357, Accuracy=0.1579861111111111\n",
      "Epoch 78 validation: Cross-entropy=2.4452853202819824, Accuracy=0.09090909361839294\n",
      "Epoch 79 train: Cross-entropy=2.3426159487830267, Accuracy=0.1579861111111111\n",
      "Epoch 79 validation: Cross-entropy=2.445496082305908, Accuracy=0.09090909361839294\n",
      "Epoch 80 train: Cross-entropy=2.3424697849485607, Accuracy=0.15625\n",
      "Epoch 80 validation: Cross-entropy=2.4457032680511475, Accuracy=0.09090909361839294\n",
      "Epoch 81 train: Cross-entropy=2.342326839764913, Accuracy=0.1579861111111111\n",
      "Epoch 81 validation: Cross-entropy=2.4459073543548584, Accuracy=0.09090909361839294\n",
      "Epoch 82 train: Cross-entropy=2.342186835077074, Accuracy=0.1597222222222222\n",
      "Epoch 82 validation: Cross-entropy=2.446108102798462, Accuracy=0.09090909361839294\n",
      "Epoch 83 train: Cross-entropy=2.34204982386695, Accuracy=0.1597222222222222\n",
      "Epoch 83 validation: Cross-entropy=2.446305513381958, Accuracy=0.09090909361839294\n",
      "Epoch 84 train: Cross-entropy=2.341915660434299, Accuracy=0.1597222222222222\n",
      "Epoch 84 validation: Cross-entropy=2.4464995861053467, Accuracy=0.09090909361839294\n",
      "Epoch 85 train: Cross-entropy=2.3417842520607843, Accuracy=0.1597222222222222\n",
      "Epoch 85 validation: Cross-entropy=2.4466910362243652, Accuracy=0.08585858345031738\n",
      "Epoch 86 train: Cross-entropy=2.341655651728312, Accuracy=0.1597222222222222\n",
      "Epoch 86 validation: Cross-entropy=2.4468791484832764, Accuracy=0.08585858345031738\n",
      "Epoch 87 train: Cross-entropy=2.3415297667185464, Accuracy=0.1579861111111111\n",
      "Epoch 87 validation: Cross-entropy=2.4470643997192383, Accuracy=0.08585858345031738\n",
      "Epoch 88 train: Cross-entropy=2.3414063586129084, Accuracy=0.1579861111111111\n",
      "Epoch 88 validation: Cross-entropy=2.447246551513672, Accuracy=0.08585858345031738\n",
      "Epoch 89 train: Cross-entropy=2.3412854936387806, Accuracy=0.1579861111111111\n",
      "Epoch 89 validation: Cross-entropy=2.4474258422851562, Accuracy=0.08585858345031738\n",
      "Epoch 90 train: Cross-entropy=2.3411671453052096, Accuracy=0.1579861111111111\n",
      "Epoch 90 validation: Cross-entropy=2.4476027488708496, Accuracy=0.08585858345031738\n",
      "Epoch 91 train: Cross-entropy=2.34105118115743, Accuracy=0.1579861111111111\n",
      "Epoch 91 validation: Cross-entropy=2.4477763175964355, Accuracy=0.08585858345031738\n",
      "Epoch 92 train: Cross-entropy=2.3409374554951987, Accuracy=0.1579861111111111\n",
      "Epoch 92 validation: Cross-entropy=2.4479475021362305, Accuracy=0.08585858345031738\n",
      "Epoch 93 train: Cross-entropy=2.340826074282328, Accuracy=0.1579861111111111\n",
      "Epoch 93 validation: Cross-entropy=2.4481160640716553, Accuracy=0.08585858345031738\n",
      "Epoch 94 train: Cross-entropy=2.3407168918185763, Accuracy=0.1579861111111111\n",
      "Epoch 94 validation: Cross-entropy=2.448282241821289, Accuracy=0.08585858345031738\n",
      "Epoch 95 train: Cross-entropy=2.340609908103943, Accuracy=0.15625\n",
      "Epoch 95 validation: Cross-entropy=2.4484455585479736, Accuracy=0.08585858345031738\n",
      "Epoch 96 train: Cross-entropy=2.3405050569110446, Accuracy=0.15625\n",
      "Epoch 96 validation: Cross-entropy=2.448606491088867, Accuracy=0.08080808073282242\n",
      "Epoch 97 train: Cross-entropy=2.340402219030592, Accuracy=0.1579861111111111\n",
      "Epoch 97 validation: Cross-entropy=2.4487650394439697, Accuracy=0.08080808073282242\n",
      "Epoch 98 train: Cross-entropy=2.3403013547261557, Accuracy=0.1579861111111111\n",
      "Epoch 98 validation: Cross-entropy=2.4489212036132812, Accuracy=0.08080808073282242\n",
      "Epoch 99 train: Cross-entropy=2.3402025434705944, Accuracy=0.1579861111111111\n",
      "Epoch 99 validation: Cross-entropy=2.4490747451782227, Accuracy=0.07575757801532745\n",
      "Epoch 100 train: Cross-entropy=2.3401056395636664, Accuracy=0.15625\n",
      "Epoch 100 validation: Cross-entropy=2.4492263793945312, Accuracy=0.07575757801532745\n",
      "Epoch 101 train: Cross-entropy=2.340010576777988, Accuracy=0.15625\n",
      "Epoch 101 validation: Cross-entropy=2.449375629425049, Accuracy=0.07575757801532745\n",
      "Epoch 102 train: Cross-entropy=2.3399173816045127, Accuracy=0.15625\n",
      "Epoch 102 validation: Cross-entropy=2.4495227336883545, Accuracy=0.07575757801532745\n",
      "Epoch 103 train: Cross-entropy=2.3398259480794272, Accuracy=0.15625\n",
      "Epoch 103 validation: Cross-entropy=2.4496679306030273, Accuracy=0.08080808073282242\n",
      "Epoch 104 train: Cross-entropy=2.3397362762027316, Accuracy=0.15625\n",
      "Epoch 104 validation: Cross-entropy=2.44981050491333, Accuracy=0.08080808073282242\n",
      "Epoch 105 train: Cross-entropy=2.339648299747043, Accuracy=0.1579861111111111\n",
      "Epoch 105 validation: Cross-entropy=2.449951410293579, Accuracy=0.08080808073282242\n",
      "Epoch 106 train: Cross-entropy=2.3395619789759317, Accuracy=0.1579861111111111\n",
      "Epoch 106 validation: Cross-entropy=2.450089931488037, Accuracy=0.08080808073282242\n",
      "Epoch 107 train: Cross-entropy=2.339477366871304, Accuracy=0.15625\n",
      "Epoch 107 validation: Cross-entropy=2.4502267837524414, Accuracy=0.08080808073282242\n",
      "Epoch 108 train: Cross-entropy=2.3393942382600574, Accuracy=0.15625\n",
      "Epoch 108 validation: Cross-entropy=2.450361490249634, Accuracy=0.08080808073282242\n",
      "Epoch 109 train: Cross-entropy=2.3393127388424344, Accuracy=0.15625\n",
      "Epoch 109 validation: Cross-entropy=2.4504942893981934, Accuracy=0.08080808073282242\n",
      "Epoch 110 train: Cross-entropy=2.3392327626546225, Accuracy=0.15625\n",
      "Epoch 110 validation: Cross-entropy=2.45062518119812, Accuracy=0.08080808073282242\n",
      "Epoch 111 train: Cross-entropy=2.3391542302237616, Accuracy=0.15625\n",
      "Epoch 111 validation: Cross-entropy=2.450754404067993, Accuracy=0.08080808073282242\n",
      "Epoch 112 train: Cross-entropy=2.339077207777235, Accuracy=0.15625\n",
      "Epoch 112 validation: Cross-entropy=2.450881242752075, Accuracy=0.08080808073282242\n",
      "Epoch 113 train: Cross-entropy=2.339001562860277, Accuracy=0.15625\n",
      "Epoch 113 validation: Cross-entropy=2.4510066509246826, Accuracy=0.08080808073282242\n",
      "Epoch 114 train: Cross-entropy=2.3389273484547934, Accuracy=0.1545138888888889\n",
      "Epoch 114 validation: Cross-entropy=2.4511301517486572, Accuracy=0.08585858345031738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 train: Cross-entropy=2.338854498333401, Accuracy=0.1545138888888889\n",
      "Epoch 115 validation: Cross-entropy=2.451251983642578, Accuracy=0.08585858345031738\n",
      "Epoch 116 train: Cross-entropy=2.338782959514194, Accuracy=0.1545138888888889\n",
      "Epoch 116 validation: Cross-entropy=2.4513721466064453, Accuracy=0.08585858345031738\n",
      "Epoch 117 train: Cross-entropy=2.338712731997172, Accuracy=0.1527777777777778\n",
      "Epoch 117 validation: Cross-entropy=2.451490640640259, Accuracy=0.08585858345031738\n",
      "Epoch 118 train: Cross-entropy=2.338643789291382, Accuracy=0.1527777777777778\n",
      "Epoch 118 validation: Cross-entropy=2.4516072273254395, Accuracy=0.08585858345031738\n",
      "Epoch 119 train: Cross-entropy=2.3385760651694403, Accuracy=0.1545138888888889\n",
      "Epoch 119 validation: Cross-entropy=2.4517223834991455, Accuracy=0.08585858345031738\n",
      "Epoch 120 train: Cross-entropy=2.338509586122301, Accuracy=0.1527777777777778\n",
      "Epoch 120 validation: Cross-entropy=2.4518356323242188, Accuracy=0.08585858345031738\n",
      "Epoch 121 train: Cross-entropy=2.3384443124135337, Accuracy=0.1527777777777778\n",
      "Epoch 121 validation: Cross-entropy=2.4519476890563965, Accuracy=0.08585858345031738\n",
      "Epoch 122 train: Cross-entropy=2.3383801778157554, Accuracy=0.1527777777777778\n",
      "Epoch 122 validation: Cross-entropy=2.4520580768585205, Accuracy=0.08585858345031738\n",
      "Epoch 123 train: Cross-entropy=2.338317208819919, Accuracy=0.1527777777777778\n",
      "Epoch 123 validation: Cross-entropy=2.45216703414917, Accuracy=0.08585858345031738\n",
      "Epoch 124 train: Cross-entropy=2.338255352444119, Accuracy=0.1527777777777778\n",
      "Epoch 124 validation: Cross-entropy=2.4522743225097656, Accuracy=0.08585858345031738\n",
      "Epoch 125 train: Cross-entropy=2.338194568951925, Accuracy=0.1527777777777778\n",
      "Epoch 125 validation: Cross-entropy=2.4523799419403076, Accuracy=0.08585858345031738\n",
      "Epoch 126 train: Cross-entropy=2.3381349907981024, Accuracy=0.1527777777777778\n",
      "Epoch 126 validation: Cross-entropy=2.452484369277954, Accuracy=0.08585858345031738\n",
      "Epoch 127 train: Cross-entropy=2.3380763000912137, Accuracy=0.1527777777777778\n",
      "Epoch 127 validation: Cross-entropy=2.452587127685547, Accuracy=0.08585858345031738\n",
      "Epoch 128 train: Cross-entropy=2.3380187352498374, Accuracy=0.1527777777777778\n",
      "Epoch 128 validation: Cross-entropy=2.452688694000244, Accuracy=0.08585858345031738\n",
      "Epoch 129 train: Cross-entropy=2.3379621373282538, Accuracy=0.1527777777777778\n",
      "Epoch 129 validation: Cross-entropy=2.452789068222046, Accuracy=0.08585858345031738\n",
      "Epoch 130 train: Cross-entropy=2.3379065990448, Accuracy=0.1527777777777778\n",
      "Epoch 130 validation: Cross-entropy=2.4528872966766357, Accuracy=0.08585858345031738\n",
      "Epoch 131 train: Cross-entropy=2.337851961453756, Accuracy=0.15104166666666666\n",
      "Epoch 131 validation: Cross-entropy=2.4529848098754883, Accuracy=0.08585858345031738\n",
      "Epoch 132 train: Cross-entropy=2.337798317273458, Accuracy=0.15104166666666666\n",
      "Epoch 132 validation: Cross-entropy=2.453080892562866, Accuracy=0.08585858345031738\n",
      "Epoch 133 train: Cross-entropy=2.3377455472946167, Accuracy=0.15104166666666666\n",
      "Epoch 133 validation: Cross-entropy=2.4531755447387695, Accuracy=0.08585858345031738\n",
      "Epoch 134 train: Cross-entropy=2.337693797217475, Accuracy=0.15104166666666666\n",
      "Epoch 134 validation: Cross-entropy=2.4532690048217773, Accuracy=0.08585858345031738\n",
      "Epoch 135 train: Cross-entropy=2.3376429080963135, Accuracy=0.15104166666666666\n",
      "Epoch 135 validation: Cross-entropy=2.4533610343933105, Accuracy=0.08585858345031738\n",
      "Epoch 136 train: Cross-entropy=2.3375927872127957, Accuracy=0.15104166666666666\n",
      "Epoch 136 validation: Cross-entropy=2.4534521102905273, Accuracy=0.08080808073282242\n",
      "Epoch 137 train: Cross-entropy=2.337543633249071, Accuracy=0.15104166666666666\n",
      "Epoch 137 validation: Cross-entropy=2.4535415172576904, Accuracy=0.08080808073282242\n",
      "Epoch 138 train: Cross-entropy=2.3374952475229898, Accuracy=0.15104166666666666\n",
      "Epoch 138 validation: Cross-entropy=2.453629970550537, Accuracy=0.08080808073282242\n",
      "Epoch 139 train: Cross-entropy=2.337447762489319, Accuracy=0.15104166666666666\n",
      "Epoch 139 validation: Cross-entropy=2.4537172317504883, Accuracy=0.08080808073282242\n",
      "Epoch 140 train: Cross-entropy=2.3374010192023382, Accuracy=0.1527777777777778\n",
      "Epoch 140 validation: Cross-entropy=2.453803062438965, Accuracy=0.08080808073282242\n",
      "Epoch 141 train: Cross-entropy=2.3373550838894315, Accuracy=0.1527777777777778\n",
      "Epoch 141 validation: Cross-entropy=2.453888177871704, Accuracy=0.08080808073282242\n",
      "Epoch 142 train: Cross-entropy=2.3373098770777383, Accuracy=0.1527777777777778\n",
      "Epoch 142 validation: Cross-entropy=2.453972101211548, Accuracy=0.08080808073282242\n",
      "Epoch 143 train: Cross-entropy=2.337265517976549, Accuracy=0.1527777777777778\n",
      "Epoch 143 validation: Cross-entropy=2.454054355621338, Accuracy=0.08080808073282242\n",
      "Epoch 144 train: Cross-entropy=2.3372218873765735, Accuracy=0.1527777777777778\n",
      "Epoch 144 validation: Cross-entropy=2.4541361331939697, Accuracy=0.08080808073282242\n",
      "Epoch 145 train: Cross-entropy=2.3371789852778115, Accuracy=0.1527777777777778\n",
      "Epoch 145 validation: Cross-entropy=2.454216241836548, Accuracy=0.08080808073282242\n",
      "Epoch 146 train: Cross-entropy=2.3371367984347873, Accuracy=0.1527777777777778\n",
      "Epoch 146 validation: Cross-entropy=2.4542953968048096, Accuracy=0.08080808073282242\n",
      "Epoch 147 train: Cross-entropy=2.337095340092977, Accuracy=0.1527777777777778\n",
      "Epoch 147 validation: Cross-entropy=2.454373836517334, Accuracy=0.08080808073282242\n",
      "Epoch 148 train: Cross-entropy=2.3370544645521374, Accuracy=0.1527777777777778\n",
      "Epoch 148 validation: Cross-entropy=2.454450845718384, Accuracy=0.08080808073282242\n",
      "Epoch 149 train: Cross-entropy=2.337014357248942, Accuracy=0.1527777777777778\n",
      "Epoch 149 validation: Cross-entropy=2.454526901245117, Accuracy=0.08080808073282242\n",
      "Epoch 150 train: Cross-entropy=2.336974951956007, Accuracy=0.1527777777777778\n",
      "Epoch 150 validation: Cross-entropy=2.4546022415161133, Accuracy=0.08080808073282242\n",
      "Epoch 151 train: Cross-entropy=2.3369361692004733, Accuracy=0.1527777777777778\n",
      "Epoch 151 validation: Cross-entropy=2.4546761512756348, Accuracy=0.08080808073282242\n",
      "Epoch 152 train: Cross-entropy=2.336897929509481, Accuracy=0.1527777777777778\n",
      "Epoch 152 validation: Cross-entropy=2.45474910736084, Accuracy=0.08080808073282242\n",
      "Epoch 153 train: Cross-entropy=2.3368604050742254, Accuracy=0.1527777777777778\n",
      "Epoch 153 validation: Cross-entropy=2.4548213481903076, Accuracy=0.08080808073282242\n",
      "Epoch 154 train: Cross-entropy=2.336823489930895, Accuracy=0.1527777777777778\n",
      "Epoch 154 validation: Cross-entropy=2.454892635345459, Accuracy=0.08080808073282242\n",
      "Epoch 155 train: Cross-entropy=2.3367871708340116, Accuracy=0.1527777777777778\n",
      "Epoch 155 validation: Cross-entropy=2.4549624919891357, Accuracy=0.08080808073282242\n",
      "Epoch 156 train: Cross-entropy=2.3367514345380993, Accuracy=0.1527777777777778\n",
      "Epoch 156 validation: Cross-entropy=2.4550318717956543, Accuracy=0.08080808073282242\n",
      "Epoch 157 train: Cross-entropy=2.336716334025065, Accuracy=0.1527777777777778\n",
      "Epoch 157 validation: Cross-entropy=2.4551000595092773, Accuracy=0.08080808073282242\n",
      "Epoch 158 train: Cross-entropy=2.3366816573672824, Accuracy=0.15104166666666666\n",
      "Epoch 158 validation: Cross-entropy=2.455167770385742, Accuracy=0.08080808073282242\n",
      "Epoch 159 train: Cross-entropy=2.3366476694742837, Accuracy=0.14930555555555555\n",
      "Epoch 159 validation: Cross-entropy=2.4552340507507324, Accuracy=0.08080808073282242\n",
      "Epoch 160 train: Cross-entropy=2.3366141319274902, Accuracy=0.14930555555555555\n",
      "Epoch 160 validation: Cross-entropy=2.4552998542785645, Accuracy=0.08080808073282242\n",
      "Epoch 161 train: Cross-entropy=2.3365811904271445, Accuracy=0.14930555555555555\n",
      "Epoch 161 validation: Cross-entropy=2.455364465713501, Accuracy=0.08080808073282242\n",
      "Epoch 162 train: Cross-entropy=2.336548844973246, Accuracy=0.14930555555555555\n",
      "Epoch 162 validation: Cross-entropy=2.4554283618927, Accuracy=0.08080808073282242\n",
      "Epoch 163 train: Cross-entropy=2.3365169631110296, Accuracy=0.14930555555555555\n",
      "Epoch 163 validation: Cross-entropy=2.455491304397583, Accuracy=0.08080808073282242\n",
      "Epoch 164 train: Cross-entropy=2.336485505104065, Accuracy=0.14930555555555555\n",
      "Epoch 164 validation: Cross-entropy=2.4555535316467285, Accuracy=0.08080808073282242\n",
      "Epoch 165 train: Cross-entropy=2.336454603407118, Accuracy=0.14930555555555555\n",
      "Epoch 165 validation: Cross-entropy=2.4556150436401367, Accuracy=0.08080808073282242\n",
      "Epoch 166 train: Cross-entropy=2.3364242447747126, Accuracy=0.14930555555555555\n",
      "Epoch 166 validation: Cross-entropy=2.4556753635406494, Accuracy=0.08080808073282242\n",
      "Epoch 167 train: Cross-entropy=2.336394336488512, Accuracy=0.14930555555555555\n",
      "Epoch 167 validation: Cross-entropy=2.455735206604004, Accuracy=0.08080808073282242\n",
      "Epoch 168 train: Cross-entropy=2.336364891793993, Accuracy=0.14930555555555555\n",
      "Epoch 168 validation: Cross-entropy=2.455793857574463, Accuracy=0.08080808073282242\n",
      "Epoch 169 train: Cross-entropy=2.3363359371821084, Accuracy=0.14930555555555555\n",
      "Epoch 169 validation: Cross-entropy=2.4558522701263428, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 train: Cross-entropy=2.3363074461619058, Accuracy=0.14930555555555555\n",
      "Epoch 170 validation: Cross-entropy=2.4559097290039062, Accuracy=0.08080808073282242\n",
      "Epoch 171 train: Cross-entropy=2.336279312769572, Accuracy=0.14756944444444445\n",
      "Epoch 171 validation: Cross-entropy=2.4559662342071533, Accuracy=0.08080808073282242\n",
      "Epoch 172 train: Cross-entropy=2.3362516827053494, Accuracy=0.14756944444444445\n",
      "Epoch 172 validation: Cross-entropy=2.456022024154663, Accuracy=0.08080808073282242\n",
      "Epoch 173 train: Cross-entropy=2.3362244764963784, Accuracy=0.14756944444444445\n",
      "Epoch 173 validation: Cross-entropy=2.4560775756835938, Accuracy=0.08080808073282242\n",
      "Epoch 174 train: Cross-entropy=2.3361977338790894, Accuracy=0.14756944444444445\n",
      "Epoch 174 validation: Cross-entropy=2.45613169670105, Accuracy=0.08080808073282242\n",
      "Epoch 175 train: Cross-entropy=2.3361712296803794, Accuracy=0.14756944444444445\n",
      "Epoch 175 validation: Cross-entropy=2.4561851024627686, Accuracy=0.08080808073282242\n",
      "Epoch 176 train: Cross-entropy=2.336145361264547, Accuracy=0.14756944444444445\n",
      "Epoch 176 validation: Cross-entropy=2.4562385082244873, Accuracy=0.08080808073282242\n",
      "Epoch 177 train: Cross-entropy=2.3361197445127697, Accuracy=0.14756944444444445\n",
      "Epoch 177 validation: Cross-entropy=2.4562907218933105, Accuracy=0.08080808073282242\n",
      "Epoch 178 train: Cross-entropy=2.3360945781071982, Accuracy=0.14756944444444445\n",
      "Epoch 178 validation: Cross-entropy=2.4563422203063965, Accuracy=0.08080808073282242\n",
      "Epoch 179 train: Cross-entropy=2.336069795820448, Accuracy=0.14756944444444445\n",
      "Epoch 179 validation: Cross-entropy=2.456393241882324, Accuracy=0.08080808073282242\n",
      "Epoch 180 train: Cross-entropy=2.3360454771253796, Accuracy=0.14756944444444445\n",
      "Epoch 180 validation: Cross-entropy=2.4564433097839355, Accuracy=0.08080808073282242\n",
      "Epoch 181 train: Cross-entropy=2.3360213703579373, Accuracy=0.14756944444444445\n",
      "Epoch 181 validation: Cross-entropy=2.4564926624298096, Accuracy=0.08585858345031738\n",
      "Epoch 182 train: Cross-entropy=2.3359977536731296, Accuracy=0.14756944444444445\n",
      "Epoch 182 validation: Cross-entropy=2.4565417766571045, Accuracy=0.08585858345031738\n",
      "Epoch 183 train: Cross-entropy=2.335974415143331, Accuracy=0.14756944444444445\n",
      "Epoch 183 validation: Cross-entropy=2.456590175628662, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.3359514342414007, Accuracy=0.14756944444444445\n",
      "Epoch 184 validation: Cross-entropy=2.456637382507324, Accuracy=0.08585858345031738\n",
      "Epoch 185 train: Cross-entropy=2.3359288771947226, Accuracy=0.14756944444444445\n",
      "Epoch 185 validation: Cross-entropy=2.4566843509674072, Accuracy=0.08585858345031738\n",
      "Epoch 186 train: Cross-entropy=2.3359066115485296, Accuracy=0.14756944444444445\n",
      "Epoch 186 validation: Cross-entropy=2.456731081008911, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.335884769757589, Accuracy=0.14756944444444445\n",
      "Epoch 187 validation: Cross-entropy=2.4567768573760986, Accuracy=0.08585858345031738\n",
      "Epoch 188 train: Cross-entropy=2.3358631001578436, Accuracy=0.14756944444444445\n",
      "Epoch 188 validation: Cross-entropy=2.4568216800689697, Accuracy=0.08585858345031738\n",
      "Epoch 189 train: Cross-entropy=2.335841801431444, Accuracy=0.14756944444444445\n",
      "Epoch 189 validation: Cross-entropy=2.45686674118042, Accuracy=0.08585858345031738\n",
      "Epoch 190 train: Cross-entropy=2.3358208735783896, Accuracy=0.14756944444444445\n",
      "Epoch 190 validation: Cross-entropy=2.4569103717803955, Accuracy=0.08585858345031738\n",
      "Epoch 191 train: Cross-entropy=2.335800197389391, Accuracy=0.14756944444444445\n",
      "Epoch 191 validation: Cross-entropy=2.456953763961792, Accuracy=0.08585858345031738\n",
      "Epoch 192 train: Cross-entropy=2.3357798126008777, Accuracy=0.14756944444444445\n",
      "Epoch 192 validation: Cross-entropy=2.4569966793060303, Accuracy=0.08585858345031738\n",
      "Epoch 193 train: Cross-entropy=2.335759811931186, Accuracy=0.14930555555555555\n",
      "Epoch 193 validation: Cross-entropy=2.4570391178131104, Accuracy=0.08585858345031738\n",
      "Epoch 194 train: Cross-entropy=2.335740076171027, Accuracy=0.14930555555555555\n",
      "Epoch 194 validation: Cross-entropy=2.457080841064453, Accuracy=0.08585858345031738\n",
      "Epoch 195 train: Cross-entropy=2.3357206185658774, Accuracy=0.14930555555555555\n",
      "Epoch 195 validation: Cross-entropy=2.4571218490600586, Accuracy=0.08585858345031738\n",
      "Epoch 196 train: Cross-entropy=2.335701412624783, Accuracy=0.14930555555555555\n",
      "Epoch 196 validation: Cross-entropy=2.457162618637085, Accuracy=0.08585858345031738\n",
      "Epoch 197 train: Cross-entropy=2.3356825643115573, Accuracy=0.14930555555555555\n",
      "Epoch 197 validation: Cross-entropy=2.457202434539795, Accuracy=0.08585858345031738\n",
      "Epoch 198 train: Cross-entropy=2.3356639676623874, Accuracy=0.14930555555555555\n",
      "Epoch 198 validation: Cross-entropy=2.457242488861084, Accuracy=0.08585858345031738\n",
      "Epoch 199 train: Cross-entropy=2.3356456226772733, Accuracy=0.14930555555555555\n",
      "Epoch 199 validation: Cross-entropy=2.4572813510894775, Accuracy=0.08585858345031738\n",
      "Epoch 0 train: Cross-entropy=2.426502055592007, Accuracy=0.09027777777777778\n",
      "Epoch 0 validation: Cross-entropy=2.417388677597046, Accuracy=0.07070706784725189\n",
      "Epoch 1 train: Cross-entropy=2.409757720099555, Accuracy=0.08159722222222222\n",
      "Epoch 1 validation: Cross-entropy=2.412201166152954, Accuracy=0.07575757801532745\n",
      "Epoch 2 train: Cross-entropy=2.403200136290656, Accuracy=0.08680555555555555\n",
      "Epoch 2 validation: Cross-entropy=2.412489414215088, Accuracy=0.09090909361839294\n",
      "Epoch 3 train: Cross-entropy=2.397535390324063, Accuracy=0.09895833333333333\n",
      "Epoch 3 validation: Cross-entropy=2.4136362075805664, Accuracy=0.07575757801532745\n",
      "Epoch 4 train: Cross-entropy=2.393098990122477, Accuracy=0.10243055555555555\n",
      "Epoch 4 validation: Cross-entropy=2.414682626724243, Accuracy=0.08080808073282242\n",
      "Epoch 5 train: Cross-entropy=2.3891290956073337, Accuracy=0.10416666666666667\n",
      "Epoch 5 validation: Cross-entropy=2.4160690307617188, Accuracy=0.07070706784725189\n",
      "Epoch 6 train: Cross-entropy=2.3856602112452188, Accuracy=0.1111111111111111\n",
      "Epoch 6 validation: Cross-entropy=2.4173643589019775, Accuracy=0.08585858345031738\n",
      "Epoch 7 train: Cross-entropy=2.3825780815548367, Accuracy=0.11631944444444445\n",
      "Epoch 7 validation: Cross-entropy=2.418743133544922, Accuracy=0.08080808073282242\n",
      "Epoch 8 train: Cross-entropy=2.379821923043993, Accuracy=0.11979166666666667\n",
      "Epoch 8 validation: Cross-entropy=2.42008638381958, Accuracy=0.08585858345031738\n",
      "Epoch 9 train: Cross-entropy=2.377346992492676, Accuracy=0.12152777777777778\n",
      "Epoch 9 validation: Cross-entropy=2.4214227199554443, Accuracy=0.08080808073282242\n",
      "Epoch 10 train: Cross-entropy=2.3751093414094715, Accuracy=0.11979166666666667\n",
      "Epoch 10 validation: Cross-entropy=2.4227235317230225, Accuracy=0.07575757801532745\n",
      "Epoch 11 train: Cross-entropy=2.373078054851956, Accuracy=0.12152777777777778\n",
      "Epoch 11 validation: Cross-entropy=2.4239888191223145, Accuracy=0.08080808073282242\n",
      "Epoch 12 train: Cross-entropy=2.3712250656551785, Accuracy=0.1232638888888889\n",
      "Epoch 12 validation: Cross-entropy=2.4252114295959473, Accuracy=0.09090909361839294\n",
      "Epoch 13 train: Cross-entropy=2.3695280419455633, Accuracy=0.1232638888888889\n",
      "Epoch 13 validation: Cross-entropy=2.42638897895813, Accuracy=0.09090909361839294\n",
      "Epoch 14 train: Cross-entropy=2.367968042691549, Accuracy=0.1284722222222222\n",
      "Epoch 14 validation: Cross-entropy=2.4275200366973877, Accuracy=0.09090909361839294\n",
      "Epoch 15 train: Cross-entropy=2.366529001129998, Accuracy=0.1267361111111111\n",
      "Epoch 15 validation: Cross-entropy=2.4286038875579834, Accuracy=0.09595959633588791\n",
      "Epoch 16 train: Cross-entropy=2.365197393629286, Accuracy=0.125\n",
      "Epoch 16 validation: Cross-entropy=2.4296414852142334, Accuracy=0.09090909361839294\n",
      "Epoch 17 train: Cross-entropy=2.3639616436428494, Accuracy=0.13368055555555555\n",
      "Epoch 17 validation: Cross-entropy=2.4306328296661377, Accuracy=0.09090909361839294\n",
      "Epoch 18 train: Cross-entropy=2.362811737590366, Accuracy=0.13541666666666666\n",
      "Epoch 18 validation: Cross-entropy=2.431579351425171, Accuracy=0.09090909361839294\n",
      "Epoch 19 train: Cross-entropy=2.3617391188939414, Accuracy=0.1371527777777778\n",
      "Epoch 19 validation: Cross-entropy=2.4324827194213867, Accuracy=0.09090909361839294\n",
      "Epoch 20 train: Cross-entropy=2.3607362376319037, Accuracy=0.1371527777777778\n",
      "Epoch 20 validation: Cross-entropy=2.433344602584839, Accuracy=0.09595959633588791\n",
      "Epoch 21 train: Cross-entropy=2.359796749220954, Accuracy=0.1388888888888889\n",
      "Epoch 21 validation: Cross-entropy=2.4341659545898438, Accuracy=0.09090909361839294\n",
      "Epoch 22 train: Cross-entropy=2.3589148256513806, Accuracy=0.140625\n",
      "Epoch 22 validation: Cross-entropy=2.4349496364593506, Accuracy=0.09090909361839294\n",
      "Epoch 23 train: Cross-entropy=2.358085446887546, Accuracy=0.1423611111111111\n",
      "Epoch 23 validation: Cross-entropy=2.435696601867676, Accuracy=0.09090909361839294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 train: Cross-entropy=2.3573042949040732, Accuracy=0.1423611111111111\n",
      "Epoch 24 validation: Cross-entropy=2.4364089965820312, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.3565672238667807, Accuracy=0.14756944444444445\n",
      "Epoch 25 validation: Cross-entropy=2.43708872795105, Accuracy=0.09090909361839294\n",
      "Epoch 26 train: Cross-entropy=2.355870935651991, Accuracy=0.14583333333333334\n",
      "Epoch 26 validation: Cross-entropy=2.437737464904785, Accuracy=0.09090909361839294\n",
      "Epoch 27 train: Cross-entropy=2.3552122116088867, Accuracy=0.14756944444444445\n",
      "Epoch 27 validation: Cross-entropy=2.4383561611175537, Accuracy=0.09090909361839294\n",
      "Epoch 28 train: Cross-entropy=2.3545882304509482, Accuracy=0.14756944444444445\n",
      "Epoch 28 validation: Cross-entropy=2.4389469623565674, Accuracy=0.09090909361839294\n",
      "Epoch 29 train: Cross-entropy=2.3539964490466647, Accuracy=0.14756944444444445\n",
      "Epoch 29 validation: Cross-entropy=2.439511299133301, Accuracy=0.10101009905338287\n",
      "Epoch 30 train: Cross-entropy=2.3534346686469183, Accuracy=0.14930555555555555\n",
      "Epoch 30 validation: Cross-entropy=2.4400506019592285, Accuracy=0.10101009905338287\n",
      "Epoch 31 train: Cross-entropy=2.3529007302390204, Accuracy=0.15104166666666666\n",
      "Epoch 31 validation: Cross-entropy=2.440566301345825, Accuracy=0.10101009905338287\n",
      "Epoch 32 train: Cross-entropy=2.3523927529652915, Accuracy=0.15625\n",
      "Epoch 32 validation: Cross-entropy=2.4410593509674072, Accuracy=0.10101009905338287\n",
      "Epoch 33 train: Cross-entropy=2.3519091076321073, Accuracy=0.15625\n",
      "Epoch 33 validation: Cross-entropy=2.4415314197540283, Accuracy=0.10101009905338287\n",
      "Epoch 34 train: Cross-entropy=2.351448244518704, Accuracy=0.15625\n",
      "Epoch 34 validation: Cross-entropy=2.441983222961426, Accuracy=0.10101009905338287\n",
      "Epoch 35 train: Cross-entropy=2.351008733113607, Accuracy=0.15625\n",
      "Epoch 35 validation: Cross-entropy=2.4424164295196533, Accuracy=0.10101009905338287\n",
      "Epoch 36 train: Cross-entropy=2.350589156150818, Accuracy=0.15625\n",
      "Epoch 36 validation: Cross-entropy=2.44283127784729, Accuracy=0.09595959633588791\n",
      "Epoch 37 train: Cross-entropy=2.3501884672376843, Accuracy=0.15625\n",
      "Epoch 37 validation: Cross-entropy=2.4432294368743896, Accuracy=0.09595959633588791\n",
      "Epoch 38 train: Cross-entropy=2.3498055140177407, Accuracy=0.1545138888888889\n",
      "Epoch 38 validation: Cross-entropy=2.4436113834381104, Accuracy=0.09595959633588791\n",
      "Epoch 39 train: Cross-entropy=2.349439263343811, Accuracy=0.15625\n",
      "Epoch 39 validation: Cross-entropy=2.4439783096313477, Accuracy=0.09595959633588791\n",
      "Epoch 40 train: Cross-entropy=2.349088854259915, Accuracy=0.1579861111111111\n",
      "Epoch 40 validation: Cross-entropy=2.4443304538726807, Accuracy=0.09595959633588791\n",
      "Epoch 41 train: Cross-entropy=2.3487532801098294, Accuracy=0.1579861111111111\n",
      "Epoch 41 validation: Cross-entropy=2.444669246673584, Accuracy=0.09595959633588791\n",
      "Epoch 42 train: Cross-entropy=2.34843193160163, Accuracy=0.1597222222222222\n",
      "Epoch 42 validation: Cross-entropy=2.4449946880340576, Accuracy=0.09595959633588791\n",
      "Epoch 43 train: Cross-entropy=2.3481238418155246, Accuracy=0.1579861111111111\n",
      "Epoch 43 validation: Cross-entropy=2.445307970046997, Accuracy=0.09595959633588791\n",
      "Epoch 44 train: Cross-entropy=2.3478285471598306, Accuracy=0.1579861111111111\n",
      "Epoch 44 validation: Cross-entropy=2.4456095695495605, Accuracy=0.09595959633588791\n",
      "Epoch 45 train: Cross-entropy=2.3475451601876154, Accuracy=0.1597222222222222\n",
      "Epoch 45 validation: Cross-entropy=2.4459004402160645, Accuracy=0.09595959633588791\n",
      "Epoch 46 train: Cross-entropy=2.347273310025533, Accuracy=0.16145833333333334\n",
      "Epoch 46 validation: Cross-entropy=2.446180582046509, Accuracy=0.09595959633588791\n",
      "Epoch 47 train: Cross-entropy=2.3470122946633234, Accuracy=0.16145833333333334\n",
      "Epoch 47 validation: Cross-entropy=2.4464504718780518, Accuracy=0.09595959633588791\n",
      "Epoch 48 train: Cross-entropy=2.346761610772875, Accuracy=0.16145833333333334\n",
      "Epoch 48 validation: Cross-entropy=2.446711301803589, Accuracy=0.09595959633588791\n",
      "Epoch 49 train: Cross-entropy=2.346520781517029, Accuracy=0.16145833333333334\n",
      "Epoch 49 validation: Cross-entropy=2.446962833404541, Accuracy=0.09595959633588791\n",
      "Epoch 50 train: Cross-entropy=2.3462893697950573, Accuracy=0.16145833333333334\n",
      "Epoch 50 validation: Cross-entropy=2.4472057819366455, Accuracy=0.09595959633588791\n",
      "Epoch 51 train: Cross-entropy=2.3460669252607556, Accuracy=0.16319444444444445\n",
      "Epoch 51 validation: Cross-entropy=2.4474401473999023, Accuracy=0.09595959633588791\n",
      "Epoch 52 train: Cross-entropy=2.345853077040778, Accuracy=0.16319444444444445\n",
      "Epoch 52 validation: Cross-entropy=2.447667121887207, Accuracy=0.09090909361839294\n",
      "Epoch 53 train: Cross-entropy=2.3456473615434437, Accuracy=0.16319444444444445\n",
      "Epoch 53 validation: Cross-entropy=2.4478867053985596, Accuracy=0.09090909361839294\n",
      "Epoch 54 train: Cross-entropy=2.3454493946499295, Accuracy=0.16145833333333334\n",
      "Epoch 54 validation: Cross-entropy=2.44809889793396, Accuracy=0.09090909361839294\n",
      "Epoch 55 train: Cross-entropy=2.345259017414517, Accuracy=0.16145833333333334\n",
      "Epoch 55 validation: Cross-entropy=2.4483046531677246, Accuracy=0.09090909361839294\n",
      "Epoch 56 train: Cross-entropy=2.345075700018141, Accuracy=0.16145833333333334\n",
      "Epoch 56 validation: Cross-entropy=2.4485034942626953, Accuracy=0.09090909361839294\n",
      "Epoch 57 train: Cross-entropy=2.344899336496989, Accuracy=0.16145833333333334\n",
      "Epoch 57 validation: Cross-entropy=2.4486963748931885, Accuracy=0.09090909361839294\n",
      "Epoch 58 train: Cross-entropy=2.3447295162412853, Accuracy=0.16145833333333334\n",
      "Epoch 58 validation: Cross-entropy=2.448883295059204, Accuracy=0.09090909361839294\n",
      "Epoch 59 train: Cross-entropy=2.3445659081141152, Accuracy=0.16145833333333334\n",
      "Epoch 59 validation: Cross-entropy=2.4490647315979004, Accuracy=0.09090909361839294\n",
      "Epoch 60 train: Cross-entropy=2.344408392906189, Accuracy=0.1597222222222222\n",
      "Epoch 60 validation: Cross-entropy=2.4492406845092773, Accuracy=0.09090909361839294\n",
      "Epoch 61 train: Cross-entropy=2.3442566527260675, Accuracy=0.1597222222222222\n",
      "Epoch 61 validation: Cross-entropy=2.449411153793335, Accuracy=0.09090909361839294\n",
      "Epoch 62 train: Cross-entropy=2.344110475646125, Accuracy=0.1597222222222222\n",
      "Epoch 62 validation: Cross-entropy=2.4495768547058105, Accuracy=0.08585858345031738\n",
      "Epoch 63 train: Cross-entropy=2.343969636493259, Accuracy=0.1597222222222222\n",
      "Epoch 63 validation: Cross-entropy=2.449737787246704, Accuracy=0.08585858345031738\n",
      "Epoch 64 train: Cross-entropy=2.34383401605818, Accuracy=0.1597222222222222\n",
      "Epoch 64 validation: Cross-entropy=2.4498941898345947, Accuracy=0.08585858345031738\n",
      "Epoch 65 train: Cross-entropy=2.3437032434675427, Accuracy=0.16145833333333334\n",
      "Epoch 65 validation: Cross-entropy=2.4500465393066406, Accuracy=0.08585858345031738\n",
      "Epoch 66 train: Cross-entropy=2.343577252493964, Accuracy=0.16145833333333334\n",
      "Epoch 66 validation: Cross-entropy=2.4501943588256836, Accuracy=0.08585858345031738\n",
      "Epoch 67 train: Cross-entropy=2.343455778227912, Accuracy=0.16145833333333334\n",
      "Epoch 67 validation: Cross-entropy=2.450338125228882, Accuracy=0.08585858345031738\n",
      "Epoch 68 train: Cross-entropy=2.3433387676874795, Accuracy=0.16145833333333334\n",
      "Epoch 68 validation: Cross-entropy=2.4504780769348145, Accuracy=0.08585858345031738\n",
      "Epoch 69 train: Cross-entropy=2.3432259692086115, Accuracy=0.16145833333333334\n",
      "Epoch 69 validation: Cross-entropy=2.4506142139434814, Accuracy=0.08585858345031738\n",
      "Epoch 70 train: Cross-entropy=2.3431172238455877, Accuracy=0.16145833333333334\n",
      "Epoch 70 validation: Cross-entropy=2.450746774673462, Accuracy=0.08585858345031738\n",
      "Epoch 71 train: Cross-entropy=2.343012425634596, Accuracy=0.16145833333333334\n",
      "Epoch 71 validation: Cross-entropy=2.450876235961914, Accuracy=0.08585858345031738\n",
      "Epoch 72 train: Cross-entropy=2.3429113494025335, Accuracy=0.16145833333333334\n",
      "Epoch 72 validation: Cross-entropy=2.4510021209716797, Accuracy=0.08080808073282242\n",
      "Epoch 73 train: Cross-entropy=2.342814008394877, Accuracy=0.1597222222222222\n",
      "Epoch 73 validation: Cross-entropy=2.451124668121338, Accuracy=0.08080808073282242\n",
      "Epoch 74 train: Cross-entropy=2.342720111211141, Accuracy=0.1597222222222222\n",
      "Epoch 74 validation: Cross-entropy=2.451244354248047, Accuracy=0.08080808073282242\n",
      "Epoch 75 train: Cross-entropy=2.3426296843422785, Accuracy=0.1597222222222222\n",
      "Epoch 75 validation: Cross-entropy=2.4513614177703857, Accuracy=0.08080808073282242\n",
      "Epoch 76 train: Cross-entropy=2.342542436387804, Accuracy=0.1597222222222222\n",
      "Epoch 76 validation: Cross-entropy=2.451475143432617, Accuracy=0.08080808073282242\n",
      "Epoch 77 train: Cross-entropy=2.3424584335751004, Accuracy=0.1597222222222222\n",
      "Epoch 77 validation: Cross-entropy=2.4515864849090576, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 train: Cross-entropy=2.342377371258206, Accuracy=0.1597222222222222\n",
      "Epoch 78 validation: Cross-entropy=2.4516947269439697, Accuracy=0.08080808073282242\n",
      "Epoch 79 train: Cross-entropy=2.3422992626825967, Accuracy=0.1597222222222222\n",
      "Epoch 79 validation: Cross-entropy=2.45180082321167, Accuracy=0.08080808073282242\n",
      "Epoch 80 train: Cross-entropy=2.34222404162089, Accuracy=0.1579861111111111\n",
      "Epoch 80 validation: Cross-entropy=2.451904058456421, Accuracy=0.08080808073282242\n",
      "Epoch 81 train: Cross-entropy=2.34215157561832, Accuracy=0.1579861111111111\n",
      "Epoch 81 validation: Cross-entropy=2.452005624771118, Accuracy=0.08080808073282242\n",
      "Epoch 82 train: Cross-entropy=2.342081665992737, Accuracy=0.1597222222222222\n",
      "Epoch 82 validation: Cross-entropy=2.452104330062866, Accuracy=0.08080808073282242\n",
      "Epoch 83 train: Cross-entropy=2.34201443195343, Accuracy=0.16145833333333334\n",
      "Epoch 83 validation: Cross-entropy=2.4522011280059814, Accuracy=0.08080808073282242\n",
      "Epoch 84 train: Cross-entropy=2.341949542363485, Accuracy=0.16145833333333334\n",
      "Epoch 84 validation: Cross-entropy=2.4522953033447266, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.3418871429231434, Accuracy=0.16319444444444445\n",
      "Epoch 85 validation: Cross-entropy=2.452388048171997, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.341826968722873, Accuracy=0.16319444444444445\n",
      "Epoch 86 validation: Cross-entropy=2.4524786472320557, Accuracy=0.08080808073282242\n",
      "Epoch 87 train: Cross-entropy=2.341768993271722, Accuracy=0.16319444444444445\n",
      "Epoch 87 validation: Cross-entropy=2.4525668621063232, Accuracy=0.08080808073282242\n",
      "Epoch 88 train: Cross-entropy=2.3417132430606418, Accuracy=0.16145833333333334\n",
      "Epoch 88 validation: Cross-entropy=2.452653646469116, Accuracy=0.08080808073282242\n",
      "Epoch 89 train: Cross-entropy=2.341659532652961, Accuracy=0.16145833333333334\n",
      "Epoch 89 validation: Cross-entropy=2.4527382850646973, Accuracy=0.08080808073282242\n",
      "Epoch 90 train: Cross-entropy=2.341607822312249, Accuracy=0.16319444444444445\n",
      "Epoch 90 validation: Cross-entropy=2.4528212547302246, Accuracy=0.08585858345031738\n",
      "Epoch 91 train: Cross-entropy=2.341558151774936, Accuracy=0.16319444444444445\n",
      "Epoch 91 validation: Cross-entropy=2.4529027938842773, Accuracy=0.08585858345031738\n",
      "Epoch 92 train: Cross-entropy=2.3415102693769665, Accuracy=0.16319444444444445\n",
      "Epoch 92 validation: Cross-entropy=2.4529826641082764, Accuracy=0.08585858345031738\n",
      "Epoch 93 train: Cross-entropy=2.3414642016092935, Accuracy=0.16319444444444445\n",
      "Epoch 93 validation: Cross-entropy=2.4530608654022217, Accuracy=0.08585858345031738\n",
      "Epoch 94 train: Cross-entropy=2.341419961717394, Accuracy=0.16319444444444445\n",
      "Epoch 94 validation: Cross-entropy=2.453136920928955, Accuracy=0.08585858345031738\n",
      "Epoch 95 train: Cross-entropy=2.341377377510071, Accuracy=0.16319444444444445\n",
      "Epoch 95 validation: Cross-entropy=2.4532124996185303, Accuracy=0.08585858345031738\n",
      "Epoch 96 train: Cross-entropy=2.3413363695144653, Accuracy=0.16145833333333334\n",
      "Epoch 96 validation: Cross-entropy=2.4532859325408936, Accuracy=0.08585858345031738\n",
      "Epoch 97 train: Cross-entropy=2.3412970436943903, Accuracy=0.16145833333333334\n",
      "Epoch 97 validation: Cross-entropy=2.4533581733703613, Accuracy=0.08585858345031738\n",
      "Epoch 98 train: Cross-entropy=2.3412592278586493, Accuracy=0.16145833333333334\n",
      "Epoch 98 validation: Cross-entropy=2.4534292221069336, Accuracy=0.08585858345031738\n",
      "Epoch 99 train: Cross-entropy=2.3412228557798596, Accuracy=0.16145833333333334\n",
      "Epoch 99 validation: Cross-entropy=2.4534988403320312, Accuracy=0.08585858345031738\n",
      "Epoch 100 train: Cross-entropy=2.341187980439928, Accuracy=0.16145833333333334\n",
      "Epoch 100 validation: Cross-entropy=2.4535670280456543, Accuracy=0.08585858345031738\n",
      "Epoch 101 train: Cross-entropy=2.3411543899112277, Accuracy=0.16319444444444445\n",
      "Epoch 101 validation: Cross-entropy=2.453634023666382, Accuracy=0.08585858345031738\n",
      "Epoch 102 train: Cross-entropy=2.341122309366862, Accuracy=0.16319444444444445\n",
      "Epoch 102 validation: Cross-entropy=2.453699827194214, Accuracy=0.08585858345031738\n",
      "Epoch 103 train: Cross-entropy=2.3410913944244385, Accuracy=0.16319444444444445\n",
      "Epoch 103 validation: Cross-entropy=2.4537644386291504, Accuracy=0.08585858345031738\n",
      "Epoch 104 train: Cross-entropy=2.3410617907842, Accuracy=0.16319444444444445\n",
      "Epoch 104 validation: Cross-entropy=2.4538280963897705, Accuracy=0.08585858345031738\n",
      "Epoch 105 train: Cross-entropy=2.3410334057278104, Accuracy=0.16145833333333334\n",
      "Epoch 105 validation: Cross-entropy=2.453890323638916, Accuracy=0.08585858345031738\n",
      "Epoch 106 train: Cross-entropy=2.3410061995188394, Accuracy=0.16145833333333334\n",
      "Epoch 106 validation: Cross-entropy=2.453951835632324, Accuracy=0.08585858345031738\n",
      "Epoch 107 train: Cross-entropy=2.340980132420858, Accuracy=0.16145833333333334\n",
      "Epoch 107 validation: Cross-entropy=2.454011917114258, Accuracy=0.08585858345031738\n",
      "Epoch 108 train: Cross-entropy=2.340955124961005, Accuracy=0.16145833333333334\n",
      "Epoch 108 validation: Cross-entropy=2.454071283340454, Accuracy=0.08585858345031738\n",
      "Epoch 109 train: Cross-entropy=2.340931256612142, Accuracy=0.16145833333333334\n",
      "Epoch 109 validation: Cross-entropy=2.454129457473755, Accuracy=0.08585858345031738\n",
      "Epoch 110 train: Cross-entropy=2.340908315446642, Accuracy=0.1597222222222222\n",
      "Epoch 110 validation: Cross-entropy=2.4541866779327393, Accuracy=0.08585858345031738\n",
      "Epoch 111 train: Cross-entropy=2.3408864471647473, Accuracy=0.1597222222222222\n",
      "Epoch 111 validation: Cross-entropy=2.4542429447174072, Accuracy=0.08585858345031738\n",
      "Epoch 112 train: Cross-entropy=2.340865479575263, Accuracy=0.1597222222222222\n",
      "Epoch 112 validation: Cross-entropy=2.454298496246338, Accuracy=0.08585858345031738\n",
      "Epoch 113 train: Cross-entropy=2.3408455318874783, Accuracy=0.1597222222222222\n",
      "Epoch 113 validation: Cross-entropy=2.4543533325195312, Accuracy=0.08585858345031738\n",
      "Epoch 114 train: Cross-entropy=2.3408264451556735, Accuracy=0.1597222222222222\n",
      "Epoch 114 validation: Cross-entropy=2.45440673828125, Accuracy=0.08585858345031738\n",
      "Epoch 115 train: Cross-entropy=2.340808245870802, Accuracy=0.1597222222222222\n",
      "Epoch 115 validation: Cross-entropy=2.4544591903686523, Accuracy=0.08585858345031738\n",
      "Epoch 116 train: Cross-entropy=2.3407908810509577, Accuracy=0.1597222222222222\n",
      "Epoch 116 validation: Cross-entropy=2.4545111656188965, Accuracy=0.08585858345031738\n",
      "Epoch 117 train: Cross-entropy=2.3407742844687567, Accuracy=0.1597222222222222\n",
      "Epoch 117 validation: Cross-entropy=2.4545626640319824, Accuracy=0.08585858345031738\n",
      "Epoch 118 train: Cross-entropy=2.340758548842536, Accuracy=0.1597222222222222\n",
      "Epoch 118 validation: Cross-entropy=2.454612970352173, Accuracy=0.08585858345031738\n",
      "Epoch 119 train: Cross-entropy=2.340743515226576, Accuracy=0.1597222222222222\n",
      "Epoch 119 validation: Cross-entropy=2.454662322998047, Accuracy=0.08585858345031738\n",
      "Epoch 120 train: Cross-entropy=2.3407292630937366, Accuracy=0.1597222222222222\n",
      "Epoch 120 validation: Cross-entropy=2.4547109603881836, Accuracy=0.08585858345031738\n",
      "Epoch 121 train: Cross-entropy=2.340715620252821, Accuracy=0.1597222222222222\n",
      "Epoch 121 validation: Cross-entropy=2.454759359359741, Accuracy=0.08585858345031738\n",
      "Epoch 122 train: Cross-entropy=2.3407028118769326, Accuracy=0.1597222222222222\n",
      "Epoch 122 validation: Cross-entropy=2.4548065662384033, Accuracy=0.08585858345031738\n",
      "Epoch 123 train: Cross-entropy=2.3406905863020153, Accuracy=0.1597222222222222\n",
      "Epoch 123 validation: Cross-entropy=2.4548532962799072, Accuracy=0.08585858345031738\n",
      "Epoch 124 train: Cross-entropy=2.3406790759828358, Accuracy=0.1579861111111111\n",
      "Epoch 124 validation: Cross-entropy=2.454899549484253, Accuracy=0.08585858345031738\n",
      "Epoch 125 train: Cross-entropy=2.34066805574629, Accuracy=0.1579861111111111\n",
      "Epoch 125 validation: Cross-entropy=2.4549448490142822, Accuracy=0.08585858345031738\n",
      "Epoch 126 train: Cross-entropy=2.3406576845380993, Accuracy=0.1579861111111111\n",
      "Epoch 126 validation: Cross-entropy=2.454989433288574, Accuracy=0.08585858345031738\n",
      "Epoch 127 train: Cross-entropy=2.3406479358673096, Accuracy=0.1579861111111111\n",
      "Epoch 127 validation: Cross-entropy=2.455033779144287, Accuracy=0.08585858345031738\n",
      "Epoch 128 train: Cross-entropy=2.340638769997491, Accuracy=0.1579861111111111\n",
      "Epoch 128 validation: Cross-entropy=2.4550771713256836, Accuracy=0.08080808073282242\n",
      "Epoch 129 train: Cross-entropy=2.3406301074557834, Accuracy=0.1579861111111111\n",
      "Epoch 129 validation: Cross-entropy=2.4551198482513428, Accuracy=0.08080808073282242\n",
      "Epoch 130 train: Cross-entropy=2.340621921751234, Accuracy=0.1579861111111111\n",
      "Epoch 130 validation: Cross-entropy=2.455162286758423, Accuracy=0.08080808073282242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 train: Cross-entropy=2.340614358584086, Accuracy=0.1579861111111111\n",
      "Epoch 131 validation: Cross-entropy=2.4552040100097656, Accuracy=0.08080808073282242\n",
      "Epoch 132 train: Cross-entropy=2.3406071265538535, Accuracy=0.1579861111111111\n",
      "Epoch 132 validation: Cross-entropy=2.455244779586792, Accuracy=0.08080808073282242\n",
      "Epoch 133 train: Cross-entropy=2.340600464079115, Accuracy=0.1579861111111111\n",
      "Epoch 133 validation: Cross-entropy=2.4552853107452393, Accuracy=0.08080808073282242\n",
      "Epoch 134 train: Cross-entropy=2.340594278441535, Accuracy=0.1579861111111111\n",
      "Epoch 134 validation: Cross-entropy=2.4553256034851074, Accuracy=0.08080808073282242\n",
      "Epoch 135 train: Cross-entropy=2.340588410695394, Accuracy=0.1579861111111111\n",
      "Epoch 135 validation: Cross-entropy=2.45536470413208, Accuracy=0.08080808073282242\n",
      "Epoch 136 train: Cross-entropy=2.3405830992592707, Accuracy=0.1579861111111111\n",
      "Epoch 136 validation: Cross-entropy=2.4554035663604736, Accuracy=0.08080808073282242\n",
      "Epoch 137 train: Cross-entropy=2.340578145451016, Accuracy=0.1579861111111111\n",
      "Epoch 137 validation: Cross-entropy=2.455441951751709, Accuracy=0.08080808073282242\n",
      "Epoch 138 train: Cross-entropy=2.34057354927063, Accuracy=0.1579861111111111\n",
      "Epoch 138 validation: Cross-entropy=2.4554800987243652, Accuracy=0.08080808073282242\n",
      "Epoch 139 train: Cross-entropy=2.3405694166819253, Accuracy=0.1579861111111111\n",
      "Epoch 139 validation: Cross-entropy=2.455517530441284, Accuracy=0.08080808073282242\n",
      "Epoch 140 train: Cross-entropy=2.3405656019846597, Accuracy=0.1597222222222222\n",
      "Epoch 140 validation: Cross-entropy=2.455554485321045, Accuracy=0.08080808073282242\n",
      "Epoch 141 train: Cross-entropy=2.3405621581607394, Accuracy=0.16145833333333334\n",
      "Epoch 141 validation: Cross-entropy=2.4555907249450684, Accuracy=0.08080808073282242\n",
      "Epoch 142 train: Cross-entropy=2.3405590057373047, Accuracy=0.16145833333333334\n",
      "Epoch 142 validation: Cross-entropy=2.4556267261505127, Accuracy=0.08080808073282242\n",
      "Epoch 143 train: Cross-entropy=2.3405562374326916, Accuracy=0.16145833333333334\n",
      "Epoch 143 validation: Cross-entropy=2.455662488937378, Accuracy=0.08080808073282242\n",
      "Epoch 144 train: Cross-entropy=2.340553773774041, Accuracy=0.16145833333333334\n",
      "Epoch 144 validation: Cross-entropy=2.4556972980499268, Accuracy=0.08080808073282242\n",
      "Epoch 145 train: Cross-entropy=2.340551575024923, Accuracy=0.16145833333333334\n",
      "Epoch 145 validation: Cross-entropy=2.4557321071624756, Accuracy=0.08080808073282242\n",
      "Epoch 146 train: Cross-entropy=2.340549733903673, Accuracy=0.16145833333333334\n",
      "Epoch 146 validation: Cross-entropy=2.455766201019287, Accuracy=0.08585858345031738\n",
      "Epoch 147 train: Cross-entropy=2.340548131201002, Accuracy=0.16145833333333334\n",
      "Epoch 147 validation: Cross-entropy=2.4558000564575195, Accuracy=0.08585858345031738\n",
      "Epoch 148 train: Cross-entropy=2.340546872880724, Accuracy=0.16145833333333334\n",
      "Epoch 148 validation: Cross-entropy=2.4558331966400146, Accuracy=0.08585858345031738\n",
      "Epoch 149 train: Cross-entropy=2.340545826488071, Accuracy=0.16145833333333334\n",
      "Epoch 149 validation: Cross-entropy=2.455866575241089, Accuracy=0.08585858345031738\n",
      "Epoch 150 train: Cross-entropy=2.3405450185139975, Accuracy=0.16145833333333334\n",
      "Epoch 150 validation: Cross-entropy=2.4558987617492676, Accuracy=0.08585858345031738\n",
      "Epoch 151 train: Cross-entropy=2.340544488694933, Accuracy=0.16145833333333334\n",
      "Epoch 151 validation: Cross-entropy=2.455930709838867, Accuracy=0.08585858345031738\n",
      "Epoch 152 train: Cross-entropy=2.3405441840489707, Accuracy=0.16145833333333334\n",
      "Epoch 152 validation: Cross-entropy=2.455962896347046, Accuracy=0.08585858345031738\n",
      "Epoch 153 train: Cross-entropy=2.3405440515942044, Accuracy=0.16145833333333334\n",
      "Epoch 153 validation: Cross-entropy=2.4559943675994873, Accuracy=0.08585858345031738\n",
      "Epoch 154 train: Cross-entropy=2.3405442900127835, Accuracy=0.16319444444444445\n",
      "Epoch 154 validation: Cross-entropy=2.4560251235961914, Accuracy=0.08585858345031738\n",
      "Epoch 155 train: Cross-entropy=2.3405445549223156, Accuracy=0.16319444444444445\n",
      "Epoch 155 validation: Cross-entropy=2.4560556411743164, Accuracy=0.08585858345031738\n",
      "Epoch 156 train: Cross-entropy=2.3405451907051935, Accuracy=0.16319444444444445\n",
      "Epoch 156 validation: Cross-entropy=2.4560861587524414, Accuracy=0.08585858345031738\n",
      "Epoch 157 train: Cross-entropy=2.340545892715454, Accuracy=0.16319444444444445\n",
      "Epoch 157 validation: Cross-entropy=2.45611572265625, Accuracy=0.08585858345031738\n",
      "Epoch 158 train: Cross-entropy=2.3405468463897705, Accuracy=0.16319444444444445\n",
      "Epoch 158 validation: Cross-entropy=2.4561452865600586, Accuracy=0.08585858345031738\n",
      "Epoch 159 train: Cross-entropy=2.340547932518853, Accuracy=0.16319444444444445\n",
      "Epoch 159 validation: Cross-entropy=2.456174373626709, Accuracy=0.08585858345031738\n",
      "Epoch 160 train: Cross-entropy=2.3405492703119912, Accuracy=0.16319444444444445\n",
      "Epoch 160 validation: Cross-entropy=2.4562032222747803, Accuracy=0.08585858345031738\n",
      "Epoch 161 train: Cross-entropy=2.3405506478415594, Accuracy=0.16145833333333334\n",
      "Epoch 161 validation: Cross-entropy=2.4562315940856934, Accuracy=0.08585858345031738\n",
      "Epoch 162 train: Cross-entropy=2.34055233001709, Accuracy=0.16145833333333334\n",
      "Epoch 162 validation: Cross-entropy=2.4562602043151855, Accuracy=0.08585858345031738\n",
      "Epoch 163 train: Cross-entropy=2.3405541711383395, Accuracy=0.16145833333333334\n",
      "Epoch 163 validation: Cross-entropy=2.4562876224517822, Accuracy=0.08585858345031738\n",
      "Epoch 164 train: Cross-entropy=2.340556012259589, Accuracy=0.16145833333333334\n",
      "Epoch 164 validation: Cross-entropy=2.456315517425537, Accuracy=0.08585858345031738\n",
      "Epoch 165 train: Cross-entropy=2.340558131535848, Accuracy=0.1597222222222222\n",
      "Epoch 165 validation: Cross-entropy=2.4563424587249756, Accuracy=0.08585858345031738\n",
      "Epoch 166 train: Cross-entropy=2.340560303794013, Accuracy=0.1597222222222222\n",
      "Epoch 166 validation: Cross-entropy=2.456369161605835, Accuracy=0.08585858345031738\n",
      "Epoch 167 train: Cross-entropy=2.340562661488851, Accuracy=0.1597222222222222\n",
      "Epoch 167 validation: Cross-entropy=2.4563958644866943, Accuracy=0.08585858345031738\n",
      "Epoch 168 train: Cross-entropy=2.340565111902025, Accuracy=0.1597222222222222\n",
      "Epoch 168 validation: Cross-entropy=2.4564220905303955, Accuracy=0.08585858345031738\n",
      "Epoch 169 train: Cross-entropy=2.3405677212609186, Accuracy=0.1597222222222222\n",
      "Epoch 169 validation: Cross-entropy=2.4564480781555176, Accuracy=0.08585858345031738\n",
      "Epoch 170 train: Cross-entropy=2.3405703836017184, Accuracy=0.1597222222222222\n",
      "Epoch 170 validation: Cross-entropy=2.4564735889434814, Accuracy=0.08585858345031738\n",
      "Epoch 171 train: Cross-entropy=2.3405731783972845, Accuracy=0.1597222222222222\n",
      "Epoch 171 validation: Cross-entropy=2.4564990997314453, Accuracy=0.08585858345031738\n",
      "Epoch 172 train: Cross-entropy=2.340576105647617, Accuracy=0.1597222222222222\n",
      "Epoch 172 validation: Cross-entropy=2.456523895263672, Accuracy=0.08585858345031738\n",
      "Epoch 173 train: Cross-entropy=2.340579072634379, Accuracy=0.1579861111111111\n",
      "Epoch 173 validation: Cross-entropy=2.4565491676330566, Accuracy=0.08585858345031738\n",
      "Epoch 174 train: Cross-entropy=2.3405821985668607, Accuracy=0.1579861111111111\n",
      "Epoch 174 validation: Cross-entropy=2.456573247909546, Accuracy=0.08585858345031738\n",
      "Epoch 175 train: Cross-entropy=2.340585390726725, Accuracy=0.1579861111111111\n",
      "Epoch 175 validation: Cross-entropy=2.4565975666046143, Accuracy=0.08585858345031738\n",
      "Epoch 176 train: Cross-entropy=2.3405887020958795, Accuracy=0.1579861111111111\n",
      "Epoch 176 validation: Cross-entropy=2.4566216468811035, Accuracy=0.08585858345031738\n",
      "Epoch 177 train: Cross-entropy=2.3405920134650335, Accuracy=0.1579861111111111\n",
      "Epoch 177 validation: Cross-entropy=2.4566452503204346, Accuracy=0.08585858345031738\n",
      "Epoch 178 train: Cross-entropy=2.3405954705344305, Accuracy=0.1579861111111111\n",
      "Epoch 178 validation: Cross-entropy=2.4566686153411865, Accuracy=0.08585858345031738\n",
      "Epoch 179 train: Cross-entropy=2.340599046813117, Accuracy=0.1579861111111111\n",
      "Epoch 179 validation: Cross-entropy=2.4566915035247803, Accuracy=0.08585858345031738\n",
      "Epoch 180 train: Cross-entropy=2.340602649582757, Accuracy=0.15625\n",
      "Epoch 180 validation: Cross-entropy=2.456714391708374, Accuracy=0.08585858345031738\n",
      "Epoch 181 train: Cross-entropy=2.34060635831621, Accuracy=0.15625\n",
      "Epoch 181 validation: Cross-entropy=2.4567372798919678, Accuracy=0.08585858345031738\n",
      "Epoch 182 train: Cross-entropy=2.3406100140677557, Accuracy=0.15625\n",
      "Epoch 182 validation: Cross-entropy=2.456759452819824, Accuracy=0.08585858345031738\n",
      "Epoch 183 train: Cross-entropy=2.3406138287650213, Accuracy=0.15625\n",
      "Epoch 183 validation: Cross-entropy=2.4567816257476807, Accuracy=0.08585858345031738\n",
      "Epoch 184 train: Cross-entropy=2.340617722935147, Accuracy=0.15625\n",
      "Epoch 184 validation: Cross-entropy=2.456803321838379, Accuracy=0.08585858345031738\n",
      "Epoch 185 train: Cross-entropy=2.3406216303507485, Accuracy=0.15625\n",
      "Epoch 185 validation: Cross-entropy=2.456824779510498, Accuracy=0.08585858345031738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 train: Cross-entropy=2.3406256569756403, Accuracy=0.15625\n",
      "Epoch 186 validation: Cross-entropy=2.456846237182617, Accuracy=0.08585858345031738\n",
      "Epoch 187 train: Cross-entropy=2.340629670355055, Accuracy=0.15625\n",
      "Epoch 187 validation: Cross-entropy=2.456867218017578, Accuracy=0.08585858345031738\n",
      "Epoch 188 train: Cross-entropy=2.3406337102254233, Accuracy=0.15625\n",
      "Epoch 188 validation: Cross-entropy=2.45688796043396, Accuracy=0.08585858345031738\n",
      "Epoch 189 train: Cross-entropy=2.340637829568651, Accuracy=0.15625\n",
      "Epoch 189 validation: Cross-entropy=2.456908941268921, Accuracy=0.08585858345031738\n",
      "Epoch 190 train: Cross-entropy=2.340642054875692, Accuracy=0.1579861111111111\n",
      "Epoch 190 validation: Cross-entropy=2.4569292068481445, Accuracy=0.08585858345031738\n",
      "Epoch 191 train: Cross-entropy=2.3406462139553494, Accuracy=0.1579861111111111\n",
      "Epoch 191 validation: Cross-entropy=2.456949472427368, Accuracy=0.08585858345031738\n",
      "Epoch 192 train: Cross-entropy=2.3406505584716797, Accuracy=0.1579861111111111\n",
      "Epoch 192 validation: Cross-entropy=2.4569690227508545, Accuracy=0.08585858345031738\n",
      "Epoch 193 train: Cross-entropy=2.3406547705332437, Accuracy=0.1579861111111111\n",
      "Epoch 193 validation: Cross-entropy=2.456989049911499, Accuracy=0.08585858345031738\n",
      "Epoch 194 train: Cross-entropy=2.340659075313144, Accuracy=0.1579861111111111\n",
      "Epoch 194 validation: Cross-entropy=2.4570083618164062, Accuracy=0.08585858345031738\n",
      "Epoch 195 train: Cross-entropy=2.340663446320428, Accuracy=0.1579861111111111\n",
      "Epoch 195 validation: Cross-entropy=2.4570274353027344, Accuracy=0.08585858345031738\n",
      "Epoch 196 train: Cross-entropy=2.3406678438186646, Accuracy=0.1579861111111111\n",
      "Epoch 196 validation: Cross-entropy=2.4570467472076416, Accuracy=0.08585858345031738\n",
      "Epoch 197 train: Cross-entropy=2.3406722942988076, Accuracy=0.1579861111111111\n",
      "Epoch 197 validation: Cross-entropy=2.4570655822753906, Accuracy=0.08585858345031738\n",
      "Epoch 198 train: Cross-entropy=2.3406767182879977, Accuracy=0.1579861111111111\n",
      "Epoch 198 validation: Cross-entropy=2.4570841789245605, Accuracy=0.08585858345031738\n",
      "Epoch 199 train: Cross-entropy=2.3406811820136175, Accuracy=0.1579861111111111\n",
      "Epoch 199 validation: Cross-entropy=2.4571025371551514, Accuracy=0.08585858345031738\n",
      "Epoch 0 train: Cross-entropy=2.4366370836893716, Accuracy=0.08333333333333333\n",
      "Epoch 0 validation: Cross-entropy=2.4094371795654297, Accuracy=0.08585858345031738\n",
      "Epoch 1 train: Cross-entropy=2.439344671037462, Accuracy=0.08506944444444445\n",
      "Epoch 1 validation: Cross-entropy=2.4132087230682373, Accuracy=0.07070706784725189\n",
      "Epoch 2 train: Cross-entropy=2.4196059041553073, Accuracy=0.0954861111111111\n",
      "Epoch 2 validation: Cross-entropy=2.412971019744873, Accuracy=0.08080808073282242\n",
      "Epoch 3 train: Cross-entropy=2.4105216132269964, Accuracy=0.0954861111111111\n",
      "Epoch 3 validation: Cross-entropy=2.4153025150299072, Accuracy=0.09090909361839294\n",
      "Epoch 4 train: Cross-entropy=2.406385170088874, Accuracy=0.09722222222222222\n",
      "Epoch 4 validation: Cross-entropy=2.4183225631713867, Accuracy=0.09090909361839294\n",
      "Epoch 5 train: Cross-entropy=2.401154465145535, Accuracy=0.09895833333333333\n",
      "Epoch 5 validation: Cross-entropy=2.4210431575775146, Accuracy=0.08585858345031738\n",
      "Epoch 6 train: Cross-entropy=2.3967745436562433, Accuracy=0.10590277777777778\n",
      "Epoch 6 validation: Cross-entropy=2.4235968589782715, Accuracy=0.08585858345031738\n",
      "Epoch 7 train: Cross-entropy=2.3932716449101767, Accuracy=0.1111111111111111\n",
      "Epoch 7 validation: Cross-entropy=2.426060676574707, Accuracy=0.09090909361839294\n",
      "Epoch 8 train: Cross-entropy=2.3901635143491955, Accuracy=0.1111111111111111\n",
      "Epoch 8 validation: Cross-entropy=2.4283807277679443, Accuracy=0.09090909361839294\n",
      "Epoch 9 train: Cross-entropy=2.3874272637897067, Accuracy=0.11631944444444445\n",
      "Epoch 9 validation: Cross-entropy=2.4305458068847656, Accuracy=0.08585858345031738\n",
      "Epoch 10 train: Cross-entropy=2.385024309158325, Accuracy=0.11979166666666667\n",
      "Epoch 10 validation: Cross-entropy=2.432570457458496, Accuracy=0.09090909361839294\n",
      "Epoch 11 train: Cross-entropy=2.3828865687052407, Accuracy=0.1232638888888889\n",
      "Epoch 11 validation: Cross-entropy=2.434459924697876, Accuracy=0.09090909361839294\n",
      "Epoch 12 train: Cross-entropy=2.380972292688158, Accuracy=0.11979166666666667\n",
      "Epoch 12 validation: Cross-entropy=2.436220169067383, Accuracy=0.09090909361839294\n",
      "Epoch 13 train: Cross-entropy=2.379250685373942, Accuracy=0.12152777777777778\n",
      "Epoch 13 validation: Cross-entropy=2.437859058380127, Accuracy=0.09090909361839294\n",
      "Epoch 14 train: Cross-entropy=2.3776944080988565, Accuracy=0.1232638888888889\n",
      "Epoch 14 validation: Cross-entropy=2.439385175704956, Accuracy=0.08585858345031738\n",
      "Epoch 15 train: Cross-entropy=2.3762816852993436, Accuracy=0.1267361111111111\n",
      "Epoch 15 validation: Cross-entropy=2.4408061504364014, Accuracy=0.08585858345031738\n",
      "Epoch 16 train: Cross-entropy=2.374994476636251, Accuracy=0.13194444444444445\n",
      "Epoch 16 validation: Cross-entropy=2.4421286582946777, Accuracy=0.08585858345031738\n",
      "Epoch 17 train: Cross-entropy=2.3738178147210016, Accuracy=0.13541666666666666\n",
      "Epoch 17 validation: Cross-entropy=2.4433603286743164, Accuracy=0.08585858345031738\n",
      "Epoch 18 train: Cross-entropy=2.3727389838960438, Accuracy=0.1371527777777778\n",
      "Epoch 18 validation: Cross-entropy=2.444507122039795, Accuracy=0.08585858345031738\n",
      "Epoch 19 train: Cross-entropy=2.3717470831341214, Accuracy=0.1371527777777778\n",
      "Epoch 19 validation: Cross-entropy=2.4455747604370117, Accuracy=0.08585858345031738\n",
      "Epoch 20 train: Cross-entropy=2.3708330260382757, Accuracy=0.13541666666666666\n",
      "Epoch 20 validation: Cross-entropy=2.4465692043304443, Accuracy=0.09090909361839294\n",
      "Epoch 21 train: Cross-entropy=2.369988785849677, Accuracy=0.13541666666666666\n",
      "Epoch 21 validation: Cross-entropy=2.447495460510254, Accuracy=0.09595959633588791\n",
      "Epoch 22 train: Cross-entropy=2.369207580884298, Accuracy=0.1371527777777778\n",
      "Epoch 22 validation: Cross-entropy=2.4483580589294434, Accuracy=0.09090909361839294\n",
      "Epoch 23 train: Cross-entropy=2.36848341094123, Accuracy=0.1388888888888889\n",
      "Epoch 23 validation: Cross-entropy=2.4491617679595947, Accuracy=0.09090909361839294\n",
      "Epoch 24 train: Cross-entropy=2.3678109778298273, Accuracy=0.140625\n",
      "Epoch 24 validation: Cross-entropy=2.4499099254608154, Accuracy=0.09090909361839294\n",
      "Epoch 25 train: Cross-entropy=2.36718573835161, Accuracy=0.140625\n",
      "Epoch 25 validation: Cross-entropy=2.450606107711792, Accuracy=0.08585858345031738\n",
      "Epoch 26 train: Cross-entropy=2.366603559917874, Accuracy=0.140625\n",
      "Epoch 26 validation: Cross-entropy=2.4512546062469482, Accuracy=0.08080808073282242\n",
      "Epoch 27 train: Cross-entropy=2.3660609457227917, Accuracy=0.1423611111111111\n",
      "Epoch 27 validation: Cross-entropy=2.4518582820892334, Accuracy=0.08080808073282242\n",
      "Epoch 28 train: Cross-entropy=2.3655545579062567, Accuracy=0.1423611111111111\n",
      "Epoch 28 validation: Cross-entropy=2.4524197578430176, Accuracy=0.08080808073282242\n",
      "Epoch 29 train: Cross-entropy=2.365081614918179, Accuracy=0.1440972222222222\n",
      "Epoch 29 validation: Cross-entropy=2.452942132949829, Accuracy=0.08080808073282242\n",
      "Epoch 30 train: Cross-entropy=2.3646395338906183, Accuracy=0.14930555555555555\n",
      "Epoch 30 validation: Cross-entropy=2.453427314758301, Accuracy=0.08080808073282242\n",
      "Epoch 31 train: Cross-entropy=2.36422598361969, Accuracy=0.15104166666666666\n",
      "Epoch 31 validation: Cross-entropy=2.453878402709961, Accuracy=0.08080808073282242\n",
      "Epoch 32 train: Cross-entropy=2.3638388448291354, Accuracy=0.14930555555555555\n",
      "Epoch 32 validation: Cross-entropy=2.4542973041534424, Accuracy=0.08080808073282242\n",
      "Epoch 33 train: Cross-entropy=2.363476210170322, Accuracy=0.1527777777777778\n",
      "Epoch 33 validation: Cross-entropy=2.4546854496002197, Accuracy=0.08080808073282242\n",
      "Epoch 34 train: Cross-entropy=2.363136569658915, Accuracy=0.15104166666666666\n",
      "Epoch 34 validation: Cross-entropy=2.455045700073242, Accuracy=0.07575757801532745\n",
      "Epoch 35 train: Cross-entropy=2.362818307346768, Accuracy=0.14930555555555555\n",
      "Epoch 35 validation: Cross-entropy=2.4553794860839844, Accuracy=0.07575757801532745\n",
      "Epoch 36 train: Cross-entropy=2.362519714567396, Accuracy=0.14930555555555555\n",
      "Epoch 36 validation: Cross-entropy=2.4556875228881836, Accuracy=0.07575757801532745\n",
      "Epoch 37 train: Cross-entropy=2.3622398376464844, Accuracy=0.14930555555555555\n",
      "Epoch 37 validation: Cross-entropy=2.455972671508789, Accuracy=0.07575757801532745\n",
      "Epoch 38 train: Cross-entropy=2.3619773785273233, Accuracy=0.14756944444444445\n",
      "Epoch 38 validation: Cross-entropy=2.456235408782959, Accuracy=0.07575757801532745\n",
      "Epoch 39 train: Cross-entropy=2.361731184853448, Accuracy=0.14756944444444445\n",
      "Epoch 39 validation: Cross-entropy=2.456477642059326, Accuracy=0.07575757801532745\n",
      "Epoch 40 train: Cross-entropy=2.3615003956688776, Accuracy=0.14583333333333334\n",
      "Epoch 40 validation: Cross-entropy=2.456700086593628, Accuracy=0.07575757801532745\n",
      "Epoch 41 train: Cross-entropy=2.36128392484453, Accuracy=0.14756944444444445\n",
      "Epoch 41 validation: Cross-entropy=2.456904411315918, Accuracy=0.07575757801532745\n",
      "Epoch 42 train: Cross-entropy=2.3610809908972845, Accuracy=0.14756944444444445\n",
      "Epoch 42 validation: Cross-entropy=2.4570913314819336, Accuracy=0.07575757801532745\n",
      "Epoch 43 train: Cross-entropy=2.360890958044264, Accuracy=0.14583333333333334\n",
      "Epoch 43 validation: Cross-entropy=2.4572620391845703, Accuracy=0.07575757801532745\n",
      "Epoch 44 train: Cross-entropy=2.3607128063837686, Accuracy=0.14756944444444445\n",
      "Epoch 44 validation: Cross-entropy=2.4574172496795654, Accuracy=0.07575757801532745\n",
      "Epoch 45 train: Cross-entropy=2.3605461385515003, Accuracy=0.14756944444444445\n",
      "Epoch 45 validation: Cross-entropy=2.4575579166412354, Accuracy=0.07575757801532745\n",
      "Epoch 46 train: Cross-entropy=2.360390159818861, Accuracy=0.14756944444444445\n",
      "Epoch 46 validation: Cross-entropy=2.4576854705810547, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 train: Cross-entropy=2.3602442741394043, Accuracy=0.14756944444444445\n",
      "Epoch 47 validation: Cross-entropy=2.4577999114990234, Accuracy=0.07575757801532745\n",
      "Epoch 48 train: Cross-entropy=2.3601080179214478, Accuracy=0.14756944444444445\n",
      "Epoch 48 validation: Cross-entropy=2.457902431488037, Accuracy=0.07575757801532745\n",
      "Epoch 49 train: Cross-entropy=2.3599808613459268, Accuracy=0.14930555555555555\n",
      "Epoch 49 validation: Cross-entropy=2.457993268966675, Accuracy=0.07575757801532745\n",
      "Epoch 50 train: Cross-entropy=2.359862314330207, Accuracy=0.14930555555555555\n",
      "Epoch 50 validation: Cross-entropy=2.458073616027832, Accuracy=0.07575757801532745\n",
      "Epoch 51 train: Cross-entropy=2.359751966264513, Accuracy=0.14756944444444445\n",
      "Epoch 51 validation: Cross-entropy=2.458143711090088, Accuracy=0.07575757801532745\n",
      "Epoch 52 train: Cross-entropy=2.359649406539069, Accuracy=0.14756944444444445\n",
      "Epoch 52 validation: Cross-entropy=2.458204507827759, Accuracy=0.07575757801532745\n",
      "Epoch 53 train: Cross-entropy=2.359554131825765, Accuracy=0.14756944444444445\n",
      "Epoch 53 validation: Cross-entropy=2.458256244659424, Accuracy=0.07575757801532745\n",
      "Epoch 54 train: Cross-entropy=2.3594659566879272, Accuracy=0.14756944444444445\n",
      "Epoch 54 validation: Cross-entropy=2.458299160003662, Accuracy=0.07575757801532745\n",
      "Epoch 55 train: Cross-entropy=2.359384377797445, Accuracy=0.14756944444444445\n",
      "Epoch 55 validation: Cross-entropy=2.4583346843719482, Accuracy=0.07575757801532745\n",
      "Epoch 56 train: Cross-entropy=2.3593090375264487, Accuracy=0.14756944444444445\n",
      "Epoch 56 validation: Cross-entropy=2.458362340927124, Accuracy=0.07575757801532745\n",
      "Epoch 57 train: Cross-entropy=2.3592398166656494, Accuracy=0.14756944444444445\n",
      "Epoch 57 validation: Cross-entropy=2.458383321762085, Accuracy=0.07575757801532745\n",
      "Epoch 58 train: Cross-entropy=2.359176370832655, Accuracy=0.14756944444444445\n",
      "Epoch 58 validation: Cross-entropy=2.458397388458252, Accuracy=0.07575757801532745\n",
      "Epoch 59 train: Cross-entropy=2.359118342399597, Accuracy=0.14756944444444445\n",
      "Epoch 59 validation: Cross-entropy=2.458405017852783, Accuracy=0.07575757801532745\n",
      "Epoch 60 train: Cross-entropy=2.3590655061933727, Accuracy=0.14756944444444445\n",
      "Epoch 60 validation: Cross-entropy=2.458406686782837, Accuracy=0.07575757801532745\n",
      "Epoch 61 train: Cross-entropy=2.35901767677731, Accuracy=0.14756944444444445\n",
      "Epoch 61 validation: Cross-entropy=2.4584033489227295, Accuracy=0.07575757801532745\n",
      "Epoch 62 train: Cross-entropy=2.358974509769016, Accuracy=0.14756944444444445\n",
      "Epoch 62 validation: Cross-entropy=2.4583942890167236, Accuracy=0.07575757801532745\n",
      "Epoch 63 train: Cross-entropy=2.358935965432061, Accuracy=0.14930555555555555\n",
      "Epoch 63 validation: Cross-entropy=2.458380699157715, Accuracy=0.07575757801532745\n",
      "Epoch 64 train: Cross-entropy=2.3589016331566706, Accuracy=0.14756944444444445\n",
      "Epoch 64 validation: Cross-entropy=2.458362340927124, Accuracy=0.07575757801532745\n",
      "Epoch 65 train: Cross-entropy=2.3588713804880777, Accuracy=0.14756944444444445\n",
      "Epoch 65 validation: Cross-entropy=2.4583396911621094, Accuracy=0.07575757801532745\n",
      "Epoch 66 train: Cross-entropy=2.358845074971517, Accuracy=0.14756944444444445\n",
      "Epoch 66 validation: Cross-entropy=2.458313226699829, Accuracy=0.07575757801532745\n",
      "Epoch 67 train: Cross-entropy=2.3588225576612682, Accuracy=0.14756944444444445\n",
      "Epoch 67 validation: Cross-entropy=2.458282470703125, Accuracy=0.07575757801532745\n",
      "Epoch 68 train: Cross-entropy=2.3588036166297064, Accuracy=0.14756944444444445\n",
      "Epoch 68 validation: Cross-entropy=2.4582488536834717, Accuracy=0.07575757801532745\n",
      "Epoch 69 train: Cross-entropy=2.3587880531946817, Accuracy=0.14583333333333334\n",
      "Epoch 69 validation: Cross-entropy=2.4582114219665527, Accuracy=0.07575757801532745\n",
      "Epoch 70 train: Cross-entropy=2.3587757613923817, Accuracy=0.14583333333333334\n",
      "Epoch 70 validation: Cross-entropy=2.4581711292266846, Accuracy=0.07575757801532745\n",
      "Epoch 71 train: Cross-entropy=2.3587666352589927, Accuracy=0.14583333333333334\n",
      "Epoch 71 validation: Cross-entropy=2.458127737045288, Accuracy=0.07575757801532745\n",
      "Epoch 72 train: Cross-entropy=2.358760462866889, Accuracy=0.14583333333333334\n",
      "Epoch 72 validation: Cross-entropy=2.4580817222595215, Accuracy=0.07575757801532745\n",
      "Epoch 73 train: Cross-entropy=2.3587570190429688, Accuracy=0.14583333333333334\n",
      "Epoch 73 validation: Cross-entropy=2.458033323287964, Accuracy=0.07575757801532745\n",
      "Epoch 74 train: Cross-entropy=2.3587563832600913, Accuracy=0.14583333333333334\n",
      "Epoch 74 validation: Cross-entropy=2.4579827785491943, Accuracy=0.07575757801532745\n",
      "Epoch 75 train: Cross-entropy=2.358758317099677, Accuracy=0.14583333333333334\n",
      "Epoch 75 validation: Cross-entropy=2.457929849624634, Accuracy=0.07575757801532745\n",
      "Epoch 76 train: Cross-entropy=2.358762754334344, Accuracy=0.1440972222222222\n",
      "Epoch 76 validation: Cross-entropy=2.4578745365142822, Accuracy=0.07575757801532745\n",
      "Epoch 77 train: Cross-entropy=2.3587695360183716, Accuracy=0.1440972222222222\n",
      "Epoch 77 validation: Cross-entropy=2.4578182697296143, Accuracy=0.07575757801532745\n",
      "Epoch 78 train: Cross-entropy=2.358778648906284, Accuracy=0.1440972222222222\n",
      "Epoch 78 validation: Cross-entropy=2.4577596187591553, Accuracy=0.07575757801532745\n",
      "Epoch 79 train: Cross-entropy=2.358789814843072, Accuracy=0.1440972222222222\n",
      "Epoch 79 validation: Cross-entropy=2.45770001411438, Accuracy=0.08080808073282242\n",
      "Epoch 80 train: Cross-entropy=2.3588030338287354, Accuracy=0.1440972222222222\n",
      "Epoch 80 validation: Cross-entropy=2.4576382637023926, Accuracy=0.08080808073282242\n",
      "Epoch 81 train: Cross-entropy=2.3588183191087513, Accuracy=0.1440972222222222\n",
      "Epoch 81 validation: Cross-entropy=2.457575798034668, Accuracy=0.08080808073282242\n",
      "Epoch 82 train: Cross-entropy=2.3588354455100164, Accuracy=0.1440972222222222\n",
      "Epoch 82 validation: Cross-entropy=2.4575116634368896, Accuracy=0.08080808073282242\n",
      "Epoch 83 train: Cross-entropy=2.358854307068719, Accuracy=0.1440972222222222\n",
      "Epoch 83 validation: Cross-entropy=2.457447052001953, Accuracy=0.08080808073282242\n",
      "Epoch 84 train: Cross-entropy=2.358874890539381, Accuracy=0.1440972222222222\n",
      "Epoch 84 validation: Cross-entropy=2.457381010055542, Accuracy=0.08080808073282242\n",
      "Epoch 85 train: Cross-entropy=2.3588971164491443, Accuracy=0.1440972222222222\n",
      "Epoch 85 validation: Cross-entropy=2.4573144912719727, Accuracy=0.08080808073282242\n",
      "Epoch 86 train: Cross-entropy=2.3589208788341947, Accuracy=0.1423611111111111\n",
      "Epoch 86 validation: Cross-entropy=2.4572465419769287, Accuracy=0.08080808073282242\n",
      "Epoch 87 train: Cross-entropy=2.3589461512035794, Accuracy=0.1423611111111111\n",
      "Epoch 87 validation: Cross-entropy=2.457178831100464, Accuracy=0.08080808073282242\n",
      "Epoch 88 train: Cross-entropy=2.3589728938208685, Accuracy=0.1423611111111111\n",
      "Epoch 88 validation: Cross-entropy=2.4571099281311035, Accuracy=0.08080808073282242\n",
      "Epoch 89 train: Cross-entropy=2.359000894758436, Accuracy=0.1423611111111111\n",
      "Epoch 89 validation: Cross-entropy=2.457040786743164, Accuracy=0.07575757801532745\n",
      "Epoch 90 train: Cross-entropy=2.3590301407708063, Accuracy=0.1423611111111111\n",
      "Epoch 90 validation: Cross-entropy=2.4569711685180664, Accuracy=0.07575757801532745\n",
      "Epoch 91 train: Cross-entropy=2.3590606848398843, Accuracy=0.1423611111111111\n",
      "Epoch 91 validation: Cross-entropy=2.4569010734558105, Accuracy=0.07575757801532745\n",
      "Epoch 92 train: Cross-entropy=2.3590923150380454, Accuracy=0.1423611111111111\n",
      "Epoch 92 validation: Cross-entropy=2.4568309783935547, Accuracy=0.07575757801532745\n",
      "Epoch 93 train: Cross-entropy=2.3591250313652887, Accuracy=0.1423611111111111\n",
      "Epoch 93 validation: Cross-entropy=2.4567606449127197, Accuracy=0.07575757801532745\n",
      "Epoch 94 train: Cross-entropy=2.3591588603125677, Accuracy=0.140625\n",
      "Epoch 94 validation: Cross-entropy=2.4566900730133057, Accuracy=0.07575757801532745\n",
      "Epoch 95 train: Cross-entropy=2.35919361644321, Accuracy=0.140625\n",
      "Epoch 95 validation: Cross-entropy=2.4566195011138916, Accuracy=0.07575757801532745\n",
      "Epoch 96 train: Cross-entropy=2.3592293527391224, Accuracy=0.140625\n",
      "Epoch 96 validation: Cross-entropy=2.4565486907958984, Accuracy=0.07575757801532745\n",
      "Epoch 97 train: Cross-entropy=2.3592659367455378, Accuracy=0.140625\n",
      "Epoch 97 validation: Cross-entropy=2.4564778804779053, Accuracy=0.07575757801532745\n",
      "Epoch 98 train: Cross-entropy=2.3593033817079334, Accuracy=0.140625\n",
      "Epoch 98 validation: Cross-entropy=2.4564075469970703, Accuracy=0.07575757801532745\n",
      "Epoch 99 train: Cross-entropy=2.3593415684170194, Accuracy=0.1388888888888889\n",
      "Epoch 99 validation: Cross-entropy=2.4563369750976562, Accuracy=0.07575757801532745\n",
      "Epoch 100 train: Cross-entropy=2.3593805763456555, Accuracy=0.1371527777777778\n",
      "Epoch 100 validation: Cross-entropy=2.4562668800354004, Accuracy=0.07575757801532745\n",
      "Epoch 101 train: Cross-entropy=2.359420233302646, Accuracy=0.1371527777777778\n",
      "Epoch 101 validation: Cross-entropy=2.4561965465545654, Accuracy=0.07575757801532745\n",
      "Epoch 102 train: Cross-entropy=2.3594605260425143, Accuracy=0.1371527777777778\n",
      "Epoch 102 validation: Cross-entropy=2.456127166748047, Accuracy=0.07575757801532745\n",
      "Epoch 103 train: Cross-entropy=2.3595014810562134, Accuracy=0.1371527777777778\n",
      "Epoch 103 validation: Cross-entropy=2.4560577869415283, Accuracy=0.07575757801532745\n",
      "Epoch 104 train: Cross-entropy=2.3595430188708835, Accuracy=0.1371527777777778\n",
      "Epoch 104 validation: Cross-entropy=2.4559884071350098, Accuracy=0.07575757801532745\n",
      "Epoch 105 train: Cross-entropy=2.359585086504618, Accuracy=0.1371527777777778\n",
      "Epoch 105 validation: Cross-entropy=2.4559197425842285, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 train: Cross-entropy=2.359627683957418, Accuracy=0.1371527777777778\n",
      "Epoch 106 validation: Cross-entropy=2.4558515548706055, Accuracy=0.07575757801532745\n",
      "Epoch 107 train: Cross-entropy=2.359670705265469, Accuracy=0.1371527777777778\n",
      "Epoch 107 validation: Cross-entropy=2.4557836055755615, Accuracy=0.07575757801532745\n",
      "Epoch 108 train: Cross-entropy=2.3597142034106784, Accuracy=0.1371527777777778\n",
      "Epoch 108 validation: Cross-entropy=2.455716133117676, Accuracy=0.07575757801532745\n",
      "Epoch 109 train: Cross-entropy=2.3597580194473267, Accuracy=0.1371527777777778\n",
      "Epoch 109 validation: Cross-entropy=2.4556493759155273, Accuracy=0.07575757801532745\n",
      "Epoch 110 train: Cross-entropy=2.359802391793993, Accuracy=0.1371527777777778\n",
      "Epoch 110 validation: Cross-entropy=2.455583095550537, Accuracy=0.07575757801532745\n",
      "Epoch 111 train: Cross-entropy=2.3598470422956677, Accuracy=0.1371527777777778\n",
      "Epoch 111 validation: Cross-entropy=2.455517053604126, Accuracy=0.07575757801532745\n",
      "Epoch 112 train: Cross-entropy=2.3598919444613986, Accuracy=0.1371527777777778\n",
      "Epoch 112 validation: Cross-entropy=2.455451726913452, Accuracy=0.07575757801532745\n",
      "Epoch 113 train: Cross-entropy=2.359937217500475, Accuracy=0.1371527777777778\n",
      "Epoch 113 validation: Cross-entropy=2.4553871154785156, Accuracy=0.07575757801532745\n",
      "Epoch 114 train: Cross-entropy=2.35998264948527, Accuracy=0.1371527777777778\n",
      "Epoch 114 validation: Cross-entropy=2.4553229808807373, Accuracy=0.07575757801532745\n",
      "Epoch 115 train: Cross-entropy=2.3600284390979342, Accuracy=0.1371527777777778\n",
      "Epoch 115 validation: Cross-entropy=2.455259323120117, Accuracy=0.07575757801532745\n",
      "Epoch 116 train: Cross-entropy=2.3600743611653647, Accuracy=0.1371527777777778\n",
      "Epoch 116 validation: Cross-entropy=2.4551966190338135, Accuracy=0.07575757801532745\n",
      "Epoch 117 train: Cross-entropy=2.3601204686694675, Accuracy=0.1371527777777778\n",
      "Epoch 117 validation: Cross-entropy=2.455134153366089, Accuracy=0.07575757801532745\n",
      "Epoch 118 train: Cross-entropy=2.36016673511929, Accuracy=0.1371527777777778\n",
      "Epoch 118 validation: Cross-entropy=2.4550726413726807, Accuracy=0.07575757801532745\n",
      "Epoch 119 train: Cross-entropy=2.3602132532331677, Accuracy=0.1371527777777778\n",
      "Epoch 119 validation: Cross-entropy=2.4550116062164307, Accuracy=0.07575757801532745\n",
      "Epoch 120 train: Cross-entropy=2.3602598110834756, Accuracy=0.1371527777777778\n",
      "Epoch 120 validation: Cross-entropy=2.454951763153076, Accuracy=0.07575757801532745\n",
      "Epoch 121 train: Cross-entropy=2.3603064351611667, Accuracy=0.1371527777777778\n",
      "Epoch 121 validation: Cross-entropy=2.4548919200897217, Accuracy=0.07575757801532745\n",
      "Epoch 122 train: Cross-entropy=2.3603532049391003, Accuracy=0.1371527777777778\n",
      "Epoch 122 validation: Cross-entropy=2.4548330307006836, Accuracy=0.07575757801532745\n",
      "Epoch 123 train: Cross-entropy=2.3604000409444175, Accuracy=0.1371527777777778\n",
      "Epoch 123 validation: Cross-entropy=2.454775094985962, Accuracy=0.07575757801532745\n",
      "Epoch 124 train: Cross-entropy=2.360446876949734, Accuracy=0.1371527777777778\n",
      "Epoch 124 validation: Cross-entropy=2.4547176361083984, Accuracy=0.07575757801532745\n",
      "Epoch 125 train: Cross-entropy=2.3604937394460044, Accuracy=0.1371527777777778\n",
      "Epoch 125 validation: Cross-entropy=2.4546608924865723, Accuracy=0.07575757801532745\n",
      "Epoch 126 train: Cross-entropy=2.3605405489603677, Accuracy=0.1371527777777778\n",
      "Epoch 126 validation: Cross-entropy=2.4546048641204834, Accuracy=0.07575757801532745\n",
      "Epoch 127 train: Cross-entropy=2.360587477684021, Accuracy=0.1371527777777778\n",
      "Epoch 127 validation: Cross-entropy=2.454549789428711, Accuracy=0.07575757801532745\n",
      "Epoch 128 train: Cross-entropy=2.360634340180291, Accuracy=0.1371527777777778\n",
      "Epoch 128 validation: Cross-entropy=2.4544951915740967, Accuracy=0.07575757801532745\n",
      "Epoch 129 train: Cross-entropy=2.360681096712748, Accuracy=0.1388888888888889\n",
      "Epoch 129 validation: Cross-entropy=2.454441547393799, Accuracy=0.07575757801532745\n",
      "Epoch 130 train: Cross-entropy=2.3607278797361584, Accuracy=0.1388888888888889\n",
      "Epoch 130 validation: Cross-entropy=2.45438814163208, Accuracy=0.07575757801532745\n",
      "Epoch 131 train: Cross-entropy=2.360774596532186, Accuracy=0.1371527777777778\n",
      "Epoch 131 validation: Cross-entropy=2.454336166381836, Accuracy=0.07575757801532745\n",
      "Epoch 132 train: Cross-entropy=2.360821180873447, Accuracy=0.1371527777777778\n",
      "Epoch 132 validation: Cross-entropy=2.454284429550171, Accuracy=0.07575757801532745\n",
      "Epoch 133 train: Cross-entropy=2.3608676195144653, Accuracy=0.1371527777777778\n",
      "Epoch 133 validation: Cross-entropy=2.4542336463928223, Accuracy=0.07575757801532745\n",
      "Epoch 134 train: Cross-entropy=2.3609140978919134, Accuracy=0.1371527777777778\n",
      "Epoch 134 validation: Cross-entropy=2.454183340072632, Accuracy=0.07575757801532745\n",
      "Epoch 135 train: Cross-entropy=2.3609603378507824, Accuracy=0.1371527777777778\n",
      "Epoch 135 validation: Cross-entropy=2.454133987426758, Accuracy=0.07575757801532745\n",
      "Epoch 136 train: Cross-entropy=2.3610065380732217, Accuracy=0.1371527777777778\n",
      "Epoch 136 validation: Cross-entropy=2.4540858268737793, Accuracy=0.07575757801532745\n",
      "Epoch 137 train: Cross-entropy=2.3610525263680353, Accuracy=0.1371527777777778\n",
      "Epoch 137 validation: Cross-entropy=2.454037666320801, Accuracy=0.07575757801532745\n",
      "Epoch 138 train: Cross-entropy=2.361098368962606, Accuracy=0.1371527777777778\n",
      "Epoch 138 validation: Cross-entropy=2.4539906978607178, Accuracy=0.07575757801532745\n",
      "Epoch 139 train: Cross-entropy=2.3611441453297934, Accuracy=0.1371527777777778\n",
      "Epoch 139 validation: Cross-entropy=2.453944206237793, Accuracy=0.07575757801532745\n",
      "Epoch 140 train: Cross-entropy=2.3611896302964954, Accuracy=0.1371527777777778\n",
      "Epoch 140 validation: Cross-entropy=2.4538986682891846, Accuracy=0.07575757801532745\n",
      "Epoch 141 train: Cross-entropy=2.361235009299384, Accuracy=0.1371527777777778\n",
      "Epoch 141 validation: Cross-entropy=2.4538536071777344, Accuracy=0.07575757801532745\n",
      "Epoch 142 train: Cross-entropy=2.361280149883694, Accuracy=0.1388888888888889\n",
      "Epoch 142 validation: Cross-entropy=2.4538094997406006, Accuracy=0.07575757801532745\n",
      "Epoch 143 train: Cross-entropy=2.361325052049425, Accuracy=0.1388888888888889\n",
      "Epoch 143 validation: Cross-entropy=2.453765869140625, Accuracy=0.07575757801532745\n",
      "Epoch 144 train: Cross-entropy=2.3613698482513428, Accuracy=0.1388888888888889\n",
      "Epoch 144 validation: Cross-entropy=2.4537229537963867, Accuracy=0.07070706784725189\n",
      "Epoch 145 train: Cross-entropy=2.361414353052775, Accuracy=0.1371527777777778\n",
      "Epoch 145 validation: Cross-entropy=2.453680992126465, Accuracy=0.07070706784725189\n",
      "Epoch 146 train: Cross-entropy=2.361458738644918, Accuracy=0.1371527777777778\n",
      "Epoch 146 validation: Cross-entropy=2.453639507293701, Accuracy=0.07070706784725189\n",
      "Epoch 147 train: Cross-entropy=2.3615028063456216, Accuracy=0.1371527777777778\n",
      "Epoch 147 validation: Cross-entropy=2.453598976135254, Accuracy=0.07070706784725189\n",
      "Epoch 148 train: Cross-entropy=2.3615466621187, Accuracy=0.1371527777777778\n",
      "Epoch 148 validation: Cross-entropy=2.453558921813965, Accuracy=0.07070706784725189\n",
      "Epoch 149 train: Cross-entropy=2.361590279473199, Accuracy=0.1371527777777778\n",
      "Epoch 149 validation: Cross-entropy=2.453519582748413, Accuracy=0.07070706784725189\n",
      "Epoch 150 train: Cross-entropy=2.361633724636502, Accuracy=0.1371527777777778\n",
      "Epoch 150 validation: Cross-entropy=2.4534809589385986, Accuracy=0.07070706784725189\n",
      "Epoch 151 train: Cross-entropy=2.3616768386628895, Accuracy=0.1371527777777778\n",
      "Epoch 151 validation: Cross-entropy=2.4534430503845215, Accuracy=0.07070706784725189\n",
      "Epoch 152 train: Cross-entropy=2.3617197142706976, Accuracy=0.1371527777777778\n",
      "Epoch 152 validation: Cross-entropy=2.4534056186676025, Accuracy=0.07070706784725189\n",
      "Epoch 153 train: Cross-entropy=2.361762285232544, Accuracy=0.1371527777777778\n",
      "Epoch 153 validation: Cross-entropy=2.453369140625, Accuracy=0.07070706784725189\n",
      "Epoch 154 train: Cross-entropy=2.3618047369851007, Accuracy=0.1371527777777778\n",
      "Epoch 154 validation: Cross-entropy=2.4533331394195557, Accuracy=0.07575757801532745\n",
      "Epoch 155 train: Cross-entropy=2.3618467913733587, Accuracy=0.1371527777777778\n",
      "Epoch 155 validation: Cross-entropy=2.4532978534698486, Accuracy=0.07575757801532745\n",
      "Epoch 156 train: Cross-entropy=2.3618885808520846, Accuracy=0.1371527777777778\n",
      "Epoch 156 validation: Cross-entropy=2.453263282775879, Accuracy=0.07575757801532745\n",
      "Epoch 157 train: Cross-entropy=2.361930145157708, Accuracy=0.13541666666666666\n",
      "Epoch 157 validation: Cross-entropy=2.4532289505004883, Accuracy=0.07575757801532745\n",
      "Epoch 158 train: Cross-entropy=2.3619713650809393, Accuracy=0.13541666666666666\n",
      "Epoch 158 validation: Cross-entropy=2.453195571899414, Accuracy=0.07575757801532745\n",
      "Epoch 159 train: Cross-entropy=2.3620123730765448, Accuracy=0.13541666666666666\n",
      "Epoch 159 validation: Cross-entropy=2.453162670135498, Accuracy=0.07575757801532745\n",
      "Epoch 160 train: Cross-entropy=2.3620531029171414, Accuracy=0.13541666666666666\n",
      "Epoch 160 validation: Cross-entropy=2.4531304836273193, Accuracy=0.07575757801532745\n",
      "Epoch 161 train: Cross-entropy=2.3620934883753457, Accuracy=0.1371527777777778\n",
      "Epoch 161 validation: Cross-entropy=2.453099012374878, Accuracy=0.07575757801532745\n",
      "Epoch 162 train: Cross-entropy=2.362133582433065, Accuracy=0.1371527777777778\n",
      "Epoch 162 validation: Cross-entropy=2.4530680179595947, Accuracy=0.07575757801532745\n",
      "Epoch 163 train: Cross-entropy=2.362173411581251, Accuracy=0.1371527777777778\n",
      "Epoch 163 validation: Cross-entropy=2.4530375003814697, Accuracy=0.07575757801532745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 train: Cross-entropy=2.362212989065382, Accuracy=0.1371527777777778\n",
      "Epoch 164 validation: Cross-entropy=2.453007936477661, Accuracy=0.07575757801532745\n",
      "Epoch 165 train: Cross-entropy=2.362252195676168, Accuracy=0.13541666666666666\n",
      "Epoch 165 validation: Cross-entropy=2.4529786109924316, Accuracy=0.07575757801532745\n",
      "Epoch 166 train: Cross-entropy=2.362291110886468, Accuracy=0.13541666666666666\n",
      "Epoch 166 validation: Cross-entropy=2.4529495239257812, Accuracy=0.07575757801532745\n",
      "Epoch 167 train: Cross-entropy=2.362329774432712, Accuracy=0.13541666666666666\n",
      "Epoch 167 validation: Cross-entropy=2.4529216289520264, Accuracy=0.07575757801532745\n",
      "Epoch 168 train: Cross-entropy=2.3623680935965643, Accuracy=0.13541666666666666\n",
      "Epoch 168 validation: Cross-entropy=2.4528942108154297, Accuracy=0.07575757801532745\n",
      "Epoch 169 train: Cross-entropy=2.362406121359931, Accuracy=0.13541666666666666\n",
      "Epoch 169 validation: Cross-entropy=2.452867031097412, Accuracy=0.07575757801532745\n",
      "Epoch 170 train: Cross-entropy=2.3624438444773355, Accuracy=0.13541666666666666\n",
      "Epoch 170 validation: Cross-entropy=2.452840805053711, Accuracy=0.07575757801532745\n",
      "Epoch 171 train: Cross-entropy=2.362481289439731, Accuracy=0.13541666666666666\n",
      "Epoch 171 validation: Cross-entropy=2.4528145790100098, Accuracy=0.08080808073282242\n",
      "Epoch 172 train: Cross-entropy=2.362518456247118, Accuracy=0.13541666666666666\n",
      "Epoch 172 validation: Cross-entropy=2.452789306640625, Accuracy=0.08080808073282242\n",
      "Epoch 173 train: Cross-entropy=2.3625552786721125, Accuracy=0.13368055555555555\n",
      "Epoch 173 validation: Cross-entropy=2.4527642726898193, Accuracy=0.08080808073282242\n",
      "Epoch 174 train: Cross-entropy=2.3625917699601917, Accuracy=0.13368055555555555\n",
      "Epoch 174 validation: Cross-entropy=2.452739715576172, Accuracy=0.08080808073282242\n",
      "Epoch 175 train: Cross-entropy=2.3626279566023083, Accuracy=0.13368055555555555\n",
      "Epoch 175 validation: Cross-entropy=2.4527158737182617, Accuracy=0.08080808073282242\n",
      "Epoch 176 train: Cross-entropy=2.3626637988620334, Accuracy=0.13368055555555555\n",
      "Epoch 176 validation: Cross-entropy=2.4526922702789307, Accuracy=0.08080808073282242\n",
      "Epoch 177 train: Cross-entropy=2.3626994689305625, Accuracy=0.13368055555555555\n",
      "Epoch 177 validation: Cross-entropy=2.452669382095337, Accuracy=0.08080808073282242\n",
      "Epoch 178 train: Cross-entropy=2.3627347548802695, Accuracy=0.13368055555555555\n",
      "Epoch 178 validation: Cross-entropy=2.4526469707489014, Accuracy=0.08080808073282242\n",
      "Epoch 179 train: Cross-entropy=2.362769775920444, Accuracy=0.13368055555555555\n",
      "Epoch 179 validation: Cross-entropy=2.452625036239624, Accuracy=0.08080808073282242\n",
      "Epoch 180 train: Cross-entropy=2.3628043863508434, Accuracy=0.13368055555555555\n",
      "Epoch 180 validation: Cross-entropy=2.452603340148926, Accuracy=0.08080808073282242\n",
      "Epoch 181 train: Cross-entropy=2.3628388113445706, Accuracy=0.13368055555555555\n",
      "Epoch 181 validation: Cross-entropy=2.4525821208953857, Accuracy=0.08080808073282242\n",
      "Epoch 182 train: Cross-entropy=2.3628728787104287, Accuracy=0.13368055555555555\n",
      "Epoch 182 validation: Cross-entropy=2.452561616897583, Accuracy=0.08080808073282242\n",
      "Epoch 183 train: Cross-entropy=2.362906641430325, Accuracy=0.13368055555555555\n",
      "Epoch 183 validation: Cross-entropy=2.4525413513183594, Accuracy=0.08080808073282242\n",
      "Epoch 184 train: Cross-entropy=2.362940125995212, Accuracy=0.13368055555555555\n",
      "Epoch 184 validation: Cross-entropy=2.452521562576294, Accuracy=0.08080808073282242\n",
      "Epoch 185 train: Cross-entropy=2.3629732529322305, Accuracy=0.13194444444444445\n",
      "Epoch 185 validation: Cross-entropy=2.4525022506713867, Accuracy=0.08080808073282242\n",
      "Epoch 186 train: Cross-entropy=2.363006167941623, Accuracy=0.13194444444444445\n",
      "Epoch 186 validation: Cross-entropy=2.4524829387664795, Accuracy=0.08080808073282242\n",
      "Epoch 187 train: Cross-entropy=2.3630387518141003, Accuracy=0.13020833333333334\n",
      "Epoch 187 validation: Cross-entropy=2.4524645805358887, Accuracy=0.08080808073282242\n",
      "Epoch 188 train: Cross-entropy=2.363071084022522, Accuracy=0.13020833333333334\n",
      "Epoch 188 validation: Cross-entropy=2.452446460723877, Accuracy=0.08080808073282242\n",
      "Epoch 189 train: Cross-entropy=2.363102992375692, Accuracy=0.13020833333333334\n",
      "Epoch 189 validation: Cross-entropy=2.4524285793304443, Accuracy=0.08080808073282242\n",
      "Epoch 190 train: Cross-entropy=2.3631346225738525, Accuracy=0.13020833333333334\n",
      "Epoch 190 validation: Cross-entropy=2.452410936355591, Accuracy=0.08080808073282242\n",
      "Epoch 191 train: Cross-entropy=2.363166014353434, Accuracy=0.13020833333333334\n",
      "Epoch 191 validation: Cross-entropy=2.4523940086364746, Accuracy=0.08080808073282242\n",
      "Epoch 192 train: Cross-entropy=2.363197167714437, Accuracy=0.13020833333333334\n",
      "Epoch 192 validation: Cross-entropy=2.4523775577545166, Accuracy=0.08080808073282242\n",
      "Epoch 193 train: Cross-entropy=2.3632279369566174, Accuracy=0.13020833333333334\n",
      "Epoch 193 validation: Cross-entropy=2.4523611068725586, Accuracy=0.08080808073282242\n",
      "Epoch 194 train: Cross-entropy=2.3632585075166492, Accuracy=0.13020833333333334\n",
      "Epoch 194 validation: Cross-entropy=2.452345371246338, Accuracy=0.08080808073282242\n",
      "Epoch 195 train: Cross-entropy=2.363288680712382, Accuracy=0.13020833333333334\n",
      "Epoch 195 validation: Cross-entropy=2.452329635620117, Accuracy=0.08080808073282242\n",
      "Epoch 196 train: Cross-entropy=2.3633186684714422, Accuracy=0.13020833333333334\n",
      "Epoch 196 validation: Cross-entropy=2.4523143768310547, Accuracy=0.08080808073282242\n",
      "Epoch 197 train: Cross-entropy=2.363348298602634, Accuracy=0.13020833333333334\n",
      "Epoch 197 validation: Cross-entropy=2.4522995948791504, Accuracy=0.08080808073282242\n",
      "Epoch 198 train: Cross-entropy=2.3633776903152466, Accuracy=0.13020833333333334\n",
      "Epoch 198 validation: Cross-entropy=2.452285051345825, Accuracy=0.08080808073282242\n",
      "Epoch 199 train: Cross-entropy=2.3634067906273737, Accuracy=0.1284722222222222\n",
      "Epoch 199 validation: Cross-entropy=2.4522705078125, Accuracy=0.08080808073282242\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "\n",
    "momentums = [0.7, 0.8, 0.9]\n",
    "learning_rates = [0.001, 0.01]\n",
    "hidden_sizes = [64, 128, 256]\n",
    "weight_decays = [0.005]\n",
    "\n",
    "best_acc = - np.nan\n",
    "models = []\n",
    "final_loss = []\n",
    "\n",
    "CROSS_losses_train = []\n",
    "CROSS_losses_val = []\n",
    "\n",
    "ACC_losses_train = []\n",
    "ACC_losses_val = []\n",
    "\n",
    "parameters = []\n",
    "batch_sizes = 32\n",
    "\n",
    "for momentum in momentums:\n",
    "    for lr in learning_rates:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for weight_decay in weight_decays:\n",
    "                parameters.append({\"hidden_size\" : hidden_size,\n",
    "                                   \"learning_rate\": lr,\n",
    "                                   \"momentum\": momentum, \n",
    "                                   \"weight_decay\": weight_decay})\n",
    "                \n",
    "                batches_per_epoch = len(x_train) // batch_size\n",
    "                model = Multiclass(input_size, hidden_size, output_size)\n",
    "                \n",
    "                current_CROSS_train = []\n",
    "                current_CROSS_val = []\n",
    "\n",
    "                current_ACC_train = []\n",
    "                current_ACC_val = []\n",
    "                \n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay = weight_decay, momentum = momentum)\n",
    "                for epoch in range(n_epochs):\n",
    "                    epoch_loss = []\n",
    "                    epoch_acc = []\n",
    "                    model.train()\n",
    "                    #with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "                        #bar.set_description(f\"Epoch {epoch}\")\n",
    "                    for i in range(batches_per_epoch):\n",
    "                            start = i * batch_size\n",
    "                            X_batch = x_train[start:start+batch_size]\n",
    "                            y_batch = y_train[start:start+batch_size]\n",
    "\n",
    "                            # forward \n",
    "                            y_pred = model(X_batch)\n",
    "                            loss = loss_fn(y_pred, y_batch)\n",
    "                            # backward \n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            # update weights\n",
    "                            optimizer.step()\n",
    "                            acc = (torch.argmax(y_pred, 1) == torch.argmax(y_batch, 1)).float().mean()\n",
    "                            epoch_loss.append(float(loss))\n",
    "                            epoch_acc.append(float(acc))\n",
    "                            #bar.set_postfix(\n",
    "                            #    loss=float(loss),\n",
    "                            #    acc=float(acc)\n",
    "                            #)\n",
    "                    # set model in evaluation mode and run through the test set\n",
    "                    \n",
    "                    model.eval()\n",
    "                    y_pred = model(x_valid)\n",
    "                    ce = loss_fn(y_pred, y_valid)\n",
    "                    acc = (torch.argmax(y_pred, 1) == torch.argmax(y_valid, 1)).float().mean()\n",
    "\n",
    "                    ce = float(ce)\n",
    "                    acc = float(acc)\n",
    "                    print(f\"Epoch {epoch} train: Cross-entropy={sum(epoch_loss)/batches_per_epoch}, Accuracy={sum(epoch_acc)/batches_per_epoch}\")\n",
    "                    \n",
    "                    current_CROSS_train.append(np.mean(epoch_loss))\n",
    "                    current_ACC_train.append(np.mean(epoch_acc))\n",
    "                    \n",
    "                    current_CROSS_val.append(ce)\n",
    "                    current_ACC_val.append(acc)\n",
    "                    \n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_weights = copy.deepcopy(model.state_dict())\n",
    "                    print(f\"Epoch {epoch} validation: Cross-entropy={ce}, Accuracy={acc}\")\n",
    "                    \n",
    "                CROSS_losses_train.append(current_CROSS_train)\n",
    "                CROSS_losses_val.append(current_CROSS_val)\n",
    "\n",
    "                ACC_losses_train.append(current_ACC_train)\n",
    "                ACC_losses_val.append(current_ACC_val)\n",
    "                final_loss.append(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ab064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'learning_rate': 0.001, 'momentum': 0.7, 'weight_decay': 0.005}\n"
     ]
    }
   ],
   "source": [
    "menor_valor = min(final_loss)  # Encontra o menor valor na lista\n",
    "indice_menor = final_loss.index(menor_valor)\n",
    "\n",
    "best_CROSS_train = CROSS_losses_train[indice_menor]\n",
    "best_CROSS_val = CROSS_losses_val[indice_menor]\n",
    "            \n",
    "best_ACC_train = ACC_losses_train[indice_menor]\n",
    "best_ACC_val = ACC_losses_val[indice_menor]\n",
    "\n",
    "print(parameters[indice_menor])\n",
    "parameters_ = parameters[indice_menor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4205ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train: Cross-entropy=2.4459342294269137, Accuracy=0.08333333333333333\n",
      "Epoch 0 Test: Cross-entropy=2.4278945922851562, Accuracy=0.07575757801532745\n",
      "Epoch 1 Train: Cross-entropy=2.438400771882799, Accuracy=0.08506944444444445\n",
      "Epoch 1 Test: Cross-entropy=2.4228203296661377, Accuracy=0.09595959633588791\n",
      "Epoch 2 Train: Cross-entropy=2.43199000093672, Accuracy=0.08680555555555555\n",
      "Epoch 2 Test: Cross-entropy=2.4187471866607666, Accuracy=0.10101009905338287\n",
      "Epoch 3 Train: Cross-entropy=2.4266338083479138, Accuracy=0.08333333333333333\n",
      "Epoch 3 Test: Cross-entropy=2.4154818058013916, Accuracy=0.09595959633588791\n",
      "Epoch 4 Train: Cross-entropy=2.42214306195577, Accuracy=0.08854166666666667\n",
      "Epoch 4 Test: Cross-entropy=2.4128715991973877, Accuracy=0.09595959633588791\n",
      "Epoch 5 Train: Cross-entropy=2.4183672269185386, Accuracy=0.09027777777777778\n",
      "Epoch 5 Test: Cross-entropy=2.410794258117676, Accuracy=0.09090909361839294\n",
      "Epoch 6 Train: Cross-entropy=2.4151848951975503, Accuracy=0.0954861111111111\n",
      "Epoch 6 Test: Cross-entropy=2.409152030944824, Accuracy=0.08585858345031738\n",
      "Epoch 7 Train: Cross-entropy=2.4124973482555814, Accuracy=0.09722222222222222\n",
      "Epoch 7 Test: Cross-entropy=2.4078643321990967, Accuracy=0.08585858345031738\n",
      "Epoch 8 Train: Cross-entropy=2.410223603248596, Accuracy=0.09722222222222222\n",
      "Epoch 8 Test: Cross-entropy=2.4068665504455566, Accuracy=0.08080808073282242\n",
      "Epoch 9 Train: Cross-entropy=2.4082964923646717, Accuracy=0.09895833333333333\n",
      "Epoch 9 Test: Cross-entropy=2.406104803085327, Accuracy=0.09595959633588791\n",
      "Epoch 10 Train: Cross-entropy=2.406660477320353, Accuracy=0.10069444444444445\n",
      "Epoch 10 Test: Cross-entropy=2.4055352210998535, Accuracy=0.09090909361839294\n",
      "Epoch 11 Train: Cross-entropy=2.40526905324724, Accuracy=0.10243055555555555\n",
      "Epoch 11 Test: Cross-entropy=2.405120849609375, Accuracy=0.07575757801532745\n",
      "Epoch 12 Train: Cross-entropy=2.4040832387076483, Accuracy=0.10243055555555555\n",
      "Epoch 12 Test: Cross-entropy=2.404831647872925, Accuracy=0.07575757801532745\n",
      "Epoch 13 Train: Cross-entropy=2.403070423338148, Accuracy=0.10069444444444445\n",
      "Epoch 13 Test: Cross-entropy=2.4046428203582764, Accuracy=0.07575757801532745\n",
      "Epoch 14 Train: Cross-entropy=2.402202924092611, Accuracy=0.10416666666666667\n",
      "Epoch 14 Test: Cross-entropy=2.4045333862304688, Accuracy=0.07575757801532745\n",
      "Epoch 15 Train: Cross-entropy=2.4014576276143393, Accuracy=0.10243055555555555\n",
      "Epoch 15 Test: Cross-entropy=2.4044861793518066, Accuracy=0.07575757801532745\n",
      "Epoch 16 Train: Cross-entropy=2.400814996825324, Accuracy=0.10069444444444445\n",
      "Epoch 16 Test: Cross-entropy=2.4044876098632812, Accuracy=0.07070706784725189\n",
      "Epoch 17 Train: Cross-entropy=2.4002586603164673, Accuracy=0.10416666666666667\n",
      "Epoch 17 Test: Cross-entropy=2.4045259952545166, Accuracy=0.07575757801532745\n",
      "Epoch 18 Train: Cross-entropy=2.3997746176189847, Accuracy=0.10590277777777778\n",
      "Epoch 18 Test: Cross-entropy=2.4045917987823486, Accuracy=0.07575757801532745\n",
      "Epoch 19 Train: Cross-entropy=2.3993512127134533, Accuracy=0.10243055555555555\n",
      "Epoch 19 Test: Cross-entropy=2.404677152633667, Accuracy=0.07575757801532745\n",
      "Epoch 20 Train: Cross-entropy=2.398978657192654, Accuracy=0.09895833333333333\n",
      "Epoch 20 Test: Cross-entropy=2.4047765731811523, Accuracy=0.06565656512975693\n",
      "Epoch 21 Train: Cross-entropy=2.3986487521065607, Accuracy=0.10243055555555555\n",
      "Epoch 21 Test: Cross-entropy=2.404884099960327, Accuracy=0.06565656512975693\n",
      "Epoch 22 Train: Cross-entropy=2.3983543978797064, Accuracy=0.10416666666666667\n",
      "Epoch 22 Test: Cross-entropy=2.404996871948242, Accuracy=0.07070706784725189\n",
      "Epoch 23 Train: Cross-entropy=2.3980899651845298, Accuracy=0.10590277777777778\n",
      "Epoch 23 Test: Cross-entropy=2.405111074447632, Accuracy=0.07575757801532745\n",
      "Epoch 24 Train: Cross-entropy=2.3978505267037287, Accuracy=0.10416666666666667\n",
      "Epoch 24 Test: Cross-entropy=2.405224561691284, Accuracy=0.07575757801532745\n",
      "Epoch 25 Train: Cross-entropy=2.3976319233576455, Accuracy=0.10416666666666667\n",
      "Epoch 25 Test: Cross-entropy=2.4053354263305664, Accuracy=0.08080808073282242\n",
      "Epoch 26 Train: Cross-entropy=2.3974307907952204, Accuracy=0.10590277777777778\n",
      "Epoch 26 Test: Cross-entropy=2.405442714691162, Accuracy=0.07575757801532745\n",
      "Epoch 27 Train: Cross-entropy=2.397244307729933, Accuracy=0.10416666666666667\n",
      "Epoch 27 Test: Cross-entropy=2.4055442810058594, Accuracy=0.08080808073282242\n",
      "Epoch 28 Train: Cross-entropy=2.3970700369940863, Accuracy=0.10416666666666667\n",
      "Epoch 28 Test: Cross-entropy=2.4056408405303955, Accuracy=0.08585858345031738\n",
      "Epoch 29 Train: Cross-entropy=2.396906057993571, Accuracy=0.10590277777777778\n",
      "Epoch 29 Test: Cross-entropy=2.405731201171875, Accuracy=0.09090909361839294\n",
      "Epoch 30 Train: Cross-entropy=2.3967506753073797, Accuracy=0.10590277777777778\n",
      "Epoch 30 Test: Cross-entropy=2.4058151245117188, Accuracy=0.09595959633588791\n",
      "Epoch 31 Train: Cross-entropy=2.3966024849149914, Accuracy=0.10590277777777778\n",
      "Epoch 31 Test: Cross-entropy=2.4058926105499268, Accuracy=0.10101009905338287\n",
      "Epoch 32 Train: Cross-entropy=2.396460360950894, Accuracy=0.1076388888888889\n",
      "Epoch 32 Test: Cross-entropy=2.405963897705078, Accuracy=0.10101009905338287\n",
      "Epoch 33 Train: Cross-entropy=2.3963234027226767, Accuracy=0.10416666666666667\n",
      "Epoch 33 Test: Cross-entropy=2.406028985977173, Accuracy=0.10606060922145844\n",
      "Epoch 34 Train: Cross-entropy=2.39619070953793, Accuracy=0.10590277777777778\n",
      "Epoch 34 Test: Cross-entropy=2.406087636947632, Accuracy=0.10606060922145844\n",
      "Epoch 35 Train: Cross-entropy=2.3960616985956826, Accuracy=0.10590277777777778\n",
      "Epoch 35 Test: Cross-entropy=2.4061403274536133, Accuracy=0.1111111119389534\n",
      "Epoch 36 Train: Cross-entropy=2.395935707622104, Accuracy=0.1111111111111111\n",
      "Epoch 36 Test: Cross-entropy=2.4061877727508545, Accuracy=0.1111111119389534\n",
      "Epoch 37 Train: Cross-entropy=2.3958123922348022, Accuracy=0.11458333333333333\n",
      "Epoch 37 Test: Cross-entropy=2.4062294960021973, Accuracy=0.1111111119389534\n",
      "Epoch 38 Train: Cross-entropy=2.395691394805908, Accuracy=0.11631944444444445\n",
      "Epoch 38 Test: Cross-entropy=2.4062659740448, Accuracy=0.1111111119389534\n",
      "Epoch 39 Train: Cross-entropy=2.395572304725647, Accuracy=0.11805555555555555\n",
      "Epoch 39 Test: Cross-entropy=2.4062981605529785, Accuracy=0.1111111119389534\n",
      "Epoch 40 Train: Cross-entropy=2.3954548438390098, Accuracy=0.11631944444444445\n",
      "Epoch 40 Test: Cross-entropy=2.406325340270996, Accuracy=0.1111111119389534\n",
      "Epoch 41 Train: Cross-entropy=2.395338853200277, Accuracy=0.11805555555555555\n",
      "Epoch 41 Test: Cross-entropy=2.406348705291748, Accuracy=0.1111111119389534\n",
      "Epoch 42 Train: Cross-entropy=2.3952241871092053, Accuracy=0.11979166666666667\n",
      "Epoch 42 Test: Cross-entropy=2.4063680171966553, Accuracy=0.1111111119389534\n",
      "Epoch 43 Train: Cross-entropy=2.395110567410787, Accuracy=0.11805555555555555\n",
      "Epoch 43 Test: Cross-entropy=2.406383514404297, Accuracy=0.1111111119389534\n",
      "Epoch 44 Train: Cross-entropy=2.3949979543685913, Accuracy=0.11979166666666667\n",
      "Epoch 44 Test: Cross-entropy=2.40639591217041, Accuracy=0.1111111119389534\n",
      "Epoch 45 Train: Cross-entropy=2.3948862552642822, Accuracy=0.11805555555555555\n",
      "Epoch 45 Test: Cross-entropy=2.406404972076416, Accuracy=0.1111111119389534\n",
      "Epoch 46 Train: Cross-entropy=2.3947753641340466, Accuracy=0.11805555555555555\n",
      "Epoch 46 Test: Cross-entropy=2.4064111709594727, Accuracy=0.1111111119389534\n",
      "Epoch 47 Train: Cross-entropy=2.3946651617685952, Accuracy=0.11805555555555555\n",
      "Epoch 47 Test: Cross-entropy=2.40641450881958, Accuracy=0.1111111119389534\n",
      "Epoch 48 Train: Cross-entropy=2.394555674658881, Accuracy=0.11979166666666667\n",
      "Epoch 48 Test: Cross-entropy=2.4064159393310547, Accuracy=0.1111111119389534\n",
      "Epoch 49 Train: Cross-entropy=2.3944467306137085, Accuracy=0.11979166666666667\n",
      "Epoch 49 Test: Cross-entropy=2.40641450881958, Accuracy=0.1111111119389534\n",
      "Epoch 50 Train: Cross-entropy=2.394338369369507, Accuracy=0.11979166666666667\n",
      "Epoch 50 Test: Cross-entropy=2.4064111709594727, Accuracy=0.1111111119389534\n",
      "Epoch 51 Train: Cross-entropy=2.3942305511898465, Accuracy=0.12152777777777778\n",
      "Epoch 51 Test: Cross-entropy=2.4064059257507324, Accuracy=0.11616161465644836\n",
      "Epoch 52 Train: Cross-entropy=2.3941232760747275, Accuracy=0.12152777777777778\n",
      "Epoch 52 Test: Cross-entropy=2.4063987731933594, Accuracy=0.11616161465644836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Train: Cross-entropy=2.39401642481486, Accuracy=0.12152777777777778\n",
      "Epoch 53 Test: Cross-entropy=2.40639066696167, Accuracy=0.11616161465644836\n",
      "Epoch 54 Train: Cross-entropy=2.3939101033740573, Accuracy=0.1232638888888889\n",
      "Epoch 54 Test: Cross-entropy=2.4063806533813477, Accuracy=0.11616161465644836\n",
      "Epoch 55 Train: Cross-entropy=2.393804179297553, Accuracy=0.1232638888888889\n",
      "Epoch 55 Test: Cross-entropy=2.4063689708709717, Accuracy=0.11616161465644836\n",
      "Epoch 56 Train: Cross-entropy=2.393698573112488, Accuracy=0.1232638888888889\n",
      "Epoch 56 Test: Cross-entropy=2.4063565731048584, Accuracy=0.11616161465644836\n",
      "Epoch 57 Train: Cross-entropy=2.393593536482917, Accuracy=0.1232638888888889\n",
      "Epoch 57 Test: Cross-entropy=2.4063427448272705, Accuracy=0.11616161465644836\n",
      "Epoch 58 Train: Cross-entropy=2.393488883972168, Accuracy=0.125\n",
      "Epoch 58 Test: Cross-entropy=2.4063282012939453, Accuracy=0.11616161465644836\n",
      "Epoch 59 Train: Cross-entropy=2.3933844566345215, Accuracy=0.1232638888888889\n",
      "Epoch 59 Test: Cross-entropy=2.4063124656677246, Accuracy=0.12121212482452393\n",
      "Epoch 60 Train: Cross-entropy=2.39328051937951, Accuracy=0.1232638888888889\n",
      "Epoch 60 Test: Cross-entropy=2.406296491622925, Accuracy=0.12121212482452393\n",
      "Epoch 61 Train: Cross-entropy=2.3931769529978433, Accuracy=0.1232638888888889\n",
      "Epoch 61 Test: Cross-entropy=2.4062790870666504, Accuracy=0.12121212482452393\n",
      "Epoch 62 Train: Cross-entropy=2.3930737177530923, Accuracy=0.1232638888888889\n",
      "Epoch 62 Test: Cross-entropy=2.4062612056732178, Accuracy=0.12121212482452393\n",
      "Epoch 63 Train: Cross-entropy=2.3929708268907337, Accuracy=0.1232638888888889\n",
      "Epoch 63 Test: Cross-entropy=2.406243085861206, Accuracy=0.12121212482452393\n",
      "Epoch 64 Train: Cross-entropy=2.392868399620056, Accuracy=0.1232638888888889\n",
      "Epoch 64 Test: Cross-entropy=2.406224012374878, Accuracy=0.12121212482452393\n",
      "Epoch 65 Train: Cross-entropy=2.3927662107679577, Accuracy=0.1267361111111111\n",
      "Epoch 65 Test: Cross-entropy=2.4062044620513916, Accuracy=0.12121212482452393\n",
      "Epoch 66 Train: Cross-entropy=2.392664392789205, Accuracy=0.1267361111111111\n",
      "Epoch 66 Test: Cross-entropy=2.406184434890747, Accuracy=0.12121212482452393\n",
      "Epoch 67 Train: Cross-entropy=2.3925629456837973, Accuracy=0.1267361111111111\n",
      "Epoch 67 Test: Cross-entropy=2.4061644077301025, Accuracy=0.12121212482452393\n",
      "Epoch 68 Train: Cross-entropy=2.392461816469828, Accuracy=0.1267361111111111\n",
      "Epoch 68 Test: Cross-entropy=2.4061436653137207, Accuracy=0.12121212482452393\n",
      "Epoch 69 Train: Cross-entropy=2.3923610713746815, Accuracy=0.1267361111111111\n",
      "Epoch 69 Test: Cross-entropy=2.406122922897339, Accuracy=0.12121212482452393\n",
      "Epoch 70 Train: Cross-entropy=2.3922605646981134, Accuracy=0.1267361111111111\n",
      "Epoch 70 Test: Cross-entropy=2.406101703643799, Accuracy=0.12121212482452393\n",
      "Epoch 71 Train: Cross-entropy=2.3921604288948908, Accuracy=0.1284722222222222\n",
      "Epoch 71 Test: Cross-entropy=2.4060802459716797, Accuracy=0.12121212482452393\n",
      "Epoch 72 Train: Cross-entropy=2.3920606507195368, Accuracy=0.1284722222222222\n",
      "Epoch 72 Test: Cross-entropy=2.4060585498809814, Accuracy=0.12121212482452393\n",
      "Epoch 73 Train: Cross-entropy=2.3919610844718084, Accuracy=0.1284722222222222\n",
      "Epoch 73 Test: Cross-entropy=2.4060370922088623, Accuracy=0.12121212482452393\n",
      "Epoch 74 Train: Cross-entropy=2.3918619553248086, Accuracy=0.1284722222222222\n",
      "Epoch 74 Test: Cross-entropy=2.406014919281006, Accuracy=0.12121212482452393\n",
      "Epoch 75 Train: Cross-entropy=2.3917631440692477, Accuracy=0.1284722222222222\n",
      "Epoch 75 Test: Cross-entropy=2.4059927463531494, Accuracy=0.12121212482452393\n",
      "Epoch 76 Train: Cross-entropy=2.391664571232266, Accuracy=0.1284722222222222\n",
      "Epoch 76 Test: Cross-entropy=2.405970811843872, Accuracy=0.12121212482452393\n",
      "Epoch 77 Train: Cross-entropy=2.3915663957595825, Accuracy=0.13020833333333334\n",
      "Epoch 77 Test: Cross-entropy=2.4059486389160156, Accuracy=0.12121212482452393\n",
      "Epoch 78 Train: Cross-entropy=2.391468498441908, Accuracy=0.13020833333333334\n",
      "Epoch 78 Test: Cross-entropy=2.40592622756958, Accuracy=0.12121212482452393\n",
      "Epoch 79 Train: Cross-entropy=2.3913709852430554, Accuracy=0.13020833333333334\n",
      "Epoch 79 Test: Cross-entropy=2.4059038162231445, Accuracy=0.12121212482452393\n",
      "Epoch 80 Train: Cross-entropy=2.391273604498969, Accuracy=0.13020833333333334\n",
      "Epoch 80 Test: Cross-entropy=2.405881404876709, Accuracy=0.12121212482452393\n",
      "Epoch 81 Train: Cross-entropy=2.3911767138375177, Accuracy=0.13020833333333334\n",
      "Epoch 81 Test: Cross-entropy=2.4058592319488525, Accuracy=0.12121212482452393\n",
      "Epoch 82 Train: Cross-entropy=2.3910800748401217, Accuracy=0.13020833333333334\n",
      "Epoch 82 Test: Cross-entropy=2.405836582183838, Accuracy=0.12121212482452393\n",
      "Epoch 83 Train: Cross-entropy=2.390983713997735, Accuracy=0.13020833333333334\n",
      "Epoch 83 Test: Cross-entropy=2.4058141708374023, Accuracy=0.12121212482452393\n",
      "Epoch 84 Train: Cross-entropy=2.3908877107832165, Accuracy=0.13020833333333334\n",
      "Epoch 84 Test: Cross-entropy=2.405791759490967, Accuracy=0.12121212482452393\n",
      "Epoch 85 Train: Cross-entropy=2.390791906250848, Accuracy=0.1284722222222222\n",
      "Epoch 85 Test: Cross-entropy=2.4057695865631104, Accuracy=0.12121212482452393\n",
      "Epoch 86 Train: Cross-entropy=2.3906965123282538, Accuracy=0.1284722222222222\n",
      "Epoch 86 Test: Cross-entropy=2.405747413635254, Accuracy=0.12121212482452393\n",
      "Epoch 87 Train: Cross-entropy=2.3906014098061457, Accuracy=0.1267361111111111\n",
      "Epoch 87 Test: Cross-entropy=2.4057247638702393, Accuracy=0.12121212482452393\n",
      "Epoch 88 Train: Cross-entropy=2.3905065457026162, Accuracy=0.1267361111111111\n",
      "Epoch 88 Test: Cross-entropy=2.405702590942383, Accuracy=0.12121212482452393\n",
      "Epoch 89 Train: Cross-entropy=2.3904120922088623, Accuracy=0.1267361111111111\n",
      "Epoch 89 Test: Cross-entropy=2.4056806564331055, Accuracy=0.11616161465644836\n",
      "Epoch 90 Train: Cross-entropy=2.390317771169874, Accuracy=0.125\n",
      "Epoch 90 Test: Cross-entropy=2.405658483505249, Accuracy=0.11616161465644836\n",
      "Epoch 91 Train: Cross-entropy=2.3902239004770913, Accuracy=0.1232638888888889\n",
      "Epoch 91 Test: Cross-entropy=2.4056365489959717, Accuracy=0.11616161465644836\n",
      "Epoch 92 Train: Cross-entropy=2.3901302019755044, Accuracy=0.1232638888888889\n",
      "Epoch 92 Test: Cross-entropy=2.4056146144866943, Accuracy=0.1111111119389534\n",
      "Epoch 93 Train: Cross-entropy=2.3900368213653564, Accuracy=0.1232638888888889\n",
      "Epoch 93 Test: Cross-entropy=2.405592679977417, Accuracy=0.1111111119389534\n",
      "Epoch 94 Train: Cross-entropy=2.3899437454011707, Accuracy=0.1232638888888889\n",
      "Epoch 94 Test: Cross-entropy=2.4055709838867188, Accuracy=0.1111111119389534\n",
      "Epoch 95 Train: Cross-entropy=2.389850934346517, Accuracy=0.1232638888888889\n",
      "Epoch 95 Test: Cross-entropy=2.4055490493774414, Accuracy=0.1111111119389534\n",
      "Epoch 96 Train: Cross-entropy=2.389758441183302, Accuracy=0.125\n",
      "Epoch 96 Test: Cross-entropy=2.405527353286743, Accuracy=0.1111111119389534\n",
      "Epoch 97 Train: Cross-entropy=2.389666279157003, Accuracy=0.125\n",
      "Epoch 97 Test: Cross-entropy=2.405506134033203, Accuracy=0.1111111119389534\n",
      "Epoch 98 Train: Cross-entropy=2.3895743555492825, Accuracy=0.1232638888888889\n",
      "Epoch 98 Test: Cross-entropy=2.405484676361084, Accuracy=0.1111111119389534\n",
      "Epoch 99 Train: Cross-entropy=2.3894827233420477, Accuracy=0.1232638888888889\n",
      "Epoch 99 Test: Cross-entropy=2.405463218688965, Accuracy=0.1111111119389534\n",
      "Epoch 100 Train: Cross-entropy=2.389391395780775, Accuracy=0.1232638888888889\n",
      "Epoch 100 Test: Cross-entropy=2.405441999435425, Accuracy=0.1111111119389534\n",
      "Epoch 101 Train: Cross-entropy=2.3893002801471286, Accuracy=0.1232638888888889\n",
      "Epoch 101 Test: Cross-entropy=2.4054205417633057, Accuracy=0.1111111119389534\n",
      "Epoch 102 Train: Cross-entropy=2.389209508895874, Accuracy=0.1232638888888889\n",
      "Epoch 102 Test: Cross-entropy=2.405399799346924, Accuracy=0.1111111119389534\n",
      "Epoch 103 Train: Cross-entropy=2.389118962817722, Accuracy=0.1232638888888889\n",
      "Epoch 103 Test: Cross-entropy=2.405378818511963, Accuracy=0.10606060922145844\n",
      "Epoch 104 Train: Cross-entropy=2.389028721385532, Accuracy=0.1267361111111111\n",
      "Epoch 104 Test: Cross-entropy=2.405357837677002, Accuracy=0.1111111119389534\n",
      "Epoch 105 Train: Cross-entropy=2.3889387448628745, Accuracy=0.1284722222222222\n",
      "Epoch 105 Test: Cross-entropy=2.405337333679199, Accuracy=0.1111111119389534\n",
      "Epoch 106 Train: Cross-entropy=2.3888490994771323, Accuracy=0.1284722222222222\n",
      "Epoch 106 Test: Cross-entropy=2.4053165912628174, Accuracy=0.1111111119389534\n",
      "Epoch 107 Train: Cross-entropy=2.388759639528063, Accuracy=0.1284722222222222\n",
      "Epoch 107 Test: Cross-entropy=2.4052958488464355, Accuracy=0.10606060922145844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Train: Cross-entropy=2.388670484224955, Accuracy=0.1284722222222222\n",
      "Epoch 108 Test: Cross-entropy=2.405275583267212, Accuracy=0.10606060922145844\n",
      "Epoch 109 Train: Cross-entropy=2.3885815805859036, Accuracy=0.13020833333333334\n",
      "Epoch 109 Test: Cross-entropy=2.4052553176879883, Accuracy=0.10606060922145844\n",
      "Epoch 110 Train: Cross-entropy=2.3884930345747204, Accuracy=0.13020833333333334\n",
      "Epoch 110 Test: Cross-entropy=2.4052350521087646, Accuracy=0.10606060922145844\n",
      "Epoch 111 Train: Cross-entropy=2.3884046342637806, Accuracy=0.13020833333333334\n",
      "Epoch 111 Test: Cross-entropy=2.40521502494812, Accuracy=0.10606060922145844\n",
      "Epoch 112 Train: Cross-entropy=2.3883165783352323, Accuracy=0.13020833333333334\n",
      "Epoch 112 Test: Cross-entropy=2.4051952362060547, Accuracy=0.10606060922145844\n",
      "Epoch 113 Train: Cross-entropy=2.3882287873162165, Accuracy=0.13020833333333334\n",
      "Epoch 113 Test: Cross-entropy=2.40517520904541, Accuracy=0.10606060922145844\n",
      "Epoch 114 Train: Cross-entropy=2.388141221470303, Accuracy=0.1284722222222222\n",
      "Epoch 114 Test: Cross-entropy=2.4051554203033447, Accuracy=0.10606060922145844\n",
      "Epoch 115 Train: Cross-entropy=2.388053947024875, Accuracy=0.1284722222222222\n",
      "Epoch 115 Test: Cross-entropy=2.4051358699798584, Accuracy=0.10606060922145844\n",
      "Epoch 116 Train: Cross-entropy=2.38796693748898, Accuracy=0.1284722222222222\n",
      "Epoch 116 Test: Cross-entropy=2.405116081237793, Accuracy=0.10606060922145844\n",
      "Epoch 117 Train: Cross-entropy=2.38788021935357, Accuracy=0.1284722222222222\n",
      "Epoch 117 Test: Cross-entropy=2.4050967693328857, Accuracy=0.10606060922145844\n",
      "Epoch 118 Train: Cross-entropy=2.3877936469184027, Accuracy=0.1284722222222222\n",
      "Epoch 118 Test: Cross-entropy=2.4050774574279785, Accuracy=0.10606060922145844\n",
      "Epoch 119 Train: Cross-entropy=2.3877074453565807, Accuracy=0.1284722222222222\n",
      "Epoch 119 Test: Cross-entropy=2.4050581455230713, Accuracy=0.10606060922145844\n",
      "Epoch 120 Train: Cross-entropy=2.3876214954588146, Accuracy=0.1284722222222222\n",
      "Epoch 120 Test: Cross-entropy=2.405039072036743, Accuracy=0.10606060922145844\n",
      "Epoch 121 Train: Cross-entropy=2.3875357839796276, Accuracy=0.1284722222222222\n",
      "Epoch 121 Test: Cross-entropy=2.405019998550415, Accuracy=0.10606060922145844\n",
      "Epoch 122 Train: Cross-entropy=2.387450244691637, Accuracy=0.1284722222222222\n",
      "Epoch 122 Test: Cross-entropy=2.405000925064087, Accuracy=0.10101009905338287\n",
      "Epoch 123 Train: Cross-entropy=2.387365049786038, Accuracy=0.1284722222222222\n",
      "Epoch 123 Test: Cross-entropy=2.404982566833496, Accuracy=0.10101009905338287\n",
      "Epoch 124 Train: Cross-entropy=2.3872801065444946, Accuracy=0.1284722222222222\n",
      "Epoch 124 Test: Cross-entropy=2.404963731765747, Accuracy=0.10101009905338287\n",
      "Epoch 125 Train: Cross-entropy=2.3871953752305775, Accuracy=0.1284722222222222\n",
      "Epoch 125 Test: Cross-entropy=2.404945135116577, Accuracy=0.10101009905338287\n",
      "Epoch 126 Train: Cross-entropy=2.387110882335239, Accuracy=0.1284722222222222\n",
      "Epoch 126 Test: Cross-entropy=2.4049265384674072, Accuracy=0.10101009905338287\n",
      "Epoch 127 Train: Cross-entropy=2.3870266808403864, Accuracy=0.1284722222222222\n",
      "Epoch 127 Test: Cross-entropy=2.4049084186553955, Accuracy=0.10101009905338287\n",
      "Epoch 128 Train: Cross-entropy=2.386942664782206, Accuracy=0.13020833333333334\n",
      "Epoch 128 Test: Cross-entropy=2.4048900604248047, Accuracy=0.10101009905338287\n",
      "Epoch 129 Train: Cross-entropy=2.386859006351895, Accuracy=0.13020833333333334\n",
      "Epoch 129 Test: Cross-entropy=2.404871702194214, Accuracy=0.10101009905338287\n",
      "Epoch 130 Train: Cross-entropy=2.3867755466037326, Accuracy=0.13020833333333334\n",
      "Epoch 130 Test: Cross-entropy=2.4048538208007812, Accuracy=0.10101009905338287\n",
      "Epoch 131 Train: Cross-entropy=2.3866923252741494, Accuracy=0.13020833333333334\n",
      "Epoch 131 Test: Cross-entropy=2.4048359394073486, Accuracy=0.10101009905338287\n",
      "Epoch 132 Train: Cross-entropy=2.3866092761357627, Accuracy=0.13020833333333334\n",
      "Epoch 132 Test: Cross-entropy=2.404818058013916, Accuracy=0.10101009905338287\n",
      "Epoch 133 Train: Cross-entropy=2.3865265316433377, Accuracy=0.13020833333333334\n",
      "Epoch 133 Test: Cross-entropy=2.4048006534576416, Accuracy=0.10101009905338287\n",
      "Epoch 134 Train: Cross-entropy=2.3864440653059216, Accuracy=0.13020833333333334\n",
      "Epoch 134 Test: Cross-entropy=2.404782772064209, Accuracy=0.10101009905338287\n",
      "Epoch 135 Train: Cross-entropy=2.3863617976506553, Accuracy=0.13020833333333334\n",
      "Epoch 135 Test: Cross-entropy=2.4047653675079346, Accuracy=0.10101009905338287\n",
      "Epoch 136 Train: Cross-entropy=2.3862797949049206, Accuracy=0.1284722222222222\n",
      "Epoch 136 Test: Cross-entropy=2.40474796295166, Accuracy=0.10101009905338287\n",
      "Epoch 137 Train: Cross-entropy=2.3861979643503823, Accuracy=0.1284722222222222\n",
      "Epoch 137 Test: Cross-entropy=2.4047303199768066, Accuracy=0.10101009905338287\n",
      "Epoch 138 Train: Cross-entropy=2.386116451687283, Accuracy=0.1284722222222222\n",
      "Epoch 138 Test: Cross-entropy=2.4047133922576904, Accuracy=0.10101009905338287\n",
      "Epoch 139 Train: Cross-entropy=2.3860351377063327, Accuracy=0.1284722222222222\n",
      "Epoch 139 Test: Cross-entropy=2.404696464538574, Accuracy=0.10101009905338287\n",
      "Epoch 140 Train: Cross-entropy=2.385954088634915, Accuracy=0.1284722222222222\n",
      "Epoch 140 Test: Cross-entropy=2.404679298400879, Accuracy=0.10101009905338287\n",
      "Epoch 141 Train: Cross-entropy=2.3858732250001697, Accuracy=0.1284722222222222\n",
      "Epoch 141 Test: Cross-entropy=2.4046621322631836, Accuracy=0.10101009905338287\n",
      "Epoch 142 Train: Cross-entropy=2.3857925997840033, Accuracy=0.13194444444444445\n",
      "Epoch 142 Test: Cross-entropy=2.4046454429626465, Accuracy=0.10101009905338287\n",
      "Epoch 143 Train: Cross-entropy=2.385712252722846, Accuracy=0.13194444444444445\n",
      "Epoch 143 Test: Cross-entropy=2.4046285152435303, Accuracy=0.10101009905338287\n",
      "Epoch 144 Train: Cross-entropy=2.3856321705712213, Accuracy=0.13194444444444445\n",
      "Epoch 144 Test: Cross-entropy=2.4046125411987305, Accuracy=0.10101009905338287\n",
      "Epoch 145 Train: Cross-entropy=2.385552167892456, Accuracy=0.13194444444444445\n",
      "Epoch 145 Test: Cross-entropy=2.4045956134796143, Accuracy=0.10101009905338287\n",
      "Epoch 146 Train: Cross-entropy=2.3854724963506064, Accuracy=0.13194444444444445\n",
      "Epoch 146 Test: Cross-entropy=2.4045791625976562, Accuracy=0.10101009905338287\n",
      "Epoch 147 Train: Cross-entropy=2.385393010245429, Accuracy=0.13194444444444445\n",
      "Epoch 147 Test: Cross-entropy=2.4045629501342773, Accuracy=0.10101009905338287\n",
      "Epoch 148 Train: Cross-entropy=2.385313802295261, Accuracy=0.13368055555555555\n",
      "Epoch 148 Test: Cross-entropy=2.4045469760894775, Accuracy=0.10101009905338287\n",
      "Epoch 149 Train: Cross-entropy=2.385234819518195, Accuracy=0.13368055555555555\n",
      "Epoch 149 Test: Cross-entropy=2.4045307636260986, Accuracy=0.10101009905338287\n",
      "Epoch 150 Train: Cross-entropy=2.3851560486687555, Accuracy=0.13368055555555555\n",
      "Epoch 150 Test: Cross-entropy=2.4045145511627197, Accuracy=0.10101009905338287\n",
      "Epoch 151 Train: Cross-entropy=2.3850775294833713, Accuracy=0.13368055555555555\n",
      "Epoch 151 Test: Cross-entropy=2.404498815536499, Accuracy=0.10101009905338287\n",
      "Epoch 152 Train: Cross-entropy=2.38499915599823, Accuracy=0.13194444444444445\n",
      "Epoch 152 Test: Cross-entropy=2.404482841491699, Accuracy=0.10101009905338287\n",
      "Epoch 153 Train: Cross-entropy=2.3849211004045276, Accuracy=0.13194444444444445\n",
      "Epoch 153 Test: Cross-entropy=2.4044671058654785, Accuracy=0.10101009905338287\n",
      "Epoch 154 Train: Cross-entropy=2.3848430977927313, Accuracy=0.13020833333333334\n",
      "Epoch 154 Test: Cross-entropy=2.404451608657837, Accuracy=0.10101009905338287\n",
      "Epoch 155 Train: Cross-entropy=2.384765452808804, Accuracy=0.13020833333333334\n",
      "Epoch 155 Test: Cross-entropy=2.404435873031616, Accuracy=0.10101009905338287\n",
      "Epoch 156 Train: Cross-entropy=2.384687993261549, Accuracy=0.13020833333333334\n",
      "Epoch 156 Test: Cross-entropy=2.4044203758239746, Accuracy=0.10101009905338287\n",
      "Epoch 157 Train: Cross-entropy=2.3846108383602567, Accuracy=0.13020833333333334\n",
      "Epoch 157 Test: Cross-entropy=2.404405117034912, Accuracy=0.10101009905338287\n",
      "Epoch 158 Train: Cross-entropy=2.384533829159207, Accuracy=0.13020833333333334\n",
      "Epoch 158 Test: Cross-entropy=2.4043896198272705, Accuracy=0.10101009905338287\n",
      "Epoch 159 Train: Cross-entropy=2.384456992149353, Accuracy=0.13020833333333334\n",
      "Epoch 159 Test: Cross-entropy=2.404374599456787, Accuracy=0.10101009905338287\n",
      "Epoch 160 Train: Cross-entropy=2.384380499521891, Accuracy=0.13020833333333334\n",
      "Epoch 160 Test: Cross-entropy=2.4043595790863037, Accuracy=0.10101009905338287\n",
      "Epoch 161 Train: Cross-entropy=2.384304073121813, Accuracy=0.1284722222222222\n",
      "Epoch 161 Test: Cross-entropy=2.404344320297241, Accuracy=0.10101009905338287\n",
      "Epoch 162 Train: Cross-entropy=2.3842278586493597, Accuracy=0.1284722222222222\n",
      "Epoch 162 Test: Cross-entropy=2.404329776763916, Accuracy=0.10101009905338287\n",
      "Epoch 163 Train: Cross-entropy=2.3841520018047757, Accuracy=0.1284722222222222\n",
      "Epoch 163 Test: Cross-entropy=2.4043145179748535, Accuracy=0.10101009905338287\n",
      "Epoch 164 Train: Cross-entropy=2.3840762774149575, Accuracy=0.1284722222222222\n",
      "Epoch 164 Test: Cross-entropy=2.4042999744415283, Accuracy=0.10101009905338287\n",
      "Epoch 165 Train: Cross-entropy=2.3840007252163358, Accuracy=0.13020833333333334\n",
      "Epoch 165 Test: Cross-entropy=2.404285430908203, Accuracy=0.10101009905338287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166 Train: Cross-entropy=2.383925451172723, Accuracy=0.13020833333333334\n",
      "Epoch 166 Test: Cross-entropy=2.404270887374878, Accuracy=0.10101009905338287\n",
      "Epoch 167 Train: Cross-entropy=2.3838503228293524, Accuracy=0.13020833333333334\n",
      "Epoch 167 Test: Cross-entropy=2.4042563438415527, Accuracy=0.10101009905338287\n",
      "Epoch 168 Train: Cross-entropy=2.383775406413608, Accuracy=0.1284722222222222\n",
      "Epoch 168 Test: Cross-entropy=2.4042418003082275, Accuracy=0.10101009905338287\n",
      "Epoch 169 Train: Cross-entropy=2.3837007416619196, Accuracy=0.1284722222222222\n",
      "Epoch 169 Test: Cross-entropy=2.4042274951934814, Accuracy=0.10101009905338287\n",
      "Epoch 170 Train: Cross-entropy=2.3836263285742865, Accuracy=0.1284722222222222\n",
      "Epoch 170 Test: Cross-entropy=2.4042134284973145, Accuracy=0.10101009905338287\n",
      "Epoch 171 Train: Cross-entropy=2.3835520611868963, Accuracy=0.1284722222222222\n",
      "Epoch 171 Test: Cross-entropy=2.4041993618011475, Accuracy=0.10101009905338287\n",
      "Epoch 172 Train: Cross-entropy=2.3834779924816556, Accuracy=0.1267361111111111\n",
      "Epoch 172 Test: Cross-entropy=2.4041852951049805, Accuracy=0.10101009905338287\n",
      "Epoch 173 Train: Cross-entropy=2.383404122458564, Accuracy=0.1267361111111111\n",
      "Epoch 173 Test: Cross-entropy=2.4041712284088135, Accuracy=0.10101009905338287\n",
      "Epoch 174 Train: Cross-entropy=2.3833304246266684, Accuracy=0.1267361111111111\n",
      "Epoch 174 Test: Cross-entropy=2.4041574001312256, Accuracy=0.10101009905338287\n",
      "Epoch 175 Train: Cross-entropy=2.3832570049497814, Accuracy=0.1267361111111111\n",
      "Epoch 175 Test: Cross-entropy=2.4041435718536377, Accuracy=0.10101009905338287\n",
      "Epoch 176 Train: Cross-entropy=2.3831837707095676, Accuracy=0.1267361111111111\n",
      "Epoch 176 Test: Cross-entropy=2.404130220413208, Accuracy=0.10101009905338287\n",
      "Epoch 177 Train: Cross-entropy=2.383110655678643, Accuracy=0.1267361111111111\n",
      "Epoch 177 Test: Cross-entropy=2.404116153717041, Accuracy=0.10101009905338287\n",
      "Epoch 178 Train: Cross-entropy=2.3830378188027277, Accuracy=0.1267361111111111\n",
      "Epoch 178 Test: Cross-entropy=2.4041025638580322, Accuracy=0.10101009905338287\n",
      "Epoch 179 Train: Cross-entropy=2.382965233590868, Accuracy=0.1267361111111111\n",
      "Epoch 179 Test: Cross-entropy=2.4040892124176025, Accuracy=0.10101009905338287\n",
      "Epoch 180 Train: Cross-entropy=2.382892714606391, Accuracy=0.1267361111111111\n",
      "Epoch 180 Test: Cross-entropy=2.404076099395752, Accuracy=0.10101009905338287\n",
      "Epoch 181 Train: Cross-entropy=2.3828205002678766, Accuracy=0.1267361111111111\n",
      "Epoch 181 Test: Cross-entropy=2.404062509536743, Accuracy=0.10101009905338287\n",
      "Epoch 182 Train: Cross-entropy=2.3827484051386514, Accuracy=0.1284722222222222\n",
      "Epoch 182 Test: Cross-entropy=2.4040493965148926, Accuracy=0.10101009905338287\n",
      "Epoch 183 Train: Cross-entropy=2.3826765484280057, Accuracy=0.1284722222222222\n",
      "Epoch 183 Test: Cross-entropy=2.404036045074463, Accuracy=0.10101009905338287\n",
      "Epoch 184 Train: Cross-entropy=2.3826049168904624, Accuracy=0.1284722222222222\n",
      "Epoch 184 Test: Cross-entropy=2.4040231704711914, Accuracy=0.10101009905338287\n",
      "Epoch 185 Train: Cross-entropy=2.3825334442986383, Accuracy=0.13020833333333334\n",
      "Epoch 185 Test: Cross-entropy=2.40401029586792, Accuracy=0.10101009905338287\n",
      "Epoch 186 Train: Cross-entropy=2.3824621438980103, Accuracy=0.13020833333333334\n",
      "Epoch 186 Test: Cross-entropy=2.4039976596832275, Accuracy=0.10101009905338287\n",
      "Epoch 187 Train: Cross-entropy=2.3823910686704846, Accuracy=0.13020833333333334\n",
      "Epoch 187 Test: Cross-entropy=2.403984546661377, Accuracy=0.10101009905338287\n",
      "Epoch 188 Train: Cross-entropy=2.3823201523886786, Accuracy=0.13020833333333334\n",
      "Epoch 188 Test: Cross-entropy=2.4039719104766846, Accuracy=0.10101009905338287\n",
      "Epoch 189 Train: Cross-entropy=2.3822494877709284, Accuracy=0.13020833333333334\n",
      "Epoch 189 Test: Cross-entropy=2.403959035873413, Accuracy=0.10101009905338287\n",
      "Epoch 190 Train: Cross-entropy=2.3821789026260376, Accuracy=0.13020833333333334\n",
      "Epoch 190 Test: Cross-entropy=2.4039466381073, Accuracy=0.10101009905338287\n",
      "Epoch 191 Train: Cross-entropy=2.382108595636156, Accuracy=0.13020833333333334\n",
      "Epoch 191 Test: Cross-entropy=2.4039340019226074, Accuracy=0.10101009905338287\n",
      "Epoch 192 Train: Cross-entropy=2.38203846083747, Accuracy=0.13020833333333334\n",
      "Epoch 192 Test: Cross-entropy=2.403921365737915, Accuracy=0.10101009905338287\n",
      "Epoch 193 Train: Cross-entropy=2.3819684982299805, Accuracy=0.13020833333333334\n",
      "Epoch 193 Test: Cross-entropy=2.4039089679718018, Accuracy=0.10101009905338287\n",
      "Epoch 194 Train: Cross-entropy=2.3818987475501165, Accuracy=0.13020833333333334\n",
      "Epoch 194 Test: Cross-entropy=2.4038968086242676, Accuracy=0.10101009905338287\n",
      "Epoch 195 Train: Cross-entropy=2.381829116079542, Accuracy=0.13020833333333334\n",
      "Epoch 195 Test: Cross-entropy=2.4038846492767334, Accuracy=0.10101009905338287\n",
      "Epoch 196 Train: Cross-entropy=2.3817597495185003, Accuracy=0.13020833333333334\n",
      "Epoch 196 Test: Cross-entropy=2.403872489929199, Accuracy=0.10101009905338287\n",
      "Epoch 197 Train: Cross-entropy=2.3816905286577015, Accuracy=0.13020833333333334\n",
      "Epoch 197 Test: Cross-entropy=2.403860330581665, Accuracy=0.10101009905338287\n",
      "Epoch 198 Train: Cross-entropy=2.381621479988098, Accuracy=0.13020833333333334\n",
      "Epoch 198 Test: Cross-entropy=2.403848648071289, Accuracy=0.10101009905338287\n",
      "Epoch 199 Train: Cross-entropy=2.3815526564915976, Accuracy=0.13020833333333334\n",
      "Epoch 199 Test: Cross-entropy=2.403836727142334, Accuracy=0.10101009905338287\n",
      "Epoch 200 Train: Cross-entropy=2.381484031677246, Accuracy=0.13020833333333334\n",
      "Epoch 200 Test: Cross-entropy=2.4038245677948, Accuracy=0.10101009905338287\n",
      "Epoch 201 Train: Cross-entropy=2.3814155525631375, Accuracy=0.13020833333333334\n",
      "Epoch 201 Test: Cross-entropy=2.403812885284424, Accuracy=0.10101009905338287\n",
      "Epoch 202 Train: Cross-entropy=2.381347232394748, Accuracy=0.13020833333333334\n",
      "Epoch 202 Test: Cross-entropy=2.403801202774048, Accuracy=0.10101009905338287\n",
      "Epoch 203 Train: Cross-entropy=2.3812791109085083, Accuracy=0.13020833333333334\n",
      "Epoch 203 Test: Cross-entropy=2.403789520263672, Accuracy=0.10101009905338287\n",
      "Epoch 204 Train: Cross-entropy=2.3812112145953708, Accuracy=0.1284722222222222\n",
      "Epoch 204 Test: Cross-entropy=2.403778076171875, Accuracy=0.10101009905338287\n",
      "Epoch 205 Train: Cross-entropy=2.38114341100057, Accuracy=0.1284722222222222\n",
      "Epoch 205 Test: Cross-entropy=2.403766632080078, Accuracy=0.10101009905338287\n",
      "Epoch 206 Train: Cross-entropy=2.381075859069824, Accuracy=0.1284722222222222\n",
      "Epoch 206 Test: Cross-entropy=2.4037551879882812, Accuracy=0.10101009905338287\n",
      "Epoch 207 Train: Cross-entropy=2.3810083866119385, Accuracy=0.1284722222222222\n",
      "Epoch 207 Test: Cross-entropy=2.4037437438964844, Accuracy=0.10101009905338287\n",
      "Epoch 208 Train: Cross-entropy=2.380941298272875, Accuracy=0.1284722222222222\n",
      "Epoch 208 Test: Cross-entropy=2.4037325382232666, Accuracy=0.10101009905338287\n",
      "Epoch 209 Train: Cross-entropy=2.3808741834428577, Accuracy=0.1284722222222222\n",
      "Epoch 209 Test: Cross-entropy=2.403721332550049, Accuracy=0.10101009905338287\n",
      "Epoch 210 Train: Cross-entropy=2.380807320276896, Accuracy=0.1284722222222222\n",
      "Epoch 210 Test: Cross-entropy=2.40371036529541, Accuracy=0.10101009905338287\n",
      "Epoch 211 Train: Cross-entropy=2.380740616056654, Accuracy=0.1284722222222222\n",
      "Epoch 211 Test: Cross-entropy=2.4036991596221924, Accuracy=0.10101009905338287\n",
      "Epoch 212 Train: Cross-entropy=2.3806740178002253, Accuracy=0.13020833333333334\n",
      "Epoch 212 Test: Cross-entropy=2.4036879539489746, Accuracy=0.10101009905338287\n",
      "Epoch 213 Train: Cross-entropy=2.3806077506807117, Accuracy=0.13020833333333334\n",
      "Epoch 213 Test: Cross-entropy=2.403676986694336, Accuracy=0.10101009905338287\n",
      "Epoch 214 Train: Cross-entropy=2.380541536543104, Accuracy=0.13020833333333334\n",
      "Epoch 214 Test: Cross-entropy=2.4036662578582764, Accuracy=0.10101009905338287\n",
      "Epoch 215 Train: Cross-entropy=2.3804755210876465, Accuracy=0.13020833333333334\n",
      "Epoch 215 Test: Cross-entropy=2.403655529022217, Accuracy=0.10101009905338287\n",
      "Epoch 216 Train: Cross-entropy=2.3804096778233848, Accuracy=0.13020833333333334\n",
      "Epoch 216 Test: Cross-entropy=2.4036448001861572, Accuracy=0.10101009905338287\n",
      "Epoch 217 Train: Cross-entropy=2.380343967013889, Accuracy=0.13020833333333334\n",
      "Epoch 217 Test: Cross-entropy=2.4036340713500977, Accuracy=0.10101009905338287\n",
      "Epoch 218 Train: Cross-entropy=2.3802784946229725, Accuracy=0.13020833333333334\n",
      "Epoch 218 Test: Cross-entropy=2.403623342514038, Accuracy=0.10101009905338287\n",
      "Epoch 219 Train: Cross-entropy=2.3802131944232516, Accuracy=0.13020833333333334\n",
      "Epoch 219 Test: Cross-entropy=2.4036128520965576, Accuracy=0.10101009905338287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220 Train: Cross-entropy=2.3801479869418674, Accuracy=0.13020833333333334\n",
      "Epoch 220 Test: Cross-entropy=2.4036026000976562, Accuracy=0.10101009905338287\n",
      "Epoch 221 Train: Cross-entropy=2.380083031124539, Accuracy=0.13020833333333334\n",
      "Epoch 221 Test: Cross-entropy=2.403592109680176, Accuracy=0.10101009905338287\n",
      "Epoch 222 Train: Cross-entropy=2.3800181945165, Accuracy=0.13020833333333334\n",
      "Epoch 222 Test: Cross-entropy=2.4035816192626953, Accuracy=0.10101009905338287\n",
      "Epoch 223 Train: Cross-entropy=2.379953490363227, Accuracy=0.13020833333333334\n",
      "Epoch 223 Test: Cross-entropy=2.403571605682373, Accuracy=0.10101009905338287\n",
      "Epoch 224 Train: Cross-entropy=2.3798890246285334, Accuracy=0.13020833333333334\n",
      "Epoch 224 Test: Cross-entropy=2.4035611152648926, Accuracy=0.10101009905338287\n",
      "Epoch 225 Train: Cross-entropy=2.3798247045940824, Accuracy=0.13020833333333334\n",
      "Epoch 225 Test: Cross-entropy=2.4035511016845703, Accuracy=0.10101009905338287\n",
      "Epoch 226 Train: Cross-entropy=2.3797605302598743, Accuracy=0.1284722222222222\n",
      "Epoch 226 Test: Cross-entropy=2.403540849685669, Accuracy=0.10101009905338287\n",
      "Epoch 227 Train: Cross-entropy=2.3796965413623385, Accuracy=0.1284722222222222\n",
      "Epoch 227 Test: Cross-entropy=2.403531074523926, Accuracy=0.10101009905338287\n",
      "Epoch 228 Train: Cross-entropy=2.379632684919569, Accuracy=0.1284722222222222\n",
      "Epoch 228 Test: Cross-entropy=2.4035210609436035, Accuracy=0.10101009905338287\n",
      "Epoch 229 Train: Cross-entropy=2.379569027158949, Accuracy=0.1284722222222222\n",
      "Epoch 229 Test: Cross-entropy=2.4035110473632812, Accuracy=0.10101009905338287\n",
      "Epoch 230 Train: Cross-entropy=2.379505501853095, Accuracy=0.1284722222222222\n",
      "Epoch 230 Test: Cross-entropy=2.403501033782959, Accuracy=0.10101009905338287\n",
      "Epoch 231 Train: Cross-entropy=2.3794420957565308, Accuracy=0.13020833333333334\n",
      "Epoch 231 Test: Cross-entropy=2.403491497039795, Accuracy=0.10101009905338287\n",
      "Epoch 232 Train: Cross-entropy=2.379378901587592, Accuracy=0.13020833333333334\n",
      "Epoch 232 Test: Cross-entropy=2.4034814834594727, Accuracy=0.10101009905338287\n",
      "Epoch 233 Train: Cross-entropy=2.3793158531188965, Accuracy=0.13020833333333334\n",
      "Epoch 233 Test: Cross-entropy=2.4034719467163086, Accuracy=0.10101009905338287\n",
      "Epoch 234 Train: Cross-entropy=2.3792530165778265, Accuracy=0.13194444444444445\n",
      "Epoch 234 Test: Cross-entropy=2.4034624099731445, Accuracy=0.10101009905338287\n",
      "Epoch 235 Train: Cross-entropy=2.3791902462641397, Accuracy=0.13194444444444445\n",
      "Epoch 235 Test: Cross-entropy=2.4034528732299805, Accuracy=0.10101009905338287\n",
      "Epoch 236 Train: Cross-entropy=2.3791277408599854, Accuracy=0.13194444444444445\n",
      "Epoch 236 Test: Cross-entropy=2.4034435749053955, Accuracy=0.10101009905338287\n",
      "Epoch 237 Train: Cross-entropy=2.3790652884377375, Accuracy=0.13368055555555555\n",
      "Epoch 237 Test: Cross-entropy=2.4034340381622314, Accuracy=0.10101009905338287\n",
      "Epoch 238 Train: Cross-entropy=2.379003087679545, Accuracy=0.13368055555555555\n",
      "Epoch 238 Test: Cross-entropy=2.4034245014190674, Accuracy=0.10101009905338287\n",
      "Epoch 239 Train: Cross-entropy=2.3789409399032593, Accuracy=0.13368055555555555\n",
      "Epoch 239 Test: Cross-entropy=2.4034154415130615, Accuracy=0.10101009905338287\n",
      "Epoch 240 Train: Cross-entropy=2.378879017300076, Accuracy=0.13368055555555555\n",
      "Epoch 240 Test: Cross-entropy=2.4034061431884766, Accuracy=0.10101009905338287\n",
      "Epoch 241 Train: Cross-entropy=2.3788172403971353, Accuracy=0.13368055555555555\n",
      "Epoch 241 Test: Cross-entropy=2.4033968448638916, Accuracy=0.10101009905338287\n",
      "Epoch 242 Train: Cross-entropy=2.378755662176344, Accuracy=0.13368055555555555\n",
      "Epoch 242 Test: Cross-entropy=2.4033877849578857, Accuracy=0.10101009905338287\n",
      "Epoch 243 Train: Cross-entropy=2.3786941634284124, Accuracy=0.13368055555555555\n",
      "Epoch 243 Test: Cross-entropy=2.403378486633301, Accuracy=0.10101009905338287\n",
      "Epoch 244 Train: Cross-entropy=2.3786328766081066, Accuracy=0.13368055555555555\n",
      "Epoch 244 Test: Cross-entropy=2.403369903564453, Accuracy=0.10101009905338287\n",
      "Epoch 245 Train: Cross-entropy=2.3785716692606607, Accuracy=0.13541666666666666\n",
      "Epoch 245 Test: Cross-entropy=2.403360605239868, Accuracy=0.10101009905338287\n",
      "Epoch 246 Train: Cross-entropy=2.3785106473498874, Accuracy=0.13541666666666666\n",
      "Epoch 246 Test: Cross-entropy=2.4033520221710205, Accuracy=0.10101009905338287\n",
      "Epoch 247 Train: Cross-entropy=2.3784498241212635, Accuracy=0.13541666666666666\n",
      "Epoch 247 Test: Cross-entropy=2.4033432006835938, Accuracy=0.10101009905338287\n",
      "Epoch 248 Train: Cross-entropy=2.3783890671200223, Accuracy=0.1371527777777778\n",
      "Epoch 248 Test: Cross-entropy=2.403334140777588, Accuracy=0.10101009905338287\n",
      "Epoch 249 Train: Cross-entropy=2.378328482309977, Accuracy=0.1371527777777778\n",
      "Epoch 249 Test: Cross-entropy=2.4033255577087402, Accuracy=0.10101009905338287\n",
      "Epoch 250 Train: Cross-entropy=2.378268109427558, Accuracy=0.1371527777777778\n",
      "Epoch 250 Test: Cross-entropy=2.4033169746398926, Accuracy=0.10101009905338287\n",
      "Epoch 251 Train: Cross-entropy=2.3782078292634754, Accuracy=0.1371527777777778\n",
      "Epoch 251 Test: Cross-entropy=2.403308391571045, Accuracy=0.10101009905338287\n",
      "Epoch 252 Train: Cross-entropy=2.3781477080451117, Accuracy=0.1371527777777778\n",
      "Epoch 252 Test: Cross-entropy=2.403299570083618, Accuracy=0.10101009905338287\n",
      "Epoch 253 Train: Cross-entropy=2.3780877457724676, Accuracy=0.1388888888888889\n",
      "Epoch 253 Test: Cross-entropy=2.4032912254333496, Accuracy=0.10101009905338287\n",
      "Epoch 254 Train: Cross-entropy=2.3780278894636364, Accuracy=0.1388888888888889\n",
      "Epoch 254 Test: Cross-entropy=2.403282642364502, Accuracy=0.10101009905338287\n",
      "Epoch 255 Train: Cross-entropy=2.3779682715733848, Accuracy=0.1388888888888889\n",
      "Epoch 255 Test: Cross-entropy=2.4032742977142334, Accuracy=0.10101009905338287\n",
      "Epoch 256 Train: Cross-entropy=2.3779086934195623, Accuracy=0.1388888888888889\n",
      "Epoch 256 Test: Cross-entropy=2.4032657146453857, Accuracy=0.10101009905338287\n",
      "Epoch 257 Train: Cross-entropy=2.377849300702413, Accuracy=0.140625\n",
      "Epoch 257 Test: Cross-entropy=2.4032576084136963, Accuracy=0.10101009905338287\n",
      "Epoch 258 Train: Cross-entropy=2.377790093421936, Accuracy=0.1423611111111111\n",
      "Epoch 258 Test: Cross-entropy=2.403249502182007, Accuracy=0.10101009905338287\n",
      "Epoch 259 Train: Cross-entropy=2.3777310185962253, Accuracy=0.1423611111111111\n",
      "Epoch 259 Test: Cross-entropy=2.4032413959503174, Accuracy=0.10101009905338287\n",
      "Epoch 260 Train: Cross-entropy=2.377671996752421, Accuracy=0.1423611111111111\n",
      "Epoch 260 Test: Cross-entropy=2.4032328128814697, Accuracy=0.10101009905338287\n",
      "Epoch 261 Train: Cross-entropy=2.377613253063626, Accuracy=0.140625\n",
      "Epoch 261 Test: Cross-entropy=2.4032249450683594, Accuracy=0.10101009905338287\n",
      "Epoch 262 Train: Cross-entropy=2.3775545756022134, Accuracy=0.140625\n",
      "Epoch 262 Test: Cross-entropy=2.40321683883667, Accuracy=0.10101009905338287\n",
      "Epoch 263 Train: Cross-entropy=2.377496110068427, Accuracy=0.140625\n",
      "Epoch 263 Test: Cross-entropy=2.4032089710235596, Accuracy=0.10101009905338287\n",
      "Epoch 264 Train: Cross-entropy=2.3774376710255942, Accuracy=0.140625\n",
      "Epoch 264 Test: Cross-entropy=2.403201103210449, Accuracy=0.10101009905338287\n",
      "Epoch 265 Train: Cross-entropy=2.377379443910387, Accuracy=0.140625\n",
      "Epoch 265 Test: Cross-entropy=2.403193235397339, Accuracy=0.09595959633588791\n",
      "Epoch 266 Train: Cross-entropy=2.3773212697770862, Accuracy=0.140625\n",
      "Epoch 266 Test: Cross-entropy=2.4031853675842285, Accuracy=0.09595959633588791\n",
      "Epoch 267 Train: Cross-entropy=2.377263347307841, Accuracy=0.140625\n",
      "Epoch 267 Test: Cross-entropy=2.403177499771118, Accuracy=0.09595959633588791\n",
      "Epoch 268 Train: Cross-entropy=2.377205583784315, Accuracy=0.140625\n",
      "Epoch 268 Test: Cross-entropy=2.403169631958008, Accuracy=0.10101009905338287\n",
      "Epoch 269 Train: Cross-entropy=2.3771478599972196, Accuracy=0.140625\n",
      "Epoch 269 Test: Cross-entropy=2.4031622409820557, Accuracy=0.10101009905338287\n",
      "Epoch 270 Train: Cross-entropy=2.3770903613832264, Accuracy=0.140625\n",
      "Epoch 270 Test: Cross-entropy=2.4031543731689453, Accuracy=0.10101009905338287\n",
      "Epoch 271 Train: Cross-entropy=2.3770329687330456, Accuracy=0.140625\n",
      "Epoch 271 Test: Cross-entropy=2.403146982192993, Accuracy=0.10101009905338287\n",
      "Epoch 272 Train: Cross-entropy=2.376975668801202, Accuracy=0.140625\n",
      "Epoch 272 Test: Cross-entropy=2.403139352798462, Accuracy=0.10101009905338287\n",
      "Epoch 273 Train: Cross-entropy=2.3769185543060303, Accuracy=0.140625\n",
      "Epoch 273 Test: Cross-entropy=2.4031319618225098, Accuracy=0.10101009905338287\n",
      "Epoch 274 Train: Cross-entropy=2.376861479547289, Accuracy=0.140625\n",
      "Epoch 274 Test: Cross-entropy=2.4031243324279785, Accuracy=0.10101009905338287\n",
      "Epoch 275 Train: Cross-entropy=2.376804749170939, Accuracy=0.140625\n",
      "Epoch 275 Test: Cross-entropy=2.4031171798706055, Accuracy=0.10101009905338287\n",
      "Epoch 276 Train: Cross-entropy=2.3767480187945895, Accuracy=0.1423611111111111\n",
      "Epoch 276 Test: Cross-entropy=2.4031097888946533, Accuracy=0.10101009905338287\n",
      "Epoch 277 Train: Cross-entropy=2.3766914473639593, Accuracy=0.1440972222222222\n",
      "Epoch 277 Test: Cross-entropy=2.4031026363372803, Accuracy=0.10101009905338287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278 Train: Cross-entropy=2.3766349289152355, Accuracy=0.1440972222222222\n",
      "Epoch 278 Test: Cross-entropy=2.403095245361328, Accuracy=0.10101009905338287\n",
      "Epoch 279 Train: Cross-entropy=2.376578582657708, Accuracy=0.1440972222222222\n",
      "Epoch 279 Test: Cross-entropy=2.403088092803955, Accuracy=0.10101009905338287\n",
      "Epoch 280 Train: Cross-entropy=2.3765224085913763, Accuracy=0.1440972222222222\n",
      "Epoch 280 Test: Cross-entropy=2.403080701828003, Accuracy=0.10101009905338287\n",
      "Epoch 281 Train: Cross-entropy=2.3764663404888577, Accuracy=0.1440972222222222\n",
      "Epoch 281 Test: Cross-entropy=2.403073787689209, Accuracy=0.10101009905338287\n",
      "Epoch 282 Train: Cross-entropy=2.3764104975594416, Accuracy=0.1440972222222222\n",
      "Epoch 282 Test: Cross-entropy=2.403066635131836, Accuracy=0.10101009905338287\n",
      "Epoch 283 Train: Cross-entropy=2.3763546811209784, Accuracy=0.1440972222222222\n",
      "Epoch 283 Test: Cross-entropy=2.403059482574463, Accuracy=0.10101009905338287\n",
      "Epoch 284 Train: Cross-entropy=2.3762989971372814, Accuracy=0.14583333333333334\n",
      "Epoch 284 Test: Cross-entropy=2.403052806854248, Accuracy=0.10101009905338287\n",
      "Epoch 285 Train: Cross-entropy=2.3762435250812106, Accuracy=0.14583333333333334\n",
      "Epoch 285 Test: Cross-entropy=2.403045892715454, Accuracy=0.10101009905338287\n",
      "Epoch 286 Train: Cross-entropy=2.376188119252523, Accuracy=0.14583333333333334\n",
      "Epoch 286 Test: Cross-entropy=2.40303897857666, Accuracy=0.10101009905338287\n",
      "Epoch 287 Train: Cross-entropy=2.3761328988605075, Accuracy=0.14583333333333334\n",
      "Epoch 287 Test: Cross-entropy=2.403032064437866, Accuracy=0.10101009905338287\n",
      "Epoch 288 Train: Cross-entropy=2.3760776917139688, Accuracy=0.14583333333333334\n",
      "Epoch 288 Test: Cross-entropy=2.4030253887176514, Accuracy=0.10101009905338287\n",
      "Epoch 289 Train: Cross-entropy=2.3760226832495794, Accuracy=0.14583333333333334\n",
      "Epoch 289 Test: Cross-entropy=2.4030187129974365, Accuracy=0.10101009905338287\n",
      "Epoch 290 Train: Cross-entropy=2.3759678072399564, Accuracy=0.14583333333333334\n",
      "Epoch 290 Test: Cross-entropy=2.4030120372772217, Accuracy=0.10101009905338287\n",
      "Epoch 291 Train: Cross-entropy=2.3759131034215293, Accuracy=0.14583333333333334\n",
      "Epoch 291 Test: Cross-entropy=2.403005361557007, Accuracy=0.10101009905338287\n",
      "Epoch 292 Train: Cross-entropy=2.375858465830485, Accuracy=0.1440972222222222\n",
      "Epoch 292 Test: Cross-entropy=2.402998447418213, Accuracy=0.10101009905338287\n",
      "Epoch 293 Train: Cross-entropy=2.3758039342032538, Accuracy=0.1423611111111111\n",
      "Epoch 293 Test: Cross-entropy=2.4029922485351562, Accuracy=0.10101009905338287\n",
      "Epoch 294 Train: Cross-entropy=2.3757495880126953, Accuracy=0.1423611111111111\n",
      "Epoch 294 Test: Cross-entropy=2.4029855728149414, Accuracy=0.10101009905338287\n",
      "Epoch 295 Train: Cross-entropy=2.375695334540473, Accuracy=0.1423611111111111\n",
      "Epoch 295 Test: Cross-entropy=2.4029791355133057, Accuracy=0.10101009905338287\n",
      "Epoch 296 Train: Cross-entropy=2.3756412267684937, Accuracy=0.1423611111111111\n",
      "Epoch 296 Test: Cross-entropy=2.402972936630249, Accuracy=0.10101009905338287\n",
      "Epoch 297 Train: Cross-entropy=2.3755872514512806, Accuracy=0.1423611111111111\n",
      "Epoch 297 Test: Cross-entropy=2.4029664993286133, Accuracy=0.10101009905338287\n",
      "Epoch 298 Train: Cross-entropy=2.3755333688524036, Accuracy=0.1423611111111111\n",
      "Epoch 298 Test: Cross-entropy=2.4029600620269775, Accuracy=0.10101009905338287\n",
      "Epoch 299 Train: Cross-entropy=2.3754796187082925, Accuracy=0.1423611111111111\n",
      "Epoch 299 Test: Cross-entropy=2.402953863143921, Accuracy=0.10101009905338287\n"
     ]
    }
   ],
   "source": [
    "hidden_size = parameters_[\"hidden_size\"]\n",
    "lr = parameters_[\"learning_rate\"]\n",
    "momentum = parameters_[\"momentum\"]\n",
    "weight_decay = parameters_[\"weight_decay\"]\n",
    " \n",
    "batch_size = 32\n",
    "\n",
    "batches_per_epoch = len(x_train) // batch_size\n",
    "model = Multiclass(input_size, hidden_size, output_size)\n",
    "\n",
    "final_model_cross = []\n",
    "final_model_acc = []\n",
    "\n",
    "x_train = torch.cat((x_train, x_valid), dim=0)\n",
    "y_train = torch.cat((y_train, y_valid), dim=0)\n",
    "\n",
    "CROSS_train = []\n",
    "CROSS_test = []\n",
    "\n",
    "ACC_train = []\n",
    "ACC_test = []\n",
    "\n",
    "n_epochs = 300\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay = weight_decay, momentum = momentum)\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    model.train()\n",
    "    #with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "        #bar.set_description(f\"Epoch {epoch}\")\n",
    "    for i in range(batches_per_epoch):\n",
    "            start = i * batch_size\n",
    "            X_batch = x_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "\n",
    "                # forward \n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "                # backward \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "                            # update weights\n",
    "            optimizer.step()\n",
    "            acc = (torch.argmax(y_pred, 1) == torch.argmax(y_batch, 1)).float().mean()\n",
    "            epoch_loss.append(float(loss))\n",
    "            epoch_acc.append(float(acc))\n",
    "            #bar.set_postfix( loss=float(loss), acc=float(acc))\n",
    "            # set model in evaluation mode and run through the test set\n",
    "                    \n",
    "            model.eval()\n",
    "            y_pred = model(x_test)\n",
    "            ce = loss_fn(y_pred, y_test)\n",
    "            acc = (torch.argmax(y_pred, 1) == torch.argmax(y_test, 1)).float().mean()\n",
    "\n",
    "            ce = float(ce)\n",
    "            acc = float(acc)\n",
    "                    \n",
    "    CROSS_train.append(np.mean(epoch_loss))\n",
    "    ACC_train.append(np.mean(epoch_acc))\n",
    "                    \n",
    "    CROSS_test.append(ce)\n",
    "    ACC_test.append(acc)\n",
    "                    \n",
    "    if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    print(f\"Epoch {epoch} Train: Cross-entropy={np.mean(epoch_loss)}, Accuracy={np.mean(epoch_acc)}\")\n",
    "    print(f\"Epoch {epoch} Test: Cross-entropy={ce}, Accuracy={acc}\")\n",
    "    final_loss.append(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e0ec65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(CROSS_train) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(epochs, CROSS_train, 'b', label='Train Cross-Entropy')\n",
    "ax.plot(epochs, CROSS_test, 'r', label='Test Cross-Entropy')\n",
    "plt.title('Cross-Entropy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Value')\n",
    "plt.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ee9666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(ACC_train) + 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "ax.plot(epochs, ACC_train, 'b', label='Train Accuracy')\n",
    "ax.plot(epochs, ACC_test, 'r', label='Test Accuracy')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e007c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro(CROSS) do teste:  2.402953863143921\n",
      "Acurácia do teste:  0.10101009905338287\n"
     ]
    }
   ],
   "source": [
    "# utilizar o treino\n",
    "mse = nn.CrossEntropyLoss()\n",
    "\n",
    "test_outputs = model(x_test)\n",
    "test_loss = mse(test_outputs, y_test).item()\n",
    "\n",
    "acc = (torch.argmax(test_outputs, 1) == torch.argmax(y_test, 1)).float().mean()\n",
    "\n",
    "print(\"Erro(CROSS) do teste: \", test_loss)\n",
    "print(\"Acurácia do teste: \", acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
